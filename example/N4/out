21406
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1963],
             [112.1963],
             [112.1960],
             [112.1960]],

            [[112.3167],
             [112.3097],
             [112.3165],
             [112.3165]],

            [[112.2228],
             [112.2270],
             [112.2206],
             [112.2295]],

            ...,

            [[112.1959],
             [112.1959],
             [112.1959],
             [112.1959]],

            [[112.3165],
             [112.3153],
             [112.3163],
             [112.3145]],

            [[112.1961],
             [112.1962],
             [112.1965],
             [112.1965]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7846, 449.2595, 448.8998,  ..., 448.7835, 449.2627, 448.7854],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7846, 449.2595, 448.8998,  ..., 448.7835, 449.2627, 448.7854],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7972],
             [111.7967],
             [111.7349],
             [111.7349]],

            [[110.9512],
             [110.9512],
             [110.9319],
             [110.9319]],

            [[111.7623],
             [111.7623],
             [111.7608],
             [111.7608]],

            ...,

            [[111.8339],
             [111.8458],
             [111.8369],
             [111.8441]],

            [[111.2773],
             [111.1460],
             [111.1209],
             [111.3060]],

            [[110.9408],
             [110.9495],
             [110.9304],
             [110.9600]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.0638, 443.7662, 447.0462,  ..., 447.3607, 444.8503, 443.7807],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.0638, 443.7662, 447.0462,  ..., 447.3607, 444.8503, 443.7807],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[109.5810],
             [109.6118],
             [109.5847],
             [109.5847]],

            [[111.5329],
             [111.5310],
             [111.5330],
             [111.5307]],

            [[109.7625],
             [109.6739],
             [109.6131],
             [109.9916]],

            ...,

            [[110.9155],
             [110.9288],
             [111.0077],
             [110.8300]],

            [[109.6064],
             [109.6326],
             [109.5915],
             [109.5915]],

            [[109.5856],
             [109.5856],
             [109.5711],
             [109.5711]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([438.3622, 446.1276, 439.0410,  ..., 443.6820, 438.4219, 438.3135],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([438.3622, 446.1276, 439.0410,  ..., 443.6820, 438.4219, 438.3135],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.1454],
             [111.0862],
             [111.1500],
             [111.0855]],

            [[111.5197],
             [111.5197],
             [111.5197],
             [111.5197]],

            [[111.4995],
             [111.4852],
             [111.4675],
             [111.4881]],

            ...,

            [[111.4802],
             [111.4798],
             [111.4525],
             [111.4886]],

            [[111.1102],
             [111.1483],
             [111.1072],
             [111.1108]],

            [[111.0895],
             [111.0895],
             [111.0913],
             [111.0913]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.4671, 446.0787, 445.9403,  ..., 445.9011, 444.4766, 444.3615],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.4671, 446.0787, 445.9403,  ..., 445.9011, 444.4766, 444.3615],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.8357],
             [112.8422],
             [112.8367],
             [112.8367]],

            [[112.7291],
             [112.7598],
             [112.7506],
             [112.8189]],

            [[112.8528],
             [112.8544],
             [112.8496],
             [112.8504]],

            ...,

            [[112.5421],
             [112.5205],
             [112.6403],
             [112.7264]],

            [[112.8619],
             [112.8616],
             [112.8619],
             [112.8616]],

            [[112.6901],
             [112.8240],
             [112.6979],
             [112.6910]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([451.3513, 451.0584, 451.4073,  ..., 450.4292, 451.4470, 450.9030],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([451.3513, 451.0584, 451.4073,  ..., 450.4292, 451.4470, 450.9030],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.8444],
             [113.8444],
             [113.9497],
             [113.9497]],

            [[113.7952],
             [114.0269],
             [113.6404],
             [113.8346]],

            [[111.6271],
             [111.6271],
             [111.6271],
             [111.6271]],

            ...,

            [[111.6416],
             [111.6626],
             [111.6416],
             [111.6626]],

            [[114.0487],
             [114.1356],
             [114.0312],
             [114.0456]],

            [[111.6271],
             [111.6271],
             [111.6271],
             [111.6271]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([455.5881, 455.2971, 446.5085,  ..., 446.6085, 456.2612, 446.5085],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([455.5881, 455.2971, 446.5085,  ..., 446.6085, 456.2612, 446.5085],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[114.3848],
             [114.3852],
             [114.4392],
             [114.3835]],

            [[114.4534],
             [114.4535],
             [114.4532],
             [114.4532]],

            [[111.9826],
             [112.3648],
             [111.9724],
             [112.3865]],

            ...,

            [[113.2162],
             [113.8812],
             [113.1472],
             [113.9455]],

            [[114.4434],
             [114.4434],
             [114.4450],
             [114.4450]],

            [[114.4544],
             [114.4544],
             [114.4542],
             [114.4542]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([457.5928, 457.8133, 448.7062,  ..., 454.1902, 457.7768, 457.8173],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([457.5928, 457.8133, 448.7062,  ..., 454.1902, 457.7768, 457.8173],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[114.1192],
             [114.1239],
             [114.1165],
             [114.1578]],

            [[114.1469],
             [114.1451],
             [114.1493],
             [114.1529]],

            [[114.1125],
             [114.0047],
             [114.0441],
             [114.0441]],

            ...,

            [[112.7320],
             [113.3834],
             [112.8594],
             [112.9078]],

            [[114.0740],
             [114.0740],
             [114.1443],
             [114.0772]],

            [[111.7554],
             [111.7554],
             [111.7554],
             [111.7554]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([456.5175, 456.5942, 456.2054,  ..., 451.8826, 456.3694, 447.0215],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([456.5175, 456.5942, 456.2054,  ..., 451.8826, 456.3694, 447.0215],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.2231],
             [113.4640],
             [113.2374],
             [113.4470]],

            [[111.8294],
             [111.8294],
             [111.8294],
             [111.8294]],

            [[113.7514],
             [113.7640],
             [113.7228],
             [113.7228]],

            ...,

            [[112.3524],
             [112.3524],
             [112.8052],
             [112.8052]],

            [[111.8306],
             [111.8303],
             [111.8308],
             [111.8311]],

            [[112.5558],
             [112.9189],
             [112.3809],
             [112.6372]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([453.3715, 447.3175, 454.9609,  ..., 450.3152, 447.3228, 450.4929],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([453.3715, 447.3175, 454.9609,  ..., 450.3152, 447.3228, 450.4929],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.3732],
             [113.3753],
             [113.3764],
             [113.3805]],

            [[113.3807],
             [113.3866],
             [113.3789],
             [113.3731]],

            [[113.0835],
             [113.0932],
             [113.2775],
             [113.1660]],

            ...,

            [[112.0854],
             [112.0794],
             [112.1065],
             [112.2255]],

            [[113.3466],
             [113.3659],
             [113.3371],
             [113.3378]],

            [[111.9889],
             [112.0039],
             [111.9697],
             [112.0524]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([453.5053, 453.5193, 452.6203,  ..., 448.4968, 453.3875, 448.0149],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([453.5053, 453.5193, 452.6203,  ..., 448.4968, 453.3875, 448.0149],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9444],
             [111.9447],
             [111.9445],
             [111.9445]],

            [[111.9444],
             [111.9443],
             [111.9443],
             [111.9444]],

            [[111.9441],
             [111.9441],
             [111.9441],
             [111.9441]],

            ...,

            [[111.9494],
             [111.9542],
             [111.9514],
             [111.9514]],

            [[111.9472],
             [111.9457],
             [111.9458],
             [111.9473]],

            [[112.9762],
             [113.0345],
             [113.0334],
             [112.9558]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7781, 447.7774, 447.7764,  ..., 447.8063, 447.7860, 452.0000],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7781, 447.7774, 447.7764,  ..., 447.8063, 447.7860, 452.0000],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.7330],
             [112.7592],
             [112.7530],
             [112.6161]],

            [[112.7298],
             [112.7593],
             [112.7621],
             [112.7506]],

            [[112.7378],
             [112.7378],
             [112.7604],
             [112.7604]],

            ...,

            [[112.0071],
             [112.0169],
             [112.0105],
             [112.0105]],

            [[111.9930],
             [111.9930],
             [111.9930],
             [111.9930]],

            [[112.0122],
             [112.0223],
             [112.0212],
             [112.0212]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.8614, 451.0018, 450.9964,  ..., 448.0450, 447.9719, 448.0770],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.8614, 451.0018, 450.9964,  ..., 448.0450, 447.9719, 448.0770],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6423],
             [112.5913],
             [112.6389],
             [112.6556]],

            [[112.5677],
             [112.5882],
             [112.6447],
             [112.6588]],

            [[112.6371],
             [112.6592],
             [112.6494],
             [112.6529]],

            ...,

            [[112.0326],
             [112.0341],
             [112.0332],
             [112.0332]],

            [[112.0300],
             [112.0300],
             [112.0300],
             [112.0300]],

            [[112.0301],
             [112.0301],
             [112.0301],
             [112.0301]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.5281, 450.4594, 450.5987,  ..., 448.1331, 448.1200, 448.1202],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.5281, 450.4594, 450.5987,  ..., 448.1331, 448.1200, 448.1202],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0850],
             [112.0850],
             [112.0962],
             [112.0962]],

            [[112.0607],
             [112.0607],
             [112.0608],
             [112.0608]],

            [[112.6097],
             [112.6097],
             [112.6167],
             [112.6167]],

            ...,

            [[112.6258],
             [112.6233],
             [112.6195],
             [112.6195]],

            [[112.0985],
             [112.1128],
             [112.0992],
             [112.1161]],

            [[112.6196],
             [112.6196],
             [112.6235],
             [112.6235]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3622, 448.2429, 450.4529,  ..., 450.4881, 448.4266, 450.4862],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3622, 448.2429, 450.4529,  ..., 450.4881, 448.4266, 450.4862],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0320],
             [112.0320],
             [112.0320],
             [112.0318]],

            [[112.6000],
             [112.6040],
             [112.6069],
             [112.6069]],

            [[112.6284],
             [112.6097],
             [112.6064],
             [112.6290]],

            ...,

            [[112.6062],
             [112.6051],
             [112.6062],
             [112.6062]],

            [[112.6065],
             [112.6020],
             [112.6056],
             [112.6046]],

            [[112.7245],
             [112.7301],
             [112.7217],
             [112.7301]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1279, 450.4177, 450.4735,  ..., 450.4237, 450.4186, 450.9064],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1279, 450.4177, 450.4735,  ..., 450.4237, 450.4186, 450.9064],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9607],
             [111.9607],
             [111.9607],
             [111.9607]],

            [[111.9673],
             [111.9689],
             [111.9673],
             [111.9688]],

            [[112.3619],
             [112.3320],
             [112.2999],
             [112.3036]],

            ...,

            [[112.4195],
             [112.4991],
             [112.4973],
             [112.4722]],

            [[111.9613],
             [111.9613],
             [111.9613],
             [111.9613]],

            [[112.0096],
             [112.0096],
             [112.0078],
             [112.0078]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8427, 447.8723, 449.2973,  ..., 449.8881, 447.8452, 448.0347],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8427, 447.8723, 449.2973,  ..., 449.8881, 447.8452, 448.0347],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5311],
             [112.5311],
             [112.4025],
             [112.4025]],

            [[111.9393],
             [111.9393],
             [111.9484],
             [111.9484]],

            [[112.6037],
             [112.6124],
             [112.6029],
             [112.6014]],

            ...,

            [[112.5465],
             [112.5907],
             [112.5651],
             [112.5528]],

            [[112.2709],
             [112.3293],
             [112.3326],
             [112.2782]],

            [[112.5981],
             [112.5552],
             [112.6082],
             [112.5895]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.8673, 447.7755, 450.4205,  ..., 450.2550, 449.2109, 450.3510],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.8673, 447.7755, 450.4205,  ..., 450.2550, 449.2109, 450.3510],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5686],
             [112.5686],
             [112.5769],
             [112.5769]],

            [[112.5422],
             [112.5737],
             [112.5570],
             [112.5539]],

            [[112.5626],
             [112.5741],
             [112.5741],
             [112.5709]],

            ...,

            [[112.5518],
             [112.4982],
             [112.5077],
             [112.5077]],

            [[112.2694],
             [112.2694],
             [112.2919],
             [112.2919]],

            [[112.5568],
             [112.5756],
             [112.5389],
             [112.5357]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.2909, 450.2268, 450.2817,  ..., 450.0653, 449.1225, 450.2071],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.2909, 450.2268, 450.2817,  ..., 450.0653, 449.1225, 450.2071],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9509e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.4408],
             [112.3575],
             [112.4367],
             [112.4567]],

            [[111.7187],
             [111.7187],
             [111.7188],
             [111.7192]],

            [[111.7200],
             [111.7209],
             [111.7195],
             [111.7196]],

            ...,

            [[112.4622],
             [112.4594],
             [112.4699],
             [112.4699]],

            [[112.4743],
             [112.4673],
             [112.4618],
             [112.4618]],

            [[112.4658],
             [112.4473],
             [112.4589],
             [112.4550]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.6917, 446.8754, 446.8799,  ..., 449.8614, 449.8652, 449.8270],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.6917, 446.8754, 446.8799,  ..., 449.8614, 449.8652, 449.8270],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7218],
             [111.7222],
             [111.7205],
             [111.7204]],

            [[112.4268],
             [112.4437],
             [112.4722],
             [112.4126]],

            [[112.4755],
             [112.4713],
             [112.4759],
             [112.4716]],

            ...,

            [[111.7149],
             [111.7149],
             [111.7149],
             [111.7149]],

            [[111.7149],
             [111.7149],
             [111.7149],
             [111.7149]],

            [[112.4687],
             [112.4049],
             [112.4245],
             [112.3293]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.8849, 449.7554, 449.8943,  ..., 446.8597, 446.8596, 449.6273],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.8849, 449.7554, 449.8943,  ..., 446.8597, 446.8596, 449.6273],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7157],
             [111.7157],
             [111.7157],
             [111.7157]],

            [[111.7163],
             [111.7163],
             [111.7164],
             [111.7164]],

            [[111.7149],
             [111.7149],
             [111.7149],
             [111.7149]],

            ...,

            [[111.9032],
             [111.9032],
             [111.9076],
             [111.9076]],

            [[111.8265],
             [111.7900],
             [111.7942],
             [111.8223]],

            [[111.9945],
             [111.8885],
             [111.9679],
             [111.8742]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.8628, 446.8654, 446.8596, 449.8468, 449.5451, 446.8612, 447.9290,
            446.8600, 449.5640, 448.0249, 449.3476, 446.8596, 449.8699, 449.8840,
            449.8130, 446.9010, 449.7539, 447.1428, 446.8631, 449.8918, 446.8596,
            446.8603, 446.8597, 448.8551, 447.3861, 446.8606, 448.7182, 446.8691,
            446.8603, 446.8815, 446.8596, 449.8539, 446.8737, 449.6297, 449.5019,
            449.8433, 449.8706, 447.7649, 446.8689, 448.8953, 449.0516, 446.9388,
            449.8526, 449.8779, 449.6790, 449.3336, 449.7576, 446.8620, 449.7553,
            449.6544, 449.6302, 449.8400, 449.4111, 449.8077, 446.8608, 449.6808,
            449.5698, 448.7319, 449.9032, 449.5900, 449.7001, 446.8610, 449.6555,
            449.7825, 446.8625, 449.7638, 449.8189, 449.8458, 448.2717, 449.6101,
            449.6031, 449.8265, 449.2260, 449.7451, 449.4180, 449.4681, 449.8410,
            447.1088, 449.6860, 446.8599, 449.7085, 446.8596, 449.2444, 449.0189,
            446.8723, 446.8600, 449.5503, 447.2893, 446.8596, 449.8821, 449.8529,
            448.7897, 448.9785, 449.5816, 449.8278, 449.8076, 449.8975, 446.8624,
            449.8176, 447.2605, 449.6134, 446.8609, 449.7094, 449.7990, 449.7393,
            447.9557, 446.9818, 449.8732, 449.6709, 449.8872, 449.5377, 446.8817,
            449.3903, 446.8596, 448.6965, 446.8979, 446.8597, 449.5008, 448.8235,
            446.8596, 449.8301, 446.8599, 449.7865, 449.8483, 446.8602, 449.0695,
            446.8621, 449.8903, 449.8920, 449.5473, 446.8596, 449.7195, 446.8596,
            449.8461, 449.7791, 447.0074, 446.8600, 448.0298, 449.8059, 446.8596,
            446.8608, 449.6872, 449.8659, 449.5670, 446.9612, 449.8324, 449.1782,
            449.2252, 448.7523, 449.6627, 449.2888, 446.8596, 446.8611, 449.8165,
            447.6402, 449.9049, 447.1530, 446.9153, 446.8739, 449.6802, 449.6605,
            446.9608, 449.6878, 448.4012, 449.6827, 449.8521, 449.8330, 448.9286,
            449.5185, 447.6248, 446.8596, 449.3836, 449.5737, 447.9455, 449.9058,
            449.8696, 449.6913, 449.8873, 449.6291, 446.9474, 446.8603, 449.8371,
            446.8596, 448.5903, 446.8596, 446.8645, 449.4439, 449.0163, 446.8599,
            449.5090, 446.8596, 449.8694, 446.8735, 449.5464, 449.4534, 449.3254,
            446.8597, 449.6385, 449.2074, 449.8652, 449.8942, 446.8597, 448.7767,
            446.8662, 446.8597, 446.8596, 449.8633, 446.8598, 449.0706, 446.9786,
            446.8596, 447.2741, 446.8599, 449.8959, 449.7866, 446.8770, 449.8104,
            446.8628, 448.4222, 449.4680, 449.5001, 449.8755, 449.6378, 446.8752,
            449.8365, 449.3479, 449.3491, 449.8997, 446.9290, 447.8775, 446.8853,
            449.8815, 449.7048, 449.7836, 449.5205, 447.8786, 449.5924, 447.1370,
            446.8596, 447.7126, 449.7090, 449.7184, 449.8374, 448.1354, 449.7032,
            449.5132, 449.8274, 446.8629, 446.8600, 449.8672, 449.5503, 449.4494,
            449.8732, 446.8596, 449.7961, 449.6882, 446.8596, 449.8612, 447.7914,
            449.0989, 446.8596, 449.7282, 446.8596, 447.5939, 446.8611, 449.8918,
            449.8646, 449.8842, 449.5364, 449.8752, 449.6417, 446.8618, 449.4378,
            446.8712, 447.0554, 448.7031, 449.3630, 448.9288, 449.6819, 449.7271,
            446.8625, 446.8596, 449.9005, 446.8739, 449.4376, 448.0975, 449.8089,
            449.6770, 446.8599, 448.1116, 449.8746, 449.8407, 446.8596, 449.3342,
            447.7196, 446.9590, 446.8597, 446.8638, 446.8616, 449.6432, 449.5849,
            449.8904, 449.3612, 449.6381, 446.8598, 449.8430, 449.5943, 446.8678,
            449.0771, 449.8739, 449.8209, 449.1134, 449.4841, 446.8617, 449.5458,
            449.3418, 449.8592, 449.6725, 448.3611, 446.8597, 449.6134, 446.8743,
            446.8950, 449.8165, 449.8491, 449.8185, 449.2208, 449.7083, 446.8596,
            446.8596, 449.5498, 449.4310, 449.7854, 449.7494, 449.8788, 446.8597,
            446.8631, 449.8345, 446.8761, 446.8960, 446.8915, 446.8596, 446.9234,
            446.8837, 449.9046, 449.7710, 449.8964, 449.2910, 448.3422, 449.7759,
            446.8600, 448.6964, 449.4311, 449.7657, 449.6167, 446.8598, 446.9678,
            449.8438, 449.3474, 447.4068, 449.3524, 449.8561, 447.8972, 448.4556,
            446.8596, 449.8438, 448.9664, 449.6340, 446.8725, 446.9573, 447.0226,
            446.8597, 449.8481, 446.8818, 446.8642, 449.6362, 449.7910, 446.8618,
            449.8012, 446.8641, 446.8597, 446.8709, 448.9532, 446.9127, 446.8597,
            446.9008, 446.8640, 448.2085, 447.8836, 447.8143, 449.8629, 449.3076,
            449.8835, 449.0803, 447.0019, 449.8614, 446.8614, 446.8597, 449.5008,
            449.9014, 449.4377, 446.8596, 446.8619, 449.1664, 449.6995, 449.8628,
            449.2071, 446.9464, 449.8782, 449.7478, 447.1141, 446.8600, 449.7824,
            449.8145, 449.8399, 449.8076, 448.5617, 449.6481, 449.1701, 446.8597,
            446.9291, 449.8873, 449.9029, 449.5451, 449.7890, 449.8287, 448.1459,
            449.8608, 446.9893, 449.4167, 449.8895, 449.7220, 446.8596, 446.8596,
            446.8596, 446.8600, 446.8844, 449.8028, 446.8607, 449.8019, 447.3801,
            449.6053, 449.8713, 449.1669, 449.8465, 446.8602, 446.8642, 447.3426,
            449.2399, 449.4586, 449.7568, 449.7564, 449.7867, 446.8597, 446.8719,
            448.7509, 449.8921, 448.8649, 449.6567, 449.8341, 446.8610, 446.8641,
            446.8596, 449.8418, 449.9083, 448.1702, 446.8596, 446.8603, 449.8579,
            446.8596, 449.8130, 446.8596, 449.7487, 449.2139, 446.8599, 449.5465,
            449.8286, 449.8318, 449.8113, 446.8965, 449.8520, 446.9732, 449.8696,
            446.8631, 446.8596, 449.7143, 447.3623, 449.7993, 449.5386, 449.5766,
            447.5065, 449.6913, 449.8797, 448.6276, 447.6536, 449.5269, 449.8900,
            446.8601, 446.8600, 449.9005, 447.9161, 449.8315, 447.4367, 449.8539,
            446.8618, 449.6493, 447.1129, 449.5347, 449.5722, 449.7722, 449.2514,
            446.9040, 447.0884, 449.4879, 449.4657, 446.8599, 449.7099, 449.6018,
            449.6281, 449.8834, 449.8699, 449.7056, 449.7982, 449.3118, 449.8735,
            446.8675, 449.7294, 449.8661, 449.3275, 447.8165, 449.6599, 446.8659,
            446.8609, 448.6404, 446.8745, 449.8549, 446.8596, 446.8760, 449.7675,
            448.5190, 449.6893, 449.2122, 448.1385, 449.8898, 446.8981, 449.7699,
            449.7322, 449.7812, 449.7936, 446.8626, 446.8596, 449.8733, 449.8685,
            446.8846, 448.6003, 449.8116, 449.5512, 449.1926, 449.8875, 449.8492,
            446.8596, 446.8635, 446.9409, 446.8626, 448.8012, 448.6257, 448.9382,
            449.7147, 449.6584, 449.3779, 446.8630, 449.8421, 448.3830, 449.7029,
            449.7505, 449.8697, 449.8757, 446.8597, 449.5455, 447.4452, 449.6068,
            449.0887, 449.3487, 449.3335, 448.8741, 449.8077, 449.6838, 449.7748,
            449.8483, 446.9690, 449.7377, 449.8071, 447.0670, 446.9297, 446.8700,
            446.8644, 449.2811, 449.5457, 448.5142, 447.2017, 449.6761, 446.8615,
            446.8613, 449.8701, 449.8127, 447.2092, 446.8685, 449.8745, 449.3443,
            449.8745, 449.8863, 449.8126, 446.8597, 449.3533, 449.7345, 449.8024,
            449.8394, 449.8759, 446.8596, 446.8736, 446.8768, 449.1321, 446.9008,
            449.8105, 446.9372, 446.8627, 449.2377, 446.8932, 446.8873, 446.9925,
            447.6183, 449.5619, 449.8698, 446.8597, 449.8672, 449.8622, 446.8599,
            446.8596, 449.6431, 448.3389, 449.5960, 446.8630, 447.3783, 449.7697,
            449.8833, 449.7434, 449.5575, 446.9672, 449.8446, 446.8597, 449.7875,
            446.8596, 449.6070, 446.8629, 446.9728, 448.2455, 449.8704, 446.8596,
            449.8853, 449.8560, 449.5503, 446.8605, 449.5488, 449.8651, 446.8596,
            449.7557, 449.7057, 448.3822, 446.8699, 446.8597, 448.1700, 446.8673,
            448.0029, 449.7057, 446.8598, 449.7681, 446.8616, 447.2573, 449.1412,
            446.9676, 446.8597, 446.8600, 449.6521, 449.3208, 449.8294, 448.2711,
            447.0224, 448.2711, 449.5214, 448.3855, 446.8604, 448.8109, 446.8600,
            447.5565, 446.8752, 449.8263, 449.3096, 449.8194, 446.8600, 447.6218,
            449.6894, 449.5004, 448.0730, 449.8470, 449.1134, 449.8057, 447.0734,
            447.0977, 448.8791, 449.8218, 446.8657, 448.5836, 446.8876, 449.8318,
            448.2475, 449.8218, 446.8596, 449.7622, 449.7136, 446.8621, 449.3567,
            449.7374, 449.7398, 446.8923, 447.2992, 447.4714, 449.8920, 449.6751,
            449.8687, 449.8387, 449.7563, 449.3755, 448.2709, 449.5880, 449.9059,
            446.9537, 446.8728, 446.8597, 449.8910, 449.7053, 449.3319, 449.8063,
            448.2833, 446.8596, 449.7254, 449.7553, 449.4968, 446.8596, 449.3279,
            446.8596, 449.7527, 449.7551, 447.0049, 447.6176, 446.8597, 449.5688,
            449.8050, 448.5023, 446.8596, 446.8597, 449.8368, 449.2534, 449.1807,
            446.9756, 446.9410, 449.3690, 449.4046, 449.1558, 449.4379, 449.6278,
            446.8785, 449.7492, 447.3339, 448.6561, 449.6576, 449.8036, 449.0107,
            446.8672, 446.8597, 449.6688, 449.7394, 446.8602, 448.0844, 446.8632,
            449.3308, 448.0811, 449.8154, 446.8596, 446.8644, 449.8558, 446.9086,
            447.5215, 449.8757, 446.9825, 449.7752, 447.0512, 449.6664, 449.7870,
            449.7334, 449.8636, 449.7654, 449.7330, 449.2722, 446.8773, 446.8596,
            446.8607, 449.8081, 447.3218, 446.8596, 449.7787, 449.0512, 449.7264,
            449.6265, 446.8597, 446.8597, 446.8600, 449.8367, 446.8596, 446.8597,
            446.8608, 448.3853, 446.8605, 449.9059, 449.7000, 449.8810, 446.8596,
            449.6136, 449.8627, 449.8528, 448.7299, 449.6993, 446.8607, 449.6942,
            449.8365, 449.8115, 449.7559, 449.8707, 449.8549, 447.8098, 449.6620,
            446.8659, 446.8601, 449.7882, 449.6153, 446.8916, 446.8702, 449.9017,
            449.8301, 449.8255, 449.5701, 449.8099, 448.7626, 446.8608, 446.9164,
            449.7803, 448.6393, 446.8766, 449.9039, 449.7878, 449.8998, 449.7603,
            446.8596, 449.7006, 449.8307, 449.4943, 446.8600, 449.8636, 449.8749,
            449.5911, 446.8604, 447.0540, 448.8911, 446.9073, 446.8713, 446.8599,
            449.4269, 446.8630, 449.8467, 449.9038, 449.0655, 449.7603, 446.8608,
            446.8596, 446.8596, 447.1159, 449.1687, 449.8312, 446.8618, 446.8602,
            446.8611, 449.3268, 446.8597, 449.8640, 449.7827, 446.8698, 449.2893,
            448.0609, 446.8597, 446.8615, 449.8241, 449.7703, 449.6648, 446.8599,
            447.3022, 446.9341, 448.2713, 446.8597, 447.5856, 449.8524, 447.6087,
            449.8538, 449.8793, 449.7411, 449.8007, 447.9783, 446.8625, 446.8609,
            446.8596, 449.1319, 449.5889, 446.8782, 449.7336, 446.8598, 447.6217,
            447.2331, 447.7252], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.8628, 446.8654, 446.8596, 449.8468, 449.5451, 446.8612, 447.9290,
        446.8600, 449.5640, 448.0249, 449.3476, 446.8596, 449.8699, 449.8840,
        449.8130, 446.9010, 449.7539, 447.1428, 446.8631, 449.8918, 446.8596,
        446.8603, 446.8597, 448.8551, 447.3861, 446.8606, 448.7182, 446.8691,
        446.8603, 446.8815, 446.8596, 449.8539, 446.8737, 449.6297, 449.5019,
        449.8433, 449.8706, 447.7649, 446.8689, 448.8953, 449.0516, 446.9388,
        449.8526, 449.8779, 449.6790, 449.3336, 449.7576, 446.8620, 449.7553,
        449.6544, 449.6302, 449.8400, 449.4111, 449.8077, 446.8608, 449.6808,
        449.5698, 448.7319, 449.9032, 449.5900, 449.7001, 446.8610, 449.6555,
        449.7825, 446.8625, 449.7638, 449.8189, 449.8458, 448.2717, 449.6101,
        449.6031, 449.8265, 449.2260, 449.7451, 449.4180, 449.4681, 449.8410,
        447.1088, 449.6860, 446.8599, 449.7085, 446.8596, 449.2444, 449.0189,
        446.8723, 446.8600, 449.5503, 447.2893, 446.8596, 449.8821, 449.8529,
        448.7897, 448.9785, 449.5816, 449.8278, 449.8076, 449.8975, 446.8624,
        449.8176, 447.2605, 449.6134, 446.8609, 449.7094, 449.7990, 449.7393,
        447.9557, 446.9818, 449.8732, 449.6709, 449.8872, 449.5377, 446.8817,
        449.3903, 446.8596, 448.6965, 446.8979, 446.8597, 449.5008, 448.8235,
        446.8596, 449.8301, 446.8599, 449.7865, 449.8483, 446.8602, 449.0695,
        446.8621, 449.8903, 449.8920, 449.5473, 446.8596, 449.7195, 446.8596,
        449.8461, 449.7791, 447.0074, 446.8600, 448.0298, 449.8059, 446.8596,
        446.8608, 449.6872, 449.8659, 449.5670, 446.9612, 449.8324, 449.1782,
        449.2252, 448.7523, 449.6627, 449.2888, 446.8596, 446.8611, 449.8165,
        447.6402, 449.9049, 447.1530, 446.9153, 446.8739, 449.6802, 449.6605,
        446.9608, 449.6878, 448.4012, 449.6827, 449.8521, 449.8330, 448.9286,
        449.5185, 447.6248, 446.8596, 449.3836, 449.5737, 447.9455, 449.9058,
        449.8696, 449.6913, 449.8873, 449.6291, 446.9474, 446.8603, 449.8371,
        446.8596, 448.5903, 446.8596, 446.8645, 449.4439, 449.0163, 446.8599,
        449.5090, 446.8596, 449.8694, 446.8735, 449.5464, 449.4534, 449.3254,
        446.8597, 449.6385, 449.2074, 449.8652, 449.8942, 446.8597, 448.7767,
        446.8662, 446.8597, 446.8596, 449.8633, 446.8598, 449.0706, 446.9786,
        446.8596, 447.2741, 446.8599, 449.8959, 449.7866, 446.8770, 449.8104,
        446.8628, 448.4222, 449.4680, 449.5001, 449.8755, 449.6378, 446.8752,
        449.8365, 449.3479, 449.3491, 449.8997, 446.9290, 447.8775, 446.8853,
        449.8815, 449.7048, 449.7836, 449.5205, 447.8786, 449.5924, 447.1370,
        446.8596, 447.7126, 449.7090, 449.7184, 449.8374, 448.1354, 449.7032,
        449.5132, 449.8274, 446.8629, 446.8600, 449.8672, 449.5503, 449.4494,
        449.8732, 446.8596, 449.7961, 449.6882, 446.8596, 449.8612, 447.7914,
        449.0989, 446.8596, 449.7282, 446.8596, 447.5939, 446.8611, 449.8918,
        449.8646, 449.8842, 449.5364, 449.8752, 449.6417, 446.8618, 449.4378,
        446.8712, 447.0554, 448.7031, 449.3630, 448.9288, 449.6819, 449.7271,
        446.8625, 446.8596, 449.9005, 446.8739, 449.4376, 448.0975, 449.8089,
        449.6770, 446.8599, 448.1116, 449.8746, 449.8407, 446.8596, 449.3342,
        447.7196, 446.9590, 446.8597, 446.8638, 446.8616, 449.6432, 449.5849,
        449.8904, 449.3612, 449.6381, 446.8598, 449.8430, 449.5943, 446.8678,
        449.0771, 449.8739, 449.8209, 449.1134, 449.4841, 446.8617, 449.5458,
        449.3418, 449.8592, 449.6725, 448.3611, 446.8597, 449.6134, 446.8743,
        446.8950, 449.8165, 449.8491, 449.8185, 449.2208, 449.7083, 446.8596,
        446.8596, 449.5498, 449.4310, 449.7854, 449.7494, 449.8788, 446.8597,
        446.8631, 449.8345, 446.8761, 446.8960, 446.8915, 446.8596, 446.9234,
        446.8837, 449.9046, 449.7710, 449.8964, 449.2910, 448.3422, 449.7759,
        446.8600, 448.6964, 449.4311, 449.7657, 449.6167, 446.8598, 446.9678,
        449.8438, 449.3474, 447.4068, 449.3524, 449.8561, 447.8972, 448.4556,
        446.8596, 449.8438, 448.9664, 449.6340, 446.8725, 446.9573, 447.0226,
        446.8597, 449.8481, 446.8818, 446.8642, 449.6362, 449.7910, 446.8618,
        449.8012, 446.8641, 446.8597, 446.8709, 448.9532, 446.9127, 446.8597,
        446.9008, 446.8640, 448.2085, 447.8836, 447.8143, 449.8629, 449.3076,
        449.8835, 449.0803, 447.0019, 449.8614, 446.8614, 446.8597, 449.5008,
        449.9014, 449.4377, 446.8596, 446.8619, 449.1664, 449.6995, 449.8628,
        449.2071, 446.9464, 449.8782, 449.7478, 447.1141, 446.8600, 449.7824,
        449.8145, 449.8399, 449.8076, 448.5617, 449.6481, 449.1701, 446.8597,
        446.9291, 449.8873, 449.9029, 449.5451, 449.7890, 449.8287, 448.1459,
        449.8608, 446.9893, 449.4167, 449.8895, 449.7220, 446.8596, 446.8596,
        446.8596, 446.8600, 446.8844, 449.8028, 446.8607, 449.8019, 447.3801,
        449.6053, 449.8713, 449.1669, 449.8465, 446.8602, 446.8642, 447.3426,
        449.2399, 449.4586, 449.7568, 449.7564, 449.7867, 446.8597, 446.8719,
        448.7509, 449.8921, 448.8649, 449.6567, 449.8341, 446.8610, 446.8641,
        446.8596, 449.8418, 449.9083, 448.1702, 446.8596, 446.8603, 449.8579,
        446.8596, 449.8130, 446.8596, 449.7487, 449.2139, 446.8599, 449.5465,
        449.8286, 449.8318, 449.8113, 446.8965, 449.8520, 446.9732, 449.8696,
        446.8631, 446.8596, 449.7143, 447.3623, 449.7993, 449.5386, 449.5766,
        447.5065, 449.6913, 449.8797, 448.6276, 447.6536, 449.5269, 449.8900,
        446.8601, 446.8600, 449.9005, 447.9161, 449.8315, 447.4367, 449.8539,
        446.8618, 449.6493, 447.1129, 449.5347, 449.5722, 449.7722, 449.2514,
        446.9040, 447.0884, 449.4879, 449.4657, 446.8599, 449.7099, 449.6018,
        449.6281, 449.8834, 449.8699, 449.7056, 449.7982, 449.3118, 449.8735,
        446.8675, 449.7294, 449.8661, 449.3275, 447.8165, 449.6599, 446.8659,
        446.8609, 448.6404, 446.8745, 449.8549, 446.8596, 446.8760, 449.7675,
        448.5190, 449.6893, 449.2122, 448.1385, 449.8898, 446.8981, 449.7699,
        449.7322, 449.7812, 449.7936, 446.8626, 446.8596, 449.8733, 449.8685,
        446.8846, 448.6003, 449.8116, 449.5512, 449.1926, 449.8875, 449.8492,
        446.8596, 446.8635, 446.9409, 446.8626, 448.8012, 448.6257, 448.9382,
        449.7147, 449.6584, 449.3779, 446.8630, 449.8421, 448.3830, 449.7029,
        449.7505, 449.8697, 449.8757, 446.8597, 449.5455, 447.4452, 449.6068,
        449.0887, 449.3487, 449.3335, 448.8741, 449.8077, 449.6838, 449.7748,
        449.8483, 446.9690, 449.7377, 449.8071, 447.0670, 446.9297, 446.8700,
        446.8644, 449.2811, 449.5457, 448.5142, 447.2017, 449.6761, 446.8615,
        446.8613, 449.8701, 449.8127, 447.2092, 446.8685, 449.8745, 449.3443,
        449.8745, 449.8863, 449.8126, 446.8597, 449.3533, 449.7345, 449.8024,
        449.8394, 449.8759, 446.8596, 446.8736, 446.8768, 449.1321, 446.9008,
        449.8105, 446.9372, 446.8627, 449.2377, 446.8932, 446.8873, 446.9925,
        447.6183, 449.5619, 449.8698, 446.8597, 449.8672, 449.8622, 446.8599,
        446.8596, 449.6431, 448.3389, 449.5960, 446.8630, 447.3783, 449.7697,
        449.8833, 449.7434, 449.5575, 446.9672, 449.8446, 446.8597, 449.7875,
        446.8596, 449.6070, 446.8629, 446.9728, 448.2455, 449.8704, 446.8596,
        449.8853, 449.8560, 449.5503, 446.8605, 449.5488, 449.8651, 446.8596,
        449.7557, 449.7057, 448.3822, 446.8699, 446.8597, 448.1700, 446.8673,
        448.0029, 449.7057, 446.8598, 449.7681, 446.8616, 447.2573, 449.1412,
        446.9676, 446.8597, 446.8600, 449.6521, 449.3208, 449.8294, 448.2711,
        447.0224, 448.2711, 449.5214, 448.3855, 446.8604, 448.8109, 446.8600,
        447.5565, 446.8752, 449.8263, 449.3096, 449.8194, 446.8600, 447.6218,
        449.6894, 449.5004, 448.0730, 449.8470, 449.1134, 449.8057, 447.0734,
        447.0977, 448.8791, 449.8218, 446.8657, 448.5836, 446.8876, 449.8318,
        448.2475, 449.8218, 446.8596, 449.7622, 449.7136, 446.8621, 449.3567,
        449.7374, 449.7398, 446.8923, 447.2992, 447.4714, 449.8920, 449.6751,
        449.8687, 449.8387, 449.7563, 449.3755, 448.2709, 449.5880, 449.9059,
        446.9537, 446.8728, 446.8597, 449.8910, 449.7053, 449.3319, 449.8063,
        448.2833, 446.8596, 449.7254, 449.7553, 449.4968, 446.8596, 449.3279,
        446.8596, 449.7527, 449.7551, 447.0049, 447.6176, 446.8597, 449.5688,
        449.8050, 448.5023, 446.8596, 446.8597, 449.8368, 449.2534, 449.1807,
        446.9756, 446.9410, 449.3690, 449.4046, 449.1558, 449.4379, 449.6278,
        446.8785, 449.7492, 447.3339, 448.6561, 449.6576, 449.8036, 449.0107,
        446.8672, 446.8597, 449.6688, 449.7394, 446.8602, 448.0844, 446.8632,
        449.3308, 448.0811, 449.8154, 446.8596, 446.8644, 449.8558, 446.9086,
        447.5215, 449.8757, 446.9825, 449.7752, 447.0512, 449.6664, 449.7870,
        449.7334, 449.8636, 449.7654, 449.7330, 449.2722, 446.8773, 446.8596,
        446.8607, 449.8081, 447.3218, 446.8596, 449.7787, 449.0512, 449.7264,
        449.6265, 446.8597, 446.8597, 446.8600, 449.8367, 446.8596, 446.8597,
        446.8608, 448.3853, 446.8605, 449.9059, 449.7000, 449.8810, 446.8596,
        449.6136, 449.8627, 449.8528, 448.7299, 449.6993, 446.8607, 449.6942,
        449.8365, 449.8115, 449.7559, 449.8707, 449.8549, 447.8098, 449.6620,
        446.8659, 446.8601, 449.7882, 449.6153, 446.8916, 446.8702, 449.9017,
        449.8301, 449.8255, 449.5701, 449.8099, 448.7626, 446.8608, 446.9164,
        449.7803, 448.6393, 446.8766, 449.9039, 449.7878, 449.8998, 449.7603,
        446.8596, 449.7006, 449.8307, 449.4943, 446.8600, 449.8636, 449.8749,
        449.5911, 446.8604, 447.0540, 448.8911, 446.9073, 446.8713, 446.8599,
        449.4269, 446.8630, 449.8467, 449.9038, 449.0655, 449.7603, 446.8608,
        446.8596, 446.8596, 447.1159, 449.1687, 449.8312, 446.8618, 446.8602,
        446.8611, 449.3268, 446.8597, 449.8640, 449.7827, 446.8698, 449.2893,
        448.0609, 446.8597, 446.8615, 449.8241, 449.7703, 449.6648, 446.8599,
        447.3022, 446.9341, 448.2713, 446.8597, 447.5856, 449.8524, 447.6087,
        449.8538, 449.8793, 449.7411, 449.8007, 447.9783, 446.8625, 446.8609,
        446.8596, 449.1319, 449.5889, 446.8782, 449.7336, 446.8598, 447.6217,
        447.2331, 447.7252], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([428.2841], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3805],
             [112.4504],
             [112.4740],
             [112.4740]],

            [[112.4685],
             [112.4552],
             [112.4771],
             [112.4771]],

            [[112.4723],
             [112.4723],
             [112.4688],
             [112.4688]],

            ...,

            [[111.7205],
             [111.7193],
             [111.7196],
             [111.7196]],

            [[112.4448],
             [112.4448],
             [112.3204],
             [112.3204]],

            [[111.7157],
             [111.7156],
             [111.7156],
             [111.7156]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.7790, 449.8778, 449.8822,  ..., 446.8789, 449.5303, 446.8625],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.7790, 449.8778, 449.8822,  ..., 446.8789, 449.5303, 446.8625],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2972],
             [112.2972],
             [112.3039],
             [112.3039]],

            [[112.2939],
             [112.3010],
             [112.3027],
             [112.3004]],

            [[111.9032],
             [111.9032],
             [112.1015],
             [112.1015]],

            ...,

            [[111.6673],
             [111.6647],
             [111.6653],
             [111.6653]],

            [[112.2477],
             [112.2477],
             [112.0706],
             [112.0706]],

            [[111.6754],
             [111.6754],
             [111.6705],
             [111.6705]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2023, 449.1979, 448.0093,  ..., 446.6626, 448.6366, 446.6917],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2023, 449.1979, 448.0093,  ..., 446.6626, 448.6366, 446.6917],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.6117],
             [111.6117],
             [111.6117],
             [111.6117]],

            [[111.9614],
             [111.9690],
             [112.0321],
             [112.0321]],

            [[112.0628],
             [111.9063],
             [111.9311],
             [112.0143]],

            ...,

            [[112.1037],
             [112.0907],
             [112.0304],
             [112.1340]],

            [[112.1255],
             [112.1368],
             [112.1390],
             [112.1350]],

            [[112.1005],
             [112.1005],
             [112.1381],
             [112.1381]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.4467, 447.9946, 447.9145,  ..., 448.3589, 448.5364, 448.4773],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.4467, 447.9946, 447.9145,  ..., 448.3589, 448.5364, 448.4773],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9620],
             [111.9620],
             [111.9546],
             [111.9546]],

            [[111.6100],
             [111.6100],
             [111.6100],
             [111.6100]],

            [[111.8145],
             [111.6284],
             [111.8336],
             [111.9079]],

            ...,

            [[111.7276],
             [111.7276],
             [111.8409],
             [111.8409]],

            [[111.6100],
             [111.6099],
             [111.6099],
             [111.6100]],

            [[111.9576],
             [111.9818],
             [111.9513],
             [111.9722]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8333, 446.4402, 447.1843,  ..., 447.1370, 446.4396, 447.8630],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8333, 446.4402, 447.1843,  ..., 447.1370, 446.4396, 447.8630],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0040],
             [112.0351],
             [112.0537],
             [112.0459]],

            [[111.6027],
             [111.6027],
             [111.6021],
             [111.6031]],

            [[111.9895],
             [111.9879],
             [111.9943],
             [111.9827]],

            ...,

            [[111.9796],
             [112.0336],
             [112.0311],
             [112.0311]],

            [[111.9926],
             [111.9116],
             [112.0390],
             [112.0390]],

            [[112.0531],
             [112.0523],
             [112.0418],
             [112.0421]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1387, 446.4105, 447.9544,  ..., 448.0753, 447.9822, 448.1892],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1387, 446.4105, 447.9544,  ..., 448.0753, 447.9822, 448.1892],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8413],
             [112.0159],
             [111.9482],
             [112.0807]],

            [[111.5956],
             [111.5956],
             [111.5956],
             [111.5956]],

            [[111.5955],
             [111.5955],
             [111.5956],
             [111.5956]],

            ...,

            [[111.7480],
             [111.8957],
             [112.0361],
             [112.0208]],

            [[111.9564],
             [112.0283],
             [112.1352],
             [112.1141]],

            [[112.0991],
             [112.1486],
             [112.1037],
             [112.1426]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8862, 446.3826, 446.3821,  ..., 447.7007, 448.2340, 448.4941],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8862, 446.3826, 446.3821,  ..., 447.7007, 448.2340, 448.4941],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.6951],
             [111.6173],
             [111.6267],
             [111.6267]],

            [[111.5926],
             [111.5952],
             [111.5926],
             [111.5953]],

            [[112.2922],
             [112.2845],
             [112.2810],
             [112.2750]],

            ...,

            [[112.2656],
             [112.2664],
             [112.2796],
             [112.2794]],

            [[112.2985],
             [112.2985],
             [112.3022],
             [112.3022]],

            [[111.6358],
             [111.6331],
             [111.6049],
             [111.6049]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.5656, 446.3757, 449.1327,  ..., 449.0910, 449.2015, 446.4787],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.5656, 446.3757, 449.1327,  ..., 449.0910, 449.2015, 446.4787],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.5409],
             [111.5409],
             [111.5409],
             [111.5409]],

            [[111.5416],
             [111.5416],
             [111.5416],
             [111.5416]],

            [[112.3563],
             [112.3632],
             [112.3600],
             [112.3649]],

            ...,

            [[112.4031],
             [112.4031],
             [112.4251],
             [112.4251]],

            [[111.7660],
             [111.9620],
             [111.7928],
             [111.6505]],

            [[111.5567],
             [111.5480],
             [111.5454],
             [111.5454]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.1635, 446.1663, 449.4444,  ..., 449.6563, 447.1713, 446.1955],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.1635, 446.1663, 449.4444,  ..., 449.6563, 447.1713, 446.1955],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3703],
             [112.4828],
             [112.4162],
             [112.3861]],

            [[112.4863],
             [112.3156],
             [112.5339],
             [112.5285]],

            [[112.5087],
             [112.4676],
             [112.5042],
             [112.5197]],

            ...,

            [[112.5199],
             [112.5199],
             [112.5277],
             [112.5277]],

            [[112.5134],
             [112.5134],
             [112.5263],
             [112.5263]],

            [[112.4901],
             [112.4901],
             [112.5247],
             [112.5247]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.6555, 449.8643, 450.0002,  ..., 450.0952, 450.0793, 450.0295],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.6555, 449.8643, 450.0002,  ..., 450.0952, 450.0793, 450.0295],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5197],
             [112.5197],
             [112.5791],
             [112.5791]],

            [[112.5195],
             [112.6240],
             [112.6153],
             [112.4815]],

            [[111.4494],
             [111.4493],
             [111.4463],
             [111.4463]],

            ...,

            [[111.9971],
             [112.0563],
             [111.9874],
             [112.1826]],

            [[112.1612],
             [112.6090],
             [112.5880],
             [112.3945]],

            [[112.4031],
             [112.5638],
             [112.5078],
             [112.6243]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.1976, 450.2403, 445.7914,  ..., 448.2234, 449.7528, 450.0989],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.1976, 450.2403, 445.7914,  ..., 448.2234, 449.7528, 450.0989],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6523],
             [112.6366],
             [112.6681],
             [112.6678]],

            [[112.6673],
             [112.6682],
             [112.6146],
             [112.6585]],

            [[112.6406],
             [112.6642],
             [112.5699],
             [112.6686]],

            ...,

            [[112.6521],
             [112.6662],
             [112.6538],
             [112.6672]],

            [[111.4101],
             [111.4101],
             [111.4105],
             [111.4105]],

            [[111.9700],
             [111.8071],
             [111.8641],
             [112.0206]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.6248, 450.6086, 450.5433,  ..., 450.6393, 445.6413, 447.6619],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.6248, 450.6086, 450.5433,  ..., 450.6393, 445.6413, 447.6619],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.3876],
             [111.3808],
             [111.3886],
             [111.3813]],

            [[112.7318],
             [112.7363],
             [112.7394],
             [112.7394]],

            [[112.7058],
             [112.7363],
             [112.7151],
             [112.7370]],

            ...,

            [[112.7355],
             [112.7354],
             [112.7033],
             [112.7004]],

            [[111.3648],
             [111.3648],
             [111.3648],
             [111.3648]],

            [[111.3934],
             [111.4059],
             [111.3938],
             [111.4065]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([445.5382, 450.9470, 450.8943,  ..., 450.8747, 445.4590, 445.5997],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([445.5382, 450.9470, 450.8943,  ..., 450.8747, 445.4590, 445.5997],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.3065],
             [111.3082],
             [111.3145],
             [111.3145]],

            [[112.7761],
             [112.7761],
             [112.8074],
             [112.8074]],

            [[111.2984],
             [111.2985],
             [111.2984],
             [111.2985]],

            ...,

            [[111.2984],
             [111.2984],
             [111.2984],
             [111.2984]],

            [[112.7960],
             [112.8077],
             [112.7980],
             [112.7962]],

            [[112.5230],
             [112.6828],
             [112.7426],
             [112.7918]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([445.2438, 451.1671, 445.1937,  ..., 445.1937, 451.1978, 450.7403],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([445.2438, 451.1671, 445.1937,  ..., 445.1937, 451.1978, 450.7403],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.1954],
             [111.1954],
             [111.1954],
             [111.1954]],

            [[112.6752],
             [112.8823],
             [112.8891],
             [112.8900]],

            [[111.1955],
             [111.1955],
             [111.1955],
             [111.1955]],

            ...,

            [[112.7446],
             [112.8873],
             [112.8897],
             [112.8891]],

            [[111.1954],
             [111.1955],
             [111.1954],
             [111.1955]],

            [[111.3396],
             [111.5484],
             [111.2445],
             [111.2445]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.7818, 451.3366, 444.7819,  ..., 451.4107, 444.7818, 445.3768],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.7818, 451.3366, 444.7819,  ..., 451.4107, 444.7818, 445.3768],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.9143],
             [112.9303],
             [112.9227],
             [112.9218]],

            [[112.8360],
             [112.9108],
             [112.8599],
             [112.8599]],

            [[111.2610],
             [111.3969],
             [111.2151],
             [111.2151]],

            ...,

            [[112.8839],
             [112.9207],
             [112.6464],
             [112.6464]],

            [[111.3787],
             [111.2636],
             [111.3919],
             [111.2568]],

            [[112.8286],
             [112.8286],
             [112.9108],
             [112.9108]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([451.6891, 451.4666, 445.0882,  ..., 451.0975, 445.2910, 451.4788],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([451.6891, 451.4666, 445.0882,  ..., 451.0975, 445.2910, 451.4788],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.1602],
             [111.1446],
             [111.1374],
             [111.1408]],

            [[112.9878],
             [112.9030],
             [112.9857],
             [112.9857]],

            [[112.9340],
             [112.9340],
             [112.9844],
             [112.9844]],

            ...,

            [[111.1449],
             [111.1595],
             [111.1455],
             [111.1608]],

            [[111.9162],
             [111.9162],
             [112.6506],
             [112.6506]],

            [[111.9601],
             [111.8806],
             [112.6288],
             [112.6288]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.5830, 451.8621, 451.8368,  ..., 444.6108, 449.1336, 449.0984],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.5830, 451.8621, 451.8368,  ..., 444.6108, 449.1336, 449.0984],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.0591],
             [111.0591],
             [111.0591],
             [111.0591]],

            [[113.0523],
             [113.0508],
             [113.0501],
             [113.0435]],

            [[113.0535],
             [113.0545],
             [113.0553],
             [113.0553]],

            ...,

            [[112.4466],
             [112.7986],
             [113.0271],
             [113.0271]],

            [[111.4253],
             [112.1842],
             [111.1270],
             [111.3955]],

            [[113.0360],
             [113.0549],
             [112.5602],
             [113.0328]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.2364, 452.1967, 452.2185,  ..., 451.2995, 446.1321, 451.6840],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.2364, 452.1967, 452.2185,  ..., 451.2995, 446.1321, 451.6840],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.0568],
             [113.0744],
             [112.9499],
             [112.9499]],

            [[111.3870],
             [112.0687],
             [111.1397],
             [111.1668]],

            [[112.8530],
             [113.0721],
             [113.0755],
             [113.0741]],

            ...,

            [[113.0730],
             [113.0744],
             [113.0743],
             [113.0734]],

            [[112.9121],
             [112.8985],
             [113.0491],
             [113.0491]],

            [[111.0749],
             [111.0749],
             [111.0749],
             [111.0749]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([452.0309, 445.7622, 452.0746,  ..., 452.2951, 451.9088, 444.2994],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([452.0309, 445.7622, 452.0746,  ..., 452.2951, 451.9088, 444.2994],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0280e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.0177],
             [113.0453],
             [112.9867],
             [113.0424]],

            [[113.0422],
             [113.0422],
             [113.0488],
             [113.0488]],

            [[113.0010],
             [113.0339],
             [113.0468],
             [113.0404]],

            ...,

            [[112.2229],
             [112.8872],
             [112.0492],
             [112.8529]],

            [[111.1076],
             [111.1076],
             [111.1079],
             [111.1079]],

            [[113.0320],
             [113.0320],
             [113.0487],
             [113.0487]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([452.0921, 452.1821, 452.1221,  ..., 450.0123, 444.4310, 452.1614],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([452.0921, 452.1821, 452.1221,  ..., 450.0123, 444.4310, 452.1614],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.0414],
             [113.0480],
             [113.0491],
             [112.9400]],

            [[111.1081],
             [111.1112],
             [111.1086],
             [111.1092]],

            [[111.2572],
             [111.9270],
             [111.3636],
             [112.6620]],

            ...,

            [[112.9852],
             [113.0477],
             [113.0466],
             [113.0491]],

            [[113.0372],
             [113.0499],
             [113.0434],
             [113.0445]],

            [[111.1073],
             [111.1073],
             [111.1073],
             [111.1073]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([452.0785, 444.4371, 447.2098,  ..., 452.1285, 452.1750, 444.4292],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([452.0785, 444.4371, 447.2098,  ..., 452.1285, 452.1750, 444.4292],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.1074],
             [111.1078],
             [111.1075],
             [111.1075]],

            [[113.0420],
             [113.0503],
             [113.0014],
             [113.0467]],

            [[111.1476],
             [111.1476],
             [111.1750],
             [111.1750]],

            ...,

            [[112.8433],
             [113.0430],
             [113.0483],
             [113.0490]],

            [[113.0447],
             [112.9386],
             [113.0490],
             [113.0483]],

            [[113.0200],
             [113.0157],
             [113.0458],
             [113.0458]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.4302, 452.1404, 444.6451, 452.1723, 452.1459, 451.7369, 452.1302,
            452.1203, 444.4290, 452.1827, 452.1702, 451.5886, 452.1361, 444.4981,
            444.4290, 444.8115, 452.0349, 452.1321, 444.4371, 452.1746, 452.1065,
            446.3591, 451.5417, 452.1901, 451.2388, 452.1805, 452.1898, 445.9039,
            452.1544, 444.4400, 452.0405, 452.1822, 446.5384, 452.1853, 452.1714,
            444.4329, 444.4290, 452.1550, 449.5034, 444.4290, 449.4722, 444.4296,
            444.4291, 444.4290, 447.3326, 452.1369, 444.4440, 451.5590, 451.7735,
            444.4296, 452.1879, 444.4333, 444.4325, 452.1464, 446.7933, 452.0560,
            444.4303, 445.4728, 452.1079, 452.1790, 452.1221, 450.8890, 452.0723,
            444.4312, 448.9769, 452.1722, 444.4443, 444.4438, 444.5710, 452.1614,
            447.8071, 452.1649, 452.1804, 452.1360, 452.1111, 444.4306, 452.1609,
            444.4336, 451.4883, 449.1169, 445.9851, 452.1299, 452.1663, 452.1900,
            451.5416, 444.4337, 444.4430, 452.1651, 444.4290, 444.4999, 452.1885,
            452.0232, 444.4317, 444.4427, 452.1872, 444.4307, 444.5260, 452.1896,
            451.1136, 444.4394, 452.1695, 444.5035, 444.4297, 447.1376, 452.1727,
            449.8538, 452.1183, 445.7583, 452.1818, 444.4292, 448.1984, 451.9368,
            452.0924, 451.9148, 452.1706, 444.4290, 452.1865, 444.5363, 452.1091,
            452.1688, 444.4641, 449.1918, 451.1550, 451.7408, 452.0231, 445.3776,
            452.1306, 452.0191, 444.4293, 450.7910, 452.1662, 444.4290, 452.1803,
            452.0310, 452.1447, 452.1230, 448.9023, 452.1826, 452.1013, 444.4437,
            444.9894, 444.6791, 451.9146, 452.1656, 452.1021, 452.1751, 452.1300,
            444.4687, 452.0685, 452.1533, 444.4290, 449.6492, 452.1773, 452.1723,
            451.9749, 444.4306, 446.9492, 451.0250, 452.1581, 452.1575, 452.0821,
            452.1635, 444.4291, 452.1337, 452.1895, 452.0780, 452.1066, 444.4434,
            451.2216, 452.1325, 444.4615, 452.0010, 447.9093, 449.2650, 452.0664,
            452.1856, 450.9520, 452.1346, 450.6037, 451.8773, 444.7791, 444.4313,
            445.0992, 444.4373, 452.0141, 452.1705, 452.1168, 452.1429, 451.9404,
            452.0221, 451.6129, 444.5953, 444.4290, 451.6282, 444.4290, 452.0910,
            452.0293, 444.4337, 452.1638, 452.1765, 444.4292, 452.1741, 452.0901,
            445.8841, 452.1633, 452.1714, 444.4314, 444.7082, 452.0579, 444.4290,
            444.4314, 444.4291, 444.4373, 444.4311, 452.1590, 452.0650, 452.1738,
            452.1230, 452.1868, 452.1175, 444.4444, 451.7941, 449.9656, 444.4290,
            444.4293, 452.1052, 452.1735, 452.1703, 452.1820, 452.0544, 444.4891,
            444.4363, 452.1645, 448.0738, 452.1887, 452.1467, 444.6796, 452.1026,
            444.4290, 444.4302, 452.0037, 451.9313, 444.5066, 446.0297, 452.0236,
            444.4431, 452.1533, 451.6564, 452.1814, 449.2764, 444.4291, 444.4290,
            444.4301, 451.9875, 452.1637, 446.8551, 444.4297, 451.9847, 444.4290,
            444.4578, 451.8450, 452.0521, 444.4411, 452.1707, 451.8779, 444.8961,
            451.8029, 444.4291, 452.1857, 451.5478, 452.1072, 444.7994, 452.1613,
            451.7960, 444.4295, 444.4291, 444.4295, 452.1415, 444.4865, 444.4293,
            452.1725, 444.4313, 452.0744, 451.9482, 444.4307, 450.6682, 444.5398,
            452.1882, 444.9550, 444.4315, 451.9525, 452.1307, 448.1267, 452.1601,
            452.0547, 451.4385, 444.4340, 452.1896, 449.9865, 452.1747, 450.2451,
            452.1622, 452.1487, 451.8348, 444.4290, 451.5459, 452.1771, 444.4290,
            444.4290, 452.1642, 444.4297, 451.5073, 444.4306, 452.1784, 452.0959,
            451.7607, 444.4484, 446.2625, 445.8248, 445.8356, 451.7584, 452.1620,
            452.1707, 444.4290, 452.1050, 444.4443, 452.1377, 448.5144, 446.5974,
            451.4664, 451.0758, 444.4318, 452.1834, 450.6540, 447.0024, 451.9616,
            452.1600, 452.1476, 444.4517, 444.4290, 452.1240, 452.1199, 452.0756,
            452.1448, 444.4306, 444.4600, 444.4319, 444.7093, 452.1821, 452.1261,
            452.1281, 451.1105, 448.0482, 451.9957, 452.1569, 444.4672, 444.4294,
            450.0157, 452.1674, 450.1529, 444.4290, 444.5605, 451.6065, 451.2576,
            452.1169, 444.4738, 444.4294, 450.4610, 452.1660, 446.5455, 452.0743,
            452.1301, 445.6590, 451.7913, 444.4293, 444.4317, 452.0876, 452.1398,
            452.1902, 452.1809, 452.0620, 452.1511, 452.1644, 444.4317, 444.4290,
            444.4295, 447.4748, 446.4006, 452.1230, 452.1907, 444.4395, 444.4312,
            451.3260, 444.4291, 450.4242, 452.1700, 452.1852, 444.4313, 452.1530,
            448.3866, 444.4290, 452.1132, 444.4387, 452.1748, 444.4290, 448.3729,
            450.1223, 451.8828, 452.1836, 445.0786, 451.0793, 451.5199, 451.7239,
            444.4291, 452.1854, 444.4362, 444.4291, 452.1635, 452.1354, 444.4994,
            444.4377, 452.1819, 451.0381, 444.5367, 445.1773, 452.1629, 452.1772,
            444.7255, 451.7043, 452.0805, 452.1420, 452.1447, 444.4290, 444.4290,
            444.4359, 451.7566, 445.6891, 452.1710, 444.4356, 452.0126, 444.4298,
            449.2964, 444.4290, 444.4327, 444.4290, 452.1284, 452.1669, 445.2508,
            452.1774, 444.4291, 452.1559, 452.1461, 452.1413, 452.1429, 452.1750,
            452.1327, 447.5932, 444.4384, 444.8115, 452.1684, 452.0414, 444.4303,
            446.8327, 452.0314, 452.1452, 444.4576, 444.4290, 444.4291, 452.1318,
            452.1703, 444.4308, 444.4290, 452.1228, 446.3896, 451.8606, 452.1622,
            444.6708, 452.1782, 452.1226, 444.4721, 451.7811, 452.0382, 444.4294,
            444.5381, 452.0712, 451.5778, 451.9419, 452.1351, 444.7842, 451.9147,
            451.7146, 444.4292, 444.4290, 444.4302, 444.4291, 444.4299, 452.0942,
            444.5084, 444.4290, 444.4290, 450.5069, 452.0848, 452.1650, 444.4291,
            444.4310, 451.9957, 444.4305, 449.7786, 444.7784, 451.9398, 444.4290,
            452.0988, 444.7064, 444.4290, 452.1414, 452.1189, 452.1193, 452.0452,
            452.0083, 452.0416, 451.6381, 452.1366, 452.0291, 444.4410, 452.1451,
            452.1853, 444.4290, 452.1626, 444.4309, 444.4295, 444.4498, 451.8171,
            451.7708, 452.0149, 449.0015, 450.8129, 446.3958, 446.3228, 452.1520,
            448.3323, 444.4429, 452.1423, 452.0985, 452.0727, 452.1936, 451.8155,
            448.7632, 452.1312, 444.5183, 444.4723, 444.4540, 444.4290, 452.0695,
            452.1055, 447.5356, 445.0158, 452.0375, 452.1114, 452.1501, 444.4290,
            444.4292, 452.1126, 446.2839, 452.1165, 444.6220, 444.4301, 444.4291,
            452.1229, 444.5001, 452.1539, 451.0079, 444.7353, 452.1542, 444.4309,
            444.4290, 444.4290, 444.4307, 451.7640, 444.4290, 444.4387, 444.4312,
            444.4290, 451.9898, 451.5959, 444.4290, 444.4310, 448.1523, 444.4290,
            446.6048, 444.4290, 452.0697, 444.4291, 451.6866, 444.4399, 444.4333,
            450.3869, 452.1708, 448.7509, 452.1875, 450.9157, 452.1605, 451.8344,
            451.8351, 452.0627, 452.0675, 444.4409, 451.6993, 452.0862, 451.0039,
            451.5564, 447.1346, 452.1216, 445.9066, 452.0974, 452.2010, 444.4290,
            452.1563, 448.0970, 445.2142, 452.1203, 452.1216, 444.4295, 452.1885,
            451.9505, 444.4350, 452.1094, 452.1874, 444.4290, 444.4290, 451.8692,
            451.8363, 444.4290, 444.4290, 452.1552, 451.8681, 444.4559, 452.1709,
            444.4290, 451.2177, 449.5847, 452.1500, 451.0720, 452.1619, 452.0507,
            452.1577, 450.0508, 445.4849, 444.4290, 452.1629, 444.4291, 444.4301,
            452.1662, 451.9878, 444.4291, 451.9277, 452.1806, 451.0044, 451.9714,
            452.1495, 451.0664, 452.0218, 451.4431, 452.0957, 444.4290, 444.5457,
            452.1355, 452.1783, 452.0939, 445.8266, 445.3477, 444.4290, 445.8115,
            451.8988, 452.1555, 444.4290, 452.1198, 452.1606, 445.1926, 452.1602,
            444.4858, 452.1877, 452.1000, 444.4415, 444.4304, 452.1851, 444.4293,
            444.4487, 448.6708, 444.4525, 452.0710, 450.8093, 444.4854, 451.9806,
            448.9824, 450.7062, 452.1906, 452.1605, 452.1876, 452.1773, 451.9069,
            444.4291, 451.8468, 446.1840, 452.1901, 451.6062, 452.0869, 452.1279,
            444.4294, 452.0812, 452.0597, 452.1632, 452.1225, 444.4937, 452.1103,
            445.2372, 444.4291, 452.1066, 444.4474, 444.4405, 451.8545, 452.1874,
            450.5984, 452.1661, 452.0055, 449.2913, 451.1385, 452.0961, 449.9366,
            444.5159, 452.1625, 450.6411, 444.4290, 452.1263, 444.4290, 444.4320,
            447.7097, 452.1086, 444.4297, 444.4300, 449.2069, 444.4431, 452.0953,
            452.1644, 444.4897, 444.7084, 451.4876, 452.1164, 452.1830, 444.4652,
            445.1432, 451.8426, 452.1794, 452.1617, 452.0873, 452.1082, 452.1823,
            444.4313, 444.4290, 446.7286, 448.0111, 451.7826, 452.1311, 451.5670,
            451.5953, 452.1172, 444.4290, 451.7148, 444.4984, 451.9967, 451.6825,
            444.4454, 444.4295, 452.1232, 444.4291, 452.1531, 452.1561, 452.1563,
            452.1224, 444.4369, 452.0554, 452.1560, 445.3660, 451.9718, 452.1477,
            444.4296, 451.9907, 444.4307, 444.7609, 444.4681, 444.5565, 452.1509,
            444.4291, 444.4442, 452.1581, 452.1680, 452.1621, 444.7033, 444.5063,
            444.4349, 452.1635, 452.1191, 444.5681, 444.4847, 452.1563, 444.4313,
            452.1353, 452.0272, 444.4316, 444.4421, 444.4290, 444.4290, 444.4415,
            448.9838, 444.4337, 451.8708, 444.4290, 445.7592, 452.1779, 444.4504,
            444.4353, 444.4290, 444.6147, 444.4290, 452.1659, 452.0483, 444.4293,
            444.4311, 444.4374, 445.0550, 452.1824, 444.4383, 444.4297, 444.4290,
            451.7893, 444.4370, 452.0865, 449.6512, 451.7729, 451.7111, 444.7883,
            452.0592, 452.1646, 444.4334, 444.4290, 452.1677, 450.6406, 444.4308,
            451.7918, 452.1832, 447.7606, 452.1324, 452.1738, 452.0303, 444.9795,
            452.1797, 451.5932, 444.4370, 446.5259, 444.4301, 445.6358, 444.4884,
            444.4291, 444.4290, 444.4296, 444.7731, 452.1513, 452.1007, 445.0555,
            444.4336, 452.1852, 444.4292, 452.0817, 452.1660, 451.3741, 444.7007,
            444.4888, 444.4292, 450.7189, 450.0081, 452.0799, 451.7157, 451.8953,
            451.6058, 451.9187, 444.4484, 452.1230, 444.4341, 451.8304, 450.7026,
            452.1594, 448.0322, 452.1779, 452.1853, 450.7978, 444.4327, 452.1277,
            444.5604, 451.7932, 444.4607, 444.4290, 451.6917, 444.4338, 444.4291,
            451.6455, 444.4407, 444.4292, 452.1406, 452.1664, 444.7558, 452.1638,
            445.8690, 444.5246, 444.4296, 444.4448, 450.0278, 448.6994, 452.0950,
            444.4342, 452.1611, 452.1865, 444.4358, 444.7987, 452.1349, 451.9836,
            452.0807, 452.1273], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.4302, 452.1404, 444.6451, 452.1723, 452.1459, 451.7369, 452.1302,
        452.1203, 444.4290, 452.1827, 452.1702, 451.5886, 452.1361, 444.4981,
        444.4290, 444.8115, 452.0349, 452.1321, 444.4371, 452.1746, 452.1065,
        446.3591, 451.5417, 452.1901, 451.2388, 452.1805, 452.1898, 445.9039,
        452.1544, 444.4400, 452.0405, 452.1822, 446.5384, 452.1853, 452.1714,
        444.4329, 444.4290, 452.1550, 449.5034, 444.4290, 449.4722, 444.4296,
        444.4291, 444.4290, 447.3326, 452.1369, 444.4440, 451.5590, 451.7735,
        444.4296, 452.1879, 444.4333, 444.4325, 452.1464, 446.7933, 452.0560,
        444.4303, 445.4728, 452.1079, 452.1790, 452.1221, 450.8890, 452.0723,
        444.4312, 448.9769, 452.1722, 444.4443, 444.4438, 444.5710, 452.1614,
        447.8071, 452.1649, 452.1804, 452.1360, 452.1111, 444.4306, 452.1609,
        444.4336, 451.4883, 449.1169, 445.9851, 452.1299, 452.1663, 452.1900,
        451.5416, 444.4337, 444.4430, 452.1651, 444.4290, 444.4999, 452.1885,
        452.0232, 444.4317, 444.4427, 452.1872, 444.4307, 444.5260, 452.1896,
        451.1136, 444.4394, 452.1695, 444.5035, 444.4297, 447.1376, 452.1727,
        449.8538, 452.1183, 445.7583, 452.1818, 444.4292, 448.1984, 451.9368,
        452.0924, 451.9148, 452.1706, 444.4290, 452.1865, 444.5363, 452.1091,
        452.1688, 444.4641, 449.1918, 451.1550, 451.7408, 452.0231, 445.3776,
        452.1306, 452.0191, 444.4293, 450.7910, 452.1662, 444.4290, 452.1803,
        452.0310, 452.1447, 452.1230, 448.9023, 452.1826, 452.1013, 444.4437,
        444.9894, 444.6791, 451.9146, 452.1656, 452.1021, 452.1751, 452.1300,
        444.4687, 452.0685, 452.1533, 444.4290, 449.6492, 452.1773, 452.1723,
        451.9749, 444.4306, 446.9492, 451.0250, 452.1581, 452.1575, 452.0821,
        452.1635, 444.4291, 452.1337, 452.1895, 452.0780, 452.1066, 444.4434,
        451.2216, 452.1325, 444.4615, 452.0010, 447.9093, 449.2650, 452.0664,
        452.1856, 450.9520, 452.1346, 450.6037, 451.8773, 444.7791, 444.4313,
        445.0992, 444.4373, 452.0141, 452.1705, 452.1168, 452.1429, 451.9404,
        452.0221, 451.6129, 444.5953, 444.4290, 451.6282, 444.4290, 452.0910,
        452.0293, 444.4337, 452.1638, 452.1765, 444.4292, 452.1741, 452.0901,
        445.8841, 452.1633, 452.1714, 444.4314, 444.7082, 452.0579, 444.4290,
        444.4314, 444.4291, 444.4373, 444.4311, 452.1590, 452.0650, 452.1738,
        452.1230, 452.1868, 452.1175, 444.4444, 451.7941, 449.9656, 444.4290,
        444.4293, 452.1052, 452.1735, 452.1703, 452.1820, 452.0544, 444.4891,
        444.4363, 452.1645, 448.0738, 452.1887, 452.1467, 444.6796, 452.1026,
        444.4290, 444.4302, 452.0037, 451.9313, 444.5066, 446.0297, 452.0236,
        444.4431, 452.1533, 451.6564, 452.1814, 449.2764, 444.4291, 444.4290,
        444.4301, 451.9875, 452.1637, 446.8551, 444.4297, 451.9847, 444.4290,
        444.4578, 451.8450, 452.0521, 444.4411, 452.1707, 451.8779, 444.8961,
        451.8029, 444.4291, 452.1857, 451.5478, 452.1072, 444.7994, 452.1613,
        451.7960, 444.4295, 444.4291, 444.4295, 452.1415, 444.4865, 444.4293,
        452.1725, 444.4313, 452.0744, 451.9482, 444.4307, 450.6682, 444.5398,
        452.1882, 444.9550, 444.4315, 451.9525, 452.1307, 448.1267, 452.1601,
        452.0547, 451.4385, 444.4340, 452.1896, 449.9865, 452.1747, 450.2451,
        452.1622, 452.1487, 451.8348, 444.4290, 451.5459, 452.1771, 444.4290,
        444.4290, 452.1642, 444.4297, 451.5073, 444.4306, 452.1784, 452.0959,
        451.7607, 444.4484, 446.2625, 445.8248, 445.8356, 451.7584, 452.1620,
        452.1707, 444.4290, 452.1050, 444.4443, 452.1377, 448.5144, 446.5974,
        451.4664, 451.0758, 444.4318, 452.1834, 450.6540, 447.0024, 451.9616,
        452.1600, 452.1476, 444.4517, 444.4290, 452.1240, 452.1199, 452.0756,
        452.1448, 444.4306, 444.4600, 444.4319, 444.7093, 452.1821, 452.1261,
        452.1281, 451.1105, 448.0482, 451.9957, 452.1569, 444.4672, 444.4294,
        450.0157, 452.1674, 450.1529, 444.4290, 444.5605, 451.6065, 451.2576,
        452.1169, 444.4738, 444.4294, 450.4610, 452.1660, 446.5455, 452.0743,
        452.1301, 445.6590, 451.7913, 444.4293, 444.4317, 452.0876, 452.1398,
        452.1902, 452.1809, 452.0620, 452.1511, 452.1644, 444.4317, 444.4290,
        444.4295, 447.4748, 446.4006, 452.1230, 452.1907, 444.4395, 444.4312,
        451.3260, 444.4291, 450.4242, 452.1700, 452.1852, 444.4313, 452.1530,
        448.3866, 444.4290, 452.1132, 444.4387, 452.1748, 444.4290, 448.3729,
        450.1223, 451.8828, 452.1836, 445.0786, 451.0793, 451.5199, 451.7239,
        444.4291, 452.1854, 444.4362, 444.4291, 452.1635, 452.1354, 444.4994,
        444.4377, 452.1819, 451.0381, 444.5367, 445.1773, 452.1629, 452.1772,
        444.7255, 451.7043, 452.0805, 452.1420, 452.1447, 444.4290, 444.4290,
        444.4359, 451.7566, 445.6891, 452.1710, 444.4356, 452.0126, 444.4298,
        449.2964, 444.4290, 444.4327, 444.4290, 452.1284, 452.1669, 445.2508,
        452.1774, 444.4291, 452.1559, 452.1461, 452.1413, 452.1429, 452.1750,
        452.1327, 447.5932, 444.4384, 444.8115, 452.1684, 452.0414, 444.4303,
        446.8327, 452.0314, 452.1452, 444.4576, 444.4290, 444.4291, 452.1318,
        452.1703, 444.4308, 444.4290, 452.1228, 446.3896, 451.8606, 452.1622,
        444.6708, 452.1782, 452.1226, 444.4721, 451.7811, 452.0382, 444.4294,
        444.5381, 452.0712, 451.5778, 451.9419, 452.1351, 444.7842, 451.9147,
        451.7146, 444.4292, 444.4290, 444.4302, 444.4291, 444.4299, 452.0942,
        444.5084, 444.4290, 444.4290, 450.5069, 452.0848, 452.1650, 444.4291,
        444.4310, 451.9957, 444.4305, 449.7786, 444.7784, 451.9398, 444.4290,
        452.0988, 444.7064, 444.4290, 452.1414, 452.1189, 452.1193, 452.0452,
        452.0083, 452.0416, 451.6381, 452.1366, 452.0291, 444.4410, 452.1451,
        452.1853, 444.4290, 452.1626, 444.4309, 444.4295, 444.4498, 451.8171,
        451.7708, 452.0149, 449.0015, 450.8129, 446.3958, 446.3228, 452.1520,
        448.3323, 444.4429, 452.1423, 452.0985, 452.0727, 452.1936, 451.8155,
        448.7632, 452.1312, 444.5183, 444.4723, 444.4540, 444.4290, 452.0695,
        452.1055, 447.5356, 445.0158, 452.0375, 452.1114, 452.1501, 444.4290,
        444.4292, 452.1126, 446.2839, 452.1165, 444.6220, 444.4301, 444.4291,
        452.1229, 444.5001, 452.1539, 451.0079, 444.7353, 452.1542, 444.4309,
        444.4290, 444.4290, 444.4307, 451.7640, 444.4290, 444.4387, 444.4312,
        444.4290, 451.9898, 451.5959, 444.4290, 444.4310, 448.1523, 444.4290,
        446.6048, 444.4290, 452.0697, 444.4291, 451.6866, 444.4399, 444.4333,
        450.3869, 452.1708, 448.7509, 452.1875, 450.9157, 452.1605, 451.8344,
        451.8351, 452.0627, 452.0675, 444.4409, 451.6993, 452.0862, 451.0039,
        451.5564, 447.1346, 452.1216, 445.9066, 452.0974, 452.2010, 444.4290,
        452.1563, 448.0970, 445.2142, 452.1203, 452.1216, 444.4295, 452.1885,
        451.9505, 444.4350, 452.1094, 452.1874, 444.4290, 444.4290, 451.8692,
        451.8363, 444.4290, 444.4290, 452.1552, 451.8681, 444.4559, 452.1709,
        444.4290, 451.2177, 449.5847, 452.1500, 451.0720, 452.1619, 452.0507,
        452.1577, 450.0508, 445.4849, 444.4290, 452.1629, 444.4291, 444.4301,
        452.1662, 451.9878, 444.4291, 451.9277, 452.1806, 451.0044, 451.9714,
        452.1495, 451.0664, 452.0218, 451.4431, 452.0957, 444.4290, 444.5457,
        452.1355, 452.1783, 452.0939, 445.8266, 445.3477, 444.4290, 445.8115,
        451.8988, 452.1555, 444.4290, 452.1198, 452.1606, 445.1926, 452.1602,
        444.4858, 452.1877, 452.1000, 444.4415, 444.4304, 452.1851, 444.4293,
        444.4487, 448.6708, 444.4525, 452.0710, 450.8093, 444.4854, 451.9806,
        448.9824, 450.7062, 452.1906, 452.1605, 452.1876, 452.1773, 451.9069,
        444.4291, 451.8468, 446.1840, 452.1901, 451.6062, 452.0869, 452.1279,
        444.4294, 452.0812, 452.0597, 452.1632, 452.1225, 444.4937, 452.1103,
        445.2372, 444.4291, 452.1066, 444.4474, 444.4405, 451.8545, 452.1874,
        450.5984, 452.1661, 452.0055, 449.2913, 451.1385, 452.0961, 449.9366,
        444.5159, 452.1625, 450.6411, 444.4290, 452.1263, 444.4290, 444.4320,
        447.7097, 452.1086, 444.4297, 444.4300, 449.2069, 444.4431, 452.0953,
        452.1644, 444.4897, 444.7084, 451.4876, 452.1164, 452.1830, 444.4652,
        445.1432, 451.8426, 452.1794, 452.1617, 452.0873, 452.1082, 452.1823,
        444.4313, 444.4290, 446.7286, 448.0111, 451.7826, 452.1311, 451.5670,
        451.5953, 452.1172, 444.4290, 451.7148, 444.4984, 451.9967, 451.6825,
        444.4454, 444.4295, 452.1232, 444.4291, 452.1531, 452.1561, 452.1563,
        452.1224, 444.4369, 452.0554, 452.1560, 445.3660, 451.9718, 452.1477,
        444.4296, 451.9907, 444.4307, 444.7609, 444.4681, 444.5565, 452.1509,
        444.4291, 444.4442, 452.1581, 452.1680, 452.1621, 444.7033, 444.5063,
        444.4349, 452.1635, 452.1191, 444.5681, 444.4847, 452.1563, 444.4313,
        452.1353, 452.0272, 444.4316, 444.4421, 444.4290, 444.4290, 444.4415,
        448.9838, 444.4337, 451.8708, 444.4290, 445.7592, 452.1779, 444.4504,
        444.4353, 444.4290, 444.6147, 444.4290, 452.1659, 452.0483, 444.4293,
        444.4311, 444.4374, 445.0550, 452.1824, 444.4383, 444.4297, 444.4290,
        451.7893, 444.4370, 452.0865, 449.6512, 451.7729, 451.7111, 444.7883,
        452.0592, 452.1646, 444.4334, 444.4290, 452.1677, 450.6406, 444.4308,
        451.7918, 452.1832, 447.7606, 452.1324, 452.1738, 452.0303, 444.9795,
        452.1797, 451.5932, 444.4370, 446.5259, 444.4301, 445.6358, 444.4884,
        444.4291, 444.4290, 444.4296, 444.7731, 452.1513, 452.1007, 445.0555,
        444.4336, 452.1852, 444.4292, 452.0817, 452.1660, 451.3741, 444.7007,
        444.4888, 444.4292, 450.7189, 450.0081, 452.0799, 451.7157, 451.8953,
        451.6058, 451.9187, 444.4484, 452.1230, 444.4341, 451.8304, 450.7026,
        452.1594, 448.0322, 452.1779, 452.1853, 450.7978, 444.4327, 452.1277,
        444.5604, 451.7932, 444.4607, 444.4290, 451.6917, 444.4338, 444.4291,
        451.6455, 444.4407, 444.4292, 452.1406, 452.1664, 444.7558, 452.1638,
        445.8690, 444.5246, 444.4296, 444.4448, 450.0278, 448.6994, 452.0950,
        444.4342, 452.1611, 452.1865, 444.4358, 444.7987, 452.1349, 451.9836,
        452.0807, 452.1273], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([396.6989], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.0369],
             [113.0369],
             [113.0493],
             [113.0493]],

            [[112.7471],
             [112.7471],
             [112.9931],
             [112.9931]],

            [[113.0420],
             [113.0494],
             [113.0487],
             [113.0227]],

            ...,

            [[111.1074],
             [111.1077],
             [111.1075],
             [111.1078]],

            [[111.1086],
             [111.1079],
             [111.1078],
             [111.1088]],

            [[112.8783],
             [112.8867],
             [112.8883],
             [112.8783]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([452.1722, 451.4804, 452.1628,  ..., 444.4305, 444.4330, 451.5315],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([452.1722, 451.4804, 452.1628,  ..., 444.4305, 444.4330, 451.5315],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.1673],
             [111.1673],
             [111.1673],
             [111.1673]],

            [[112.9463],
             [112.9463],
             [112.9607],
             [112.9607]],

            [[112.9596],
             [112.9607],
             [112.9573],
             [112.9579]],

            ...,

            [[112.9407],
             [112.9589],
             [112.8827],
             [112.8827]],

            [[112.9153],
             [112.9614],
             [112.9531],
             [112.8541]],

            [[112.8651],
             [112.9572],
             [112.9611],
             [112.9617]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([444.6693, 451.8139, 451.8355,  ..., 451.6649, 451.6840, 451.7451],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([444.6693, 451.8139, 451.8355,  ..., 451.6649, 451.6840, 451.7451],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.8324],
             [112.8717],
             [112.8759],
             [112.8772]],

            [[112.8676],
             [112.8676],
             [112.8791],
             [112.8791]],

            [[111.2668],
             [111.3059],
             [111.2666],
             [111.3060]],

            ...,

            [[112.7784],
             [112.8611],
             [112.8129],
             [112.8653]],

            [[112.8782],
             [112.8804],
             [112.8442],
             [112.8442]],

            [[111.2330],
             [111.2330],
             [111.2330],
             [111.2330]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([451.4572, 451.4935, 445.1454,  ..., 451.3177, 451.4470, 444.9319],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([451.4572, 451.4935, 445.1454,  ..., 451.3177, 451.4470, 444.9319],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.7589],
             [112.7540],
             [112.7600],
             [112.7600]],

            [[112.4553],
             [112.4098],
             [112.7048],
             [112.7048]],

            [[111.3129],
             [111.3130],
             [111.3129],
             [111.3129]],

            ...,

            [[112.7577],
             [112.7551],
             [112.7641],
             [112.7641]],

            [[112.7464],
             [112.7463],
             [112.7610],
             [112.7047]],

            [[111.3129],
             [111.3129],
             [111.3129],
             [111.3129]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([451.0330, 450.2747, 445.2517,  ..., 451.0410, 450.9583, 445.2517],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([451.0330, 450.2747, 445.2517,  ..., 451.0410, 450.9583, 445.2517],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.6066],
             [112.1291],
             [112.0323],
             [112.0323]],

            [[112.6356],
             [112.6092],
             [112.6337],
             [112.6337]],

            [[111.6111],
             [111.4476],
             [112.3045],
             [112.3045]],

            ...,

            [[111.3981],
             [111.3981],
             [111.3981],
             [111.3981]],

            [[111.4495],
             [111.5129],
             [111.4185],
             [111.4489]],

            [[112.2814],
             [112.5711],
             [112.5978],
             [112.6260]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8002, 450.5121, 447.6676,  ..., 445.5925, 445.8297, 450.0763],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8002, 450.5121, 447.6676,  ..., 445.5925, 445.8297, 450.0763],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5244],
             [112.5242],
             [112.5270],
             [112.5270]],

            [[111.4823],
             [111.4823],
             [111.4823],
             [111.4823]],

            [[111.4823],
             [111.4823],
             [111.4823],
             [111.4823]],

            ...,

            [[112.4501],
             [112.4501],
             [112.4501],
             [112.4501]],

            [[112.5320],
             [112.5320],
             [112.5313],
             [112.5313]],

            [[111.5087],
             [111.5501],
             [111.5089],
             [111.5681]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.1026, 445.9293, 445.9293,  ..., 449.8006, 450.1265, 446.1358],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.1026, 445.9293, 445.9293,  ..., 449.8006, 450.1265, 446.1358],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.4451],
             [112.3781],
             [112.4545],
             [112.4558]],

            [[112.4493],
             [112.4493],
             [112.4507],
             [112.4507]],

            [[111.5554],
             [111.5869],
             [111.5534],
             [111.5534]],

            ...,

            [[112.4558],
             [112.4474],
             [112.4520],
             [112.4520]],

            [[112.4472],
             [112.4472],
             [112.4549],
             [112.4549]],

            [[111.5531],
             [111.5601],
             [111.5531],
             [111.5531]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.7336, 449.8000, 446.2491,  ..., 449.8072, 449.8041, 446.2194],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.7336, 449.8000, 446.2491,  ..., 449.8072, 449.8041, 446.2194],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.6780],
             [111.6135],
             [111.6872],
             [111.6113]],

            [[112.4200],
             [112.4231],
             [112.4203],
             [112.4190]],

            [[112.4211],
             [112.4211],
             [112.4180],
             [112.4180]],

            ...,

            [[111.6010],
             [111.6175],
             [111.6013],
             [111.6190]],

            [[112.4167],
             [112.4145],
             [112.4222],
             [112.4222]],

            [[111.6833],
             [111.6735],
             [112.0036],
             [112.0036]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.5900, 449.6824, 449.6783,  ..., 446.4388, 449.6754, 447.3640],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.5900, 449.6824, 449.6783,  ..., 446.4388, 449.6754, 447.3640],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3833],
             [112.3816],
             [112.3705],
             [112.3799]],

            [[111.6753],
             [111.6766],
             [111.6726],
             [111.7327]],

            [[112.3868],
             [112.2793],
             [112.3839],
             [112.3839]],

            ...,

            [[111.6633],
             [111.6633],
             [111.6633],
             [111.6633]],

            [[111.6652],
             [111.6704],
             [111.6652],
             [111.6705]],

            [[111.7519],
             [111.7519],
             [112.1193],
             [112.1193]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.5153, 446.7572, 449.4338,  ..., 446.6530, 446.6714, 447.7424],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.5153, 446.7572, 449.4338,  ..., 446.6530, 446.6714, 447.7424],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3408],
             [112.3378],
             [112.3418],
             [112.3418]],

            [[111.7290],
             [111.7290],
             [111.7290],
             [111.7290]],

            [[112.3313],
             [112.3415],
             [112.3410],
             [112.3418]],

            ...,

            [[111.7290],
             [111.7290],
             [111.7290],
             [111.7290]],

            [[111.7294],
             [111.7309],
             [111.7297],
             [111.7297]],

            [[112.3419],
             [112.3431],
             [112.3379],
             [112.3379]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3623, 446.9159, 449.3557,  ..., 446.9158, 446.9197, 449.3607],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3623, 446.9159, 449.3557,  ..., 446.9158, 446.9197, 449.3607],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3041],
             [112.2566],
             [112.3019],
             [112.3019]],

            [[111.7882],
             [111.8011],
             [111.7866],
             [111.7950]],

            [[112.3020],
             [112.2566],
             [112.2568],
             [112.3020]],

            ...,

            [[112.2984],
             [112.2457],
             [112.2641],
             [112.2044]],

            [[112.3040],
             [112.3043],
             [112.3043],
             [112.3051]],

            [[112.2634],
             [112.3046],
             [112.2961],
             [112.2916]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1645, 447.1709, 449.1174,  ..., 449.0126, 449.2177, 449.1556],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1645, 447.1709, 449.1174,  ..., 449.0126, 449.2177, 449.1556],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0256],
             [112.0256],
             [112.0150],
             [112.0150]],

            [[112.2524],
             [112.2323],
             [112.2497],
             [112.2534]],

            [[112.0714],
             [111.8678],
             [112.0421],
             [112.0421]],

            ...,

            [[111.8402],
             [111.8402],
             [111.8402],
             [111.8402]],

            [[111.8404],
             [111.8410],
             [111.8407],
             [111.8407]],

            [[111.8503],
             [112.0493],
             [111.8640],
             [111.9527]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0812, 448.9877, 448.0234,  ..., 447.3609, 447.3629, 447.7162],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0812, 448.9877, 448.0234,  ..., 447.3609, 447.3629, 447.7162],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1950],
             [112.1950],
             [112.1982],
             [112.1982]],

            [[112.1855],
             [112.1664],
             [112.0983],
             [112.1971]],

            [[111.8828],
             [111.8828],
             [111.8828],
             [111.8828]],

            ...,

            [[111.8953],
             [111.8953],
             [112.0405],
             [112.0405]],

            [[111.8876],
             [111.9452],
             [111.8871],
             [111.9420]],

            [[111.8829],
             [111.8833],
             [111.8829],
             [111.8829]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7866, 448.6473, 447.5312,  ..., 447.8716, 447.6618, 447.5321],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7866, 448.6473, 447.5312,  ..., 447.8716, 447.6618, 447.5321],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1742],
             [112.1743],
             [112.1744],
             [112.1741]],

            [[112.1581],
             [112.1748],
             [112.1771],
             [112.1771]],

            [[112.1738],
             [112.1738],
             [112.1694],
             [112.1694]],

            ...,

            [[112.1693],
             [112.1756],
             [112.1777],
             [112.1777]],

            [[112.0289],
             [112.1482],
             [112.1732],
             [112.1732]],

            [[112.1732],
             [112.1732],
             [112.1758],
             [112.1758]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6971, 448.6872, 448.6864,  ..., 448.7004, 448.5234, 448.6982],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6971, 448.6872, 448.6864,  ..., 448.7004, 448.5234, 448.6982],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9326],
             [111.9371],
             [111.9325],
             [111.9366]],

            [[112.1643],
             [112.1657],
             [112.1660],
             [112.1697]],

            [[112.1577],
             [112.1602],
             [112.1660],
             [112.1649]],

            ...,

            [[112.1709],
             [112.1690],
             [112.1695],
             [112.1696]],

            [[112.1184],
             [112.1625],
             [112.1633],
             [112.1226]],

            [[111.9324],
             [111.9324],
             [111.9324],
             [111.9324]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7388, 448.6657, 448.6488,  ..., 448.6791, 448.5668, 447.7296],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7388, 448.6657, 448.6488,  ..., 448.6791, 448.5668, 447.7296],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1578],
             [112.1647],
             [112.1592],
             [112.1608]],

            [[112.1117],
             [112.1570],
             [112.1541],
             [112.1541]],

            [[112.1549],
             [112.1594],
             [112.1602],
             [112.1581]],

            ...,

            [[112.1530],
             [112.1606],
             [112.1573],
             [112.1619]],

            [[112.1414],
             [112.1601],
             [112.1579],
             [112.1629]],

            [[112.1593],
             [112.1584],
             [112.1594],
             [112.1663]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6425, 448.5770, 448.6327,  ..., 448.6327, 448.6224, 448.6433],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6425, 448.5770, 448.6327,  ..., 448.6327, 448.6224, 448.6433],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9865],
             [111.9865],
             [111.9865],
             [111.9865]],

            [[111.9867],
             [111.9867],
             [111.9909],
             [111.9909]],

            [[112.1118],
             [112.1118],
             [112.1321],
             [112.1321]],

            ...,

            [[112.1433],
             [112.1433],
             [112.1451],
             [112.1451]],

            [[112.0041],
             [112.1117],
             [112.1326],
             [112.1406]],

            [[112.1289],
             [112.1289],
             [112.1360],
             [112.1360]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9460, 447.9553, 448.4877,  ..., 448.5769, 448.3889, 448.5298],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9460, 447.9553, 448.4877,  ..., 448.5769, 448.3889, 448.5298],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0078],
             [112.0119],
             [112.0078],
             [112.0119]],

            [[112.1261],
             [112.1326],
             [112.1306],
             [112.1359]],

            [[112.0078],
             [112.0078],
             [112.0082],
             [112.0078]],

            ...,

            [[112.1327],
             [112.1320],
             [112.1395],
             [112.1314]],

            [[112.1278],
             [112.1334],
             [112.1350],
             [112.1321]],

            [[112.1279],
             [112.1336],
             [112.1355],
             [112.1320]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0394, 448.5252, 448.0316,  ..., 448.5356, 448.5284, 448.5291],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0394, 448.5252, 448.0316,  ..., 448.5356, 448.5284, 448.5291],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0198e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1195],
             [112.1285],
             [112.1227],
             [112.1204]],

            [[112.1041],
             [112.0346],
             [112.1031],
             [112.0370]],

            [[112.0243],
             [112.0243],
             [112.0243],
             [112.0243]],

            ...,

            [[112.0956],
             [112.0956],
             [112.0988],
             [112.0988]],

            [[112.0243],
             [112.0243],
             [112.0243],
             [112.0243]],

            [[112.0243],
             [112.0243],
             [112.0243],
             [112.0243]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4910, 448.2788, 448.0973,  ..., 448.3889, 448.0972, 448.0972],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4910, 448.2788, 448.0973,  ..., 448.3889, 448.0972, 448.0972],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1214],
             [112.1214],
             [112.1306],
             [112.1216]],

            [[112.1182],
             [112.1236],
             [112.1253],
             [112.1204]],

            [[112.1237],
             [112.1252],
             [112.1238],
             [112.1244]],

            ...,

            [[112.0935],
             [112.1090],
             [112.0989],
             [112.1199]],

            [[112.1251],
             [112.1251],
             [112.1283],
             [112.1283]],

            [[112.0265],
             [112.0265],
             [112.0268],
             [112.0268]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4950, 448.4874, 448.4970,  ..., 448.4213, 448.5067, 448.1065],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4950, 448.4874, 448.4970,  ..., 448.4213, 448.5067, 448.1065],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0241],
             [112.0250],
             [112.0241],
             [112.0241]],

            [[112.0392],
             [112.1065],
             [112.0305],
             [112.1026]],

            [[112.0245],
             [112.0245],
             [112.0816],
             [112.0247]],

            ...,

            [[112.1218],
             [112.1218],
             [112.1267],
             [112.1267]],

            [[112.1166],
             [112.1230],
             [112.1286],
             [112.1196]],

            [[112.1207],
             [112.1228],
             [112.1227],
             [112.1343]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0974, 448.2789, 448.1552, 448.4998, 448.4926, 448.4668, 448.5163,
            448.2841, 448.0972, 448.1236, 448.3800, 448.0972, 448.4632, 448.4979,
            448.0972, 448.0973, 448.0973, 448.4932, 448.4196, 448.4867, 448.4923,
            448.4494, 448.4819, 448.1941, 448.4891, 448.5029, 448.4710, 448.3912,
            448.4783, 448.5490, 448.5229, 448.5145, 448.4906, 448.5045, 448.3362,
            448.5067, 448.0972, 448.0974, 448.4951, 448.4078, 448.5001, 448.4936,
            448.4086, 448.4698, 448.4563, 448.5012, 448.1026, 448.4747, 448.4788,
            448.0973, 448.0973, 448.1011, 448.5106, 448.4882, 448.4821, 448.4811,
            448.5096, 448.5050, 448.4813, 448.0967, 448.1935, 448.5114, 448.5009,
            448.3895, 448.2060, 448.0973, 448.4869, 448.0971, 448.1520, 448.4891,
            448.5193, 448.4952, 448.4875, 448.0972, 448.3515, 448.4811, 448.4850,
            448.4737, 448.5003, 448.4911, 448.2834, 448.0973, 448.5078, 448.0972,
            448.0969, 448.2492, 448.3948, 448.4851, 448.4929, 448.4998, 448.4731,
            448.2286, 448.5121, 448.0972, 448.4832, 448.0970, 448.1119, 448.4088,
            448.4936, 448.4762, 448.0973, 448.4926, 448.5008, 448.4034, 448.1976,
            448.0972, 448.0971, 448.0973, 448.0969, 448.4915, 448.4069, 448.1684,
            448.3180, 448.0973, 448.0973, 448.0972, 448.1741, 448.4878, 448.4037,
            448.0972, 448.0972, 448.0973, 448.0973, 448.4695, 448.4901, 448.4755,
            448.1000, 448.0968, 448.0973, 448.4420, 448.3821, 448.4754, 448.0973,
            448.4936, 448.5043, 448.4841, 448.4902, 448.4982, 448.4845, 448.0973,
            448.0973, 448.0973, 448.5491, 448.4941, 448.0987, 448.5141, 448.0994,
            448.0973, 448.4918, 448.0973, 448.4946, 448.4916, 448.4729, 448.5004,
            448.4796, 448.5006, 448.4879, 448.1641, 448.5486, 448.5195, 448.0972,
            448.4877, 448.0970, 448.4271, 448.2264, 448.0973, 448.5112, 448.3641,
            448.1477, 448.0972, 448.0972, 448.2382, 448.5055, 448.4999, 448.1174,
            448.4551, 448.0975, 448.1003, 448.4967, 448.4883, 448.0972, 448.0973,
            448.0973, 448.0973, 448.1115, 448.1876, 448.5143, 448.0972, 448.4796,
            448.4585, 448.4901, 448.0969, 448.0968, 448.2632, 448.5113, 448.5038,
            448.4933, 448.4913, 448.0973, 448.0973, 448.4203, 448.0973, 448.4855,
            448.4811, 448.1580, 448.4657, 448.0972, 448.1069, 448.3224, 448.0973,
            448.4857, 448.4795, 448.5035, 448.0970, 448.4631, 448.4756, 448.4927,
            448.4988, 448.1025, 448.1083, 448.4922, 448.2823, 448.4826, 448.0973,
            448.4902, 448.4036, 448.1616, 448.0973, 448.0973, 448.2849, 448.1902,
            448.5015, 448.4975, 448.2714, 448.0973, 448.4908, 448.4808, 448.5012,
            448.0972, 448.0969, 448.0973, 448.3789, 448.1144, 448.3521, 448.4793,
            448.1893, 448.5037, 448.1658, 448.4865, 448.4888, 448.4865, 448.0968,
            448.4886, 448.2952, 448.4827, 448.0973, 448.0973, 448.4715, 448.4926,
            448.4950, 448.0972, 448.4856, 448.4841, 448.0967, 448.2690, 448.4836,
            448.4787, 448.4786, 448.2822, 448.0968, 448.4968, 448.4979, 448.4970,
            448.0972, 448.4846, 448.4981, 448.5000, 448.0973, 448.3397, 448.4878,
            448.1270, 448.4869, 448.4410, 448.4877, 448.4854, 448.4894, 448.0973,
            448.4834, 448.4934, 448.3004, 448.0971, 448.5067, 448.4888, 448.3631,
            448.4381, 448.4909, 448.5115, 448.4977, 448.5008, 448.5083, 448.0973,
            448.4097, 448.0973, 448.3344, 448.0973, 448.0969, 448.5032, 448.0992,
            448.0973, 448.4955, 448.2039, 448.4871, 448.2762, 448.0973, 448.0968,
            448.4941, 448.4659, 448.4833, 448.4946, 448.4908, 448.0969, 448.0973,
            448.4577, 448.4998, 448.1450, 448.2814, 448.4924, 448.3874, 448.2383,
            448.4808, 448.0973, 448.4978, 448.2363, 448.4900, 448.1531, 448.0973,
            448.0973, 448.4822, 448.0970, 448.1101, 448.0968, 448.4931, 448.1013,
            448.0971, 448.0973, 448.4879, 448.1183, 448.4970, 448.4816, 448.4943,
            448.0970, 448.4872, 448.0984, 448.1063, 448.0964, 448.0973, 448.1254,
            448.1224, 448.0973, 448.5047, 448.5107, 448.3546, 448.4696, 448.4807,
            448.4787, 448.1008, 448.4650, 448.0970, 448.4214, 448.4999, 448.1593,
            448.5024, 448.1445, 448.0972, 448.0973, 448.4758, 448.0968, 448.4966,
            448.4866, 448.5141, 448.4924, 448.0967, 448.4802, 448.0972, 448.4767,
            448.4831, 448.4256, 448.1067, 448.5081, 448.4384, 448.4710, 448.0972,
            448.5038, 448.5485, 448.5002, 448.0973, 448.4932, 448.4742, 448.4935,
            448.0963, 448.4992, 448.5036, 448.4818, 448.4966, 448.4839, 448.4735,
            448.0973, 448.4825, 448.4807, 448.4189, 448.3983, 448.5060, 448.5092,
            448.4973, 448.1187, 448.0990, 448.1012, 448.4997, 448.5024, 448.0972,
            448.4015, 448.4672, 448.4741, 448.0999, 448.0972, 448.5492, 448.0969,
            448.4834, 448.2278, 448.4819, 448.4972, 448.0973, 448.4621, 448.5089,
            448.0973, 448.4881, 448.0968, 448.5030, 448.0973, 448.4858, 448.0973,
            448.4684, 448.4796, 448.4164, 448.0972, 448.4780, 448.4988, 448.4913,
            448.0973, 448.4054, 448.0972, 448.0973, 448.4911, 448.4974, 448.0969,
            448.4971, 448.5017, 448.0973, 448.4710, 448.4999, 448.4944, 448.4959,
            448.0973, 448.3442, 448.4807, 448.4924, 448.4556, 448.5037, 448.1013,
            448.3831, 448.4905, 448.4864, 448.5035, 448.4987, 448.0970, 448.4829,
            448.1258, 448.4549, 448.4995, 448.0969, 448.4867, 448.4928, 448.4824,
            448.5060, 448.1011, 448.5048, 448.4711, 448.2974, 448.4966, 448.0973,
            448.3208, 448.5181, 448.0973, 448.0971, 448.1114, 448.5104, 448.0970,
            448.5088, 448.3798, 448.4882, 448.4857, 448.4577, 448.3821, 448.5059,
            448.3642, 448.4751, 448.4931, 448.2330, 448.4343, 448.0973, 448.3433,
            448.4394, 448.4815, 448.4728, 448.5003, 448.0973, 448.5159, 448.0971,
            448.4879, 448.0973, 448.0972, 448.4793, 448.3116, 448.5052, 448.1910,
            448.4188, 448.1779, 448.4624, 448.0964, 448.2780, 448.5183, 448.0970,
            448.0971, 448.4633, 448.4857, 448.4936, 448.5067, 448.4041, 448.4883,
            448.4981, 448.4849, 448.2953, 448.4715, 448.4942, 448.5038, 448.3278,
            448.4877, 448.4708, 448.0972, 448.4997, 448.1937, 448.0971, 448.4991,
            448.4810, 448.4789, 448.0986, 448.2815, 448.5151, 448.4941, 448.4706,
            448.2206, 448.4819, 448.5004, 448.0971, 448.5078, 448.2822, 448.0973,
            448.4940, 448.3195, 448.5254, 448.5482, 448.5200, 448.5071, 448.4586,
            448.4983, 448.4937, 448.0969, 448.4866, 448.4839, 448.0964, 448.5028,
            448.0970, 448.0973, 448.4847, 448.0972, 448.4808, 448.4909, 448.4855,
            448.4868, 448.4888, 448.4676, 448.0969, 448.0973, 448.0972, 448.4859,
            448.4949, 448.1821, 448.4961, 448.4858, 448.5020, 448.0971, 448.2627,
            448.4888, 448.4887, 448.0973, 448.1848, 448.3674, 448.4919, 448.4966,
            448.0973, 448.0973, 448.1147, 448.4874, 448.4804, 448.4987, 448.4913,
            448.5067, 448.4723, 448.1042, 448.4848, 448.2908, 448.4928, 448.4770,
            448.5481, 448.0973, 448.0971, 448.4960, 448.4935, 448.1012, 448.5030,
            448.4597, 448.4987, 448.4841, 448.4265, 448.0992, 448.5045, 448.0965,
            448.3698, 448.4784, 448.5491, 448.0966, 448.0973, 448.4703, 448.4815,
            448.4348, 448.0970, 448.4642, 448.5180, 448.0973, 448.2189, 448.4969,
            448.1032, 448.5007, 448.5121, 448.4531, 448.0973, 448.4930, 448.0973,
            448.2806, 448.2749, 448.0967, 448.4899, 448.0968, 448.4886, 448.1127,
            448.4620, 448.4927, 448.4956, 448.3389, 448.4852, 448.4813, 448.5108,
            448.3078, 448.4668, 448.4999, 448.4673, 448.4910, 448.2531, 448.2671,
            448.0973, 448.0965, 448.0972, 448.0970, 448.4886, 448.4885, 448.3123,
            448.4864, 448.4975, 448.4434, 448.4961, 448.4944, 448.1045, 448.4867,
            448.0972, 448.0973, 448.3766, 448.4950, 448.3691, 448.4888, 448.5006,
            448.0969, 448.4368, 448.5094, 448.4933, 448.1682, 448.5134, 448.1678,
            448.5005, 448.1591, 448.0972, 448.0973, 448.4980, 448.4970, 448.0973,
            448.4894, 448.5029, 448.5168, 448.0973, 448.4891, 448.0988, 448.4941,
            448.4945, 448.4969, 448.4709, 448.0971, 448.5007, 448.2521, 448.0973,
            448.5119, 448.0970, 448.4935, 448.4961, 448.4223, 448.4754, 448.4901,
            448.2690, 448.4695, 448.0973, 448.0973, 448.0973, 448.2462, 448.0973,
            448.4932, 448.4727, 448.4862, 448.0972, 448.5201, 448.5002, 448.0972,
            448.4976, 448.5453, 448.4849, 448.0972, 448.0973, 448.0972, 448.3891,
            448.4471, 448.5152, 448.4379, 448.4979, 448.0972, 448.4962, 448.5054,
            448.0971, 448.5020, 448.4940, 448.0967, 448.4536, 448.2640, 448.4878,
            448.5026, 448.3738, 448.4846, 448.3725, 448.4865, 448.4689, 448.4953,
            448.0969, 448.0972, 448.5089, 448.4210, 448.0973, 448.1820, 448.2835,
            448.4925, 448.1014, 448.4142, 448.5052, 448.5176, 448.4562, 448.4971,
            448.4943, 448.4916, 448.0973, 448.0972, 448.4943, 448.0973, 448.4966,
            448.0972, 448.4842, 448.5006, 448.0971, 448.0973, 448.5241, 448.4023,
            448.0973, 448.4564, 448.4998, 448.4858, 448.0973, 448.2875, 448.1783,
            448.0972, 448.4885, 448.4960, 448.0986, 448.5006, 448.0972, 448.4962,
            448.4979, 448.4872, 448.4939, 448.4895, 448.4819, 448.3631, 448.0973,
            448.4840, 448.4893, 448.4750, 448.4622, 448.4751, 448.5184, 448.0973,
            448.0973, 448.3334, 448.5089, 448.4805, 448.0973, 448.0973, 448.0972,
            448.0970, 448.2059, 448.3964, 448.5056, 448.4562, 448.1055, 448.3430,
            448.5067, 448.5238, 448.0969, 448.3939, 448.0967, 448.4703, 448.0973,
            448.4983, 448.4868, 448.0973, 448.0973, 448.4185, 448.4769, 448.0973,
            448.0970, 448.0976, 448.4794, 448.4968, 448.3871, 448.4858, 448.0988,
            448.0966, 448.4639, 448.4743, 448.4867, 448.5038, 448.4850, 448.4987,
            448.1031, 448.0972, 448.4752, 448.4852, 448.0967, 448.4833, 448.4969,
            448.0970, 448.4985, 448.0972, 448.4690, 448.0973, 448.0969, 448.4978,
            448.4345, 448.4924, 448.0973, 448.1844, 448.4916, 448.0973, 448.4864,
            448.4971, 448.0971, 448.4835, 448.4730, 448.4874, 448.0973, 448.4744,
            448.0976, 448.4990, 448.0969, 448.0972, 448.0972, 448.2913, 448.4752,
            448.0970, 448.1718, 448.4909, 448.0973, 448.4836, 448.0973, 448.4988,
            448.0973, 448.0999, 448.4805, 448.4883, 448.4987, 448.1173, 448.4971,
            448.4878, 448.5005], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0974, 448.2789, 448.1552, 448.4998, 448.4926, 448.4668, 448.5163,
        448.2841, 448.0972, 448.1236, 448.3800, 448.0972, 448.4632, 448.4979,
        448.0972, 448.0973, 448.0973, 448.4932, 448.4196, 448.4867, 448.4923,
        448.4494, 448.4819, 448.1941, 448.4891, 448.5029, 448.4710, 448.3912,
        448.4783, 448.5490, 448.5229, 448.5145, 448.4906, 448.5045, 448.3362,
        448.5067, 448.0972, 448.0974, 448.4951, 448.4078, 448.5001, 448.4936,
        448.4086, 448.4698, 448.4563, 448.5012, 448.1026, 448.4747, 448.4788,
        448.0973, 448.0973, 448.1011, 448.5106, 448.4882, 448.4821, 448.4811,
        448.5096, 448.5050, 448.4813, 448.0967, 448.1935, 448.5114, 448.5009,
        448.3895, 448.2060, 448.0973, 448.4869, 448.0971, 448.1520, 448.4891,
        448.5193, 448.4952, 448.4875, 448.0972, 448.3515, 448.4811, 448.4850,
        448.4737, 448.5003, 448.4911, 448.2834, 448.0973, 448.5078, 448.0972,
        448.0969, 448.2492, 448.3948, 448.4851, 448.4929, 448.4998, 448.4731,
        448.2286, 448.5121, 448.0972, 448.4832, 448.0970, 448.1119, 448.4088,
        448.4936, 448.4762, 448.0973, 448.4926, 448.5008, 448.4034, 448.1976,
        448.0972, 448.0971, 448.0973, 448.0969, 448.4915, 448.4069, 448.1684,
        448.3180, 448.0973, 448.0973, 448.0972, 448.1741, 448.4878, 448.4037,
        448.0972, 448.0972, 448.0973, 448.0973, 448.4695, 448.4901, 448.4755,
        448.1000, 448.0968, 448.0973, 448.4420, 448.3821, 448.4754, 448.0973,
        448.4936, 448.5043, 448.4841, 448.4902, 448.4982, 448.4845, 448.0973,
        448.0973, 448.0973, 448.5491, 448.4941, 448.0987, 448.5141, 448.0994,
        448.0973, 448.4918, 448.0973, 448.4946, 448.4916, 448.4729, 448.5004,
        448.4796, 448.5006, 448.4879, 448.1641, 448.5486, 448.5195, 448.0972,
        448.4877, 448.0970, 448.4271, 448.2264, 448.0973, 448.5112, 448.3641,
        448.1477, 448.0972, 448.0972, 448.2382, 448.5055, 448.4999, 448.1174,
        448.4551, 448.0975, 448.1003, 448.4967, 448.4883, 448.0972, 448.0973,
        448.0973, 448.0973, 448.1115, 448.1876, 448.5143, 448.0972, 448.4796,
        448.4585, 448.4901, 448.0969, 448.0968, 448.2632, 448.5113, 448.5038,
        448.4933, 448.4913, 448.0973, 448.0973, 448.4203, 448.0973, 448.4855,
        448.4811, 448.1580, 448.4657, 448.0972, 448.1069, 448.3224, 448.0973,
        448.4857, 448.4795, 448.5035, 448.0970, 448.4631, 448.4756, 448.4927,
        448.4988, 448.1025, 448.1083, 448.4922, 448.2823, 448.4826, 448.0973,
        448.4902, 448.4036, 448.1616, 448.0973, 448.0973, 448.2849, 448.1902,
        448.5015, 448.4975, 448.2714, 448.0973, 448.4908, 448.4808, 448.5012,
        448.0972, 448.0969, 448.0973, 448.3789, 448.1144, 448.3521, 448.4793,
        448.1893, 448.5037, 448.1658, 448.4865, 448.4888, 448.4865, 448.0968,
        448.4886, 448.2952, 448.4827, 448.0973, 448.0973, 448.4715, 448.4926,
        448.4950, 448.0972, 448.4856, 448.4841, 448.0967, 448.2690, 448.4836,
        448.4787, 448.4786, 448.2822, 448.0968, 448.4968, 448.4979, 448.4970,
        448.0972, 448.4846, 448.4981, 448.5000, 448.0973, 448.3397, 448.4878,
        448.1270, 448.4869, 448.4410, 448.4877, 448.4854, 448.4894, 448.0973,
        448.4834, 448.4934, 448.3004, 448.0971, 448.5067, 448.4888, 448.3631,
        448.4381, 448.4909, 448.5115, 448.4977, 448.5008, 448.5083, 448.0973,
        448.4097, 448.0973, 448.3344, 448.0973, 448.0969, 448.5032, 448.0992,
        448.0973, 448.4955, 448.2039, 448.4871, 448.2762, 448.0973, 448.0968,
        448.4941, 448.4659, 448.4833, 448.4946, 448.4908, 448.0969, 448.0973,
        448.4577, 448.4998, 448.1450, 448.2814, 448.4924, 448.3874, 448.2383,
        448.4808, 448.0973, 448.4978, 448.2363, 448.4900, 448.1531, 448.0973,
        448.0973, 448.4822, 448.0970, 448.1101, 448.0968, 448.4931, 448.1013,
        448.0971, 448.0973, 448.4879, 448.1183, 448.4970, 448.4816, 448.4943,
        448.0970, 448.4872, 448.0984, 448.1063, 448.0964, 448.0973, 448.1254,
        448.1224, 448.0973, 448.5047, 448.5107, 448.3546, 448.4696, 448.4807,
        448.4787, 448.1008, 448.4650, 448.0970, 448.4214, 448.4999, 448.1593,
        448.5024, 448.1445, 448.0972, 448.0973, 448.4758, 448.0968, 448.4966,
        448.4866, 448.5141, 448.4924, 448.0967, 448.4802, 448.0972, 448.4767,
        448.4831, 448.4256, 448.1067, 448.5081, 448.4384, 448.4710, 448.0972,
        448.5038, 448.5485, 448.5002, 448.0973, 448.4932, 448.4742, 448.4935,
        448.0963, 448.4992, 448.5036, 448.4818, 448.4966, 448.4839, 448.4735,
        448.0973, 448.4825, 448.4807, 448.4189, 448.3983, 448.5060, 448.5092,
        448.4973, 448.1187, 448.0990, 448.1012, 448.4997, 448.5024, 448.0972,
        448.4015, 448.4672, 448.4741, 448.0999, 448.0972, 448.5492, 448.0969,
        448.4834, 448.2278, 448.4819, 448.4972, 448.0973, 448.4621, 448.5089,
        448.0973, 448.4881, 448.0968, 448.5030, 448.0973, 448.4858, 448.0973,
        448.4684, 448.4796, 448.4164, 448.0972, 448.4780, 448.4988, 448.4913,
        448.0973, 448.4054, 448.0972, 448.0973, 448.4911, 448.4974, 448.0969,
        448.4971, 448.5017, 448.0973, 448.4710, 448.4999, 448.4944, 448.4959,
        448.0973, 448.3442, 448.4807, 448.4924, 448.4556, 448.5037, 448.1013,
        448.3831, 448.4905, 448.4864, 448.5035, 448.4987, 448.0970, 448.4829,
        448.1258, 448.4549, 448.4995, 448.0969, 448.4867, 448.4928, 448.4824,
        448.5060, 448.1011, 448.5048, 448.4711, 448.2974, 448.4966, 448.0973,
        448.3208, 448.5181, 448.0973, 448.0971, 448.1114, 448.5104, 448.0970,
        448.5088, 448.3798, 448.4882, 448.4857, 448.4577, 448.3821, 448.5059,
        448.3642, 448.4751, 448.4931, 448.2330, 448.4343, 448.0973, 448.3433,
        448.4394, 448.4815, 448.4728, 448.5003, 448.0973, 448.5159, 448.0971,
        448.4879, 448.0973, 448.0972, 448.4793, 448.3116, 448.5052, 448.1910,
        448.4188, 448.1779, 448.4624, 448.0964, 448.2780, 448.5183, 448.0970,
        448.0971, 448.4633, 448.4857, 448.4936, 448.5067, 448.4041, 448.4883,
        448.4981, 448.4849, 448.2953, 448.4715, 448.4942, 448.5038, 448.3278,
        448.4877, 448.4708, 448.0972, 448.4997, 448.1937, 448.0971, 448.4991,
        448.4810, 448.4789, 448.0986, 448.2815, 448.5151, 448.4941, 448.4706,
        448.2206, 448.4819, 448.5004, 448.0971, 448.5078, 448.2822, 448.0973,
        448.4940, 448.3195, 448.5254, 448.5482, 448.5200, 448.5071, 448.4586,
        448.4983, 448.4937, 448.0969, 448.4866, 448.4839, 448.0964, 448.5028,
        448.0970, 448.0973, 448.4847, 448.0972, 448.4808, 448.4909, 448.4855,
        448.4868, 448.4888, 448.4676, 448.0969, 448.0973, 448.0972, 448.4859,
        448.4949, 448.1821, 448.4961, 448.4858, 448.5020, 448.0971, 448.2627,
        448.4888, 448.4887, 448.0973, 448.1848, 448.3674, 448.4919, 448.4966,
        448.0973, 448.0973, 448.1147, 448.4874, 448.4804, 448.4987, 448.4913,
        448.5067, 448.4723, 448.1042, 448.4848, 448.2908, 448.4928, 448.4770,
        448.5481, 448.0973, 448.0971, 448.4960, 448.4935, 448.1012, 448.5030,
        448.4597, 448.4987, 448.4841, 448.4265, 448.0992, 448.5045, 448.0965,
        448.3698, 448.4784, 448.5491, 448.0966, 448.0973, 448.4703, 448.4815,
        448.4348, 448.0970, 448.4642, 448.5180, 448.0973, 448.2189, 448.4969,
        448.1032, 448.5007, 448.5121, 448.4531, 448.0973, 448.4930, 448.0973,
        448.2806, 448.2749, 448.0967, 448.4899, 448.0968, 448.4886, 448.1127,
        448.4620, 448.4927, 448.4956, 448.3389, 448.4852, 448.4813, 448.5108,
        448.3078, 448.4668, 448.4999, 448.4673, 448.4910, 448.2531, 448.2671,
        448.0973, 448.0965, 448.0972, 448.0970, 448.4886, 448.4885, 448.3123,
        448.4864, 448.4975, 448.4434, 448.4961, 448.4944, 448.1045, 448.4867,
        448.0972, 448.0973, 448.3766, 448.4950, 448.3691, 448.4888, 448.5006,
        448.0969, 448.4368, 448.5094, 448.4933, 448.1682, 448.5134, 448.1678,
        448.5005, 448.1591, 448.0972, 448.0973, 448.4980, 448.4970, 448.0973,
        448.4894, 448.5029, 448.5168, 448.0973, 448.4891, 448.0988, 448.4941,
        448.4945, 448.4969, 448.4709, 448.0971, 448.5007, 448.2521, 448.0973,
        448.5119, 448.0970, 448.4935, 448.4961, 448.4223, 448.4754, 448.4901,
        448.2690, 448.4695, 448.0973, 448.0973, 448.0973, 448.2462, 448.0973,
        448.4932, 448.4727, 448.4862, 448.0972, 448.5201, 448.5002, 448.0972,
        448.4976, 448.5453, 448.4849, 448.0972, 448.0973, 448.0972, 448.3891,
        448.4471, 448.5152, 448.4379, 448.4979, 448.0972, 448.4962, 448.5054,
        448.0971, 448.5020, 448.4940, 448.0967, 448.4536, 448.2640, 448.4878,
        448.5026, 448.3738, 448.4846, 448.3725, 448.4865, 448.4689, 448.4953,
        448.0969, 448.0972, 448.5089, 448.4210, 448.0973, 448.1820, 448.2835,
        448.4925, 448.1014, 448.4142, 448.5052, 448.5176, 448.4562, 448.4971,
        448.4943, 448.4916, 448.0973, 448.0972, 448.4943, 448.0973, 448.4966,
        448.0972, 448.4842, 448.5006, 448.0971, 448.0973, 448.5241, 448.4023,
        448.0973, 448.4564, 448.4998, 448.4858, 448.0973, 448.2875, 448.1783,
        448.0972, 448.4885, 448.4960, 448.0986, 448.5006, 448.0972, 448.4962,
        448.4979, 448.4872, 448.4939, 448.4895, 448.4819, 448.3631, 448.0973,
        448.4840, 448.4893, 448.4750, 448.4622, 448.4751, 448.5184, 448.0973,
        448.0973, 448.3334, 448.5089, 448.4805, 448.0973, 448.0973, 448.0972,
        448.0970, 448.2059, 448.3964, 448.5056, 448.4562, 448.1055, 448.3430,
        448.5067, 448.5238, 448.0969, 448.3939, 448.0967, 448.4703, 448.0973,
        448.4983, 448.4868, 448.0973, 448.0973, 448.4185, 448.4769, 448.0973,
        448.0970, 448.0976, 448.4794, 448.4968, 448.3871, 448.4858, 448.0988,
        448.0966, 448.4639, 448.4743, 448.4867, 448.5038, 448.4850, 448.4987,
        448.1031, 448.0972, 448.4752, 448.4852, 448.0967, 448.4833, 448.4969,
        448.0970, 448.4985, 448.0972, 448.4690, 448.0973, 448.0969, 448.4978,
        448.4345, 448.4924, 448.0973, 448.1844, 448.4916, 448.0973, 448.4864,
        448.4971, 448.0971, 448.4835, 448.4730, 448.4874, 448.0973, 448.4744,
        448.0976, 448.4990, 448.0969, 448.0972, 448.0972, 448.2913, 448.4752,
        448.0970, 448.1718, 448.4909, 448.0973, 448.4836, 448.0973, 448.4988,
        448.0973, 448.0999, 448.4805, 448.4883, 448.4987, 448.1173, 448.4971,
        448.4878, 448.5005], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([400.2382], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1176],
             [112.1176],
             [112.1220],
             [112.1220]],

            [[112.1241],
             [112.1241],
             [112.1240],
             [112.1240]],

            [[112.0589],
             [112.0372],
             [112.0994],
             [112.1131]],

            ...,

            [[112.1224],
             [112.1306],
             [112.1204],
             [112.1224]],

            [[112.0243],
             [112.0242],
             [112.0243],
             [112.0243]],

            [[112.0705],
             [112.1167],
             [112.0744],
             [112.1169]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4792, 448.4962, 448.3087,  ..., 448.4958, 448.0970, 448.3784],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4792, 448.4962, 448.3087,  ..., 448.4958, 448.0970, 448.3784],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0976],
             [112.0966],
             [112.1006],
             [112.1040]],

            [[112.0998],
             [112.0998],
             [112.1059],
             [112.1059]],

            [[112.0415],
             [112.0424],
             [112.0424],
             [112.0415]],

            ...,

            [[112.1010],
             [112.0981],
             [112.0987],
             [112.1060]],

            [[112.1048],
             [112.1094],
             [112.1051],
             [112.1021]],

            [[112.0400],
             [112.0400],
             [112.0856],
             [112.0856]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3988, 448.4114, 448.1678,  ..., 448.4037, 448.4214, 448.2513],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3988, 448.4114, 448.1678,  ..., 448.4037, 448.4214, 448.2513],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0582],
             [112.0582],
             [112.0581],
             [112.0581]],

            [[112.0582],
             [112.0582],
             [112.0582],
             [112.0582]],

            [[112.0817],
             [112.0851],
             [112.0794],
             [112.0805]],

            ...,

            [[112.0582],
             [112.0582],
             [112.0582],
             [112.0582]],

            [[112.0765],
             [112.0828],
             [112.0876],
             [112.0802]],

            [[112.0737],
             [112.0805],
             [112.0807],
             [112.0685]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2325, 448.2328, 448.3267,  ..., 448.2328, 448.3271, 448.3033],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2325, 448.2328, 448.3267,  ..., 448.2328, 448.3271, 448.3033],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0547],
             [112.0609],
             [112.0612],
             [112.0612]],

            [[112.0553],
             [112.0553],
             [112.0590],
             [112.0590]],

            [[112.0869],
             [112.0745],
             [112.0885],
             [112.0799]],

            ...,

            [[112.0891],
             [112.0871],
             [112.0872],
             [112.0718]],

            [[112.0614],
             [112.0614],
             [112.0690],
             [112.0690]],

            [[112.0630],
             [112.0630],
             [112.0755],
             [112.0755]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2381, 448.2285, 448.3299,  ..., 448.3350, 448.2609, 448.2771],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2381, 448.2285, 448.3299,  ..., 448.3350, 448.2609, 448.2771],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1162],
             [112.1162],
             [112.1162],
             [112.1162]],

            [[112.0413],
             [112.0470],
             [112.0453],
             [112.0450]],

            [[112.0447],
             [112.0475],
             [112.0500],
             [112.0500]],

            ...,

            [[112.0620],
             [112.0620],
             [112.0568],
             [112.0568]],

            [[112.0465],
             [112.0465],
             [112.0513],
             [112.0513]],

            [[112.0452],
             [112.0510],
             [112.0569],
             [112.0569]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4648, 448.1786, 448.1923,  ..., 448.2376, 448.1955, 448.2101],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4648, 448.1786, 448.1923,  ..., 448.2376, 448.1955, 448.2101],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0370],
             [112.0366],
             [112.0418],
             [112.0417]],

            [[112.0450],
             [112.0440],
             [112.0567],
             [112.0567]],

            [[112.1088],
             [112.1088],
             [112.1099],
             [112.1099]],

            ...,

            [[112.0395],
             [112.0477],
             [112.0398],
             [112.0398]],

            [[112.0372],
             [112.0419],
             [112.0373],
             [112.0439]],

            [[112.0444],
             [112.0364],
             [112.0390],
             [112.0376]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1571, 448.2025, 448.4374,  ..., 448.1668, 448.1603, 448.1574],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1571, 448.2025, 448.4374,  ..., 448.1668, 448.1603, 448.1574],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0181],
             [112.0181],
             [112.0213],
             [112.0213]],

            [[112.0992],
             [112.0982],
             [112.0211],
             [112.0211]],

            [[112.0215],
             [112.0215],
             [112.0238],
             [112.0238]],

            ...,

            [[112.0202],
             [112.0214],
             [112.0212],
             [112.0213]],

            [[112.0214],
             [112.0214],
             [112.0280],
             [112.0280]],

            [[112.0230],
             [112.0249],
             [112.0194],
             [112.0224]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0788, 448.2397, 448.0906,  ..., 448.0841, 448.0988, 448.0897],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0788, 448.2397, 448.0906,  ..., 448.0841, 448.0988, 448.0897],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1557],
             [112.1557],
             [112.1555],
             [112.1555]],

            [[111.9930],
             [111.9793],
             [112.0078],
             [111.9804]],

            [[111.9860],
             [111.9860],
             [111.9987],
             [111.9987]],

            ...,

            [[111.9799],
             [111.9922],
             [112.0014],
             [111.9798]],

            [[111.9866],
             [111.9831],
             [111.9818],
             [111.9828]],

            [[111.9832],
             [111.9790],
             [111.9790],
             [111.9832]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6224, 447.9604, 447.9694,  ..., 447.9531, 447.9343, 447.9244],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6224, 447.9604, 447.9694,  ..., 447.9531, 447.9343, 447.9244],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9424],
             [111.9461],
             [111.9437],
             [111.9551]],

            [[112.1700],
             [112.1663],
             [112.1692],
             [112.1692]],

            [[112.0580],
             [112.1100],
             [112.1451],
             [111.9559]],

            ...,

            [[111.9443],
             [111.9438],
             [111.9434],
             [111.9431]],

            [[111.9412],
             [111.9452],
             [111.9441],
             [111.9441]],

            [[111.9440],
             [112.0388],
             [112.0682],
             [111.9425]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7874, 448.6747, 448.2690,  ..., 447.7745, 447.7745, 447.9935],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7874, 448.6747, 448.2690,  ..., 447.7745, 447.7745, 447.9935],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8923],
             [111.8923],
             [111.8965],
             [111.8965]],

            [[111.9080],
             [111.8956],
             [111.8964],
             [111.8964]],

            [[111.8962],
             [111.8962],
             [111.9005],
             [111.9005]],

            ...,

            [[111.8942],
             [111.9061],
             [111.8969],
             [111.8974]],

            [[111.8964],
             [111.8982],
             [111.8925],
             [111.8965]],

            [[112.1864],
             [112.1864],
             [112.1864],
             [112.1864]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5775, 447.5965, 447.5933,  ..., 447.5947, 447.5836, 448.7455],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5775, 447.5965, 447.5933,  ..., 447.5947, 447.5836, 448.7455],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2017],
             [112.1992],
             [112.2016],
             [112.1987]],

            [[111.8442],
             [111.8470],
             [111.8457],
             [111.8457]],

            [[111.8472],
             [111.8459],
             [111.8471],
             [111.8546]],

            ...,

            [[111.8467],
             [111.8481],
             [111.8469],
             [111.8483]],

            [[112.2018],
             [112.1998],
             [112.1999],
             [112.2021]],

            [[111.8496],
             [111.8521],
             [111.8504],
             [111.8509]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8012, 447.3826, 447.3949,  ..., 447.3899, 448.8036, 447.4030],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8012, 447.3826, 447.3949,  ..., 447.3899, 448.8036, 447.4030],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2123],
             [112.2119],
             [112.2122],
             [112.2122]],

            [[111.8044],
             [111.8046],
             [111.8022],
             [111.8161]],

            [[112.1996],
             [112.1221],
             [112.1963],
             [112.1963]],

            ...,

            [[112.1773],
             [111.9728],
             [111.9691],
             [111.9691]],

            [[112.1654],
             [111.9172],
             [112.1672],
             [112.1672]],

            [[111.7981],
             [111.7981],
             [111.8030],
             [111.8030]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8487, 447.2272, 448.7144,  ..., 448.0883, 448.4171, 447.2022],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8487, 447.2272, 448.7144,  ..., 448.0883, 448.4171, 447.2022],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7693],
             [111.7669],
             [111.7682],
             [111.7678]],

            [[112.2153],
             [112.2016],
             [112.2157],
             [112.2130]],

            [[111.7587],
             [111.7648],
             [111.7611],
             [111.7656]],

            ...,

            [[111.7996],
             [111.7612],
             [111.7774],
             [111.7774]],

            [[111.7652],
             [111.7647],
             [111.7711],
             [111.7624]],

            [[111.7615],
             [111.7664],
             [111.7644],
             [111.7626]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.0722, 448.8457, 447.0501,  ..., 447.1155, 447.0633, 447.0548],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.0722, 448.8457, 447.0501,  ..., 447.1155, 447.0633, 447.0548],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7296],
             [111.7269],
             [111.7295],
             [111.7345]],

            [[111.7230],
             [111.7287],
             [111.7404],
             [111.7285]],

            [[111.7223],
             [111.7944],
             [111.8501],
             [111.7235]],

            ...,

            [[111.7261],
             [111.7257],
             [111.7303],
             [111.7303]],

            [[111.7290],
             [111.7547],
             [111.7204],
             [111.7298]],

            [[111.7269],
             [111.7299],
             [111.7252],
             [111.7288]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9205, 446.9205, 447.0903,  ..., 446.9125, 446.9339, 446.9108],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9205, 446.9205, 447.0903,  ..., 446.9125, 446.9339, 446.9108],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7363],
             [111.7434],
             [111.7413],
             [111.7427]],

            [[112.2087],
             [112.1914],
             [112.2064],
             [112.1760]],

            [[111.7378],
             [111.7378],
             [111.7428],
             [111.7428]],

            ...,

            [[112.2068],
             [112.1756],
             [112.1990],
             [112.1990]],

            [[112.1875],
             [112.0433],
             [112.1985],
             [112.1265]],

            [[111.7327],
             [111.7411],
             [111.7328],
             [111.7419]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9638, 448.7825, 446.9613,  ..., 448.7805, 448.5558, 446.9484],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9638, 448.7825, 446.9613,  ..., 448.7805, 448.5558, 446.9484],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1829],
             [112.1829],
             [112.0699],
             [112.0699]],

            [[112.1236],
             [112.1833],
             [112.1925],
             [112.0734]],

            [[111.7605],
             [111.7605],
             [111.7575],
             [111.7639]],

            ...,

            [[111.7578],
             [111.7639],
             [111.7573],
             [111.7621]],

            [[111.7609],
             [111.7578],
             [111.7682],
             [111.7605]],

            [[111.7580],
             [111.7619],
             [111.7559],
             [111.7599]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5057, 448.5727, 447.0424,  ..., 447.0410, 447.0475, 447.0356],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5057, 448.5727, 447.0424,  ..., 447.0410, 447.0475, 447.0356],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7817],
             [111.7784],
             [111.7770],
             [111.7736]],

            [[111.7786],
             [111.7786],
             [111.7790],
             [111.7790]],

            [[112.2041],
             [112.2041],
             [112.2041],
             [112.2041]],

            ...,

            [[111.7724],
             [111.7769],
             [111.7780],
             [111.7780]],

            [[112.2039],
             [112.2039],
             [112.2039],
             [112.2039]],

            [[111.7723],
             [111.7921],
             [111.8147],
             [111.7719]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.1107, 447.1153, 448.8166,  ..., 447.1053, 448.8156, 447.1510],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.1107, 447.1153, 448.8166,  ..., 447.1053, 448.8156, 447.1510],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7796],
             [111.7841],
             [111.7826],
             [111.7876]],

            [[111.7829],
             [111.7896],
             [111.7890],
             [111.7891]],

            [[111.7991],
             [111.7853],
             [111.7902],
             [111.7902]],

            ...,

            [[111.7887],
             [111.7887],
             [111.7985],
             [111.7985]],

            [[111.7795],
             [111.7872],
             [111.7791],
             [111.7874]],

            [[112.2063],
             [112.2062],
             [112.2063],
             [112.2063]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.1339, 447.1505, 447.1649,  ..., 447.1744, 447.1332, 448.8252],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.1339, 447.1505, 447.1649,  ..., 447.1744, 447.1332, 448.8252],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0109e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0397],
             [112.1844],
             [112.1773],
             [112.0162]],

            [[112.2053],
             [112.2036],
             [112.2050],
             [112.2050]],

            [[111.8124],
             [111.8057],
             [111.8072],
             [111.8127]],

            ...,

            [[111.8055],
             [111.8088],
             [111.8129],
             [111.8129]],

            [[111.8190],
             [111.8190],
             [111.8216],
             [111.8216]],

            [[111.8042],
             [111.8121],
             [111.8086],
             [111.8095]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4176, 448.8188, 447.2381,  ..., 447.2401, 447.2812, 447.2344],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4176, 448.8188, 447.2381,  ..., 447.2401, 447.2812, 447.2344],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8146],
             [111.8146],
             [111.8244],
             [111.8244]],

            [[111.8129],
             [111.8151],
             [111.8198],
             [111.8099]],

            [[111.8138],
             [111.8090],
             [111.8151],
             [111.8082]],

            ...,

            [[112.2048],
             [112.2054],
             [112.2054],
             [112.2042]],

            [[111.8112],
             [111.8160],
             [111.8117],
             [111.8175]],

            [[111.8117],
             [111.8149],
             [111.8084],
             [111.8126]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2779, 447.2577, 447.2461,  ..., 448.8198, 447.2564, 447.2475],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2779, 447.2577, 447.2461,  ..., 448.8198, 447.2564, 447.2475],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8148],
             [111.8090],
             [111.8131],
             [111.8067]],

            [[111.8124],
             [111.8067],
             [111.8088],
             [111.8115]],

            [[111.8825],
             [111.8825],
             [111.8097],
             [111.8097]],

            ...,

            [[111.8093],
             [111.8093],
             [111.8134],
             [111.8134]],

            [[111.8134],
             [111.8110],
             [111.8188],
             [111.8188]],

            [[112.0261],
             [112.0261],
             [111.8521],
             [111.8521]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2437, 447.2393, 447.3844, 447.2467, 447.2621, 447.2760, 448.8164,
            448.0554, 448.7716, 448.8170, 448.8213, 448.8032, 447.2396, 448.8154,
            447.2606, 448.4214, 448.7626, 447.2840, 447.2352, 448.4350, 448.7043,
            447.2443, 448.5593, 447.2594, 447.2488, 447.2581, 448.8218, 447.2610,
            448.7011, 447.2732, 448.1927, 447.2606, 447.2645, 448.8220, 447.2761,
            448.0104, 447.2404, 447.1294, 447.2601, 448.5210, 447.2507, 447.8842,
            447.6967, 447.2765, 447.2679, 448.7736, 448.7781, 448.8212, 448.8140,
            447.2512, 448.4030, 447.2317, 448.6945, 447.2780, 447.7851, 447.2491,
            447.9243, 447.2460, 448.8223, 448.8056, 447.2446, 448.8223, 447.3646,
            447.2702, 447.2358, 447.2500, 447.2885, 447.2695, 447.2555, 447.2423,
            447.2555, 447.8768, 447.2530, 447.2499, 448.7674, 447.2533, 447.4327,
            448.5782, 447.2370, 448.8222, 447.2421, 447.2562, 448.5221, 447.2806,
            447.2510, 447.2581, 447.2742, 447.2312, 448.6464, 447.2347, 447.2659,
            447.2603, 447.2512, 447.1321, 448.8008, 448.8223, 448.8112, 447.2502,
            447.2697, 448.5814, 448.6405, 447.2610, 448.7125, 447.2505, 447.2572,
            447.2578, 447.2557, 448.8145, 447.2567, 447.5084, 447.8156, 447.2399,
            447.5286, 447.2570, 448.8215, 447.2350, 447.5926, 447.2737, 447.1979,
            448.8215, 447.1293, 447.2390, 447.2404, 448.8203, 448.5428, 448.7005,
            448.1677, 448.7789, 447.2720, 447.2475, 447.2476, 447.4420, 447.2787,
            447.2495, 448.8210, 448.8223, 447.2483, 447.2520, 447.2615, 448.8135,
            447.2560, 447.2398, 447.2667, 447.4140, 447.2692, 447.2500, 447.2437,
            447.2789, 447.2474, 448.3968, 447.2550, 447.2751, 448.8206, 448.8215,
            448.6950, 448.8223, 448.2684, 448.6201, 447.2482, 448.8201, 447.2657,
            447.2663, 447.2593, 447.2366, 448.8088, 447.2667, 447.2644, 447.2689,
            447.2563, 447.2463, 447.2704, 447.2477, 447.1297, 447.2568, 447.2501,
            447.2888, 448.8223, 448.5403, 448.8029, 448.8223, 448.8164, 448.8221,
            447.2534, 447.2814, 447.5027, 447.2454, 447.2560, 448.5795, 447.9032,
            447.2499, 448.7908, 448.7961, 448.0107, 448.8206, 448.8223, 447.2371,
            448.8100, 448.8209, 447.2528, 447.2634, 447.2411, 447.2631, 447.3188,
            447.2747, 447.6392, 447.2409, 447.2408, 447.2767, 448.8223, 447.2631,
            448.8223, 448.7997, 448.8153, 447.4428, 447.2642, 447.2333, 447.2724,
            448.8215, 447.2787, 447.2390, 447.2491, 447.3627, 448.0843, 447.2728,
            447.2394, 448.8213, 447.2628, 447.2517, 447.2542, 447.1302, 447.2629,
            447.2455, 448.7726, 447.2327, 448.8174, 447.2592, 447.2568, 447.2913,
            447.2348, 447.2734, 447.8376, 447.2559, 447.2260, 447.9476, 448.8154,
            448.4203, 447.2598, 447.2577, 448.8223, 447.2639, 448.7026, 447.2750,
            448.4214, 447.2901, 447.2455, 447.2504, 447.2361, 447.2520, 447.2745,
            447.2795, 448.7005, 447.2406, 447.2482, 447.2573, 447.2724, 447.0989,
            447.2608, 447.2336, 448.8223, 447.5659, 448.7904, 448.3398, 447.2414,
            447.2509, 447.2794, 447.2597, 447.2441, 447.3240, 448.8103, 447.3758,
            448.8222, 447.2477, 448.8203, 447.2455, 448.0599, 448.8223, 448.8218,
            447.5480, 448.8222, 448.8200, 447.2382, 447.2479, 447.2531, 447.3565,
            447.2408, 448.8223, 447.6451, 447.2554, 448.8201, 447.2598, 447.2485,
            447.1726, 447.2501, 447.2478, 447.2497, 448.7353, 448.1139, 448.7797,
            448.7906, 447.2405, 447.2413, 448.8050, 448.8223, 448.5630, 447.2379,
            447.2309, 448.3340, 447.2498, 448.3194, 447.2665, 448.8219, 447.2462,
            448.8202, 448.2014, 447.2439, 447.2602, 447.1335, 448.8223, 447.2378,
            447.2715, 447.2357, 447.2775, 447.2710, 447.5443, 448.5098, 447.2535,
            447.2962, 447.2643, 447.2459, 448.8193, 447.2567, 447.2624, 447.2589,
            448.3406, 447.2634, 447.2746, 447.9852, 447.2487, 448.8203, 447.2570,
            448.0851, 447.2543, 447.2648, 447.3016, 447.2568, 447.2327, 448.7948,
            447.2527, 447.2634, 447.2622, 448.8159, 448.8219, 448.8215, 447.2518,
            447.2727, 447.2365, 447.2586, 447.2600, 447.2552, 447.2616, 447.2481,
            448.7871, 447.2666, 447.2610, 448.0033, 448.8117, 447.2336, 448.8163,
            448.8088, 448.5507, 447.2336, 448.8143, 447.2725, 448.8214, 447.2620,
            447.5244, 447.2393, 447.2308, 447.2483, 447.2864, 447.4867, 448.8223,
            448.2704, 447.2469, 448.8194, 447.2608, 447.2433, 447.2991, 447.2693,
            447.2981, 447.2551, 447.2664, 448.8216, 447.2614, 447.3606, 447.2527,
            447.4858, 447.7261, 447.2336, 447.2487, 447.2625, 447.2623, 448.4323,
            448.8182, 447.2769, 447.2969, 447.2757, 448.8211, 447.2530, 447.2663,
            448.8223, 448.8221, 447.2404, 447.2384, 448.8202, 447.2649, 447.2460,
            447.2518, 447.2780, 447.2634, 448.8223, 448.7301, 447.2628, 448.8223,
            447.2562, 448.8161, 447.3034, 448.6490, 448.8223, 448.7005, 447.2473,
            448.8088, 447.2493, 448.7769, 448.8110, 447.2547, 447.2638, 448.8218,
            447.2663, 447.2361, 447.2591, 447.2658, 448.8222, 448.0052, 448.8218,
            447.2535, 447.2333, 447.2563, 447.2627, 447.2562, 447.2502, 447.2529,
            448.8219, 447.2662, 447.2568, 447.2600, 448.8179, 447.2508, 447.2659,
            447.2618, 448.7745, 448.8222, 447.2513, 447.2562, 447.1299, 447.2498,
            447.2504, 447.2711, 447.2912, 447.2621, 448.8219, 447.2776, 447.2372,
            448.5188, 447.2654, 447.2542, 448.8223, 448.7130, 447.2620, 447.2429,
            448.3249, 447.2357, 447.2468, 447.2765, 447.2795, 447.2661, 447.2523,
            447.2507, 447.2473, 448.8110, 447.2456, 448.8039, 448.8221, 448.8223,
            447.2409, 448.3748, 447.2586, 448.8223, 447.2515, 447.2632, 448.4712,
            448.7785, 448.8126, 448.8103, 447.2471, 447.2482, 448.8223, 448.7546,
            447.2388, 447.2471, 448.8146, 447.6556, 447.2670, 447.2433, 447.1293,
            447.2845, 447.2611, 447.2615, 447.2542, 448.7476, 448.8172, 447.2588,
            447.2384, 447.2866, 447.2617, 447.2555, 448.8191, 448.8164, 447.2778,
            447.4265, 448.8074, 447.5228, 447.2468, 447.2652, 447.2612, 447.2736,
            447.2780, 447.2354, 447.2460, 447.2600, 448.4633, 447.2316, 447.1294,
            448.8223, 447.2737, 447.2507, 447.2470, 448.5806, 448.2974, 448.7959,
            448.8222, 448.7412, 448.8214, 447.7242, 447.2504, 447.2784, 447.2401,
            447.2623, 447.3025, 448.8223, 448.8223, 447.2338, 448.3404, 447.5859,
            447.0491, 447.2653, 448.2979, 447.2481, 447.1292, 448.6617, 447.2523,
            447.2596, 447.2587, 447.2379, 447.7968, 447.2678, 448.8221, 448.7446,
            448.8101, 448.5079, 447.2741, 448.4776, 447.2658, 447.2391, 448.0848,
            447.5189, 447.2667, 448.7784, 448.7497, 447.2592, 448.8223, 447.2450,
            447.2849, 447.3301, 447.2666, 447.2473, 447.5301, 447.2613, 447.2712,
            447.6853, 447.2650, 448.7336, 447.2371, 447.2538, 448.8221, 448.8006,
            447.2737, 447.2631, 447.8977, 447.2504, 447.2816, 447.2571, 448.8112,
            447.2477, 447.2609, 447.9429, 447.2560, 447.5855, 447.2637, 448.8195,
            447.2435, 447.2606, 447.2411, 447.2513, 447.2591, 447.2589, 447.2693,
            448.7489, 448.8222, 447.2485, 447.2609, 448.8223, 447.3121, 448.5616,
            447.3431, 448.8223, 448.7954, 447.2557, 447.2535, 447.2464, 447.2612,
            447.2333, 448.3777, 447.6297, 447.2457, 448.8218, 447.2334, 448.5653,
            447.2633, 447.2368, 447.5494, 448.8223, 448.5544, 447.2717, 447.2724,
            447.2611, 448.8147, 447.2521, 447.3542, 447.2555, 448.8010, 447.2137,
            447.2810, 448.8212, 448.8072, 447.2435, 447.2567, 447.2488, 447.2563,
            447.2545, 448.8192, 448.5761, 447.2554, 448.8197, 447.2462, 447.2356,
            448.8126, 447.2474, 448.8223, 447.2419, 447.5543, 448.1307, 447.2379,
            448.5513, 447.2315, 447.2384, 448.7766, 447.2796, 447.2588, 447.2567,
            447.8276, 447.2444, 447.2764, 447.2741, 448.8223, 448.8130, 448.8152,
            448.7879, 447.3622, 447.2525, 447.2557, 448.7155, 448.8223, 447.1030,
            448.8045, 447.9232, 447.2537, 447.2752, 447.2745, 447.2617, 448.6671,
            447.3053, 448.5220, 447.2433, 447.2610, 447.6377, 447.2656, 447.2475,
            447.2524, 447.2518, 447.2404, 448.8176, 447.2683, 447.5865, 447.2497,
            447.2599, 447.2537, 447.2434, 448.1965, 447.2765, 448.8220, 448.8216,
            447.2817, 447.2542, 447.2726, 447.2451, 447.2456, 447.2783, 447.9293,
            447.2393, 447.8924, 448.8138, 447.0913, 447.2575, 447.2484, 447.2706,
            448.6845, 447.2781, 447.4666, 447.3714, 447.2362, 448.8221, 448.8213,
            447.2591, 447.2345, 447.1290, 447.2563, 447.5884, 448.8217, 447.2740,
            447.3392, 448.8223, 447.2426, 448.7255, 447.2531, 448.8223, 447.2792,
            447.3015, 448.8035, 447.2579, 448.5573, 447.2625, 448.8109, 447.2487,
            448.6996, 448.7977, 448.8223, 448.8223, 447.2632, 447.2423, 447.6466,
            448.7153, 447.2577, 447.2737, 448.8223, 447.2600, 448.7064, 447.2333,
            448.0071, 448.8147, 448.8222, 447.2654, 447.2413, 447.2332, 447.2494,
            448.6774, 447.4667, 448.8074, 447.7324, 448.8223, 448.5190, 448.7895,
            447.2421, 447.2737, 447.2811, 447.2608, 448.8205, 447.2505, 447.4897,
            447.8928, 448.8223, 447.2422, 447.2478, 448.8216, 447.2423, 448.6817,
            447.6468, 447.2503, 448.8132, 447.2510, 448.5775, 447.2704, 447.3699,
            447.3450, 448.8223, 447.9830, 447.2512, 447.2346, 448.4818, 447.2617,
            447.3964, 447.2484, 447.2560, 447.2865, 448.5219, 447.2402, 447.2681,
            448.5274, 448.8075, 447.2534, 448.2101, 447.2674, 447.2726, 447.2432,
            447.2662, 447.2533, 447.2332, 447.2469, 447.2473, 447.2830, 447.2450,
            447.4192, 447.2564, 448.8216, 447.2308, 447.2305, 447.2310, 447.6348,
            447.2581, 447.3026, 447.2581, 448.8217, 447.2737, 447.2788, 447.2658,
            447.2648, 447.3859, 447.2801, 447.2694, 447.2659, 447.2449, 447.2501,
            447.2555, 447.7682, 448.8223, 447.2477, 448.0923, 448.6884, 447.2542,
            448.8117, 447.2390, 447.2599, 447.2542, 447.2576, 448.8131, 448.7180,
            447.2420, 448.8223, 447.2642, 447.2694, 447.2585, 447.2501, 447.2604,
            447.1321, 447.2466, 447.2339, 447.2371, 447.5200, 448.8223, 448.8216,
            447.2448, 447.2705, 447.2493, 447.2610, 448.5659, 447.2355, 447.2888,
            447.2704, 447.2456, 448.8051, 447.2860, 447.2499, 447.2530, 447.2454,
            447.2619, 447.7565], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2437, 447.2393, 447.3844, 447.2467, 447.2621, 447.2760, 448.8164,
        448.0554, 448.7716, 448.8170, 448.8213, 448.8032, 447.2396, 448.8154,
        447.2606, 448.4214, 448.7626, 447.2840, 447.2352, 448.4350, 448.7043,
        447.2443, 448.5593, 447.2594, 447.2488, 447.2581, 448.8218, 447.2610,
        448.7011, 447.2732, 448.1927, 447.2606, 447.2645, 448.8220, 447.2761,
        448.0104, 447.2404, 447.1294, 447.2601, 448.5210, 447.2507, 447.8842,
        447.6967, 447.2765, 447.2679, 448.7736, 448.7781, 448.8212, 448.8140,
        447.2512, 448.4030, 447.2317, 448.6945, 447.2780, 447.7851, 447.2491,
        447.9243, 447.2460, 448.8223, 448.8056, 447.2446, 448.8223, 447.3646,
        447.2702, 447.2358, 447.2500, 447.2885, 447.2695, 447.2555, 447.2423,
        447.2555, 447.8768, 447.2530, 447.2499, 448.7674, 447.2533, 447.4327,
        448.5782, 447.2370, 448.8222, 447.2421, 447.2562, 448.5221, 447.2806,
        447.2510, 447.2581, 447.2742, 447.2312, 448.6464, 447.2347, 447.2659,
        447.2603, 447.2512, 447.1321, 448.8008, 448.8223, 448.8112, 447.2502,
        447.2697, 448.5814, 448.6405, 447.2610, 448.7125, 447.2505, 447.2572,
        447.2578, 447.2557, 448.8145, 447.2567, 447.5084, 447.8156, 447.2399,
        447.5286, 447.2570, 448.8215, 447.2350, 447.5926, 447.2737, 447.1979,
        448.8215, 447.1293, 447.2390, 447.2404, 448.8203, 448.5428, 448.7005,
        448.1677, 448.7789, 447.2720, 447.2475, 447.2476, 447.4420, 447.2787,
        447.2495, 448.8210, 448.8223, 447.2483, 447.2520, 447.2615, 448.8135,
        447.2560, 447.2398, 447.2667, 447.4140, 447.2692, 447.2500, 447.2437,
        447.2789, 447.2474, 448.3968, 447.2550, 447.2751, 448.8206, 448.8215,
        448.6950, 448.8223, 448.2684, 448.6201, 447.2482, 448.8201, 447.2657,
        447.2663, 447.2593, 447.2366, 448.8088, 447.2667, 447.2644, 447.2689,
        447.2563, 447.2463, 447.2704, 447.2477, 447.1297, 447.2568, 447.2501,
        447.2888, 448.8223, 448.5403, 448.8029, 448.8223, 448.8164, 448.8221,
        447.2534, 447.2814, 447.5027, 447.2454, 447.2560, 448.5795, 447.9032,
        447.2499, 448.7908, 448.7961, 448.0107, 448.8206, 448.8223, 447.2371,
        448.8100, 448.8209, 447.2528, 447.2634, 447.2411, 447.2631, 447.3188,
        447.2747, 447.6392, 447.2409, 447.2408, 447.2767, 448.8223, 447.2631,
        448.8223, 448.7997, 448.8153, 447.4428, 447.2642, 447.2333, 447.2724,
        448.8215, 447.2787, 447.2390, 447.2491, 447.3627, 448.0843, 447.2728,
        447.2394, 448.8213, 447.2628, 447.2517, 447.2542, 447.1302, 447.2629,
        447.2455, 448.7726, 447.2327, 448.8174, 447.2592, 447.2568, 447.2913,
        447.2348, 447.2734, 447.8376, 447.2559, 447.2260, 447.9476, 448.8154,
        448.4203, 447.2598, 447.2577, 448.8223, 447.2639, 448.7026, 447.2750,
        448.4214, 447.2901, 447.2455, 447.2504, 447.2361, 447.2520, 447.2745,
        447.2795, 448.7005, 447.2406, 447.2482, 447.2573, 447.2724, 447.0989,
        447.2608, 447.2336, 448.8223, 447.5659, 448.7904, 448.3398, 447.2414,
        447.2509, 447.2794, 447.2597, 447.2441, 447.3240, 448.8103, 447.3758,
        448.8222, 447.2477, 448.8203, 447.2455, 448.0599, 448.8223, 448.8218,
        447.5480, 448.8222, 448.8200, 447.2382, 447.2479, 447.2531, 447.3565,
        447.2408, 448.8223, 447.6451, 447.2554, 448.8201, 447.2598, 447.2485,
        447.1726, 447.2501, 447.2478, 447.2497, 448.7353, 448.1139, 448.7797,
        448.7906, 447.2405, 447.2413, 448.8050, 448.8223, 448.5630, 447.2379,
        447.2309, 448.3340, 447.2498, 448.3194, 447.2665, 448.8219, 447.2462,
        448.8202, 448.2014, 447.2439, 447.2602, 447.1335, 448.8223, 447.2378,
        447.2715, 447.2357, 447.2775, 447.2710, 447.5443, 448.5098, 447.2535,
        447.2962, 447.2643, 447.2459, 448.8193, 447.2567, 447.2624, 447.2589,
        448.3406, 447.2634, 447.2746, 447.9852, 447.2487, 448.8203, 447.2570,
        448.0851, 447.2543, 447.2648, 447.3016, 447.2568, 447.2327, 448.7948,
        447.2527, 447.2634, 447.2622, 448.8159, 448.8219, 448.8215, 447.2518,
        447.2727, 447.2365, 447.2586, 447.2600, 447.2552, 447.2616, 447.2481,
        448.7871, 447.2666, 447.2610, 448.0033, 448.8117, 447.2336, 448.8163,
        448.8088, 448.5507, 447.2336, 448.8143, 447.2725, 448.8214, 447.2620,
        447.5244, 447.2393, 447.2308, 447.2483, 447.2864, 447.4867, 448.8223,
        448.2704, 447.2469, 448.8194, 447.2608, 447.2433, 447.2991, 447.2693,
        447.2981, 447.2551, 447.2664, 448.8216, 447.2614, 447.3606, 447.2527,
        447.4858, 447.7261, 447.2336, 447.2487, 447.2625, 447.2623, 448.4323,
        448.8182, 447.2769, 447.2969, 447.2757, 448.8211, 447.2530, 447.2663,
        448.8223, 448.8221, 447.2404, 447.2384, 448.8202, 447.2649, 447.2460,
        447.2518, 447.2780, 447.2634, 448.8223, 448.7301, 447.2628, 448.8223,
        447.2562, 448.8161, 447.3034, 448.6490, 448.8223, 448.7005, 447.2473,
        448.8088, 447.2493, 448.7769, 448.8110, 447.2547, 447.2638, 448.8218,
        447.2663, 447.2361, 447.2591, 447.2658, 448.8222, 448.0052, 448.8218,
        447.2535, 447.2333, 447.2563, 447.2627, 447.2562, 447.2502, 447.2529,
        448.8219, 447.2662, 447.2568, 447.2600, 448.8179, 447.2508, 447.2659,
        447.2618, 448.7745, 448.8222, 447.2513, 447.2562, 447.1299, 447.2498,
        447.2504, 447.2711, 447.2912, 447.2621, 448.8219, 447.2776, 447.2372,
        448.5188, 447.2654, 447.2542, 448.8223, 448.7130, 447.2620, 447.2429,
        448.3249, 447.2357, 447.2468, 447.2765, 447.2795, 447.2661, 447.2523,
        447.2507, 447.2473, 448.8110, 447.2456, 448.8039, 448.8221, 448.8223,
        447.2409, 448.3748, 447.2586, 448.8223, 447.2515, 447.2632, 448.4712,
        448.7785, 448.8126, 448.8103, 447.2471, 447.2482, 448.8223, 448.7546,
        447.2388, 447.2471, 448.8146, 447.6556, 447.2670, 447.2433, 447.1293,
        447.2845, 447.2611, 447.2615, 447.2542, 448.7476, 448.8172, 447.2588,
        447.2384, 447.2866, 447.2617, 447.2555, 448.8191, 448.8164, 447.2778,
        447.4265, 448.8074, 447.5228, 447.2468, 447.2652, 447.2612, 447.2736,
        447.2780, 447.2354, 447.2460, 447.2600, 448.4633, 447.2316, 447.1294,
        448.8223, 447.2737, 447.2507, 447.2470, 448.5806, 448.2974, 448.7959,
        448.8222, 448.7412, 448.8214, 447.7242, 447.2504, 447.2784, 447.2401,
        447.2623, 447.3025, 448.8223, 448.8223, 447.2338, 448.3404, 447.5859,
        447.0491, 447.2653, 448.2979, 447.2481, 447.1292, 448.6617, 447.2523,
        447.2596, 447.2587, 447.2379, 447.7968, 447.2678, 448.8221, 448.7446,
        448.8101, 448.5079, 447.2741, 448.4776, 447.2658, 447.2391, 448.0848,
        447.5189, 447.2667, 448.7784, 448.7497, 447.2592, 448.8223, 447.2450,
        447.2849, 447.3301, 447.2666, 447.2473, 447.5301, 447.2613, 447.2712,
        447.6853, 447.2650, 448.7336, 447.2371, 447.2538, 448.8221, 448.8006,
        447.2737, 447.2631, 447.8977, 447.2504, 447.2816, 447.2571, 448.8112,
        447.2477, 447.2609, 447.9429, 447.2560, 447.5855, 447.2637, 448.8195,
        447.2435, 447.2606, 447.2411, 447.2513, 447.2591, 447.2589, 447.2693,
        448.7489, 448.8222, 447.2485, 447.2609, 448.8223, 447.3121, 448.5616,
        447.3431, 448.8223, 448.7954, 447.2557, 447.2535, 447.2464, 447.2612,
        447.2333, 448.3777, 447.6297, 447.2457, 448.8218, 447.2334, 448.5653,
        447.2633, 447.2368, 447.5494, 448.8223, 448.5544, 447.2717, 447.2724,
        447.2611, 448.8147, 447.2521, 447.3542, 447.2555, 448.8010, 447.2137,
        447.2810, 448.8212, 448.8072, 447.2435, 447.2567, 447.2488, 447.2563,
        447.2545, 448.8192, 448.5761, 447.2554, 448.8197, 447.2462, 447.2356,
        448.8126, 447.2474, 448.8223, 447.2419, 447.5543, 448.1307, 447.2379,
        448.5513, 447.2315, 447.2384, 448.7766, 447.2796, 447.2588, 447.2567,
        447.8276, 447.2444, 447.2764, 447.2741, 448.8223, 448.8130, 448.8152,
        448.7879, 447.3622, 447.2525, 447.2557, 448.7155, 448.8223, 447.1030,
        448.8045, 447.9232, 447.2537, 447.2752, 447.2745, 447.2617, 448.6671,
        447.3053, 448.5220, 447.2433, 447.2610, 447.6377, 447.2656, 447.2475,
        447.2524, 447.2518, 447.2404, 448.8176, 447.2683, 447.5865, 447.2497,
        447.2599, 447.2537, 447.2434, 448.1965, 447.2765, 448.8220, 448.8216,
        447.2817, 447.2542, 447.2726, 447.2451, 447.2456, 447.2783, 447.9293,
        447.2393, 447.8924, 448.8138, 447.0913, 447.2575, 447.2484, 447.2706,
        448.6845, 447.2781, 447.4666, 447.3714, 447.2362, 448.8221, 448.8213,
        447.2591, 447.2345, 447.1290, 447.2563, 447.5884, 448.8217, 447.2740,
        447.3392, 448.8223, 447.2426, 448.7255, 447.2531, 448.8223, 447.2792,
        447.3015, 448.8035, 447.2579, 448.5573, 447.2625, 448.8109, 447.2487,
        448.6996, 448.7977, 448.8223, 448.8223, 447.2632, 447.2423, 447.6466,
        448.7153, 447.2577, 447.2737, 448.8223, 447.2600, 448.7064, 447.2333,
        448.0071, 448.8147, 448.8222, 447.2654, 447.2413, 447.2332, 447.2494,
        448.6774, 447.4667, 448.8074, 447.7324, 448.8223, 448.5190, 448.7895,
        447.2421, 447.2737, 447.2811, 447.2608, 448.8205, 447.2505, 447.4897,
        447.8928, 448.8223, 447.2422, 447.2478, 448.8216, 447.2423, 448.6817,
        447.6468, 447.2503, 448.8132, 447.2510, 448.5775, 447.2704, 447.3699,
        447.3450, 448.8223, 447.9830, 447.2512, 447.2346, 448.4818, 447.2617,
        447.3964, 447.2484, 447.2560, 447.2865, 448.5219, 447.2402, 447.2681,
        448.5274, 448.8075, 447.2534, 448.2101, 447.2674, 447.2726, 447.2432,
        447.2662, 447.2533, 447.2332, 447.2469, 447.2473, 447.2830, 447.2450,
        447.4192, 447.2564, 448.8216, 447.2308, 447.2305, 447.2310, 447.6348,
        447.2581, 447.3026, 447.2581, 448.8217, 447.2737, 447.2788, 447.2658,
        447.2648, 447.3859, 447.2801, 447.2694, 447.2659, 447.2449, 447.2501,
        447.2555, 447.7682, 448.8223, 447.2477, 448.0923, 448.6884, 447.2542,
        448.8117, 447.2390, 447.2599, 447.2542, 447.2576, 448.8131, 448.7180,
        447.2420, 448.8223, 447.2642, 447.2694, 447.2585, 447.2501, 447.2604,
        447.1321, 447.2466, 447.2339, 447.2371, 447.5200, 448.8223, 448.8216,
        447.2448, 447.2705, 447.2493, 447.2610, 448.5659, 447.2355, 447.2888,
        447.2704, 447.2456, 448.8051, 447.2860, 447.2499, 447.2530, 447.2454,
        447.2619, 447.7565], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([403.7991], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8138],
             [111.8209],
             [111.8153],
             [111.8153]],

            [[111.8096],
             [111.8096],
             [111.8145],
             [111.8145]],

            [[111.8722],
             [111.8722],
             [111.8795],
             [111.8795]],

            ...,

            [[111.8137],
             [111.8100],
             [111.8131],
             [111.8224]],

            [[111.8088],
             [111.8088],
             [111.8144],
             [111.8144]],

            [[111.8112],
             [111.8170],
             [111.8121],
             [111.8184]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2654, 447.2482, 447.5034,  ..., 447.2592, 447.2464, 447.2586],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2654, 447.2482, 447.5034,  ..., 447.2592, 447.2464, 447.2586],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8416],
             [111.8451],
             [111.8408],
             [111.8458]],

            [[111.8408],
             [111.8993],
             [112.0175],
             [111.8402]],

            [[111.8817],
             [111.8493],
             [111.8435],
             [111.8449]],

            ...,

            [[111.8396],
             [111.8396],
             [111.8455],
             [111.8455]],

            [[112.2014],
             [112.2001],
             [112.2014],
             [112.1999]],

            [[111.9685],
             [111.9982],
             [111.8381],
             [111.8385]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3734, 447.5979, 447.4194,  ..., 447.3701, 448.8028, 447.6432],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3734, 447.5979, 447.4194,  ..., 447.3701, 448.8028, 447.6432],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8548],
             [111.8548],
             [111.8600],
             [111.8600]],

            [[111.8924],
             [111.8601],
             [111.8583],
             [111.8583]],

            [[111.8691],
             [111.8714],
             [111.8648],
             [111.8657]],

            ...,

            [[112.2016],
             [112.2016],
             [112.2016],
             [112.2016]],

            [[111.8601],
             [111.8603],
             [111.8540],
             [111.8588]],

            [[111.8655],
             [111.8571],
             [111.8956],
             [111.8592]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4295, 447.4692, 447.4711,  ..., 448.8062, 447.4333, 447.4775],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4295, 447.4692, 447.4711,  ..., 448.8062, 447.4333, 447.4775],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1840],
             [112.0761],
             [112.1912],
             [112.1050]],

            [[112.1997],
             [112.1866],
             [112.2001],
             [112.1879]],

            [[111.8680],
             [111.8753],
             [111.8726],
             [111.8726]],

            ...,

            [[112.2023],
             [112.2023],
             [112.2023],
             [112.2023]],

            [[111.8725],
             [111.8729],
             [111.8811],
             [111.8678]],

            [[111.8678],
             [111.8743],
             [111.8742],
             [111.8722]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5562, 448.7744, 447.4885,  ..., 448.8092, 447.4943, 447.4884],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5562, 448.7744, 447.4885,  ..., 448.8092, 447.4943, 447.4884],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2173],
             [112.2172],
             [112.2067],
             [112.2067]],

            [[112.2194],
             [112.2195],
             [112.2195],
             [112.2194]],

            [[112.1942],
             [112.0433],
             [112.1822],
             [112.1822]],

            ...,

            [[111.8850],
             [111.8814],
             [111.8785],
             [111.8906]],

            [[112.1538],
             [112.2099],
             [112.2105],
             [112.1560]],

            [[111.8758],
             [111.8808],
             [111.8760],
             [111.8803]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8480, 448.8777, 448.6019,  ..., 447.5355, 448.7303, 447.5130],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8480, 448.8777, 448.6019,  ..., 447.5355, 448.7303, 447.5130],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9183],
             [111.9183],
             [111.9277],
             [111.9277]],

            [[111.8985],
             [111.8985],
             [111.8985],
             [111.8985]],

            [[112.2329],
             [112.2316],
             [112.2227],
             [112.2227]],

            ...,

            [[112.2345],
             [112.2345],
             [112.2345],
             [112.2345]],

            [[111.8867],
             [111.8867],
             [111.8867],
             [111.8867]],

            [[112.2253],
             [112.2333],
             [112.2332],
             [112.2252]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6918, 447.5941, 448.9099,  ..., 448.9380, 447.5467, 448.9171],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6918, 447.5941, 448.9099,  ..., 448.9380, 447.5467, 448.9171],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9319],
             [111.9319],
             [111.8863],
             [111.8863]],

            [[112.2472],
             [112.2473],
             [112.2473],
             [112.2472]],

            [[111.8965],
             [111.8857],
             [111.8834],
             [111.8875]],

            ...,

            [[111.8779],
             [111.8821],
             [111.8819],
             [111.8819]],

            [[112.2364],
             [112.1671],
             [112.2364],
             [112.1671]],

            [[112.2473],
             [112.2473],
             [112.2473],
             [112.2473]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6364, 448.9891, 447.5530,  ..., 447.5237, 448.8069, 448.9893],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6364, 448.9891, 447.5530,  ..., 447.5237, 448.8069, 448.9893],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8819],
             [111.8899],
             [111.8806],
             [111.8953]],

            [[111.8839],
             [111.8805],
             [111.8815],
             [111.8815]],

            [[111.8790],
             [111.8800],
             [111.8792],
             [111.8957]],

            ...,

            [[111.8853],
             [111.8853],
             [111.8860],
             [111.8860]],

            [[112.0054],
             [111.8815],
             [112.0048],
             [111.8815]],

            [[112.2585],
             [112.2584],
             [112.2585],
             [112.2585]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5477, 447.5272, 447.5340,  ..., 447.5426, 447.7732, 449.0338],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5477, 447.5272, 447.5340,  ..., 447.5426, 447.7732, 449.0338],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8822],
             [111.8830],
             [111.8834],
             [111.8839]],

            [[111.8830],
             [111.8832],
             [111.8799],
             [111.9049]],

            [[111.8831],
             [111.8831],
             [111.9097],
             [111.8821]],

            ...,

            [[111.8840],
             [111.8840],
             [111.9019],
             [111.9019]],

            [[111.8875],
             [111.8890],
             [111.8909],
             [111.8836]],

            [[111.8849],
             [111.8833],
             [111.8801],
             [111.8801]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5325, 447.5510, 447.5579,  ..., 447.5720, 447.5510, 447.5284],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5325, 447.5510, 447.5579,  ..., 447.5720, 447.5510, 447.5284],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2771],
             [112.2771],
             [112.2771],
             [112.2771]],

            [[111.8796],
             [111.8822],
             [111.8760],
             [111.8948]],

            [[112.2769],
             [112.2756],
             [112.2756],
             [112.2771]],

            ...,

            [[112.2771],
             [112.2771],
             [112.2771],
             [112.2771]],

            [[112.2771],
             [112.2771],
             [112.2771],
             [112.2771]],

            [[112.2755],
             [112.2680],
             [112.2680],
             [112.2759]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1084, 447.5326, 449.1052,  ..., 449.1084, 449.1085, 449.0873],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1084, 447.5326, 449.1052,  ..., 449.1084, 449.1085, 449.0873],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8804],
             [111.8804],
             [111.8825],
             [111.8825]],

            [[111.8791],
             [111.8943],
             [111.8742],
             [111.8787]],

            [[111.8748],
             [111.8766],
             [111.8848],
             [111.8848]],

            ...,

            [[111.8788],
             [111.8893],
             [111.8758],
             [111.8758]],

            [[112.2783],
             [112.2783],
             [112.2663],
             [112.2663]],

            [[111.8768],
             [111.9001],
             [111.8783],
             [111.8783]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5259, 447.5263, 447.5210,  ..., 447.5197, 449.0891, 447.5336],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5259, 447.5263, 447.5210,  ..., 447.5197, 449.0891, 447.5336],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8588],
             [111.8588],
             [111.8748],
             [111.8748]],

            [[112.2915],
             [112.2909],
             [112.2915],
             [112.2910]],

            [[111.8686],
             [111.8652],
             [111.8620],
             [111.8720]],

            ...,

            [[111.8609],
             [111.8644],
             [111.8555],
             [111.8555]],

            [[111.8616],
             [111.8600],
             [111.8753],
             [111.8753]],

            [[111.8687],
             [111.8614],
             [111.8564],
             [111.8745]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4672, 449.1649, 447.4678,  ..., 447.4362, 447.4722, 447.4610],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4672, 449.1649, 447.4678,  ..., 447.4362, 447.4722, 447.4610],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8518],
             [111.8627],
             [111.8532],
             [111.8604]],

            [[112.2960],
             [112.2960],
             [112.2960],
             [112.2960]],

            [[111.8516],
             [111.8552],
             [111.8577],
             [111.8577]],

            ...,

            [[111.8554],
             [111.8542],
             [111.8543],
             [111.8689]],

            [[112.2956],
             [112.2956],
             [112.2936],
             [112.2936]],

            [[111.8567],
             [111.8577],
             [111.8536],
             [111.8807]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4281, 449.1841, 447.4223,  ..., 447.4328, 449.1783, 447.4487],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4281, 449.1841, 447.4223,  ..., 447.4328, 449.1783, 447.4487],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8332],
             [111.8332],
             [111.8658],
             [111.8366]],

            [[111.8318],
             [111.8318],
             [111.8493],
             [111.8493]],

            [[111.8340],
             [111.8380],
             [111.8286],
             [111.8286]],

            ...,

            [[111.8283],
             [111.8279],
             [111.8316],
             [111.8316]],

            [[111.8327],
             [111.8327],
             [111.8309],
             [111.8309]],

            [[111.8363],
             [111.8371],
             [111.8609],
             [111.8609]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3689, 447.3622, 447.3292,  ..., 447.3193, 447.3272, 447.3951],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3689, 447.3622, 447.3292,  ..., 447.3193, 447.3272, 447.3951],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8326],
             [111.8460],
             [111.8244],
             [111.8289]],

            [[111.8418],
             [111.8266],
             [111.8286],
             [111.8286]],

            [[112.3086],
             [112.3086],
             [112.3094],
             [112.3094]],

            ...,

            [[112.3127],
             [112.3127],
             [112.3127],
             [112.3127]],

            [[112.3130],
             [112.3130],
             [112.3130],
             [112.3130]],

            [[112.3130],
             [112.3130],
             [112.3130],
             [112.3130]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3318, 447.3255, 449.2360,  ..., 449.2506, 449.2518, 449.2518],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3318, 447.3255, 449.2360,  ..., 449.2506, 449.2518, 449.2518],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8321],
             [111.8305],
             [111.8347],
             [111.8332]],

            [[112.0531],
             [111.8357],
             [112.0192],
             [111.9727]],

            [[111.8302],
             [111.8302],
             [111.8333],
             [111.8333]],

            ...,

            [[112.0888],
             [112.1036],
             [111.8394],
             [111.8394]],

            [[112.2806],
             [112.1010],
             [112.2968],
             [112.2319]],

            [[112.3142],
             [112.3142],
             [112.3142],
             [112.3142]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3306, 447.8807, 447.3270,  ..., 447.8712, 448.9104, 449.2567],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3306, 447.8807, 447.3270,  ..., 447.8712, 448.9104, 449.2567],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3155],
             [112.3082],
             [112.3159],
             [112.3094]],

            [[111.8409],
             [111.8344],
             [111.8360],
             [111.8340]],

            [[111.8262],
             [111.9031],
             [111.8272],
             [111.8272]],

            ...,

            [[112.2273],
             [112.2274],
             [112.0327],
             [112.0327]],

            [[111.8440],
             [111.8302],
             [111.8268],
             [111.8456]],

            [[112.3170],
             [112.3170],
             [112.3170],
             [112.3170]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2491, 447.3454, 447.3836,  ..., 448.5201, 447.3466, 449.2682],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2491, 447.3454, 447.3836,  ..., 448.5201, 447.3466, 449.2682],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8260],
             [111.8260],
             [111.8342],
             [111.8342]],

            [[111.8354],
             [111.8265],
             [111.8309],
             [111.8453]],

            [[111.8528],
             [111.8280],
             [111.8309],
             [111.8309]],

            ...,

            [[111.8356],
             [111.8425],
             [111.8366],
             [111.8366]],

            [[111.8299],
             [111.8299],
             [111.8299],
             [111.8299]],

            [[111.8257],
             [111.8354],
             [111.8272],
             [111.8325]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3203, 447.3381, 447.3426,  ..., 447.3513, 447.3197, 447.3208],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3203, 447.3381, 447.3426,  ..., 447.3513, 447.3197, 447.3208],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9759e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3071],
             [112.3071],
             [112.3071],
             [112.3071]],

            [[111.8406],
             [111.8429],
             [111.8420],
             [111.8454]],

            [[111.8347],
             [111.8394],
             [111.8339],
             [111.8490]],

            ...,

            [[112.3065],
             [112.3065],
             [112.3064],
             [112.3064]],

            [[111.8373],
             [111.8387],
             [111.8543],
             [111.8357]],

            [[111.8839],
             [111.8371],
             [111.8439],
             [111.8439]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2283, 447.3709, 447.3570,  ..., 449.2258, 447.3660, 447.4088],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2283, 447.3709, 447.3570,  ..., 449.2258, 447.3660, 447.4088],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8411],
             [111.8413],
             [111.8334],
             [111.8379]],

            [[112.1941],
             [112.1941],
             [111.9111],
             [111.9111]],

            [[112.3065],
             [112.3070],
             [112.3064],
             [112.3070]],

            ...,

            [[112.2900],
             [112.2900],
             [112.2116],
             [112.2116]],

            [[112.3070],
             [112.3070],
             [112.3070],
             [112.3070]],

            [[111.8347],
             [111.8365],
             [111.8353],
             [111.8364]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3536, 448.2105, 449.2268,  ..., 449.0031, 449.2279, 447.3429],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3536, 448.2105, 449.2268,  ..., 449.0031, 449.2279, 447.3429],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8371],
             [111.8371],
             [111.8495],
             [111.8495]],

            [[111.8384],
             [111.8374],
             [111.8532],
             [111.8343]],

            [[111.8381],
             [111.8360],
             [111.8494],
             [111.8338]],

            ...,

            [[111.8392],
             [111.8392],
             [111.8379],
             [111.8379]],

            [[111.8405],
             [111.8409],
             [111.8419],
             [111.8429]],

            [[111.9260],
             [111.8372],
             [111.8454],
             [111.8454]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3730, 447.3633, 447.3575, 447.3703, 449.1901, 449.0368, 449.2242,
            447.3406, 447.5779, 447.3739, 447.3639, 447.3762, 447.3508, 447.4071,
            447.3697, 447.3420, 447.3716, 447.3922, 448.5674, 449.1966, 449.2284,
            447.7186, 447.3657, 447.2934, 449.2012, 447.7732, 449.0684, 449.2284,
            447.3495, 447.3386, 447.4585, 447.6680, 449.2273, 449.2245, 447.3671,
            447.8092, 447.3592, 447.4576, 449.2245, 449.2284, 447.3589, 447.4294,
            449.2248, 447.4947, 449.1275, 449.2281, 447.4004, 449.1918, 447.3676,
            447.2527, 449.2270, 447.3662, 447.3537, 447.4051, 449.2284, 447.4473,
            447.3706, 447.4067, 447.3840, 448.8674, 447.3510, 447.3509, 447.8862,
            449.2281, 449.2162, 447.3901, 447.3553, 449.2242, 448.7198, 447.3755,
            449.2283, 447.3990, 447.3856, 447.4497, 449.2280, 447.3553, 447.3531,
            447.3573, 447.3878, 448.3437, 449.2284, 447.3740, 447.3519, 449.2257,
            447.3569, 447.4230, 448.1545, 447.3536, 447.3439, 449.2284, 447.3494,
            447.5461, 447.2067, 447.3494, 449.2267, 447.3523, 447.4177, 447.3406,
            448.9902, 447.5956, 447.3856, 447.3589, 447.3552, 448.4760, 447.3524,
            447.4173, 447.3910, 448.1190, 447.3633, 449.1921, 449.0868, 447.4088,
            447.2682, 449.0452, 449.2283, 447.3622, 447.3524, 447.3713, 449.2283,
            447.3935, 448.2191, 447.8730, 447.3951, 447.3740, 447.3481, 447.3513,
            449.1083, 447.3594, 447.3593, 447.3486, 449.2276, 447.3810, 447.3760,
            447.3602, 447.3548, 447.3477, 449.2234, 447.3679, 447.4134, 449.2283,
            449.2283, 447.4020, 447.3611, 447.3524, 449.2283, 448.5272, 447.4317,
            447.3384, 449.2283, 447.4145, 448.6730, 447.3565, 449.2277, 447.3506,
            449.1044, 447.3474, 447.9274, 449.2261, 447.3466, 447.3768, 447.3724,
            449.0624, 448.7462, 447.3969, 449.2220, 449.2284, 447.3656, 447.3742,
            449.2262, 449.2238, 447.3608, 448.5500, 448.9915, 447.3847, 449.2284,
            449.2283, 447.3910, 447.3817, 447.7839, 447.3927, 447.3687, 447.3483,
            447.3567, 447.3719, 447.8993, 449.2233, 449.2283, 449.2167, 447.3489,
            447.3532, 447.4019, 447.3455, 449.0368, 447.3582, 447.3488, 447.3434,
            447.3418, 449.2160, 447.3425, 447.7218, 448.8610, 449.2248, 449.1426,
            447.3482, 449.2282, 449.0621, 449.2160, 447.5980, 449.1172, 448.6315,
            449.1633, 449.0788, 447.9307, 447.3540, 449.2283, 449.2284, 447.3676,
            449.0061, 447.3438, 449.2276, 447.3587, 447.3696, 447.3718, 449.2082,
            447.3799, 449.1672, 447.4857, 447.3758, 447.3634, 448.4803, 449.2283,
            449.2283, 447.3563, 449.2158, 447.3364, 449.2245, 447.3529, 449.2259,
            447.8093, 449.2121, 447.3688, 447.3683, 447.4259, 447.3437, 447.3628,
            447.3470, 447.3548, 447.3835, 448.4258, 449.2261, 447.3563, 449.1965,
            447.3658, 447.3683, 447.3692, 447.3541, 447.3544, 447.8437, 449.2282,
            449.2249, 447.3512, 448.4066, 447.3761, 449.1979, 449.2164, 447.3614,
            447.3852, 449.1995, 449.2281, 449.2274, 448.5968, 449.2110, 447.6991,
            447.3728, 449.2250, 448.0171, 447.3436, 448.9914, 447.3447, 447.3658,
            447.3753, 447.3712, 447.3747, 447.3578, 447.3775, 447.4028, 447.3604,
            449.2033, 447.3802, 447.8899, 447.3696, 447.3436, 447.3615, 449.2272,
            447.3513, 448.5547, 449.0452, 449.2259, 447.3420, 447.4704, 447.3486,
            447.3652, 447.3726, 449.1284, 449.2283, 447.3994, 448.4604, 447.3914,
            449.2205, 447.3606, 447.3829, 447.3499, 449.2281, 447.3681, 447.3590,
            447.3652, 447.3552, 447.3730, 447.4013, 449.2253, 449.1539, 448.8488,
            447.3599, 449.0389, 447.3530, 448.0097, 447.3588, 447.3934, 447.3630,
            449.2283, 447.7667, 449.2283, 447.3593, 448.8751, 448.9109, 447.7234,
            447.7807, 447.3434, 447.3803, 447.4694, 447.3719, 447.4099, 447.4202,
            449.2037, 449.2132, 447.4089, 447.3614, 449.2282, 447.3658, 447.3611,
            447.3665, 448.4545, 449.0790, 449.2284, 449.2265, 447.3748, 447.3655,
            447.3862, 447.3889, 449.2283, 447.3823, 447.3824, 448.9240, 448.2995,
            447.4011, 447.3492, 447.3729, 447.3781, 449.2284, 447.4009, 448.4387,
            449.2282, 447.4189, 449.2214, 449.0619, 447.3538, 447.3421, 447.3694,
            447.3813, 449.1955, 448.8602, 447.3646, 449.2282, 447.3622, 447.3435,
            447.3677, 448.9116, 449.2284, 447.3688, 448.3702, 447.8601, 447.3698,
            447.3648, 447.3851, 447.3537, 447.3638, 449.2271, 449.2284, 447.3571,
            449.1310, 449.2144, 447.6270, 447.3510, 449.2235, 447.3694, 447.3772,
            447.3471, 447.3588, 447.3564, 447.3441, 447.3685, 447.3566, 447.3823,
            447.3998, 449.2253, 447.3553, 447.3690, 449.2282, 449.2280, 447.3558,
            447.3488, 447.3637, 447.7098, 449.1793, 447.4017, 447.8112, 447.3496,
            447.3732, 449.2284, 447.3747, 449.2253, 449.2255, 447.4007, 447.3849,
            447.6210, 449.2251, 447.3535, 447.3745, 447.2855, 447.3829, 447.4007,
            447.8810, 447.3564, 447.3683, 447.5374, 447.3771, 449.1838, 447.3461,
            447.3846, 449.2284, 447.3737, 447.3731, 447.3564, 449.2047, 449.0421,
            447.3873, 447.3929, 447.4044, 447.3942, 447.3681, 449.2252, 447.4049,
            447.3723, 449.2284, 447.6603, 447.3668, 447.3554, 447.3702, 447.3793,
            447.3427, 447.3648, 449.2252, 447.3736, 448.7392, 447.3504, 447.3850,
            447.3468, 447.3621, 448.5977, 447.3604, 447.3957, 447.3525, 447.3631,
            447.3844, 449.2134, 447.3810, 447.3752, 449.2284, 447.3628, 447.3608,
            449.2212, 449.2143, 447.3537, 447.3764, 449.2183, 449.1979, 447.3698,
            447.3658, 447.4052, 447.3495, 449.2282, 449.1373, 447.4095, 447.3899,
            447.3481, 447.3882, 449.2254, 447.3586, 447.3493, 449.2150, 449.2284,
            447.3494, 449.1111, 447.4396, 447.4054, 449.2284, 447.3594, 447.3674,
            449.2109, 447.3563, 449.2245, 447.3470, 448.5936, 447.3691, 447.3556,
            449.0479, 449.2162, 447.3724, 449.2284, 447.3583, 447.3541, 447.3472,
            449.1937, 447.3625, 447.3504, 448.1731, 447.5310, 447.3562, 447.3666,
            447.3696, 447.3741, 447.4191, 447.3452, 449.2281, 448.4086, 449.0452,
            447.1549, 447.3531, 447.3389, 447.3931, 449.2284, 447.4222, 447.3522,
            449.0421, 447.3689, 447.3570, 447.3665, 447.3925, 447.4014, 447.6941,
            447.3471, 449.2284, 447.3907, 447.3685, 449.2282, 447.2922, 447.3774,
            449.2205, 447.3805, 449.0816, 447.4149, 447.3760, 447.3666, 447.3646,
            447.3542, 447.9153, 447.3655, 449.2265, 449.0809, 449.2284, 448.4210,
            449.2284, 447.3702, 447.3590, 449.2251, 447.7376, 449.2283, 447.3751,
            448.0947, 448.7628, 447.3709, 449.2104, 447.3958, 447.4127, 449.2265,
            448.9863, 449.2211, 447.3788, 449.2277, 447.3583, 447.3653, 449.1783,
            447.3759, 449.2283, 447.3731, 449.2258, 447.3595, 447.3729, 447.3654,
            447.3422, 447.3593, 449.2128, 447.5259, 449.2161, 447.3701, 449.2223,
            447.3742, 447.3742, 448.4554, 447.3773, 447.3535, 447.3744, 449.0814,
            448.0944, 447.3472, 447.3536, 447.3527, 447.4171, 448.8703, 447.3930,
            447.3654, 447.3992, 447.4030, 449.2284, 448.1597, 447.3635, 447.3649,
            449.2274, 449.2101, 447.5677, 447.3674, 449.2275, 447.3718, 447.8417,
            447.3683, 447.4246, 447.3495, 449.2283, 449.2046, 447.3682, 447.9160,
            449.2234, 449.2261, 447.3998, 447.3960, 449.2278, 447.3565, 447.3527,
            447.3571, 449.1647, 447.3545, 447.3899, 447.3688, 447.4047, 449.0316,
            447.3485, 449.2283, 447.3471, 447.3767, 448.9407, 449.2283, 449.1735,
            449.2191, 447.3472, 447.3474, 447.3665, 447.3742, 447.3749, 448.3914,
            447.3577, 447.3533, 449.2283, 448.3155, 447.3533, 447.3680, 449.2283,
            449.2284, 447.3499, 449.0740, 448.1363, 447.4436, 447.3787, 449.2223,
            449.2234, 447.3531, 447.3690, 447.4013, 447.3864, 447.3828, 447.5215,
            449.2245, 448.3465, 449.2142, 449.2280, 447.3705, 449.1936, 447.3574,
            449.2272, 447.3659, 449.2284, 449.2262, 447.3782, 449.2284, 447.3431,
            449.1315, 447.3694, 447.3947, 449.2232, 447.8934, 449.0477, 449.2279,
            449.2283, 449.2283, 447.3609, 447.8867, 449.2284, 449.2270, 449.0357,
            447.3655, 447.4310, 447.4105, 447.3592, 449.1840, 449.2283, 448.2639,
            448.4694, 447.3750, 449.2233, 447.8773, 447.4098, 449.2203, 447.3704,
            449.2284, 447.3735, 449.2191, 447.3672, 447.3506, 449.2242, 449.1046,
            449.2284, 449.2240, 447.3534, 447.3665, 447.3708, 447.4334, 449.2237,
            447.8953, 447.4041, 447.3740, 449.2132, 447.3832, 447.3533, 449.2284,
            447.3661, 448.8431, 449.2283, 449.2283, 447.3756, 447.3508, 449.0392,
            447.4050, 447.3602, 447.3922, 447.3493, 447.3518, 449.0938, 447.4033,
            447.3621, 449.2284, 449.2266, 448.8565, 447.3518, 449.2188, 447.3484,
            448.1422, 447.3700, 449.2284, 447.3643, 449.2276, 449.2283, 447.3961,
            447.4029, 447.3514, 447.8652, 447.3552, 448.6520, 449.0255, 447.3691,
            449.2284, 447.3602, 447.3472, 447.3651, 449.2226, 447.4200, 447.3417,
            447.3843, 447.3579, 447.3688, 449.1686, 447.3663, 449.2187, 449.0895,
            447.3463, 447.3548, 447.3739, 447.3530, 449.2275, 449.1971, 447.3429,
            447.3609, 447.3808, 447.3545, 449.2224, 447.7805, 449.0433, 447.3700,
            449.2231, 449.1873, 447.3581, 447.3686, 447.3538, 449.2155, 447.3764,
            447.3807, 449.2284, 447.3463, 447.3415, 447.3452, 449.2282, 447.3521,
            447.3729, 447.3769, 447.3592, 447.3539, 447.3781, 448.8339, 448.4770,
            448.0930, 449.1890, 449.0392, 447.5493, 447.3712, 447.3588, 447.3734,
            448.6965, 447.6371, 447.4028, 447.3821, 447.3497, 447.4109, 449.2239,
            447.3928, 449.2264, 447.3762, 447.4004, 447.3922, 447.3564, 447.3531,
            447.3892, 447.3584, 447.3835, 448.8366, 447.3483, 449.2279, 447.3984,
            447.4041, 447.3728, 447.3889, 449.2283, 447.5037, 447.3835, 447.8893,
            449.1388, 448.8594, 449.2284, 449.1581, 449.2269, 449.2284, 447.3806,
            447.3673, 449.2021, 449.1613, 447.3684, 447.3853, 447.4736, 449.2267,
            449.2067, 447.3901, 447.7697, 447.4196, 447.3532, 447.3812, 449.2284,
            447.2859, 447.3643, 449.1647, 447.3617, 447.3890, 448.6730, 447.3488,
            447.3543, 448.8254, 449.1423, 447.3720, 447.3886, 447.8483, 449.2155,
            447.3754, 447.3848, 447.3733, 447.3467, 447.3828, 448.6402, 447.3543,
            447.3661, 447.4541], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3730, 447.3633, 447.3575, 447.3703, 449.1901, 449.0368, 449.2242,
        447.3406, 447.5779, 447.3739, 447.3639, 447.3762, 447.3508, 447.4071,
        447.3697, 447.3420, 447.3716, 447.3922, 448.5674, 449.1966, 449.2284,
        447.7186, 447.3657, 447.2934, 449.2012, 447.7732, 449.0684, 449.2284,
        447.3495, 447.3386, 447.4585, 447.6680, 449.2273, 449.2245, 447.3671,
        447.8092, 447.3592, 447.4576, 449.2245, 449.2284, 447.3589, 447.4294,
        449.2248, 447.4947, 449.1275, 449.2281, 447.4004, 449.1918, 447.3676,
        447.2527, 449.2270, 447.3662, 447.3537, 447.4051, 449.2284, 447.4473,
        447.3706, 447.4067, 447.3840, 448.8674, 447.3510, 447.3509, 447.8862,
        449.2281, 449.2162, 447.3901, 447.3553, 449.2242, 448.7198, 447.3755,
        449.2283, 447.3990, 447.3856, 447.4497, 449.2280, 447.3553, 447.3531,
        447.3573, 447.3878, 448.3437, 449.2284, 447.3740, 447.3519, 449.2257,
        447.3569, 447.4230, 448.1545, 447.3536, 447.3439, 449.2284, 447.3494,
        447.5461, 447.2067, 447.3494, 449.2267, 447.3523, 447.4177, 447.3406,
        448.9902, 447.5956, 447.3856, 447.3589, 447.3552, 448.4760, 447.3524,
        447.4173, 447.3910, 448.1190, 447.3633, 449.1921, 449.0868, 447.4088,
        447.2682, 449.0452, 449.2283, 447.3622, 447.3524, 447.3713, 449.2283,
        447.3935, 448.2191, 447.8730, 447.3951, 447.3740, 447.3481, 447.3513,
        449.1083, 447.3594, 447.3593, 447.3486, 449.2276, 447.3810, 447.3760,
        447.3602, 447.3548, 447.3477, 449.2234, 447.3679, 447.4134, 449.2283,
        449.2283, 447.4020, 447.3611, 447.3524, 449.2283, 448.5272, 447.4317,
        447.3384, 449.2283, 447.4145, 448.6730, 447.3565, 449.2277, 447.3506,
        449.1044, 447.3474, 447.9274, 449.2261, 447.3466, 447.3768, 447.3724,
        449.0624, 448.7462, 447.3969, 449.2220, 449.2284, 447.3656, 447.3742,
        449.2262, 449.2238, 447.3608, 448.5500, 448.9915, 447.3847, 449.2284,
        449.2283, 447.3910, 447.3817, 447.7839, 447.3927, 447.3687, 447.3483,
        447.3567, 447.3719, 447.8993, 449.2233, 449.2283, 449.2167, 447.3489,
        447.3532, 447.4019, 447.3455, 449.0368, 447.3582, 447.3488, 447.3434,
        447.3418, 449.2160, 447.3425, 447.7218, 448.8610, 449.2248, 449.1426,
        447.3482, 449.2282, 449.0621, 449.2160, 447.5980, 449.1172, 448.6315,
        449.1633, 449.0788, 447.9307, 447.3540, 449.2283, 449.2284, 447.3676,
        449.0061, 447.3438, 449.2276, 447.3587, 447.3696, 447.3718, 449.2082,
        447.3799, 449.1672, 447.4857, 447.3758, 447.3634, 448.4803, 449.2283,
        449.2283, 447.3563, 449.2158, 447.3364, 449.2245, 447.3529, 449.2259,
        447.8093, 449.2121, 447.3688, 447.3683, 447.4259, 447.3437, 447.3628,
        447.3470, 447.3548, 447.3835, 448.4258, 449.2261, 447.3563, 449.1965,
        447.3658, 447.3683, 447.3692, 447.3541, 447.3544, 447.8437, 449.2282,
        449.2249, 447.3512, 448.4066, 447.3761, 449.1979, 449.2164, 447.3614,
        447.3852, 449.1995, 449.2281, 449.2274, 448.5968, 449.2110, 447.6991,
        447.3728, 449.2250, 448.0171, 447.3436, 448.9914, 447.3447, 447.3658,
        447.3753, 447.3712, 447.3747, 447.3578, 447.3775, 447.4028, 447.3604,
        449.2033, 447.3802, 447.8899, 447.3696, 447.3436, 447.3615, 449.2272,
        447.3513, 448.5547, 449.0452, 449.2259, 447.3420, 447.4704, 447.3486,
        447.3652, 447.3726, 449.1284, 449.2283, 447.3994, 448.4604, 447.3914,
        449.2205, 447.3606, 447.3829, 447.3499, 449.2281, 447.3681, 447.3590,
        447.3652, 447.3552, 447.3730, 447.4013, 449.2253, 449.1539, 448.8488,
        447.3599, 449.0389, 447.3530, 448.0097, 447.3588, 447.3934, 447.3630,
        449.2283, 447.7667, 449.2283, 447.3593, 448.8751, 448.9109, 447.7234,
        447.7807, 447.3434, 447.3803, 447.4694, 447.3719, 447.4099, 447.4202,
        449.2037, 449.2132, 447.4089, 447.3614, 449.2282, 447.3658, 447.3611,
        447.3665, 448.4545, 449.0790, 449.2284, 449.2265, 447.3748, 447.3655,
        447.3862, 447.3889, 449.2283, 447.3823, 447.3824, 448.9240, 448.2995,
        447.4011, 447.3492, 447.3729, 447.3781, 449.2284, 447.4009, 448.4387,
        449.2282, 447.4189, 449.2214, 449.0619, 447.3538, 447.3421, 447.3694,
        447.3813, 449.1955, 448.8602, 447.3646, 449.2282, 447.3622, 447.3435,
        447.3677, 448.9116, 449.2284, 447.3688, 448.3702, 447.8601, 447.3698,
        447.3648, 447.3851, 447.3537, 447.3638, 449.2271, 449.2284, 447.3571,
        449.1310, 449.2144, 447.6270, 447.3510, 449.2235, 447.3694, 447.3772,
        447.3471, 447.3588, 447.3564, 447.3441, 447.3685, 447.3566, 447.3823,
        447.3998, 449.2253, 447.3553, 447.3690, 449.2282, 449.2280, 447.3558,
        447.3488, 447.3637, 447.7098, 449.1793, 447.4017, 447.8112, 447.3496,
        447.3732, 449.2284, 447.3747, 449.2253, 449.2255, 447.4007, 447.3849,
        447.6210, 449.2251, 447.3535, 447.3745, 447.2855, 447.3829, 447.4007,
        447.8810, 447.3564, 447.3683, 447.5374, 447.3771, 449.1838, 447.3461,
        447.3846, 449.2284, 447.3737, 447.3731, 447.3564, 449.2047, 449.0421,
        447.3873, 447.3929, 447.4044, 447.3942, 447.3681, 449.2252, 447.4049,
        447.3723, 449.2284, 447.6603, 447.3668, 447.3554, 447.3702, 447.3793,
        447.3427, 447.3648, 449.2252, 447.3736, 448.7392, 447.3504, 447.3850,
        447.3468, 447.3621, 448.5977, 447.3604, 447.3957, 447.3525, 447.3631,
        447.3844, 449.2134, 447.3810, 447.3752, 449.2284, 447.3628, 447.3608,
        449.2212, 449.2143, 447.3537, 447.3764, 449.2183, 449.1979, 447.3698,
        447.3658, 447.4052, 447.3495, 449.2282, 449.1373, 447.4095, 447.3899,
        447.3481, 447.3882, 449.2254, 447.3586, 447.3493, 449.2150, 449.2284,
        447.3494, 449.1111, 447.4396, 447.4054, 449.2284, 447.3594, 447.3674,
        449.2109, 447.3563, 449.2245, 447.3470, 448.5936, 447.3691, 447.3556,
        449.0479, 449.2162, 447.3724, 449.2284, 447.3583, 447.3541, 447.3472,
        449.1937, 447.3625, 447.3504, 448.1731, 447.5310, 447.3562, 447.3666,
        447.3696, 447.3741, 447.4191, 447.3452, 449.2281, 448.4086, 449.0452,
        447.1549, 447.3531, 447.3389, 447.3931, 449.2284, 447.4222, 447.3522,
        449.0421, 447.3689, 447.3570, 447.3665, 447.3925, 447.4014, 447.6941,
        447.3471, 449.2284, 447.3907, 447.3685, 449.2282, 447.2922, 447.3774,
        449.2205, 447.3805, 449.0816, 447.4149, 447.3760, 447.3666, 447.3646,
        447.3542, 447.9153, 447.3655, 449.2265, 449.0809, 449.2284, 448.4210,
        449.2284, 447.3702, 447.3590, 449.2251, 447.7376, 449.2283, 447.3751,
        448.0947, 448.7628, 447.3709, 449.2104, 447.3958, 447.4127, 449.2265,
        448.9863, 449.2211, 447.3788, 449.2277, 447.3583, 447.3653, 449.1783,
        447.3759, 449.2283, 447.3731, 449.2258, 447.3595, 447.3729, 447.3654,
        447.3422, 447.3593, 449.2128, 447.5259, 449.2161, 447.3701, 449.2223,
        447.3742, 447.3742, 448.4554, 447.3773, 447.3535, 447.3744, 449.0814,
        448.0944, 447.3472, 447.3536, 447.3527, 447.4171, 448.8703, 447.3930,
        447.3654, 447.3992, 447.4030, 449.2284, 448.1597, 447.3635, 447.3649,
        449.2274, 449.2101, 447.5677, 447.3674, 449.2275, 447.3718, 447.8417,
        447.3683, 447.4246, 447.3495, 449.2283, 449.2046, 447.3682, 447.9160,
        449.2234, 449.2261, 447.3998, 447.3960, 449.2278, 447.3565, 447.3527,
        447.3571, 449.1647, 447.3545, 447.3899, 447.3688, 447.4047, 449.0316,
        447.3485, 449.2283, 447.3471, 447.3767, 448.9407, 449.2283, 449.1735,
        449.2191, 447.3472, 447.3474, 447.3665, 447.3742, 447.3749, 448.3914,
        447.3577, 447.3533, 449.2283, 448.3155, 447.3533, 447.3680, 449.2283,
        449.2284, 447.3499, 449.0740, 448.1363, 447.4436, 447.3787, 449.2223,
        449.2234, 447.3531, 447.3690, 447.4013, 447.3864, 447.3828, 447.5215,
        449.2245, 448.3465, 449.2142, 449.2280, 447.3705, 449.1936, 447.3574,
        449.2272, 447.3659, 449.2284, 449.2262, 447.3782, 449.2284, 447.3431,
        449.1315, 447.3694, 447.3947, 449.2232, 447.8934, 449.0477, 449.2279,
        449.2283, 449.2283, 447.3609, 447.8867, 449.2284, 449.2270, 449.0357,
        447.3655, 447.4310, 447.4105, 447.3592, 449.1840, 449.2283, 448.2639,
        448.4694, 447.3750, 449.2233, 447.8773, 447.4098, 449.2203, 447.3704,
        449.2284, 447.3735, 449.2191, 447.3672, 447.3506, 449.2242, 449.1046,
        449.2284, 449.2240, 447.3534, 447.3665, 447.3708, 447.4334, 449.2237,
        447.8953, 447.4041, 447.3740, 449.2132, 447.3832, 447.3533, 449.2284,
        447.3661, 448.8431, 449.2283, 449.2283, 447.3756, 447.3508, 449.0392,
        447.4050, 447.3602, 447.3922, 447.3493, 447.3518, 449.0938, 447.4033,
        447.3621, 449.2284, 449.2266, 448.8565, 447.3518, 449.2188, 447.3484,
        448.1422, 447.3700, 449.2284, 447.3643, 449.2276, 449.2283, 447.3961,
        447.4029, 447.3514, 447.8652, 447.3552, 448.6520, 449.0255, 447.3691,
        449.2284, 447.3602, 447.3472, 447.3651, 449.2226, 447.4200, 447.3417,
        447.3843, 447.3579, 447.3688, 449.1686, 447.3663, 449.2187, 449.0895,
        447.3463, 447.3548, 447.3739, 447.3530, 449.2275, 449.1971, 447.3429,
        447.3609, 447.3808, 447.3545, 449.2224, 447.7805, 449.0433, 447.3700,
        449.2231, 449.1873, 447.3581, 447.3686, 447.3538, 449.2155, 447.3764,
        447.3807, 449.2284, 447.3463, 447.3415, 447.3452, 449.2282, 447.3521,
        447.3729, 447.3769, 447.3592, 447.3539, 447.3781, 448.8339, 448.4770,
        448.0930, 449.1890, 449.0392, 447.5493, 447.3712, 447.3588, 447.3734,
        448.6965, 447.6371, 447.4028, 447.3821, 447.3497, 447.4109, 449.2239,
        447.3928, 449.2264, 447.3762, 447.4004, 447.3922, 447.3564, 447.3531,
        447.3892, 447.3584, 447.3835, 448.8366, 447.3483, 449.2279, 447.3984,
        447.4041, 447.3728, 447.3889, 449.2283, 447.5037, 447.3835, 447.8893,
        449.1388, 448.8594, 449.2284, 449.1581, 449.2269, 449.2284, 447.3806,
        447.3673, 449.2021, 449.1613, 447.3684, 447.3853, 447.4736, 449.2267,
        449.2067, 447.3901, 447.7697, 447.4196, 447.3532, 447.3812, 449.2284,
        447.2859, 447.3643, 449.1647, 447.3617, 447.3890, 448.6730, 447.3488,
        447.3543, 448.8254, 449.1423, 447.3720, 447.3886, 447.8483, 449.2155,
        447.3754, 447.3848, 447.3733, 447.3467, 447.3828, 448.6402, 447.3543,
        447.3661, 447.4541], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([418.0939], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2173],
             [112.2173],
             [112.1850],
             [112.1850]],

            [[111.8334],
             [111.8351],
             [111.8426],
             [111.8426]],

            [[111.8867],
             [111.8370],
             [111.8455],
             [111.8455]],

            ...,

            [[111.8386],
             [111.8538],
             [111.8339],
             [111.8392]],

            [[111.8435],
             [111.8378],
             [111.8386],
             [111.8386]],

            [[112.3071],
             [112.3071],
             [112.3071],
             [112.3071]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8047, 447.3538, 447.4147,  ..., 447.3655, 447.3585, 449.2284],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8047, 447.3538, 447.4147,  ..., 447.3655, 447.3585, 449.2284],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2848],
             [112.2382],
             [112.2853],
             [112.2389]],

            [[111.8423],
             [111.8470],
             [111.8475],
             [111.8455]],

            [[111.8474],
             [111.8474],
             [111.8759],
             [111.8759]],

            ...,

            [[111.8464],
             [111.8464],
             [111.8527],
             [111.8523]],

            [[112.2820],
             [112.2040],
             [112.2732],
             [112.1234]],

            [[111.8465],
             [111.8415],
             [111.8461],
             [111.8603]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0472, 447.3824, 447.4466,  ..., 447.3978, 448.8828, 447.3944],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0472, 447.3824, 447.4466,  ..., 447.3978, 448.8828, 447.3944],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1565],
             [111.8616],
             [112.1597],
             [111.8620]],

            [[112.2542],
             [111.9008],
             [112.0661],
             [112.0661]],

            [[111.8587],
             [111.8474],
             [111.8415],
             [111.8544]],

            ...,

            [[111.8411],
             [111.8466],
             [111.8448],
             [111.8448]],

            [[111.8565],
             [111.8438],
             [111.8532],
             [111.8438]],

            [[111.8513],
             [111.8442],
             [111.8465],
             [111.8716]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0398, 448.2872, 447.4021,  ..., 447.3773, 447.3973, 447.4137],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0398, 448.2872, 447.4021,  ..., 447.3773, 447.3973, 447.4137],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8591],
             [111.8594],
             [111.8616],
             [111.8484]],

            [[112.3013],
             [112.3013],
             [112.2276],
             [112.2276]],

            [[111.8454],
             [111.8429],
             [111.8460],
             [111.8451]],

            ...,

            [[111.8759],
             [111.8759],
             [111.8445],
             [111.8445]],

            [[111.8501],
             [111.8459],
             [111.8505],
             [111.8519]],

            [[111.9005],
             [111.9005],
             [111.8753],
             [111.8753]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4286, 449.0578, 447.3794,  ..., 447.4410, 447.3984, 447.5516],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4286, 449.0578, 447.3794,  ..., 447.4410, 447.3984, 447.5516],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3038],
             [112.2619],
             [112.3060],
             [112.2722]],

            [[111.8675],
             [111.8675],
             [111.8737],
             [111.8737]],

            [[111.8683],
             [111.8640],
             [111.8859],
             [111.8632]],

            ...,

            [[111.8704],
             [111.8684],
             [111.8872],
             [111.8872]],

            [[112.3102],
             [112.3082],
             [112.3102],
             [112.3080]],

            [[111.8676],
             [111.8773],
             [111.8628],
             [111.8808]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1438, 447.4824, 447.4814,  ..., 447.5132, 449.2365, 447.4885],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1438, 447.4824, 447.4814,  ..., 447.5132, 449.2365, 447.4885],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2574],
             [111.9530],
             [112.0965],
             [112.0965]],

            [[111.8969],
             [111.8903],
             [111.8894],
             [111.9082]],

            [[112.2935],
             [112.2935],
             [112.2859],
             [112.2852]],

            ...,

            [[112.0237],
             [111.9754],
             [112.2629],
             [112.2629]],

            [[111.9842],
             [111.8906],
             [111.9254],
             [111.9254]],

            [[111.8913],
             [111.8932],
             [111.8955],
             [111.8955]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4034, 447.5848, 449.1581,  ..., 448.5249, 447.7256, 447.5755],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4034, 447.5848, 449.1581,  ..., 448.5249, 447.7256, 447.5755],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9070],
             [111.9038],
             [111.9322],
             [111.9135]],

            [[112.2731],
             [112.2731],
             [112.2731],
             [112.2731]],

            [[111.9257],
             [111.9075],
             [111.9067],
             [111.9067]],

            ...,

            [[111.9083],
             [111.9093],
             [111.9102],
             [111.9102]],

            [[111.9311],
             [111.9037],
             [111.9119],
             [111.9077]],

            [[111.9074],
             [111.9100],
             [111.9041],
             [111.9230]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6564, 449.0925, 447.6465,  ..., 447.6380, 447.6545, 447.6446],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6564, 449.0925, 447.6465,  ..., 447.6380, 447.6545, 447.6446],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9090],
             [111.9090],
             [111.9434],
             [111.9054]],

            [[111.9120],
             [111.9188],
             [111.9039],
             [111.9039]],

            [[111.9090],
             [111.9090],
             [111.9090],
             [111.9090]],

            ...,

            [[111.9037],
             [111.9119],
             [111.9142],
             [111.9048]],

            [[111.9085],
             [111.9079],
             [111.9177],
             [111.9177]],

            [[112.2506],
             [112.1710],
             [112.2506],
             [112.1712]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6667, 447.6385, 447.6361,  ..., 447.6346, 447.6518, 448.8434],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6667, 447.6385, 447.6361,  ..., 447.6346, 447.6518, 448.8434],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2167],
             [112.2066],
             [112.1917],
             [112.0327]],

            [[112.2362],
             [112.2289],
             [112.2355],
             [112.2355]],

            [[111.9787],
             [111.9787],
             [111.9309],
             [111.9489]],

            ...,

            [[112.2372],
             [112.2372],
             [112.2372],
             [112.2372]],

            [[112.2372],
             [112.2372],
             [112.2372],
             [112.2372]],

            [[111.9374],
             [111.9475],
             [111.9306],
             [111.9352]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6477, 448.9362, 447.8372,  ..., 448.9487, 448.9487, 447.7507],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6477, 448.9362, 447.8372,  ..., 448.9487, 448.9487, 447.7507],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9555],
             [111.9555],
             [111.9557],
             [111.9557]],

            [[111.9768],
             [111.9619],
             [111.9612],
             [111.9745]],

            [[112.1124],
             [111.9651],
             [111.9762],
             [111.9558]],

            ...,

            [[112.1885],
             [112.1872],
             [112.1873],
             [112.1887]],

            [[111.9578],
             [111.9578],
             [111.9575],
             [111.9575]],

            [[112.1867],
             [112.1867],
             [112.1861],
             [112.1861]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8224, 447.8743, 448.0096,  ..., 448.7516, 447.8307, 448.7457],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8224, 447.8743, 448.0096,  ..., 448.7516, 447.8307, 448.7457],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1477],
             [112.1477],
             [112.1477],
             [112.1477]],

            [[112.1477],
             [112.1476],
             [112.1477],
             [112.1477]],

            [[111.9746],
             [111.9796],
             [111.9661],
             [111.9652]],

            ...,

            [[112.1458],
             [112.1466],
             [112.1453],
             [112.1441]],

            [[112.1372],
             [112.0938],
             [112.1267],
             [111.9821]],

            [[112.0000],
             [112.0000],
             [111.9881],
             [111.9881]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5907, 448.5906, 447.8856,  ..., 448.5818, 448.3398, 447.9762],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5907, 448.5906, 447.8856,  ..., 448.5818, 448.3398, 447.9762],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9893],
             [111.9848],
             [111.9900],
             [112.0206]],

            [[112.1204],
             [112.1209],
             [112.1209],
             [112.1204]],

            [[111.9886],
             [112.0045],
             [111.9985],
             [111.9872]],

            ...,

            [[111.9896],
             [111.9792],
             [111.9819],
             [111.9952]],

            [[111.9842],
             [111.9928],
             [111.9884],
             [112.0006]],

            [[112.0067],
             [112.0067],
             [112.0045],
             [112.0045]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9847, 448.4827, 447.9788,  ..., 447.9459, 447.9660, 448.0224],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9847, 448.4827, 447.9788,  ..., 447.9459, 447.9660, 448.0224],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1011],
             [112.0908],
             [112.1006],
             [112.0887]],

            [[112.1001],
             [112.0837],
             [112.1003],
             [112.0846]],

            [[112.0263],
             [111.9621],
             [112.0686],
             [111.9585]],

            ...,

            [[111.9702],
             [111.9832],
             [111.9738],
             [111.9926]],

            [[111.9664],
             [111.9589],
             [111.9663],
             [111.9787]],

            [[111.9948],
             [111.9937],
             [112.0068],
             [112.0068]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3812, 448.3688, 448.0154,  ..., 447.9197, 447.8702, 448.0022],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3812, 448.3688, 448.0154,  ..., 447.9197, 447.8702, 448.0022],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9538],
             [111.9538],
             [111.9745],
             [111.9745]],

            [[111.9768],
             [111.9634],
             [111.9459],
             [111.9844]],

            [[111.9768],
             [111.9761],
             [111.9595],
             [111.9595]],

            ...,

            [[111.9877],
             [111.9965],
             [111.9930],
             [111.9930]],

            [[111.9761],
             [111.9752],
             [111.9813],
             [111.9969]],

            [[112.0778],
             [112.0449],
             [112.0688],
             [112.0688]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8566, 447.8705, 447.8719,  ..., 447.9703, 447.9295, 448.2603],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8566, 447.8705, 447.8719,  ..., 447.9703, 447.9295, 448.2603],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9454],
             [111.9746],
             [111.9379],
             [111.9743]],

            [[112.0244],
             [112.0112],
             [112.0507],
             [112.0143]],

            [[111.9608],
             [111.9852],
             [111.9815],
             [112.0004]],

            ...,

            [[111.9831],
             [111.9831],
             [111.9892],
             [111.9892]],

            [[111.9775],
             [111.9582],
             [112.0237],
             [111.9508]],

            [[112.0603],
             [112.0457],
             [112.0597],
             [112.0404]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8322, 448.1006, 447.9279,  ..., 447.9445, 447.9102, 448.2061],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8322, 448.1006, 447.9279,  ..., 447.9445, 447.9102, 448.2061],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9618],
             [111.9519],
             [111.9526],
             [111.9542]],

            [[111.9715],
             [111.9865],
             [111.9700],
             [111.9855]],

            [[111.9779],
             [111.9836],
             [111.9838],
             [111.9881]],

            ...,

            [[111.9987],
             [111.9744],
             [111.9785],
             [111.9785]],

            [[111.9663],
             [111.9801],
             [111.9740],
             [111.9740]],

            [[111.9496],
             [111.9739],
             [111.9573],
             [111.9760]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8205, 447.9135, 447.9334,  ..., 447.9302, 447.8944, 447.8569],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8205, 447.9135, 447.9334,  ..., 447.9302, 447.8944, 447.8569],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0210],
             [112.0184],
             [112.0210],
             [112.0180]],

            [[111.9661],
             [111.9730],
             [111.9697],
             [111.9697]],

            [[112.0085],
             [111.9202],
             [112.0095],
             [111.9222]],

            ...,

            [[112.0210],
             [112.0210],
             [112.0209],
             [112.0209]],

            [[111.9302],
             [111.9302],
             [111.9261],
             [111.9261]],

            [[111.9360],
             [111.9612],
             [111.9681],
             [111.9540]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0784, 447.8785, 447.8605,  ..., 448.0837, 447.7127, 447.8193],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0784, 447.8785, 447.8605,  ..., 448.0837, 447.7127, 447.8193],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0019],
             [112.0022],
             [112.0022],
             [112.0019]],

            [[111.9163],
             [111.9153],
             [111.9382],
             [111.9382]],

            [[111.9477],
             [111.9477],
             [111.9477],
             [111.9477]],

            ...,

            [[112.0022],
             [112.0022],
             [112.0022],
             [112.0022]],

            [[111.9417],
             [111.9429],
             [111.9562],
             [111.9562]],

            [[111.9462],
             [111.9328],
             [111.9539],
             [111.9539]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0082, 447.7080, 447.7908,  ..., 448.0088, 447.7970, 447.7867],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0082, 447.7080, 447.7908,  ..., 448.0088, 447.7970, 447.7867],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9912e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9146],
             [111.9128],
             [111.9193],
             [111.9332]],

            [[111.9292],
             [111.9301],
             [111.9292],
             [111.9301]],

            [[111.9083],
             [111.9195],
             [111.9134],
             [111.9345]],

            ...,

            [[112.0233],
             [112.0161],
             [112.0214],
             [112.0214]],

            [[111.9157],
             [111.9313],
             [111.9306],
             [111.9306]],

            [[111.9183],
             [111.9134],
             [111.9185],
             [111.9380]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6800, 447.7186, 447.6757,  ..., 448.0821, 447.7081, 447.6883],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6800, 447.7186, 447.6757,  ..., 448.0821, 447.7081, 447.6883],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9205],
             [111.8993],
             [111.9104],
             [111.9225]],

            [[111.9124],
             [111.9219],
             [111.9120],
             [111.9254]],

            [[111.9295],
             [111.9295],
             [111.9324],
             [111.9324]],

            ...,

            [[111.9278],
             [111.9278],
             [111.9363],
             [111.9363]],

            [[111.9100],
             [111.9094],
             [111.9222],
             [111.9222]],

            [[112.0238],
             [112.0238],
             [112.0238],
             [112.0235]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6527, 447.6716, 447.7238,  ..., 447.7281, 447.6638, 448.0950],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6527, 447.6716, 447.7238,  ..., 447.7281, 447.6638, 448.0950],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0238],
             [112.0238],
             [112.0238],
             [112.0238]],

            [[111.9186],
             [111.9211],
             [111.9186],
             [111.9211]],

            [[111.9144],
             [111.9144],
             [111.9278],
             [111.9278]],

            ...,

            [[111.9090],
             [111.9169],
             [111.9116],
             [111.9259]],

            [[111.9049],
             [111.9119],
             [111.9197],
             [111.9318]],

            [[111.8478],
             [111.8478],
             [111.8477],
             [111.8477]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0952, 447.6794, 447.6845, 447.7167, 448.0782, 447.4978, 447.6504,
            448.0955, 447.6553, 447.5536, 448.0915, 447.8412, 447.6594, 447.6498,
            447.6692, 447.6792, 447.6556, 448.0938, 447.7090, 447.5721, 447.6441,
            447.6076, 447.5061, 447.6660, 447.6133, 447.6105, 447.6788, 447.6288,
            447.7025, 447.7017, 447.5143, 447.6754, 447.7551, 447.6656, 448.0952,
            447.7155, 448.0062, 448.0787, 448.0923, 448.0617, 448.0750, 447.6159,
            447.6742, 447.6619, 447.7163, 447.6842, 447.6616, 448.0208, 447.5096,
            447.6908, 447.5861, 447.6900, 447.6866, 448.0955, 447.9667, 448.0860,
            447.7670, 447.7498, 448.0577, 447.6713, 447.7261, 448.0954, 447.6942,
            447.6206, 447.6487, 447.7130, 447.6740, 447.5428, 447.6410, 447.5818,
            448.0290, 447.6957, 447.6802, 447.6549, 448.0768, 447.5900, 447.6754,
            447.6470, 447.6680, 447.7280, 447.5714, 447.5092, 447.7212, 447.5599,
            447.6622, 447.6914, 448.0197, 447.7194, 447.6561, 447.6862, 447.6849,
            448.0652, 448.0955, 447.6705, 447.6472, 448.0757, 447.6406, 447.6861,
            447.6866, 447.6126, 447.8654, 448.0955, 447.6829, 447.6018, 447.6931,
            447.9747, 448.0731, 447.6799, 447.6284, 447.7105, 448.0951, 447.7068,
            447.6467, 447.5114, 447.6649, 447.9869, 447.6748, 448.0954, 448.0477,
            447.5056, 447.6641, 447.6597, 448.0869, 447.7226, 447.7212, 447.5007,
            447.6731, 448.0457, 448.0869, 447.6424, 447.6576, 447.5593, 447.6954,
            448.0650, 447.7093, 447.6758, 447.6912, 447.6357, 447.6863, 447.7144,
            447.6748, 447.6933, 447.6558, 447.9387, 448.0711, 448.0819, 447.6630,
            447.6701, 447.6371, 447.6614, 448.0872, 448.0895, 447.9772, 447.6902,
            447.7101, 447.6420, 447.6886, 447.6826, 447.6640, 447.6012, 447.6613,
            447.6505, 447.7010, 447.6368, 447.6556, 448.0808, 448.0947, 447.6599,
            448.0721, 448.0954, 447.9731, 447.6844, 447.6901, 447.6768, 447.7206,
            448.0768, 447.6780, 447.4867, 447.6497, 448.0665, 447.8586, 447.7101,
            447.6882, 448.0739, 447.5601, 447.6294, 447.7125, 447.6738, 448.0244,
            447.6646, 448.0951, 448.0161, 447.5152, 448.0955, 448.0950, 447.6905,
            448.0457, 447.6534, 448.0954, 447.6975, 447.7056, 447.7008, 447.7130,
            447.8654, 447.7285, 448.0922, 447.7050, 448.0951, 447.6735, 447.6960,
            448.0587, 447.7197, 447.6821, 447.7324, 447.6461, 448.0949, 447.6627,
            447.6862, 447.6699, 447.5563, 447.5850, 447.5271, 448.0919, 447.6885,
            447.6841, 447.5916, 447.6761, 447.6722, 447.6462, 448.0950, 448.0797,
            448.0955, 447.6238, 447.6384, 447.6746, 447.5401, 447.4614, 448.0922,
            448.0953, 447.6216, 447.6793, 447.7104, 447.6934, 447.7039, 447.6949,
            447.6839, 447.6736, 447.6624, 447.6687, 447.6653, 447.5128, 447.5880,
            447.5396, 448.0945, 447.5202, 447.6434, 447.5999, 448.0764, 447.5892,
            447.6799, 447.6880, 448.0953, 447.5132, 447.6784, 447.6996, 447.5308,
            448.0624, 447.4725, 447.6653, 447.6489, 447.6803, 447.7143, 447.5932,
            447.6770, 447.5073, 447.6239, 448.0955, 448.0955, 448.0948, 447.6163,
            447.4656, 447.7009, 447.6934, 447.5275, 447.6750, 447.6627, 447.6562,
            447.9387, 447.6888, 447.7098, 447.6552, 447.9661, 447.6366, 447.6870,
            447.6855, 447.7062, 448.0953, 448.0906, 447.6196, 447.6774, 447.6711,
            447.6760, 447.7057, 447.6509, 447.8341, 447.6216, 448.0923, 448.0755,
            447.7233, 447.6942, 448.0586, 447.6503, 447.6649, 447.6936, 448.0795,
            447.6604, 448.0952, 447.5786, 447.6687, 447.7897, 447.5931, 448.0936,
            447.7410, 447.6114, 447.6548, 448.0724, 447.6034, 447.6216, 447.6661,
            448.0174, 447.6082, 447.7036, 447.5020, 448.0394, 448.0474, 447.6612,
            447.7126, 447.6078, 447.6364, 447.6125, 447.5378, 447.7095, 447.9119,
            447.4990, 447.8400, 447.6542, 447.6826, 448.0863, 447.6658, 447.6779,
            447.6667, 447.6153, 447.4664, 448.0868, 447.6843, 447.5736, 447.6849,
            447.7149, 447.6788, 447.6592, 447.6422, 448.0833, 447.5496, 447.6682,
            447.6876, 447.6641, 447.5819, 447.6712, 447.4653, 447.6333, 448.0954,
            447.6072, 447.6932, 447.8790, 447.9478, 447.6453, 448.0952, 447.6718,
            447.5047, 447.6218, 447.4996, 447.6536, 448.0952, 447.6586, 447.6888,
            447.5975, 447.6573, 447.6478, 447.5991, 447.6950, 447.7136, 447.6458,
            447.6571, 448.0917, 447.6956, 447.6801, 447.6639, 447.6674, 448.0949,
            447.6744, 447.6689, 447.9865, 448.0877, 447.5821, 447.4260, 447.4849,
            447.6197, 447.7121, 447.6236, 447.6528, 447.6065, 447.6553, 448.0228,
            447.4334, 447.5011, 447.5980, 447.7117, 447.6275, 447.6643, 447.6894,
            447.6174, 447.6874, 447.6525, 448.0941, 447.6658, 448.0955, 447.6095,
            447.6883, 447.7190, 447.6941, 447.7025, 448.0674, 447.6696, 448.0217,
            447.5827, 447.6534, 447.6743, 447.6667, 447.5917, 447.6458, 447.6456,
            447.7142, 447.6535, 448.0363, 447.6873, 447.6189, 447.5361, 447.6678,
            447.5484, 447.9579, 447.6573, 447.6544, 448.0048, 448.0955, 447.6814,
            447.6575, 447.7220, 447.6512, 448.0952, 447.6572, 448.0547, 448.0946,
            448.0955, 447.6556, 448.0726, 447.6534, 447.5410, 447.6630, 447.6678,
            447.6603, 447.7048, 447.6907, 447.7093, 447.6331, 447.6441, 447.6198,
            447.7133, 447.7070, 447.6245, 447.5804, 447.6621, 447.5741, 447.6513,
            448.0953, 447.6777, 447.6792, 447.6847, 447.5217, 447.6014, 447.5712,
            447.6633, 447.6322, 447.6829, 447.7055, 447.6066, 447.5819, 447.6019,
            447.6685, 447.6605, 447.6495, 447.6812, 447.6844, 447.6570, 447.6654,
            447.6996, 448.0952, 447.6871, 447.6885, 447.6637, 447.5838, 447.5082,
            447.6681, 447.6127, 447.6544, 447.5751, 447.6712, 447.6906, 447.6580,
            447.6312, 447.7001, 447.6855, 447.6447, 448.0583, 447.6704, 447.7086,
            448.0188, 447.6555, 447.6463, 448.0774, 447.6335, 448.0316, 448.0954,
            447.6954, 447.6671, 447.6419, 447.6733, 447.5424, 447.6226, 447.6545,
            447.6881, 447.6865, 447.6542, 447.4735, 447.6423, 447.6595, 447.6226,
            448.0928, 448.0934, 447.7149, 447.6822, 447.6695, 447.6104, 447.6848,
            447.7151, 447.5524, 447.5515, 447.6441, 447.6761, 447.6696, 447.6046,
            447.5810, 448.0954, 447.6790, 447.6820, 447.7108, 447.6792, 447.6790,
            447.6865, 447.6000, 447.6620, 447.5651, 447.7090, 447.6754, 448.0407,
            447.9828, 447.6836, 448.0596, 448.0710, 447.6863, 447.7108, 447.6421,
            447.7175, 447.6820, 447.3933, 448.0640, 447.8428, 447.3957, 448.0935,
            447.6771, 447.8759, 447.7753, 447.6488, 447.9360, 447.6745, 447.6691,
            447.6742, 447.6765, 447.4616, 448.0711, 447.6568, 447.6936, 448.0952,
            447.4991, 448.0874, 448.0903, 447.6919, 447.7192, 447.7023, 447.6083,
            447.6538, 447.4992, 448.0948, 447.9962, 447.6258, 447.6597, 448.0718,
            447.6200, 447.6553, 447.5884, 448.0792, 447.6843, 447.7130, 447.6534,
            447.6916, 447.6640, 447.6623, 447.5227, 447.6946, 447.7164, 447.6577,
            447.6911, 448.0719, 448.0955, 447.5861, 447.5471, 447.5538, 448.0955,
            447.6466, 447.7204, 448.0363, 447.5504, 447.6805, 448.0949, 447.5667,
            447.6791, 448.0951, 447.7010, 447.6805, 448.0955, 447.6751, 448.0941,
            448.0912, 447.6888, 447.6723, 447.7310, 447.8338, 447.6718, 447.6492,
            448.0955, 448.0953, 447.5051, 447.6773, 447.6880, 447.5850, 447.6574,
            447.4541, 447.7009, 447.6592, 447.7012, 447.6802, 447.6803, 447.6027,
            447.6982, 447.6805, 447.6573, 447.6851, 447.5190, 447.6428, 447.6788,
            448.0331, 447.6335, 448.0561, 448.0951, 447.8774, 447.6636, 447.5156,
            448.0920, 447.4658, 447.6473, 448.0318, 448.0955, 447.6189, 447.6508,
            447.7242, 448.0880, 447.6765, 447.6859, 448.0950, 448.0928, 448.0845,
            447.6881, 447.4739, 447.6228, 448.0889, 448.0310, 447.5713, 447.6600,
            447.7148, 448.0877, 447.6509, 447.6639, 447.6894, 447.6586, 447.7113,
            447.6869, 447.6369, 447.6888, 447.6316, 447.6237, 447.7065, 447.9726,
            447.6812, 448.0955, 448.0832, 448.0280, 448.0951, 447.6911, 447.6601,
            447.6586, 447.6440, 447.5781, 447.6392, 448.0662, 447.6188, 447.5332,
            447.7193, 447.6846, 448.0387, 447.6904, 447.8570, 447.6169, 448.0951,
            447.6284, 447.7020, 447.6891, 447.6255, 447.9407, 447.6766, 447.7106,
            447.6984, 448.0955, 447.5113, 447.6783, 447.6241, 448.0878, 447.7136,
            447.6586, 447.6752, 447.7102, 447.8914, 447.7228, 447.7015, 447.6564,
            447.6829, 447.6937, 447.6039, 448.0938, 447.5904, 448.0768, 447.6534,
            447.6736, 447.6197, 448.0946, 447.5742, 448.0955, 448.0938, 447.5484,
            447.9930, 447.6762, 447.6932, 448.0391, 448.0907, 447.9650, 448.0948,
            447.6488, 447.7061, 447.6627, 447.5989, 447.6623, 447.8596, 447.6667,
            447.8511, 447.6530, 448.0609, 447.7228, 448.0950, 447.6470, 447.7072,
            447.6511, 447.7023, 447.6634, 448.0917, 447.6994, 447.6605, 447.6447,
            447.6953, 447.8832, 447.6859, 447.7006, 448.0814, 447.6131, 447.6694,
            447.6531, 447.6162, 447.9025, 447.6879, 447.6875, 447.6609, 447.6483,
            447.6354, 447.6954, 447.6727, 447.6888, 447.7571, 447.7130, 447.7024,
            447.6866, 447.6913, 447.6280, 447.5764, 448.0603, 447.6824, 447.7103,
            447.7015, 448.0804, 447.9877, 447.6573, 447.8181, 447.6674, 448.0698,
            447.5527, 447.5429, 447.6649, 447.7004, 447.7181, 448.0941, 447.6924,
            447.6986, 447.5857, 448.0475, 448.0781, 447.6797, 448.0955, 447.5160,
            447.6823, 447.6639, 448.0651, 447.6516, 448.0954, 447.6619, 447.6952,
            448.0835, 447.6803, 447.6790, 448.0915, 447.6261, 447.6586, 447.6893,
            447.7092, 447.6694, 447.7054, 447.6436, 448.0952, 447.6601, 448.0924,
            448.0899, 448.0693, 447.6616, 448.0684, 448.0925, 447.6746, 448.0948,
            447.6894, 448.0310, 447.6133, 447.6832, 447.9383, 447.7226, 448.0698,
            447.6597, 447.6927, 448.0948, 447.6827, 447.6736, 447.5607, 447.5925,
            447.5905, 447.9939, 448.0953, 447.6426, 448.0870, 447.6329, 447.6802,
            447.6583, 447.6387, 447.7010, 447.6604, 447.6839, 447.6334, 448.0071,
            447.5888, 447.6365, 447.6459, 448.0945, 447.6924, 448.0955, 448.0878,
            447.5640, 447.6879, 447.6904, 447.6898, 447.6543, 447.6562, 447.6635,
            447.6683, 447.3911], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0952, 447.6794, 447.6845, 447.7167, 448.0782, 447.4978, 447.6504,
        448.0955, 447.6553, 447.5536, 448.0915, 447.8412, 447.6594, 447.6498,
        447.6692, 447.6792, 447.6556, 448.0938, 447.7090, 447.5721, 447.6441,
        447.6076, 447.5061, 447.6660, 447.6133, 447.6105, 447.6788, 447.6288,
        447.7025, 447.7017, 447.5143, 447.6754, 447.7551, 447.6656, 448.0952,
        447.7155, 448.0062, 448.0787, 448.0923, 448.0617, 448.0750, 447.6159,
        447.6742, 447.6619, 447.7163, 447.6842, 447.6616, 448.0208, 447.5096,
        447.6908, 447.5861, 447.6900, 447.6866, 448.0955, 447.9667, 448.0860,
        447.7670, 447.7498, 448.0577, 447.6713, 447.7261, 448.0954, 447.6942,
        447.6206, 447.6487, 447.7130, 447.6740, 447.5428, 447.6410, 447.5818,
        448.0290, 447.6957, 447.6802, 447.6549, 448.0768, 447.5900, 447.6754,
        447.6470, 447.6680, 447.7280, 447.5714, 447.5092, 447.7212, 447.5599,
        447.6622, 447.6914, 448.0197, 447.7194, 447.6561, 447.6862, 447.6849,
        448.0652, 448.0955, 447.6705, 447.6472, 448.0757, 447.6406, 447.6861,
        447.6866, 447.6126, 447.8654, 448.0955, 447.6829, 447.6018, 447.6931,
        447.9747, 448.0731, 447.6799, 447.6284, 447.7105, 448.0951, 447.7068,
        447.6467, 447.5114, 447.6649, 447.9869, 447.6748, 448.0954, 448.0477,
        447.5056, 447.6641, 447.6597, 448.0869, 447.7226, 447.7212, 447.5007,
        447.6731, 448.0457, 448.0869, 447.6424, 447.6576, 447.5593, 447.6954,
        448.0650, 447.7093, 447.6758, 447.6912, 447.6357, 447.6863, 447.7144,
        447.6748, 447.6933, 447.6558, 447.9387, 448.0711, 448.0819, 447.6630,
        447.6701, 447.6371, 447.6614, 448.0872, 448.0895, 447.9772, 447.6902,
        447.7101, 447.6420, 447.6886, 447.6826, 447.6640, 447.6012, 447.6613,
        447.6505, 447.7010, 447.6368, 447.6556, 448.0808, 448.0947, 447.6599,
        448.0721, 448.0954, 447.9731, 447.6844, 447.6901, 447.6768, 447.7206,
        448.0768, 447.6780, 447.4867, 447.6497, 448.0665, 447.8586, 447.7101,
        447.6882, 448.0739, 447.5601, 447.6294, 447.7125, 447.6738, 448.0244,
        447.6646, 448.0951, 448.0161, 447.5152, 448.0955, 448.0950, 447.6905,
        448.0457, 447.6534, 448.0954, 447.6975, 447.7056, 447.7008, 447.7130,
        447.8654, 447.7285, 448.0922, 447.7050, 448.0951, 447.6735, 447.6960,
        448.0587, 447.7197, 447.6821, 447.7324, 447.6461, 448.0949, 447.6627,
        447.6862, 447.6699, 447.5563, 447.5850, 447.5271, 448.0919, 447.6885,
        447.6841, 447.5916, 447.6761, 447.6722, 447.6462, 448.0950, 448.0797,
        448.0955, 447.6238, 447.6384, 447.6746, 447.5401, 447.4614, 448.0922,
        448.0953, 447.6216, 447.6793, 447.7104, 447.6934, 447.7039, 447.6949,
        447.6839, 447.6736, 447.6624, 447.6687, 447.6653, 447.5128, 447.5880,
        447.5396, 448.0945, 447.5202, 447.6434, 447.5999, 448.0764, 447.5892,
        447.6799, 447.6880, 448.0953, 447.5132, 447.6784, 447.6996, 447.5308,
        448.0624, 447.4725, 447.6653, 447.6489, 447.6803, 447.7143, 447.5932,
        447.6770, 447.5073, 447.6239, 448.0955, 448.0955, 448.0948, 447.6163,
        447.4656, 447.7009, 447.6934, 447.5275, 447.6750, 447.6627, 447.6562,
        447.9387, 447.6888, 447.7098, 447.6552, 447.9661, 447.6366, 447.6870,
        447.6855, 447.7062, 448.0953, 448.0906, 447.6196, 447.6774, 447.6711,
        447.6760, 447.7057, 447.6509, 447.8341, 447.6216, 448.0923, 448.0755,
        447.7233, 447.6942, 448.0586, 447.6503, 447.6649, 447.6936, 448.0795,
        447.6604, 448.0952, 447.5786, 447.6687, 447.7897, 447.5931, 448.0936,
        447.7410, 447.6114, 447.6548, 448.0724, 447.6034, 447.6216, 447.6661,
        448.0174, 447.6082, 447.7036, 447.5020, 448.0394, 448.0474, 447.6612,
        447.7126, 447.6078, 447.6364, 447.6125, 447.5378, 447.7095, 447.9119,
        447.4990, 447.8400, 447.6542, 447.6826, 448.0863, 447.6658, 447.6779,
        447.6667, 447.6153, 447.4664, 448.0868, 447.6843, 447.5736, 447.6849,
        447.7149, 447.6788, 447.6592, 447.6422, 448.0833, 447.5496, 447.6682,
        447.6876, 447.6641, 447.5819, 447.6712, 447.4653, 447.6333, 448.0954,
        447.6072, 447.6932, 447.8790, 447.9478, 447.6453, 448.0952, 447.6718,
        447.5047, 447.6218, 447.4996, 447.6536, 448.0952, 447.6586, 447.6888,
        447.5975, 447.6573, 447.6478, 447.5991, 447.6950, 447.7136, 447.6458,
        447.6571, 448.0917, 447.6956, 447.6801, 447.6639, 447.6674, 448.0949,
        447.6744, 447.6689, 447.9865, 448.0877, 447.5821, 447.4260, 447.4849,
        447.6197, 447.7121, 447.6236, 447.6528, 447.6065, 447.6553, 448.0228,
        447.4334, 447.5011, 447.5980, 447.7117, 447.6275, 447.6643, 447.6894,
        447.6174, 447.6874, 447.6525, 448.0941, 447.6658, 448.0955, 447.6095,
        447.6883, 447.7190, 447.6941, 447.7025, 448.0674, 447.6696, 448.0217,
        447.5827, 447.6534, 447.6743, 447.6667, 447.5917, 447.6458, 447.6456,
        447.7142, 447.6535, 448.0363, 447.6873, 447.6189, 447.5361, 447.6678,
        447.5484, 447.9579, 447.6573, 447.6544, 448.0048, 448.0955, 447.6814,
        447.6575, 447.7220, 447.6512, 448.0952, 447.6572, 448.0547, 448.0946,
        448.0955, 447.6556, 448.0726, 447.6534, 447.5410, 447.6630, 447.6678,
        447.6603, 447.7048, 447.6907, 447.7093, 447.6331, 447.6441, 447.6198,
        447.7133, 447.7070, 447.6245, 447.5804, 447.6621, 447.5741, 447.6513,
        448.0953, 447.6777, 447.6792, 447.6847, 447.5217, 447.6014, 447.5712,
        447.6633, 447.6322, 447.6829, 447.7055, 447.6066, 447.5819, 447.6019,
        447.6685, 447.6605, 447.6495, 447.6812, 447.6844, 447.6570, 447.6654,
        447.6996, 448.0952, 447.6871, 447.6885, 447.6637, 447.5838, 447.5082,
        447.6681, 447.6127, 447.6544, 447.5751, 447.6712, 447.6906, 447.6580,
        447.6312, 447.7001, 447.6855, 447.6447, 448.0583, 447.6704, 447.7086,
        448.0188, 447.6555, 447.6463, 448.0774, 447.6335, 448.0316, 448.0954,
        447.6954, 447.6671, 447.6419, 447.6733, 447.5424, 447.6226, 447.6545,
        447.6881, 447.6865, 447.6542, 447.4735, 447.6423, 447.6595, 447.6226,
        448.0928, 448.0934, 447.7149, 447.6822, 447.6695, 447.6104, 447.6848,
        447.7151, 447.5524, 447.5515, 447.6441, 447.6761, 447.6696, 447.6046,
        447.5810, 448.0954, 447.6790, 447.6820, 447.7108, 447.6792, 447.6790,
        447.6865, 447.6000, 447.6620, 447.5651, 447.7090, 447.6754, 448.0407,
        447.9828, 447.6836, 448.0596, 448.0710, 447.6863, 447.7108, 447.6421,
        447.7175, 447.6820, 447.3933, 448.0640, 447.8428, 447.3957, 448.0935,
        447.6771, 447.8759, 447.7753, 447.6488, 447.9360, 447.6745, 447.6691,
        447.6742, 447.6765, 447.4616, 448.0711, 447.6568, 447.6936, 448.0952,
        447.4991, 448.0874, 448.0903, 447.6919, 447.7192, 447.7023, 447.6083,
        447.6538, 447.4992, 448.0948, 447.9962, 447.6258, 447.6597, 448.0718,
        447.6200, 447.6553, 447.5884, 448.0792, 447.6843, 447.7130, 447.6534,
        447.6916, 447.6640, 447.6623, 447.5227, 447.6946, 447.7164, 447.6577,
        447.6911, 448.0719, 448.0955, 447.5861, 447.5471, 447.5538, 448.0955,
        447.6466, 447.7204, 448.0363, 447.5504, 447.6805, 448.0949, 447.5667,
        447.6791, 448.0951, 447.7010, 447.6805, 448.0955, 447.6751, 448.0941,
        448.0912, 447.6888, 447.6723, 447.7310, 447.8338, 447.6718, 447.6492,
        448.0955, 448.0953, 447.5051, 447.6773, 447.6880, 447.5850, 447.6574,
        447.4541, 447.7009, 447.6592, 447.7012, 447.6802, 447.6803, 447.6027,
        447.6982, 447.6805, 447.6573, 447.6851, 447.5190, 447.6428, 447.6788,
        448.0331, 447.6335, 448.0561, 448.0951, 447.8774, 447.6636, 447.5156,
        448.0920, 447.4658, 447.6473, 448.0318, 448.0955, 447.6189, 447.6508,
        447.7242, 448.0880, 447.6765, 447.6859, 448.0950, 448.0928, 448.0845,
        447.6881, 447.4739, 447.6228, 448.0889, 448.0310, 447.5713, 447.6600,
        447.7148, 448.0877, 447.6509, 447.6639, 447.6894, 447.6586, 447.7113,
        447.6869, 447.6369, 447.6888, 447.6316, 447.6237, 447.7065, 447.9726,
        447.6812, 448.0955, 448.0832, 448.0280, 448.0951, 447.6911, 447.6601,
        447.6586, 447.6440, 447.5781, 447.6392, 448.0662, 447.6188, 447.5332,
        447.7193, 447.6846, 448.0387, 447.6904, 447.8570, 447.6169, 448.0951,
        447.6284, 447.7020, 447.6891, 447.6255, 447.9407, 447.6766, 447.7106,
        447.6984, 448.0955, 447.5113, 447.6783, 447.6241, 448.0878, 447.7136,
        447.6586, 447.6752, 447.7102, 447.8914, 447.7228, 447.7015, 447.6564,
        447.6829, 447.6937, 447.6039, 448.0938, 447.5904, 448.0768, 447.6534,
        447.6736, 447.6197, 448.0946, 447.5742, 448.0955, 448.0938, 447.5484,
        447.9930, 447.6762, 447.6932, 448.0391, 448.0907, 447.9650, 448.0948,
        447.6488, 447.7061, 447.6627, 447.5989, 447.6623, 447.8596, 447.6667,
        447.8511, 447.6530, 448.0609, 447.7228, 448.0950, 447.6470, 447.7072,
        447.6511, 447.7023, 447.6634, 448.0917, 447.6994, 447.6605, 447.6447,
        447.6953, 447.8832, 447.6859, 447.7006, 448.0814, 447.6131, 447.6694,
        447.6531, 447.6162, 447.9025, 447.6879, 447.6875, 447.6609, 447.6483,
        447.6354, 447.6954, 447.6727, 447.6888, 447.7571, 447.7130, 447.7024,
        447.6866, 447.6913, 447.6280, 447.5764, 448.0603, 447.6824, 447.7103,
        447.7015, 448.0804, 447.9877, 447.6573, 447.8181, 447.6674, 448.0698,
        447.5527, 447.5429, 447.6649, 447.7004, 447.7181, 448.0941, 447.6924,
        447.6986, 447.5857, 448.0475, 448.0781, 447.6797, 448.0955, 447.5160,
        447.6823, 447.6639, 448.0651, 447.6516, 448.0954, 447.6619, 447.6952,
        448.0835, 447.6803, 447.6790, 448.0915, 447.6261, 447.6586, 447.6893,
        447.7092, 447.6694, 447.7054, 447.6436, 448.0952, 447.6601, 448.0924,
        448.0899, 448.0693, 447.6616, 448.0684, 448.0925, 447.6746, 448.0948,
        447.6894, 448.0310, 447.6133, 447.6832, 447.9383, 447.7226, 448.0698,
        447.6597, 447.6927, 448.0948, 447.6827, 447.6736, 447.5607, 447.5925,
        447.5905, 447.9939, 448.0953, 447.6426, 448.0870, 447.6329, 447.6802,
        447.6583, 447.6387, 447.7010, 447.6604, 447.6839, 447.6334, 448.0071,
        447.5888, 447.6365, 447.6459, 448.0945, 447.6924, 448.0955, 448.0878,
        447.5640, 447.6879, 447.6904, 447.6898, 447.6543, 447.6562, 447.6635,
        447.6683, 447.3911], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([411.8838], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9162],
             [111.9162],
             [111.9186],
             [111.9186]],

            [[111.9157],
             [111.9157],
             [111.9262],
             [111.9262]],

            [[111.8684],
             [111.9169],
             [111.8804],
             [111.9030]],

            ...,

            [[111.8683],
             [111.8920],
             [111.8961],
             [111.8890]],

            [[111.8963],
             [111.9244],
             [111.9088],
             [111.9139]],

            [[111.8962],
             [111.9169],
             [111.9117],
             [111.9117]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6697, 447.6840, 447.5687,  ..., 447.5454, 447.6434, 447.6364],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6697, 447.6840, 447.5687,  ..., 447.5454, 447.6434, 447.6364],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9288],
             [111.9288],
             [111.9320],
             [111.9320]],

            [[112.0363],
             [112.0306],
             [112.0363],
             [112.0295]],

            [[111.9211],
             [111.8648],
             [111.9204],
             [111.8680]],

            ...,

            [[111.9259],
             [111.9556],
             [111.9307],
             [111.9298]],

            [[111.8992],
             [111.9149],
             [111.9000],
             [111.9130]],

            [[111.9504],
             [111.9285],
             [111.9316],
             [111.9316]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7215, 448.1327, 447.5744,  ..., 447.7420, 447.6271, 447.7420],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7215, 448.1327, 447.5744,  ..., 447.7420, 447.6271, 447.7420],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0101],
             [112.0101],
             [112.0049],
             [112.0049]],

            [[111.9374],
             [111.9330],
             [111.9585],
             [111.9362]],

            [[111.9408],
             [111.9408],
             [111.9517],
             [111.9517]],

            ...,

            [[112.0481],
             [112.0368],
             [112.0368],
             [112.0493]],

            [[111.9373],
             [111.9336],
             [111.9635],
             [111.9363]],

            [[112.0491],
             [112.0472],
             [112.0488],
             [112.0488]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0300, 447.7650, 447.7850,  ..., 448.1709, 447.7708, 448.1940],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0300, 447.7650, 447.7850,  ..., 448.1709, 447.7708, 448.1940],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9417],
             [111.9621],
             [111.9369],
             [111.9404]],

            [[112.0463],
             [111.9540],
             [112.0458],
             [111.9558]],

            [[111.9365],
             [111.9403],
             [111.9439],
             [111.9466]],

            ...,

            [[111.9177],
             [111.9177],
             [111.9201],
             [111.9201]],

            [[111.9456],
             [111.9703],
             [111.9435],
             [111.9435]],

            [[111.8852],
             [111.8852],
             [111.9083],
             [111.9083]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7811, 448.0019, 447.7672,  ..., 447.6756, 447.8029, 447.5870],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7811, 448.0019, 447.7672,  ..., 447.6756, 447.8029, 447.5870],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8989],
             [112.0246],
             [112.0311],
             [111.8975]],

            [[111.9523],
             [111.9735],
             [111.9519],
             [111.9590]],

            [[111.9592],
             [111.9592],
             [111.9781],
             [111.9781]],

            ...,

            [[112.0375],
             [111.8996],
             [112.0312],
             [111.9863]],

            [[112.0066],
             [111.8986],
             [111.9786],
             [111.9214]],

            [[112.0531],
             [112.0531],
             [112.0532],
             [112.0532]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8521, 447.8366, 447.8747,  ..., 447.9546, 447.8052, 448.2126],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8521, 447.8366, 447.8747,  ..., 447.9546, 447.8052, 448.2126],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9628],
             [111.9628],
             [111.9522],
             [111.9522]],

            [[111.9792],
             [111.9778],
             [111.9874],
             [111.9660]],

            [[112.0482],
             [112.0482],
             [112.0482],
             [112.0482]],

            ...,

            [[111.9681],
             [111.9637],
             [111.9836],
             [111.9628]],

            [[111.9708],
             [111.9639],
             [111.9668],
             [111.9901]],

            [[111.9597],
             [111.9666],
             [111.9394],
             [111.9731]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8301, 447.9104, 448.1927,  ..., 447.8782, 447.8915, 447.8389],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8301, 447.9104, 448.1927,  ..., 447.8782, 447.8915, 447.8389],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9696],
             [111.9696],
             [111.9872],
             [111.9872]],

            [[112.0396],
             [112.0396],
             [111.9853],
             [111.9853]],

            [[111.9733],
             [112.0044],
             [111.9739],
             [111.9746]],

            ...,

            [[111.9395],
             [111.9395],
             [111.9507],
             [111.9507]],

            [[111.9791],
             [111.9809],
             [111.9767],
             [111.9971]],

            [[111.9789],
             [111.9738],
             [111.9988],
             [111.9720]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9136, 448.0498, 447.9263,  ..., 447.7805, 447.9338, 447.9235],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9136, 448.0498, 447.9263,  ..., 447.7805, 447.9338, 447.9235],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9724],
             [111.9929],
             [111.9906],
             [111.9802]],

            [[111.9704],
             [111.9816],
             [111.9730],
             [111.9954]],

            [[112.0431],
             [112.0408],
             [112.0422],
             [112.0422]],

            ...,

            [[111.9032],
             [111.9024],
             [112.0209],
             [112.0209]],

            [[112.0403],
             [112.0088],
             [112.0371],
             [112.0371]],

            [[111.9699],
             [111.9686],
             [111.9832],
             [111.9832]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9362, 447.9205, 448.1682,  ..., 447.8474, 448.1232, 447.9049],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9362, 447.9205, 448.1682,  ..., 447.8474, 448.1232, 447.9049],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0016],
             [112.0009],
             [111.9430],
             [111.9077]],

            [[112.0271],
             [111.9046],
             [111.9835],
             [111.9835]],

            [[111.9972],
             [111.9972],
             [111.9994],
             [111.9994]],

            ...,

            [[111.9737],
             [111.9939],
             [111.9647],
             [111.9746]],

            [[111.9969],
             [111.9801],
             [112.0009],
             [111.9805]],

            [[111.9831],
             [111.9830],
             [112.0039],
             [111.9785]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8533, 447.8988, 447.9932,  ..., 447.9070, 447.9583, 447.9485],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8533, 447.8988, 447.9932,  ..., 447.9070, 447.9583, 447.9485],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0422],
             [112.0422],
             [112.0421],
             [112.0421]],

            [[111.9900],
             [111.9617],
             [111.9790],
             [112.0030]],

            [[111.9381],
             [111.9816],
             [111.9763],
             [111.9763]],

            ...,

            [[112.0201],
             [111.9367],
             [112.0174],
             [111.9111]],

            [[111.9932],
             [111.9783],
             [111.9963],
             [111.9756]],

            [[111.9618],
             [111.9618],
             [111.9831],
             [111.9831]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1687, 447.9337, 447.8723,  ..., 447.8853, 447.9434, 447.8899],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1687, 447.9337, 447.8723,  ..., 447.8853, 447.9434, 447.8899],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9757],
             [111.9757],
             [111.9939],
             [111.9939]],

            [[111.9750],
             [111.9750],
             [111.9864],
             [111.9864]],

            [[111.9732],
             [111.9937],
             [111.9799],
             [111.9799]],

            ...,

            [[111.9807],
             [111.9640],
             [111.9667],
             [111.9823]],

            [[111.9667],
             [111.9816],
             [111.9663],
             [111.9815]],

            [[111.9789],
             [111.9789],
             [111.9847],
             [112.0064]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9393, 447.9227, 447.9268,  ..., 447.8938, 447.8960, 447.9490],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9393, 447.9227, 447.9268,  ..., 447.8938, 447.8960, 447.9490],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9122],
             [111.9611],
             [111.9110],
             [111.9617]],

            [[112.0820],
             [112.0822],
             [112.0822],
             [112.0820]],

            [[111.9273],
             [111.9249],
             [111.9537],
             [111.9542]],

            ...,

            [[111.9731],
             [111.9729],
             [111.9688],
             [112.0024]],

            [[111.9809],
             [111.9564],
             [111.9895],
             [111.9895]],

            [[111.9676],
             [111.9676],
             [111.9862],
             [111.9862]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7459, 448.3283, 447.7601,  ..., 447.9171, 447.9164, 447.9076],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7459, 448.3283, 447.7601,  ..., 447.9171, 447.9164, 447.9076],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9508],
             [111.9508],
             [111.9513],
             [111.9513]],

            [[111.9486],
             [111.9815],
             [111.9614],
             [111.9631]],

            [[112.0733],
             [112.0976],
             [112.0976],
             [112.0733]],

            ...,

            [[111.9697],
             [111.9665],
             [111.9657],
             [111.9957]],

            [[112.0995],
             [112.0990],
             [112.0994],
             [112.0994]],

            [[111.9606],
             [111.9778],
             [111.9812],
             [111.9861]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8043, 447.8546, 448.3419,  ..., 447.8976, 448.3972, 447.9056],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8043, 447.8546, 448.3419,  ..., 447.8976, 448.3972, 447.9056],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1115],
             [112.1039],
             [112.1095],
             [112.1095]],

            [[111.9583],
             [111.9769],
             [111.9605],
             [111.9773]],

            [[111.9905],
             [111.9928],
             [111.9905],
             [111.9928]],

            ...,

            [[111.9259],
             [111.9232],
             [112.0914],
             [112.0914]],

            [[112.0970],
             [111.9409],
             [112.0992],
             [111.9467]],

            [[111.9693],
             [111.9984],
             [111.9644],
             [111.9711]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4344, 447.8730, 447.9664,  ..., 448.0318, 448.0837, 447.9031],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4344, 447.8730, 447.9664,  ..., 448.0318, 448.0837, 447.9031],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9701],
             [111.9886],
             [111.9654],
             [111.9715]],

            [[111.9775],
             [111.9775],
             [111.9775],
             [111.9775]],

            [[112.1168],
             [112.1168],
             [112.1168],
             [112.1168]],

            ...,

            [[111.9287],
             [111.9506],
             [111.9673],
             [111.9673]],

            [[112.0917],
             [111.9304],
             [112.0917],
             [111.9304]],

            [[111.9721],
             [112.0013],
             [111.9777],
             [111.9777]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8957, 447.9099, 448.4670,  ..., 447.8140, 448.0441, 447.9288],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8957, 447.9099, 448.4670,  ..., 447.8140, 448.0441, 447.9288],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9734],
             [111.9904],
             [111.9922],
             [112.0013]],

            [[112.1077],
             [112.1077],
             [112.1080],
             [112.1080]],

            [[111.9576],
             [111.9576],
             [111.9576],
             [111.9576]],

            ...,

            [[111.9816],
             [111.9816],
             [111.9952],
             [111.9952]],

            [[111.9880],
             [111.9735],
             [112.0025],
             [111.9731]],

            [[111.9764],
             [111.9680],
             [111.9847],
             [111.9511]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9573, 448.4315, 447.8304,  ..., 447.9536, 447.9371, 447.8802],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9573, 448.4315, 447.8304,  ..., 447.9536, 447.9371, 447.8802],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9933],
             [111.9873],
             [111.9873],
             [111.9933]],

            [[111.9292],
             [111.9644],
             [111.9575],
             [111.9575]],

            [[111.9328],
             [111.9658],
             [111.9607],
             [111.9607]],

            ...,

            [[111.9541],
             [111.9541],
             [111.9712],
             [111.9712]],

            [[112.1298],
             [112.1298],
             [112.1298],
             [112.1298]],

            [[112.1265],
             [112.1265],
             [112.1265],
             [112.1265]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9612, 447.8085, 447.8200,  ..., 447.8505, 448.5191, 448.5060],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9612, 447.8085, 447.8200,  ..., 447.8505, 448.5191, 448.5060],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9615],
             [111.9379],
             [111.9379],
             [111.9615]],

            [[112.1435],
             [112.1384],
             [112.1420],
             [112.1420]],

            [[111.9231],
             [111.9231],
             [112.0641],
             [112.0641]],

            ...,

            [[111.9476],
             [111.9476],
             [111.9705],
             [111.9705]],

            [[111.9397],
             [111.9397],
             [111.9583],
             [111.9583]],

            [[111.9373],
             [111.9373],
             [111.9383],
             [111.9383]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7986, 448.5659, 447.9744,  ..., 447.8362, 447.7960, 447.7513],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7986, 448.5659, 447.9744,  ..., 447.8362, 447.7960, 447.7513],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0022e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9083],
             [111.9195],
             [111.9056],
             [111.9120]],

            [[111.9225],
             [111.9198],
             [111.9156],
             [111.9369]],

            [[112.0614],
             [111.8810],
             [112.0348],
             [111.8942]],

            ...,

            [[111.9040],
             [111.9199],
             [111.8996],
             [111.9188]],

            [[111.9212],
             [111.8938],
             [111.9242],
             [111.9242]],

            [[111.9187],
             [111.9187],
             [111.9254],
             [111.9254]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6455, 447.6947, 447.8715,  ..., 447.6424, 447.6634, 447.6882],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6455, 447.6947, 447.8715,  ..., 447.6424, 447.6634, 447.6882],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9151],
             [111.9151],
             [111.8996],
             [111.8996]],

            [[111.9132],
             [111.9294],
             [111.9063],
             [111.9063]],

            [[112.1256],
             [111.8910],
             [112.1132],
             [111.8805]],

            ...,

            [[111.9243],
             [111.9304],
             [111.9038],
             [111.9038]],

            [[111.9083],
             [111.9136],
             [111.9154],
             [111.9276]],

            [[111.9297],
             [111.9297],
             [111.9344],
             [111.9344]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6294, 447.6554, 448.0103,  ..., 447.6622, 447.6648, 447.7282],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6294, 447.6554, 448.0103,  ..., 447.6622, 447.6648, 447.7282],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9120],
             [111.9443],
             [111.9177],
             [111.9163]],

            [[111.9165],
             [111.9408],
             [111.9114],
             [111.9176]],

            [[111.9086],
             [111.9081],
             [111.9029],
             [111.9109]],

            ...,

            [[112.1481],
             [111.9906],
             [112.1422],
             [112.1422]],

            [[111.9187],
             [111.9237],
             [111.9417],
             [111.9417]],

            [[111.9126],
             [111.9221],
             [111.9363],
             [111.9363]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6902, 447.6864, 447.6305, 447.6693, 448.5782, 447.6744, 448.3324,
            447.6313, 447.6725, 448.6396, 447.6849, 448.0241, 448.5960, 448.5566,
            447.5770, 447.6721, 447.6879, 447.6409, 447.6891, 447.7063, 447.7079,
            448.6408, 447.6121, 447.6046, 447.7027, 448.5497, 448.0214, 448.0524,
            447.6769, 448.4597, 447.7026, 447.6293, 447.6495, 447.6736, 447.6417,
            447.6720, 447.6535, 447.6580, 447.5893, 447.6714, 447.7124, 448.5889,
            447.7384, 447.6955, 447.7299, 447.6682, 447.6718, 447.5890, 447.9917,
            447.7267, 448.0117, 447.6835, 447.7571, 447.6495, 447.5400, 447.6646,
            447.6631, 447.6838, 447.5880, 448.4933, 447.6581, 447.6819, 447.6206,
            448.6414, 447.6770, 447.6976, 447.6748, 448.3390, 447.7079, 447.6125,
            447.9318, 448.6406, 447.7343, 447.7012, 447.7283, 448.6416, 447.6341,
            447.6927, 447.9506, 447.6931, 447.8735, 447.6713, 447.6754, 447.7051,
            447.6744, 447.7195, 447.9609, 447.7415, 448.6399, 447.6846, 447.7380,
            447.6722, 447.6682, 447.5709, 447.6378, 447.6899, 447.7151, 448.4061,
            447.6157, 447.5409, 447.8415, 447.6604, 448.6336, 447.6819, 447.6233,
            447.6119, 447.6253, 447.6902, 447.6973, 447.6912, 447.8394, 447.6914,
            447.6840, 447.6541, 447.7332, 447.6038, 447.7081, 447.6831, 447.6874,
            448.0182, 448.0297, 448.6383, 447.6378, 447.6761, 447.6839, 447.6308,
            447.6851, 447.6997, 447.6380, 447.6358, 448.5973, 447.6996, 447.7069,
            447.5797, 448.6414, 448.5934, 447.9928, 447.6741, 447.6755, 447.6714,
            447.7324, 447.6253, 447.7013, 447.6904, 447.6598, 447.6641, 447.7299,
            447.6616, 447.6259, 448.6311, 447.6183, 448.6205, 447.9597, 447.5869,
            447.7292, 447.6990, 448.6203, 447.7214, 447.5923, 447.6966, 447.6684,
            448.6386, 448.6360, 448.3115, 447.6539, 447.6848, 447.6985, 448.6386,
            448.5888, 448.6385, 447.6735, 447.7303, 447.6040, 447.9244, 447.6139,
            447.8048, 447.6029, 448.5936, 447.6742, 447.7394, 447.7417, 448.6345,
            447.7278, 448.6415, 448.4066, 447.6806, 447.6168, 447.6498, 447.6616,
            448.6415, 447.5817, 447.6883, 447.6623, 447.6865, 447.6695, 447.6935,
            447.6052, 447.7096, 448.5977, 447.7020, 447.6754, 448.5932, 447.6995,
            447.6401, 448.6415, 447.7287, 447.5282, 447.6763, 447.6191, 447.6215,
            448.6400, 448.3173, 447.5536, 447.7228, 448.0672, 447.7331, 447.6464,
            447.7269, 447.6022, 447.6763, 447.7014, 447.6981, 447.7095, 447.5991,
            447.6774, 447.6740, 447.6403, 447.6738, 448.3989, 447.6884, 448.6078,
            447.6672, 448.6176, 448.6408, 448.6239, 448.6375, 447.6826, 447.7221,
            447.6148, 448.6411, 447.6595, 447.6621, 447.6446, 448.6224, 447.6654,
            448.6403, 447.6763, 448.1270, 448.6411, 447.6895, 447.6245, 447.6530,
            448.6107, 447.6726, 447.7278, 447.9293, 447.7244, 447.6453, 447.7163,
            447.6669, 447.7012, 447.7213, 447.6805, 447.6794, 448.6416, 448.6090,
            447.7316, 447.6782, 448.4062, 447.6700, 448.0089, 447.6120, 448.6234,
            447.6010, 447.6194, 448.6195, 447.7436, 447.6777, 447.6475, 448.6047,
            448.6400, 448.0182, 447.6773, 447.6912, 448.0190, 447.6777, 447.6210,
            447.7029, 448.5366, 448.5981, 447.7280, 447.8406, 447.6891, 447.6644,
            447.6985, 447.6678, 448.6364, 448.6405, 447.6270, 447.6722, 448.2179,
            447.6876, 447.7358, 447.7421, 447.6837, 447.7685, 448.6406, 448.3645,
            447.6638, 447.6667, 447.6648, 447.6860, 448.6411, 447.6528, 448.6189,
            448.4534, 447.6264, 448.6366, 448.0298, 448.6415, 447.6517, 447.6633,
            448.6413, 447.6764, 448.3029, 448.0728, 447.6903, 447.6300, 448.6130,
            448.1959, 447.7016, 448.0353, 448.6153, 447.6202, 448.6343, 447.6766,
            447.6784, 447.6838, 448.5171, 447.6628, 447.7129, 447.6001, 447.6401,
            447.6173, 448.6365, 448.4319, 447.7213, 447.6921, 447.7578, 447.6673,
            447.6796, 447.5717, 447.6874, 448.0999, 447.6332, 447.6253, 448.3196,
            448.2789, 447.6730, 447.7219, 447.6927, 448.5786, 447.6771, 447.6823,
            448.4718, 447.6332, 447.5711, 447.6588, 448.5826, 447.6974, 447.6628,
            447.7155, 447.6488, 448.6416, 448.6416, 447.6773, 447.6417, 448.5413,
            447.6091, 447.6978, 447.7099, 447.7211, 447.6513, 447.6861, 447.5956,
            447.6681, 447.7134, 447.6948, 447.9784, 447.7047, 448.1312, 447.6223,
            448.6411, 447.6758, 447.6820, 447.6684, 447.7343, 448.6374, 447.6393,
            447.6488, 447.5577, 448.5018, 447.5954, 447.7413, 447.6958, 447.6447,
            447.6108, 447.6209, 447.6663, 447.6798, 447.6855, 447.6906, 448.0214,
            447.6797, 447.6629, 447.7421, 447.7107, 447.6676, 447.7128, 447.7151,
            448.3040, 448.6209, 447.6823, 447.6702, 447.7103, 447.6021, 448.6334,
            447.6661, 447.6028, 447.6599, 448.5384, 447.6572, 447.5637, 447.7461,
            447.7103, 447.6883, 448.5582, 447.6822, 447.6857, 448.6330, 447.6852,
            448.6312, 447.6789, 448.6412, 448.6112, 448.6089, 447.6132, 448.6364,
            447.7141, 448.2440, 447.6754, 447.7007, 447.5960, 448.6148, 448.6415,
            447.7257, 447.6503, 447.6650, 447.5653, 448.4556, 448.6282, 447.6728,
            447.6904, 447.6939, 447.6870, 447.6744, 447.6992, 447.6331, 447.7757,
            447.7000, 447.6491, 447.6893, 448.6397, 447.7062, 448.4755, 447.6544,
            447.6400, 447.6658, 447.7160, 448.5069, 447.5884, 447.6803, 448.5007,
            447.6961, 448.6399, 447.6617, 447.6868, 447.6040, 448.2585, 447.6192,
            447.7362, 448.0091, 448.6405, 447.6637, 448.6293, 447.6701, 448.6416,
            447.6182, 447.6641, 447.6816, 447.7039, 447.5673, 448.6074, 447.6909,
            448.5694, 447.7305, 447.6760, 447.8358, 448.6363, 447.6020, 447.6415,
            448.3037, 447.6969, 447.6287, 448.6417, 447.6166, 447.7132, 447.6880,
            447.6824, 448.6322, 447.6390, 447.7060, 447.6624, 447.6852, 447.7077,
            447.6530, 447.6599, 448.6417, 448.4110, 448.4432, 448.6417, 447.6397,
            447.6767, 447.7084, 448.4667, 448.4111, 447.5812, 447.7283, 447.8214,
            447.5842, 447.6860, 447.6143, 447.5894, 448.5255, 448.4902, 447.8931,
            447.6819, 447.7153, 447.7317, 448.3930, 447.7303, 447.6633, 447.5883,
            447.6110, 447.6828, 447.6541, 447.6848, 447.5841, 447.6476, 448.6164,
            447.6924, 447.6866, 447.5765, 447.6947, 447.5805, 448.5460, 447.6398,
            447.6428, 448.6357, 447.6285, 447.7262, 447.6658, 447.6740, 448.0029,
            447.6804, 447.8003, 448.6402, 448.6415, 447.6872, 447.6837, 447.6686,
            447.7286, 447.6885, 447.6159, 448.6029, 448.6368, 447.6339, 447.6865,
            447.5726, 447.5972, 447.7208, 448.0214, 447.7274, 448.6361, 448.5745,
            447.6173, 447.6755, 448.0215, 448.6416, 447.7110, 447.5909, 448.6407,
            447.6866, 447.6843, 447.8990, 448.5238, 447.7425, 447.6726, 448.6414,
            447.6465, 447.6658, 448.6411, 447.6387, 447.7079, 447.7122, 448.6389,
            447.6639, 448.6271, 447.6779, 448.6412, 447.7452, 448.1508, 447.5396,
            447.6790, 448.6382, 447.6852, 447.6376, 447.6904, 447.6786, 447.6792,
            447.6719, 447.6718, 447.6761, 447.6720, 448.6317, 447.6610, 447.6386,
            448.6416, 447.6765, 448.6408, 447.6430, 447.6462, 447.6648, 447.6836,
            447.7137, 447.7297, 448.3686, 447.6034, 447.6758, 447.5272, 448.1038,
            447.7054, 447.7203, 448.5191, 448.4728, 447.6328, 447.6754, 447.6841,
            448.6416, 447.6233, 448.4810, 448.6417, 448.6413, 448.5450, 447.7168,
            447.6714, 447.6239, 447.7165, 448.4476, 447.7382, 448.6094, 447.7012,
            447.8734, 447.6735, 448.5615, 448.1770, 447.6275, 448.6177, 447.6807,
            447.7112, 448.6329, 447.6319, 448.6093, 447.6906, 447.6852, 447.5757,
            447.6610, 447.7271, 448.6417, 447.6934, 447.6783, 447.6871, 448.0521,
            448.6417, 447.6466, 447.7224, 447.5817, 448.6404, 447.7349, 447.7069,
            447.6586, 447.6376, 447.6890, 448.0267, 447.6897, 447.6777, 448.6417,
            448.5997, 447.6785, 447.6218, 447.7454, 447.5959, 447.7233, 447.6683,
            448.0103, 447.6437, 447.6770, 447.5826, 448.5821, 447.5994, 447.6979,
            448.6384, 447.6801, 447.6287, 447.6823, 447.6285, 447.5863, 447.6899,
            448.4529, 447.6988, 447.6616, 447.6623, 448.6110, 447.5879, 447.6619,
            448.5602, 448.6410, 447.7108, 448.6407, 448.6347, 447.6909, 447.6850,
            447.6699, 447.6887, 448.6295, 447.6434, 447.6733, 447.7148, 447.6909,
            447.5909, 447.7039, 447.6163, 447.7029, 447.6783, 448.6407, 448.6329,
            448.6416, 447.5977, 447.6760, 447.5984, 447.7155, 447.7313, 448.6193,
            447.6521, 447.7988, 447.6721, 448.6417, 447.6609, 447.6794, 447.6886,
            447.6581, 447.6228, 448.6416, 447.6828, 447.6815, 447.6119, 448.6155,
            447.5933, 447.6903, 447.6539, 447.6840, 448.6086, 447.6716, 447.6801,
            447.6684, 447.6310, 447.6572, 447.6381, 448.5332, 448.5882, 448.3342,
            447.6179, 447.7069, 447.6192, 447.5975, 447.6841, 447.6619, 447.7986,
            447.6908, 448.4198, 448.6163, 447.6703, 448.6417, 447.7477, 447.6260,
            447.7150, 448.6408, 447.7157, 447.6100, 448.0391, 447.6521, 447.6933,
            447.6728, 447.5930, 447.6776, 447.7469, 447.6713, 447.7479, 447.6734,
            447.7169, 447.6926, 447.6545, 447.5927, 447.6471, 447.7236, 448.3848,
            447.7255, 448.6416, 447.6946, 447.9912, 448.6122, 448.5768, 447.7130,
            447.6744, 447.7244, 447.6968, 448.5222, 447.7046, 448.6217, 447.6640,
            447.6773, 447.6066, 448.6371, 447.6525, 447.7283, 447.7265, 448.6295,
            447.7081, 448.5408, 447.6754, 447.7414, 448.5842, 447.6909, 447.7680,
            447.6650, 447.7260, 448.6365, 447.6413, 447.6904, 447.7016, 448.6226,
            448.5737, 447.6794, 447.6899, 447.8347, 447.7082, 447.6552, 447.6483,
            447.6093, 447.7455, 447.6826, 448.6054, 447.6653, 447.9813, 447.6470,
            447.6819, 448.6163, 448.6080, 447.7287, 447.6771, 447.6650, 448.6234,
            447.6935, 448.6416, 447.6580, 447.5889, 447.6113, 447.9210, 447.6494,
            448.3957, 447.6607, 447.7326, 447.5945, 447.6302, 447.5896, 448.6382,
            447.6972, 447.7263, 447.7086, 447.6725, 447.8633, 447.6550, 447.7056,
            447.6351, 447.6844, 447.6792, 448.6406, 447.6674, 448.5696, 447.8354,
            447.6658, 448.3058, 447.6784, 447.6387, 448.5485, 448.6370, 447.6035,
            448.6416, 448.4141, 447.6574, 447.6606, 447.7596, 448.6417, 448.4231,
            447.7259, 447.7072], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6902, 447.6864, 447.6305, 447.6693, 448.5782, 447.6744, 448.3324,
        447.6313, 447.6725, 448.6396, 447.6849, 448.0241, 448.5960, 448.5566,
        447.5770, 447.6721, 447.6879, 447.6409, 447.6891, 447.7063, 447.7079,
        448.6408, 447.6121, 447.6046, 447.7027, 448.5497, 448.0214, 448.0524,
        447.6769, 448.4597, 447.7026, 447.6293, 447.6495, 447.6736, 447.6417,
        447.6720, 447.6535, 447.6580, 447.5893, 447.6714, 447.7124, 448.5889,
        447.7384, 447.6955, 447.7299, 447.6682, 447.6718, 447.5890, 447.9917,
        447.7267, 448.0117, 447.6835, 447.7571, 447.6495, 447.5400, 447.6646,
        447.6631, 447.6838, 447.5880, 448.4933, 447.6581, 447.6819, 447.6206,
        448.6414, 447.6770, 447.6976, 447.6748, 448.3390, 447.7079, 447.6125,
        447.9318, 448.6406, 447.7343, 447.7012, 447.7283, 448.6416, 447.6341,
        447.6927, 447.9506, 447.6931, 447.8735, 447.6713, 447.6754, 447.7051,
        447.6744, 447.7195, 447.9609, 447.7415, 448.6399, 447.6846, 447.7380,
        447.6722, 447.6682, 447.5709, 447.6378, 447.6899, 447.7151, 448.4061,
        447.6157, 447.5409, 447.8415, 447.6604, 448.6336, 447.6819, 447.6233,
        447.6119, 447.6253, 447.6902, 447.6973, 447.6912, 447.8394, 447.6914,
        447.6840, 447.6541, 447.7332, 447.6038, 447.7081, 447.6831, 447.6874,
        448.0182, 448.0297, 448.6383, 447.6378, 447.6761, 447.6839, 447.6308,
        447.6851, 447.6997, 447.6380, 447.6358, 448.5973, 447.6996, 447.7069,
        447.5797, 448.6414, 448.5934, 447.9928, 447.6741, 447.6755, 447.6714,
        447.7324, 447.6253, 447.7013, 447.6904, 447.6598, 447.6641, 447.7299,
        447.6616, 447.6259, 448.6311, 447.6183, 448.6205, 447.9597, 447.5869,
        447.7292, 447.6990, 448.6203, 447.7214, 447.5923, 447.6966, 447.6684,
        448.6386, 448.6360, 448.3115, 447.6539, 447.6848, 447.6985, 448.6386,
        448.5888, 448.6385, 447.6735, 447.7303, 447.6040, 447.9244, 447.6139,
        447.8048, 447.6029, 448.5936, 447.6742, 447.7394, 447.7417, 448.6345,
        447.7278, 448.6415, 448.4066, 447.6806, 447.6168, 447.6498, 447.6616,
        448.6415, 447.5817, 447.6883, 447.6623, 447.6865, 447.6695, 447.6935,
        447.6052, 447.7096, 448.5977, 447.7020, 447.6754, 448.5932, 447.6995,
        447.6401, 448.6415, 447.7287, 447.5282, 447.6763, 447.6191, 447.6215,
        448.6400, 448.3173, 447.5536, 447.7228, 448.0672, 447.7331, 447.6464,
        447.7269, 447.6022, 447.6763, 447.7014, 447.6981, 447.7095, 447.5991,
        447.6774, 447.6740, 447.6403, 447.6738, 448.3989, 447.6884, 448.6078,
        447.6672, 448.6176, 448.6408, 448.6239, 448.6375, 447.6826, 447.7221,
        447.6148, 448.6411, 447.6595, 447.6621, 447.6446, 448.6224, 447.6654,
        448.6403, 447.6763, 448.1270, 448.6411, 447.6895, 447.6245, 447.6530,
        448.6107, 447.6726, 447.7278, 447.9293, 447.7244, 447.6453, 447.7163,
        447.6669, 447.7012, 447.7213, 447.6805, 447.6794, 448.6416, 448.6090,
        447.7316, 447.6782, 448.4062, 447.6700, 448.0089, 447.6120, 448.6234,
        447.6010, 447.6194, 448.6195, 447.7436, 447.6777, 447.6475, 448.6047,
        448.6400, 448.0182, 447.6773, 447.6912, 448.0190, 447.6777, 447.6210,
        447.7029, 448.5366, 448.5981, 447.7280, 447.8406, 447.6891, 447.6644,
        447.6985, 447.6678, 448.6364, 448.6405, 447.6270, 447.6722, 448.2179,
        447.6876, 447.7358, 447.7421, 447.6837, 447.7685, 448.6406, 448.3645,
        447.6638, 447.6667, 447.6648, 447.6860, 448.6411, 447.6528, 448.6189,
        448.4534, 447.6264, 448.6366, 448.0298, 448.6415, 447.6517, 447.6633,
        448.6413, 447.6764, 448.3029, 448.0728, 447.6903, 447.6300, 448.6130,
        448.1959, 447.7016, 448.0353, 448.6153, 447.6202, 448.6343, 447.6766,
        447.6784, 447.6838, 448.5171, 447.6628, 447.7129, 447.6001, 447.6401,
        447.6173, 448.6365, 448.4319, 447.7213, 447.6921, 447.7578, 447.6673,
        447.6796, 447.5717, 447.6874, 448.0999, 447.6332, 447.6253, 448.3196,
        448.2789, 447.6730, 447.7219, 447.6927, 448.5786, 447.6771, 447.6823,
        448.4718, 447.6332, 447.5711, 447.6588, 448.5826, 447.6974, 447.6628,
        447.7155, 447.6488, 448.6416, 448.6416, 447.6773, 447.6417, 448.5413,
        447.6091, 447.6978, 447.7099, 447.7211, 447.6513, 447.6861, 447.5956,
        447.6681, 447.7134, 447.6948, 447.9784, 447.7047, 448.1312, 447.6223,
        448.6411, 447.6758, 447.6820, 447.6684, 447.7343, 448.6374, 447.6393,
        447.6488, 447.5577, 448.5018, 447.5954, 447.7413, 447.6958, 447.6447,
        447.6108, 447.6209, 447.6663, 447.6798, 447.6855, 447.6906, 448.0214,
        447.6797, 447.6629, 447.7421, 447.7107, 447.6676, 447.7128, 447.7151,
        448.3040, 448.6209, 447.6823, 447.6702, 447.7103, 447.6021, 448.6334,
        447.6661, 447.6028, 447.6599, 448.5384, 447.6572, 447.5637, 447.7461,
        447.7103, 447.6883, 448.5582, 447.6822, 447.6857, 448.6330, 447.6852,
        448.6312, 447.6789, 448.6412, 448.6112, 448.6089, 447.6132, 448.6364,
        447.7141, 448.2440, 447.6754, 447.7007, 447.5960, 448.6148, 448.6415,
        447.7257, 447.6503, 447.6650, 447.5653, 448.4556, 448.6282, 447.6728,
        447.6904, 447.6939, 447.6870, 447.6744, 447.6992, 447.6331, 447.7757,
        447.7000, 447.6491, 447.6893, 448.6397, 447.7062, 448.4755, 447.6544,
        447.6400, 447.6658, 447.7160, 448.5069, 447.5884, 447.6803, 448.5007,
        447.6961, 448.6399, 447.6617, 447.6868, 447.6040, 448.2585, 447.6192,
        447.7362, 448.0091, 448.6405, 447.6637, 448.6293, 447.6701, 448.6416,
        447.6182, 447.6641, 447.6816, 447.7039, 447.5673, 448.6074, 447.6909,
        448.5694, 447.7305, 447.6760, 447.8358, 448.6363, 447.6020, 447.6415,
        448.3037, 447.6969, 447.6287, 448.6417, 447.6166, 447.7132, 447.6880,
        447.6824, 448.6322, 447.6390, 447.7060, 447.6624, 447.6852, 447.7077,
        447.6530, 447.6599, 448.6417, 448.4110, 448.4432, 448.6417, 447.6397,
        447.6767, 447.7084, 448.4667, 448.4111, 447.5812, 447.7283, 447.8214,
        447.5842, 447.6860, 447.6143, 447.5894, 448.5255, 448.4902, 447.8931,
        447.6819, 447.7153, 447.7317, 448.3930, 447.7303, 447.6633, 447.5883,
        447.6110, 447.6828, 447.6541, 447.6848, 447.5841, 447.6476, 448.6164,
        447.6924, 447.6866, 447.5765, 447.6947, 447.5805, 448.5460, 447.6398,
        447.6428, 448.6357, 447.6285, 447.7262, 447.6658, 447.6740, 448.0029,
        447.6804, 447.8003, 448.6402, 448.6415, 447.6872, 447.6837, 447.6686,
        447.7286, 447.6885, 447.6159, 448.6029, 448.6368, 447.6339, 447.6865,
        447.5726, 447.5972, 447.7208, 448.0214, 447.7274, 448.6361, 448.5745,
        447.6173, 447.6755, 448.0215, 448.6416, 447.7110, 447.5909, 448.6407,
        447.6866, 447.6843, 447.8990, 448.5238, 447.7425, 447.6726, 448.6414,
        447.6465, 447.6658, 448.6411, 447.6387, 447.7079, 447.7122, 448.6389,
        447.6639, 448.6271, 447.6779, 448.6412, 447.7452, 448.1508, 447.5396,
        447.6790, 448.6382, 447.6852, 447.6376, 447.6904, 447.6786, 447.6792,
        447.6719, 447.6718, 447.6761, 447.6720, 448.6317, 447.6610, 447.6386,
        448.6416, 447.6765, 448.6408, 447.6430, 447.6462, 447.6648, 447.6836,
        447.7137, 447.7297, 448.3686, 447.6034, 447.6758, 447.5272, 448.1038,
        447.7054, 447.7203, 448.5191, 448.4728, 447.6328, 447.6754, 447.6841,
        448.6416, 447.6233, 448.4810, 448.6417, 448.6413, 448.5450, 447.7168,
        447.6714, 447.6239, 447.7165, 448.4476, 447.7382, 448.6094, 447.7012,
        447.8734, 447.6735, 448.5615, 448.1770, 447.6275, 448.6177, 447.6807,
        447.7112, 448.6329, 447.6319, 448.6093, 447.6906, 447.6852, 447.5757,
        447.6610, 447.7271, 448.6417, 447.6934, 447.6783, 447.6871, 448.0521,
        448.6417, 447.6466, 447.7224, 447.5817, 448.6404, 447.7349, 447.7069,
        447.6586, 447.6376, 447.6890, 448.0267, 447.6897, 447.6777, 448.6417,
        448.5997, 447.6785, 447.6218, 447.7454, 447.5959, 447.7233, 447.6683,
        448.0103, 447.6437, 447.6770, 447.5826, 448.5821, 447.5994, 447.6979,
        448.6384, 447.6801, 447.6287, 447.6823, 447.6285, 447.5863, 447.6899,
        448.4529, 447.6988, 447.6616, 447.6623, 448.6110, 447.5879, 447.6619,
        448.5602, 448.6410, 447.7108, 448.6407, 448.6347, 447.6909, 447.6850,
        447.6699, 447.6887, 448.6295, 447.6434, 447.6733, 447.7148, 447.6909,
        447.5909, 447.7039, 447.6163, 447.7029, 447.6783, 448.6407, 448.6329,
        448.6416, 447.5977, 447.6760, 447.5984, 447.7155, 447.7313, 448.6193,
        447.6521, 447.7988, 447.6721, 448.6417, 447.6609, 447.6794, 447.6886,
        447.6581, 447.6228, 448.6416, 447.6828, 447.6815, 447.6119, 448.6155,
        447.5933, 447.6903, 447.6539, 447.6840, 448.6086, 447.6716, 447.6801,
        447.6684, 447.6310, 447.6572, 447.6381, 448.5332, 448.5882, 448.3342,
        447.6179, 447.7069, 447.6192, 447.5975, 447.6841, 447.6619, 447.7986,
        447.6908, 448.4198, 448.6163, 447.6703, 448.6417, 447.7477, 447.6260,
        447.7150, 448.6408, 447.7157, 447.6100, 448.0391, 447.6521, 447.6933,
        447.6728, 447.5930, 447.6776, 447.7469, 447.6713, 447.7479, 447.6734,
        447.7169, 447.6926, 447.6545, 447.5927, 447.6471, 447.7236, 448.3848,
        447.7255, 448.6416, 447.6946, 447.9912, 448.6122, 448.5768, 447.7130,
        447.6744, 447.7244, 447.6968, 448.5222, 447.7046, 448.6217, 447.6640,
        447.6773, 447.6066, 448.6371, 447.6525, 447.7283, 447.7265, 448.6295,
        447.7081, 448.5408, 447.6754, 447.7414, 448.5842, 447.6909, 447.7680,
        447.6650, 447.7260, 448.6365, 447.6413, 447.6904, 447.7016, 448.6226,
        448.5737, 447.6794, 447.6899, 447.8347, 447.7082, 447.6552, 447.6483,
        447.6093, 447.7455, 447.6826, 448.6054, 447.6653, 447.9813, 447.6470,
        447.6819, 448.6163, 448.6080, 447.7287, 447.6771, 447.6650, 448.6234,
        447.6935, 448.6416, 447.6580, 447.5889, 447.6113, 447.9210, 447.6494,
        448.3957, 447.6607, 447.7326, 447.5945, 447.6302, 447.5896, 448.6382,
        447.6972, 447.7263, 447.7086, 447.6725, 447.8633, 447.6550, 447.7056,
        447.6351, 447.6844, 447.6792, 448.6406, 447.6674, 448.5696, 447.8354,
        447.6658, 448.3058, 447.6784, 447.6387, 448.5485, 448.6370, 447.6035,
        448.6416, 448.4141, 447.6574, 447.6606, 447.7596, 448.6417, 448.4231,
        447.7259, 447.7072], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([407.3919], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1369],
             [111.8892],
             [112.0136],
             [112.0136]],

            [[111.9150],
             [111.9437],
             [111.9164],
             [111.9078]],

            [[111.9368],
             [111.9368],
             [111.9352],
             [111.9352]],

            ...,

            [[111.9218],
             [111.9218],
             [111.9434],
             [111.9434]],

            [[111.9240],
             [111.9206],
             [111.9426],
             [111.9426]],

            [[112.1561],
             [112.1561],
             [112.1535],
             [112.1535]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0533, 447.6830, 447.7440,  ..., 447.7305, 447.7299, 448.6191],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0533, 447.6830, 447.7440,  ..., 447.7305, 447.7299, 448.6191],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8838],
             [111.8838],
             [111.8841],
             [111.8841]],

            [[111.8925],
             [111.8925],
             [111.9080],
             [111.9080]],

            [[111.8900],
             [111.8662],
             [111.8508],
             [111.8967]],

            ...,

            [[111.8769],
             [111.8769],
             [111.8822],
             [111.9043]],

            [[111.8734],
             [111.8900],
             [111.9011],
             [111.9011]],

            [[111.8581],
             [112.0378],
             [112.0294],
             [111.8587]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5356, 447.6010, 447.5037,  ..., 447.5403, 447.5656, 447.7840],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5356, 447.6010, 447.5037,  ..., 447.5403, 447.5656, 447.7840],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1688],
             [112.1688],
             [112.1688],
             [112.1688]],

            [[112.1377],
             [111.8434],
             [112.1303],
             [111.8212]],

            [[111.8734],
             [111.8734],
             [111.8748],
             [111.8748]],

            ...,

            [[111.8586],
             [111.8772],
             [111.8540],
             [111.8598]],

            [[111.8599],
             [111.8599],
             [111.8595],
             [111.8595]],

            [[111.8413],
             [111.8646],
             [111.8542],
             [111.8716]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6751, 447.9326, 447.4964,  ..., 447.4496, 447.4388, 447.4318],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6751, 447.9326, 447.4964,  ..., 447.4496, 447.4388, 447.4318],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8394],
             [111.8394],
             [111.8522],
             [111.8522]],

            [[111.8345],
             [111.8494],
             [111.8300],
             [111.8319]],

            [[112.1677],
             [112.1676],
             [112.1676],
             [112.1677]],

            ...,

            [[111.8276],
             [111.7922],
             [111.8312],
             [111.7920]],

            [[112.1677],
             [112.1677],
             [112.1677],
             [112.1677]],

            [[111.8401],
             [111.8452],
             [111.8419],
             [111.8434]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3831, 447.3459, 448.6706,  ..., 447.2430, 448.6707, 447.3706],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3831, 447.3459, 448.6706,  ..., 447.2430, 448.6707, 447.3706],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8112],
             [111.8218],
             [111.8087],
             [111.8087]],

            [[111.8008],
             [111.8172],
             [111.8081],
             [111.8151]],

            [[111.7779],
             [111.8089],
             [111.7901],
             [111.8065]],

            ...,

            [[112.1660],
             [112.1474],
             [112.1474],
             [112.1675]],

            [[111.8057],
             [111.8035],
             [111.8102],
             [111.8236]],

            [[111.8145],
             [111.8089],
             [111.8176],
             [111.8244]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2504, 447.2412, 447.1833,  ..., 448.6283, 447.2429, 447.2654],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2504, 447.2412, 447.1833,  ..., 448.6283, 447.2429, 447.2654],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8450],
             [112.1436],
             [112.1445],
             [111.8352]],

            [[111.7660],
             [111.7879],
             [111.7823],
             [111.7823]],

            [[111.7701],
             [111.7873],
             [111.7691],
             [111.7874]],

            ...,

            [[111.7911],
             [111.7911],
             [111.7980],
             [111.7980]],

            [[112.1611],
             [112.1611],
             [112.1555],
             [112.1555]],

            [[111.7967],
             [111.7943],
             [111.7877],
             [111.7844]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9684, 447.1187, 447.1140,  ..., 447.1783, 448.6333, 447.1631],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9684, 447.1187, 447.1140,  ..., 447.1783, 448.6333, 447.1631],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1621],
             [112.1621],
             [112.1621],
             [112.1621]],

            [[111.7142],
             [111.7617],
             [111.7199],
             [111.7622]],

            [[111.7705],
             [111.7705],
             [111.7709],
             [111.7709]],

            ...,

            [[111.7680],
             [111.7377],
             [111.7683],
             [111.7683]],

            [[111.7550],
             [111.7550],
             [111.7612],
             [111.7612]],

            [[111.7570],
             [111.7570],
             [111.7680],
             [111.7680]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6483, 446.9580, 447.0827,  ..., 447.0424, 447.0325, 447.0499],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6483, 446.9580, 447.0827,  ..., 447.0424, 447.0325, 447.0499],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7422],
             [111.7412],
             [111.7501],
             [111.7501]],

            [[111.7461],
             [111.7461],
             [111.7513],
             [111.7513]],

            [[111.7205],
             [111.7468],
             [111.6993],
             [111.7460]],

            ...,

            [[112.1479],
             [112.1479],
             [112.1479],
             [112.1479]],

            [[112.0679],
             [111.6989],
             [112.0660],
             [111.6991]],

            [[112.0655],
             [111.6993],
             [112.0655],
             [111.6993]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9836, 446.9947, 446.9126,  ..., 448.5916, 447.5319, 447.5297],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9836, 446.9947, 446.9126,  ..., 448.5916, 447.5319, 447.5297],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7317],
             [111.7317],
             [111.7378],
             [111.7378]],

            [[111.7379],
             [111.7291],
             [111.7355],
             [111.7383]],

            [[111.7170],
             [111.7360],
             [111.7012],
             [111.7279]],

            ...,

            [[111.7193],
             [111.7346],
             [111.7185],
             [111.7368]],

            [[111.7283],
             [111.7252],
             [111.7369],
             [111.7381]],

            [[111.7366],
             [111.7366],
             [111.7386],
             [111.7386]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9391, 446.9408, 446.8821,  ..., 446.9092, 446.9284, 446.9503],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9391, 446.9408, 446.8821,  ..., 446.9092, 446.9284, 446.9503],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7319],
             [111.7319],
             [111.7319],
             [111.7319]],

            [[111.7348],
             [111.7348],
             [111.7361],
             [111.7361]],

            [[112.1151],
             [112.1149],
             [112.1149],
             [112.1151]],

            ...,

            [[111.7269],
             [111.7268],
             [111.7271],
             [111.7268]],

            [[112.1113],
             [112.1113],
             [112.1117],
             [112.1117]],

            [[111.7369],
             [111.7369],
             [111.7355],
             [111.7355]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9277, 446.9418, 448.4600,  ..., 446.9075, 448.4459, 446.9449],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9277, 446.9418, 448.4600,  ..., 446.9075, 448.4459, 446.9449],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7311],
             [111.7407],
             [111.7398],
             [111.7371]],

            [[111.7398],
             [111.7405],
             [111.7403],
             [111.7375]],

            [[111.7394],
             [111.7394],
             [111.7398],
             [111.7398]],

            ...,

            [[111.7389],
             [111.7384],
             [111.7389],
             [111.7384]],

            [[111.7029],
             [111.7398],
             [111.6923],
             [111.7395]],

            [[112.0974],
             [112.0975],
             [112.0861],
             [112.0861]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.9487, 446.9581, 446.9583,  ..., 446.9547, 446.8746, 448.3670],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.9487, 446.9581, 446.9583,  ..., 446.9547, 446.8746, 448.3670],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7099],
             [111.7290],
             [111.9365],
             [111.7157]],

            [[111.7427],
             [111.7384],
             [111.7395],
             [111.7395]],

            [[111.7409],
             [111.7386],
             [111.7359],
             [111.7415]],

            ...,

            [[111.7135],
             [111.7135],
             [111.7271],
             [111.7271]],

            [[112.0639],
             [112.0639],
             [111.9552],
             [111.9552]],

            [[111.7383],
             [111.7394],
             [111.7385],
             [111.7395]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.0911, 446.9601, 446.9569,  ..., 446.8811, 448.0381, 446.9557],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.0911, 446.9601, 446.9569,  ..., 446.8811, 448.0381, 446.9557],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0498],
             [111.8297],
             [112.0461],
             [111.9629]],

            [[111.7329],
             [111.7329],
             [111.7318],
             [111.7318]],

            [[111.7322],
             [111.7338],
             [111.7332],
             [111.7250]],

            ...,

            [[112.0648],
             [112.0649],
             [112.0649],
             [112.0650]],

            [[111.9004],
             [111.6643],
             [111.9281],
             [111.6873]],

            [[111.7077],
             [111.7342],
             [111.7302],
             [111.7302]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8884, 446.9294, 446.9242,  ..., 448.2597, 447.1801, 446.9024],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8884, 446.9294, 446.9242,  ..., 448.2597, 447.1801, 446.9024],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8813],
             [111.6696],
             [111.8700],
             [111.6890]],

            [[111.7262],
             [111.7262],
             [111.7246],
             [111.7145]],

            [[112.0079],
             [111.6564],
             [111.6590],
             [111.6590]],

            ...,

            [[111.7225],
             [111.7200],
             [111.7218],
             [111.7196]],

            [[112.0141],
             [111.8590],
             [111.9345],
             [111.9345]],

            [[111.6705],
             [111.6754],
             [111.7265],
             [111.7238]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.1099, 446.8915, 446.9824,  ..., 446.8839, 447.7420, 446.7963],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.1099, 446.8915, 446.9824,  ..., 446.8839, 447.7420, 446.7963],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7199],
             [111.7199],
             [111.7157],
             [111.7126]],

            [[111.7204],
             [111.7204],
             [111.7145],
             [111.7145]],

            [[111.7132],
             [111.7148],
             [111.7099],
             [111.7099]],

            ...,

            [[111.7195],
             [111.7172],
             [111.7099],
             [111.7182]],

            [[111.7174],
             [111.7174],
             [111.7132],
             [111.7132]],

            [[111.7155],
             [111.7124],
             [111.7180],
             [111.7104]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.8681, 446.8698, 446.8478,  ..., 446.8648, 446.8611, 446.8564],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.8681, 446.8698, 446.8478,  ..., 446.8648, 446.8611, 446.8564],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7290],
             [111.7290],
             [111.7184],
             [111.7184]],

            [[111.7315],
             [111.7192],
             [111.7296],
             [111.7311]],

            [[111.9111],
             [112.0480],
             [111.9030],
             [112.0448]],

            ...,

            [[111.7307],
             [111.7286],
             [111.7182],
             [111.7182]],

            [[111.8540],
             [111.6993],
             [111.6608],
             [111.6608]],

            [[111.6568],
             [111.7286],
             [111.7083],
             [111.7083]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([446.8947, 446.9114, 447.9069,  ..., 446.8957, 446.8749, 446.8020],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([446.8947, 446.9114, 447.9069,  ..., 446.8957, 446.8749, 446.8020],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7526],
             [111.7497],
             [111.7471],
             [111.7579]],

            [[111.7072],
             [111.7072],
             [111.7127],
             [111.7127]],

            [[111.9908],
             [111.6884],
             [111.7820],
             [111.7820]],

            ...,

            [[111.7547],
             [111.7473],
             [111.7528],
             [111.7523]],

            [[111.6825],
             [111.7396],
             [111.6830],
             [111.7399]],

            [[111.7561],
             [111.7511],
             [111.7462],
             [111.7562]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.0073, 446.8398, 447.2432,  ..., 447.0071, 446.8449, 447.0096],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.0073, 446.8398, 447.2432,  ..., 447.0071, 446.8449, 447.0096],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0432],
             [111.9832],
             [111.9852],
             [112.0471]],

            [[112.0425],
             [112.0219],
             [112.0425],
             [112.0219]],

            [[111.7889],
             [111.7897],
             [111.7897],
             [111.7897]],

            ...,

            [[111.7873],
             [111.7220],
             [111.7299],
             [111.7913]],

            [[111.7923],
             [111.7856],
             [111.7902],
             [111.7802]],

            [[111.9314],
             [111.7398],
             [111.9385],
             [111.7428]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0586, 448.1288, 447.1581,  ..., 447.0305, 447.1482, 447.3525],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0586, 448.1288, 447.1581,  ..., 447.0305, 447.1482, 447.3525],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9955e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8201],
             [111.8201],
             [111.8200],
             [111.8252]],

            [[111.8251],
             [111.8045],
             [111.8251],
             [111.8132]],

            [[112.0265],
             [111.9913],
             [112.0177],
             [112.0177]],

            ...,

            [[112.0285],
             [112.0285],
             [112.0285],
             [112.0285]],

            [[111.7739],
             [111.8254],
             [111.8248],
             [111.8248]],

            [[111.8200],
             [111.8200],
             [111.8246],
             [111.8246]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2855, 447.2678, 448.0531,  ..., 448.1142, 447.2490, 447.2892],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2855, 447.2678, 448.0531,  ..., 448.1142, 447.2490, 447.2892],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7897],
             [111.8257],
             [111.8248],
             [111.8248]],

            [[111.8246],
             [111.8195],
             [111.8259],
             [111.8259]],

            [[111.8065],
             [111.8258],
             [111.8243],
             [111.8243]],

            ...,

            [[111.8190],
             [111.8245],
             [111.8255],
             [111.8255]],

            [[111.8233],
             [111.8260],
             [111.8251],
             [111.8188]],

            [[111.7525],
             [111.9741],
             [111.9931],
             [111.7465]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2650, 447.2959, 447.2807,  ..., 447.2945, 447.2931, 447.4662],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2650, 447.2959, 447.2807,  ..., 447.2945, 447.2931, 447.4662],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8092],
             [111.8263],
             [111.8220],
             [111.8220]],

            [[111.8217],
             [111.8257],
             [111.8205],
             [111.8251]],

            [[111.8001],
             [111.8207],
             [111.8000],
             [111.8510]],

            ...,

            [[111.9885],
             [112.0259],
             [112.0259],
             [111.9892]],

            [[111.8210],
             [111.8245],
             [111.7999],
             [111.8254]],

            [[111.8187],
             [111.8209],
             [111.8263],
             [111.8259]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2795, 447.2929, 447.2718, 447.2896, 447.2898, 447.2227, 447.2947,
            448.1139, 447.2950, 447.2950, 447.2848, 447.2946, 447.2893, 447.1909,
            447.9965, 447.4247, 447.9922, 448.1136, 447.2871, 447.2913, 447.2974,
            447.2908, 447.2761, 447.2832, 447.2943, 447.2937, 447.2910, 447.1284,
            447.2892, 447.2925, 447.1674, 447.2557, 448.0776, 447.2472, 447.2225,
            447.2892, 447.2832, 447.2935, 447.2950, 447.2787, 447.2940, 447.2816,
            448.0791, 447.1348, 447.2824, 447.1603, 447.2900, 447.2950, 447.2745,
            447.9164, 447.2935, 448.0075, 447.2883, 448.1138, 447.2869, 447.2953,
            447.2979, 447.2950, 447.2953, 448.1114, 447.2850, 447.2943, 447.2945,
            447.4624, 447.2949, 447.2486, 447.2755, 447.2980, 447.2440, 447.2057,
            447.2906, 447.4487, 447.4089, 447.2972, 447.2960, 447.3324, 447.2950,
            448.1091, 447.2962, 447.3016, 447.9231, 447.1415, 447.2911, 447.1527,
            447.2948, 447.3946, 448.1121, 447.2892, 447.2866, 447.3229, 447.2980,
            447.2771, 447.1795, 447.2932, 447.2863, 448.0874, 448.1141, 447.2852,
            447.3008, 447.2715, 448.1142, 447.2419, 447.2845, 447.2893, 447.2646,
            448.1095, 447.2244, 447.2876, 447.2585, 447.2864, 447.2880, 447.2842,
            447.2998, 447.2941, 447.2914, 447.7865, 447.2614, 447.2219, 447.2836,
            447.9569, 447.2931, 447.2119, 447.2959, 448.0468, 447.2845, 448.1134,
            447.8774, 447.2917, 447.2943, 448.1124, 447.2928, 447.2208, 447.6601,
            448.0876, 447.2849, 448.1142, 448.0966, 447.6177, 447.8121, 447.2894,
            447.2161, 447.2943, 447.2739, 448.0807, 447.2902, 448.1140, 447.1426,
            447.2579, 448.1131, 447.2926, 447.2958, 447.2885, 447.2915, 447.2835,
            447.0348, 447.2930, 447.2961, 447.3002, 447.1017, 447.2879, 448.0971,
            447.2887, 447.2862, 447.2943, 448.0805, 447.2948, 447.2919, 447.4733,
            447.2661, 448.0287, 447.4486, 447.4379, 447.2932, 447.2899, 447.2935,
            447.2921, 448.1115, 447.4212, 447.2716, 447.2921, 447.2930, 447.4372,
            447.2914, 447.2603, 448.1103, 447.2873, 447.1398, 448.1133, 447.2966,
            447.6556, 447.2348, 447.2984, 447.6573, 447.2968, 447.3783, 447.2962,
            447.2943, 447.9658, 447.4199, 447.2882, 447.2960, 447.2845, 447.2975,
            447.0734, 448.0863, 447.2959, 447.1957, 447.2962, 447.2871, 447.2934,
            447.3759, 447.1176, 447.0356, 447.2945, 447.3608, 447.2592, 447.2893,
            447.2469, 447.2857, 447.4089, 447.2608, 447.2725, 447.2876, 447.2943,
            447.2897, 447.2980, 447.3001, 447.2950, 447.2834, 447.2484, 447.1443,
            447.8932, 447.8721, 447.3019, 448.1135, 447.2497, 448.1135, 447.2957,
            447.2935, 447.4283, 447.1327, 447.2894, 447.2926, 447.3002, 447.2793,
            447.1636, 447.2242, 447.2592, 447.2949, 447.2962, 447.2061, 447.2413,
            447.2947, 447.2837, 448.1117, 447.2926, 448.1101, 447.2908, 447.7354,
            447.2959, 447.2849, 447.2152, 447.2932, 447.2882, 448.1102, 447.2737,
            447.2415, 447.2847, 447.2982, 447.2985, 447.2959, 447.2895, 447.7952,
            447.2948, 447.8690, 447.2604, 447.2899, 447.2949, 447.2947, 448.1139,
            448.0914, 447.2954, 447.4244, 447.2962, 447.2982, 447.2844, 447.4576,
            447.2918, 447.0123, 448.1142, 447.2935, 447.1153, 447.2906, 447.2732,
            448.1142, 447.1685, 447.2900, 447.9923, 447.2921, 448.1049, 448.1135,
            447.1268, 448.1142, 448.1141, 447.2814, 447.9800, 447.1546, 447.1342,
            447.2941, 447.2471, 447.2648, 447.2959, 447.2955, 448.1139, 447.5936,
            447.2950, 447.2770, 447.9385, 448.1136, 447.2842, 447.2581, 448.1139,
            447.2885, 448.0865, 447.3636, 448.1095, 447.2911, 447.2932, 447.2982,
            447.2903, 447.4294, 447.1630, 447.2258, 447.2950, 447.2929, 447.2296,
            448.0042, 447.3083, 447.1167, 447.2551, 447.5582, 447.2161, 447.2989,
            447.5473, 447.4372, 447.2885, 447.1724, 447.2933, 447.1489, 447.2927,
            447.2980, 447.2903, 447.9774, 447.2175, 447.2184, 447.2949, 447.6811,
            447.2838, 447.1080, 447.2894, 447.2930, 447.2841, 448.1138, 447.3437,
            447.4556, 448.1058, 447.2910, 447.2755, 447.2912, 448.1140, 447.2881,
            447.2089, 447.2977, 447.2890, 448.1136, 448.1134, 447.2964, 448.1138,
            447.2947, 447.2895, 447.2945, 447.2285, 447.2959, 447.2944, 448.0977,
            447.8504, 447.2643, 447.2814, 447.1252, 447.2436, 448.1134, 447.1724,
            447.3671, 447.2905, 447.2588, 447.2945, 447.2945, 448.1140, 447.2198,
            448.0921, 447.2950, 447.2961, 447.3592, 448.1044, 447.1522, 447.2957,
            447.2672, 447.6929, 448.1096, 448.0855, 447.2857, 447.2951, 447.2939,
            447.2578, 447.2839, 447.2817, 447.5021, 447.2889, 447.2955, 447.2881,
            447.2864, 448.1141, 447.2886, 447.1916, 447.4490, 447.2522, 447.2916,
            447.2665, 447.6178, 447.2770, 447.1729, 447.2663, 447.6823, 447.2840,
            447.2797, 448.1069, 448.1110, 448.1121, 447.1754, 447.2839, 447.2874,
            447.2674, 447.2477, 447.1295, 447.9897, 447.2894, 447.2895, 447.2939,
            447.2925, 447.4338, 448.1138, 447.2794, 447.2912, 447.2955, 447.1987,
            447.3022, 447.2987, 447.2936, 447.1179, 447.2973, 447.2962, 447.2018,
            447.1923, 447.4673, 447.2702, 447.3036, 447.8859, 447.0958, 447.2946,
            448.1141, 447.2911, 447.3001, 447.4199, 447.2628, 447.1277, 447.2891,
            447.4728, 447.2650, 447.2969, 447.2946, 447.2814, 447.4490, 447.2960,
            447.2956, 447.2299, 447.2833, 447.2887, 447.2954, 447.2242, 447.2895,
            448.1092, 447.2932, 447.9186, 447.6407, 447.2938, 447.1505, 447.6931,
            447.2889, 447.2864, 447.1285, 447.1516, 447.4246, 448.0058, 447.2949,
            448.0424, 447.1542, 447.2075, 448.0757, 447.2678, 447.2869, 448.1132,
            448.1127, 447.0869, 447.2960, 447.1967, 447.2971, 447.2969, 447.2177,
            447.2805, 448.0899, 447.8817, 448.0950, 447.2952, 447.2969, 447.2965,
            448.1140, 447.2935, 447.3026, 447.2947, 447.2881, 447.2385, 447.2866,
            447.2894, 447.2978, 447.2895, 447.2853, 448.1003, 447.2946, 447.2556,
            447.4199, 447.9694, 448.1080, 447.3005, 447.2877, 448.1139, 447.2950,
            448.1128, 447.2981, 448.0994, 447.1819, 447.1892, 447.2642, 447.2752,
            447.2785, 447.2931, 447.2913, 448.0488, 447.2941, 447.1689, 448.1071,
            447.3023, 447.2893, 447.2953, 448.1140, 447.8645, 448.1142, 447.1144,
            447.5383, 447.2939, 447.2908, 448.1139, 447.5316, 447.2963, 447.8915,
            447.2094, 447.1132, 447.1757, 447.6211, 447.2960, 447.2606, 447.2957,
            447.1617, 447.2948, 447.2848, 447.2697, 447.2632, 447.2941, 447.1736,
            447.2033, 447.2900, 448.0721, 447.2728, 447.1226, 447.2845, 447.2965,
            447.1949, 448.1140, 447.3024, 447.2730, 447.2804, 447.1237, 447.2963,
            447.9847, 447.2540, 448.1077, 447.1505, 447.2955, 447.1946, 447.2886,
            447.1129, 447.2877, 447.2896, 447.2952, 447.2921, 447.2921, 447.2879,
            447.2328, 448.1112, 447.1669, 447.5696, 447.2342, 448.1139, 447.7780,
            447.2909, 447.2873, 447.4600, 447.2990, 447.2933, 447.2849, 447.2410,
            447.2952, 447.2941, 447.1945, 447.2293, 447.1867, 448.1050, 447.2916,
            447.2900, 447.2888, 447.2971, 447.2951, 447.2844, 447.1587, 447.2826,
            447.2095, 448.0156, 448.1142, 448.0731, 447.8973, 447.4424, 447.2983,
            447.3944, 447.2961, 447.2962, 448.0534, 447.4370, 447.2943, 447.2252,
            447.2767, 447.2865, 447.2888, 447.2886, 447.2812, 447.2651, 447.2632,
            447.2962, 447.2856, 448.1079, 447.1490, 447.5017, 447.2390, 447.2881,
            447.4423, 447.1485, 447.3047, 447.2900, 447.2917, 447.4008, 447.4306,
            448.0070, 448.1020, 447.2927, 447.2893, 448.0635, 447.3619, 447.2948,
            447.2905, 447.2795, 447.3015, 447.2906, 447.2823, 447.2365, 447.2932,
            447.2847, 447.2979, 447.2932, 447.2597, 447.2894, 447.2578, 448.1087,
            447.2854, 447.2213, 447.2898, 447.2918, 447.2909, 447.2964, 448.1133,
            447.2898, 447.2772, 448.0532, 448.0958, 447.2938, 448.1141, 447.2912,
            447.2364, 447.2698, 447.2600, 447.2963, 448.0870, 448.1139, 447.2960,
            447.2646, 447.2061, 447.2951, 447.2836, 447.4910, 447.3031, 447.5474,
            447.2153, 447.2906, 447.2954, 447.2961, 447.1449, 447.1583, 447.2639,
            447.2942, 448.0441, 447.1992, 447.2846, 446.9608, 447.7772, 447.7711,
            447.2953, 447.2957, 447.2220, 447.2954, 447.2962, 447.1709, 448.0940,
            447.2964, 447.2615, 447.3016, 448.1127, 447.2140, 448.1140, 447.2971,
            447.2939, 447.1469, 447.2958, 447.8658, 447.2936, 447.2889, 448.1017,
            448.1141, 447.2956, 447.2971, 447.2959, 448.1142, 448.1063, 447.2927,
            447.2954, 448.0321, 447.2734, 447.2939, 447.2949, 447.2867, 448.1136,
            447.9259, 447.2772, 447.3014, 448.1125, 447.2938, 448.1116, 447.3015,
            447.1212, 447.2902, 447.1826, 447.1077, 448.0433, 447.2781, 447.2931,
            448.1141, 448.1141, 447.1935, 448.0182, 447.1101, 447.2754, 447.2885,
            447.2238, 447.2910, 448.1135, 448.0145, 447.2942, 447.2864, 447.2957,
            447.2307, 447.1791, 447.9774, 447.4804, 447.2957, 448.1115, 447.2939,
            447.2889, 447.2951, 447.2870, 447.2943, 447.1664, 447.3035, 447.2909,
            447.1670, 447.2618, 447.2944, 447.2927, 447.2915, 447.5692, 447.2834,
            448.1136, 447.2876, 447.2897, 447.6625, 448.1069, 447.8647, 447.2170,
            448.1138, 447.2144, 447.1680, 447.2939, 447.2821, 447.2894, 448.1142,
            447.2950, 447.2919, 447.2847, 447.2782, 448.1141, 447.2936, 447.2935,
            448.0832, 448.0188, 447.2924, 447.3755, 447.2931, 447.1520, 447.1422,
            448.1140, 448.1140, 447.2928, 447.2944, 447.3116, 447.2944, 447.0710,
            447.4607, 447.2388, 447.2929, 447.2814, 448.1131, 447.2892, 447.3019,
            447.2764, 447.2369, 447.3034, 447.9308, 447.2419, 448.1064, 447.2962,
            447.2845, 447.2961, 447.2574, 447.9994, 447.2171, 447.2575, 447.2942,
            448.1118, 447.2907, 447.1864, 447.2950, 448.1139, 447.2952, 447.2842,
            447.2912, 447.2099, 448.0671, 447.2683, 447.2991, 447.2922, 447.8867,
            447.2950, 447.2965, 447.2884, 447.4930, 447.4069, 447.2946, 447.9914,
            447.2877, 447.2894, 447.2935, 448.0025, 448.0396, 448.1140, 447.2872,
            447.2936, 448.1119, 447.2958, 447.2860, 447.2874, 447.2943, 448.1015,
            447.2899, 447.2863, 447.2963, 447.4499, 447.2836, 447.2901, 448.0295,
            447.2708, 447.2918], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2795, 447.2929, 447.2718, 447.2896, 447.2898, 447.2227, 447.2947,
        448.1139, 447.2950, 447.2950, 447.2848, 447.2946, 447.2893, 447.1909,
        447.9965, 447.4247, 447.9922, 448.1136, 447.2871, 447.2913, 447.2974,
        447.2908, 447.2761, 447.2832, 447.2943, 447.2937, 447.2910, 447.1284,
        447.2892, 447.2925, 447.1674, 447.2557, 448.0776, 447.2472, 447.2225,
        447.2892, 447.2832, 447.2935, 447.2950, 447.2787, 447.2940, 447.2816,
        448.0791, 447.1348, 447.2824, 447.1603, 447.2900, 447.2950, 447.2745,
        447.9164, 447.2935, 448.0075, 447.2883, 448.1138, 447.2869, 447.2953,
        447.2979, 447.2950, 447.2953, 448.1114, 447.2850, 447.2943, 447.2945,
        447.4624, 447.2949, 447.2486, 447.2755, 447.2980, 447.2440, 447.2057,
        447.2906, 447.4487, 447.4089, 447.2972, 447.2960, 447.3324, 447.2950,
        448.1091, 447.2962, 447.3016, 447.9231, 447.1415, 447.2911, 447.1527,
        447.2948, 447.3946, 448.1121, 447.2892, 447.2866, 447.3229, 447.2980,
        447.2771, 447.1795, 447.2932, 447.2863, 448.0874, 448.1141, 447.2852,
        447.3008, 447.2715, 448.1142, 447.2419, 447.2845, 447.2893, 447.2646,
        448.1095, 447.2244, 447.2876, 447.2585, 447.2864, 447.2880, 447.2842,
        447.2998, 447.2941, 447.2914, 447.7865, 447.2614, 447.2219, 447.2836,
        447.9569, 447.2931, 447.2119, 447.2959, 448.0468, 447.2845, 448.1134,
        447.8774, 447.2917, 447.2943, 448.1124, 447.2928, 447.2208, 447.6601,
        448.0876, 447.2849, 448.1142, 448.0966, 447.6177, 447.8121, 447.2894,
        447.2161, 447.2943, 447.2739, 448.0807, 447.2902, 448.1140, 447.1426,
        447.2579, 448.1131, 447.2926, 447.2958, 447.2885, 447.2915, 447.2835,
        447.0348, 447.2930, 447.2961, 447.3002, 447.1017, 447.2879, 448.0971,
        447.2887, 447.2862, 447.2943, 448.0805, 447.2948, 447.2919, 447.4733,
        447.2661, 448.0287, 447.4486, 447.4379, 447.2932, 447.2899, 447.2935,
        447.2921, 448.1115, 447.4212, 447.2716, 447.2921, 447.2930, 447.4372,
        447.2914, 447.2603, 448.1103, 447.2873, 447.1398, 448.1133, 447.2966,
        447.6556, 447.2348, 447.2984, 447.6573, 447.2968, 447.3783, 447.2962,
        447.2943, 447.9658, 447.4199, 447.2882, 447.2960, 447.2845, 447.2975,
        447.0734, 448.0863, 447.2959, 447.1957, 447.2962, 447.2871, 447.2934,
        447.3759, 447.1176, 447.0356, 447.2945, 447.3608, 447.2592, 447.2893,
        447.2469, 447.2857, 447.4089, 447.2608, 447.2725, 447.2876, 447.2943,
        447.2897, 447.2980, 447.3001, 447.2950, 447.2834, 447.2484, 447.1443,
        447.8932, 447.8721, 447.3019, 448.1135, 447.2497, 448.1135, 447.2957,
        447.2935, 447.4283, 447.1327, 447.2894, 447.2926, 447.3002, 447.2793,
        447.1636, 447.2242, 447.2592, 447.2949, 447.2962, 447.2061, 447.2413,
        447.2947, 447.2837, 448.1117, 447.2926, 448.1101, 447.2908, 447.7354,
        447.2959, 447.2849, 447.2152, 447.2932, 447.2882, 448.1102, 447.2737,
        447.2415, 447.2847, 447.2982, 447.2985, 447.2959, 447.2895, 447.7952,
        447.2948, 447.8690, 447.2604, 447.2899, 447.2949, 447.2947, 448.1139,
        448.0914, 447.2954, 447.4244, 447.2962, 447.2982, 447.2844, 447.4576,
        447.2918, 447.0123, 448.1142, 447.2935, 447.1153, 447.2906, 447.2732,
        448.1142, 447.1685, 447.2900, 447.9923, 447.2921, 448.1049, 448.1135,
        447.1268, 448.1142, 448.1141, 447.2814, 447.9800, 447.1546, 447.1342,
        447.2941, 447.2471, 447.2648, 447.2959, 447.2955, 448.1139, 447.5936,
        447.2950, 447.2770, 447.9385, 448.1136, 447.2842, 447.2581, 448.1139,
        447.2885, 448.0865, 447.3636, 448.1095, 447.2911, 447.2932, 447.2982,
        447.2903, 447.4294, 447.1630, 447.2258, 447.2950, 447.2929, 447.2296,
        448.0042, 447.3083, 447.1167, 447.2551, 447.5582, 447.2161, 447.2989,
        447.5473, 447.4372, 447.2885, 447.1724, 447.2933, 447.1489, 447.2927,
        447.2980, 447.2903, 447.9774, 447.2175, 447.2184, 447.2949, 447.6811,
        447.2838, 447.1080, 447.2894, 447.2930, 447.2841, 448.1138, 447.3437,
        447.4556, 448.1058, 447.2910, 447.2755, 447.2912, 448.1140, 447.2881,
        447.2089, 447.2977, 447.2890, 448.1136, 448.1134, 447.2964, 448.1138,
        447.2947, 447.2895, 447.2945, 447.2285, 447.2959, 447.2944, 448.0977,
        447.8504, 447.2643, 447.2814, 447.1252, 447.2436, 448.1134, 447.1724,
        447.3671, 447.2905, 447.2588, 447.2945, 447.2945, 448.1140, 447.2198,
        448.0921, 447.2950, 447.2961, 447.3592, 448.1044, 447.1522, 447.2957,
        447.2672, 447.6929, 448.1096, 448.0855, 447.2857, 447.2951, 447.2939,
        447.2578, 447.2839, 447.2817, 447.5021, 447.2889, 447.2955, 447.2881,
        447.2864, 448.1141, 447.2886, 447.1916, 447.4490, 447.2522, 447.2916,
        447.2665, 447.6178, 447.2770, 447.1729, 447.2663, 447.6823, 447.2840,
        447.2797, 448.1069, 448.1110, 448.1121, 447.1754, 447.2839, 447.2874,
        447.2674, 447.2477, 447.1295, 447.9897, 447.2894, 447.2895, 447.2939,
        447.2925, 447.4338, 448.1138, 447.2794, 447.2912, 447.2955, 447.1987,
        447.3022, 447.2987, 447.2936, 447.1179, 447.2973, 447.2962, 447.2018,
        447.1923, 447.4673, 447.2702, 447.3036, 447.8859, 447.0958, 447.2946,
        448.1141, 447.2911, 447.3001, 447.4199, 447.2628, 447.1277, 447.2891,
        447.4728, 447.2650, 447.2969, 447.2946, 447.2814, 447.4490, 447.2960,
        447.2956, 447.2299, 447.2833, 447.2887, 447.2954, 447.2242, 447.2895,
        448.1092, 447.2932, 447.9186, 447.6407, 447.2938, 447.1505, 447.6931,
        447.2889, 447.2864, 447.1285, 447.1516, 447.4246, 448.0058, 447.2949,
        448.0424, 447.1542, 447.2075, 448.0757, 447.2678, 447.2869, 448.1132,
        448.1127, 447.0869, 447.2960, 447.1967, 447.2971, 447.2969, 447.2177,
        447.2805, 448.0899, 447.8817, 448.0950, 447.2952, 447.2969, 447.2965,
        448.1140, 447.2935, 447.3026, 447.2947, 447.2881, 447.2385, 447.2866,
        447.2894, 447.2978, 447.2895, 447.2853, 448.1003, 447.2946, 447.2556,
        447.4199, 447.9694, 448.1080, 447.3005, 447.2877, 448.1139, 447.2950,
        448.1128, 447.2981, 448.0994, 447.1819, 447.1892, 447.2642, 447.2752,
        447.2785, 447.2931, 447.2913, 448.0488, 447.2941, 447.1689, 448.1071,
        447.3023, 447.2893, 447.2953, 448.1140, 447.8645, 448.1142, 447.1144,
        447.5383, 447.2939, 447.2908, 448.1139, 447.5316, 447.2963, 447.8915,
        447.2094, 447.1132, 447.1757, 447.6211, 447.2960, 447.2606, 447.2957,
        447.1617, 447.2948, 447.2848, 447.2697, 447.2632, 447.2941, 447.1736,
        447.2033, 447.2900, 448.0721, 447.2728, 447.1226, 447.2845, 447.2965,
        447.1949, 448.1140, 447.3024, 447.2730, 447.2804, 447.1237, 447.2963,
        447.9847, 447.2540, 448.1077, 447.1505, 447.2955, 447.1946, 447.2886,
        447.1129, 447.2877, 447.2896, 447.2952, 447.2921, 447.2921, 447.2879,
        447.2328, 448.1112, 447.1669, 447.5696, 447.2342, 448.1139, 447.7780,
        447.2909, 447.2873, 447.4600, 447.2990, 447.2933, 447.2849, 447.2410,
        447.2952, 447.2941, 447.1945, 447.2293, 447.1867, 448.1050, 447.2916,
        447.2900, 447.2888, 447.2971, 447.2951, 447.2844, 447.1587, 447.2826,
        447.2095, 448.0156, 448.1142, 448.0731, 447.8973, 447.4424, 447.2983,
        447.3944, 447.2961, 447.2962, 448.0534, 447.4370, 447.2943, 447.2252,
        447.2767, 447.2865, 447.2888, 447.2886, 447.2812, 447.2651, 447.2632,
        447.2962, 447.2856, 448.1079, 447.1490, 447.5017, 447.2390, 447.2881,
        447.4423, 447.1485, 447.3047, 447.2900, 447.2917, 447.4008, 447.4306,
        448.0070, 448.1020, 447.2927, 447.2893, 448.0635, 447.3619, 447.2948,
        447.2905, 447.2795, 447.3015, 447.2906, 447.2823, 447.2365, 447.2932,
        447.2847, 447.2979, 447.2932, 447.2597, 447.2894, 447.2578, 448.1087,
        447.2854, 447.2213, 447.2898, 447.2918, 447.2909, 447.2964, 448.1133,
        447.2898, 447.2772, 448.0532, 448.0958, 447.2938, 448.1141, 447.2912,
        447.2364, 447.2698, 447.2600, 447.2963, 448.0870, 448.1139, 447.2960,
        447.2646, 447.2061, 447.2951, 447.2836, 447.4910, 447.3031, 447.5474,
        447.2153, 447.2906, 447.2954, 447.2961, 447.1449, 447.1583, 447.2639,
        447.2942, 448.0441, 447.1992, 447.2846, 446.9608, 447.7772, 447.7711,
        447.2953, 447.2957, 447.2220, 447.2954, 447.2962, 447.1709, 448.0940,
        447.2964, 447.2615, 447.3016, 448.1127, 447.2140, 448.1140, 447.2971,
        447.2939, 447.1469, 447.2958, 447.8658, 447.2936, 447.2889, 448.1017,
        448.1141, 447.2956, 447.2971, 447.2959, 448.1142, 448.1063, 447.2927,
        447.2954, 448.0321, 447.2734, 447.2939, 447.2949, 447.2867, 448.1136,
        447.9259, 447.2772, 447.3014, 448.1125, 447.2938, 448.1116, 447.3015,
        447.1212, 447.2902, 447.1826, 447.1077, 448.0433, 447.2781, 447.2931,
        448.1141, 448.1141, 447.1935, 448.0182, 447.1101, 447.2754, 447.2885,
        447.2238, 447.2910, 448.1135, 448.0145, 447.2942, 447.2864, 447.2957,
        447.2307, 447.1791, 447.9774, 447.4804, 447.2957, 448.1115, 447.2939,
        447.2889, 447.2951, 447.2870, 447.2943, 447.1664, 447.3035, 447.2909,
        447.1670, 447.2618, 447.2944, 447.2927, 447.2915, 447.5692, 447.2834,
        448.1136, 447.2876, 447.2897, 447.6625, 448.1069, 447.8647, 447.2170,
        448.1138, 447.2144, 447.1680, 447.2939, 447.2821, 447.2894, 448.1142,
        447.2950, 447.2919, 447.2847, 447.2782, 448.1141, 447.2936, 447.2935,
        448.0832, 448.0188, 447.2924, 447.3755, 447.2931, 447.1520, 447.1422,
        448.1140, 448.1140, 447.2928, 447.2944, 447.3116, 447.2944, 447.0710,
        447.4607, 447.2388, 447.2929, 447.2814, 448.1131, 447.2892, 447.3019,
        447.2764, 447.2369, 447.3034, 447.9308, 447.2419, 448.1064, 447.2962,
        447.2845, 447.2961, 447.2574, 447.9994, 447.2171, 447.2575, 447.2942,
        448.1118, 447.2907, 447.1864, 447.2950, 448.1139, 447.2952, 447.2842,
        447.2912, 447.2099, 448.0671, 447.2683, 447.2991, 447.2922, 447.8867,
        447.2950, 447.2965, 447.2884, 447.4930, 447.4069, 447.2946, 447.9914,
        447.2877, 447.2894, 447.2935, 448.0025, 448.0396, 448.1140, 447.2872,
        447.2936, 448.1119, 447.2958, 447.2860, 447.2874, 447.2943, 448.1015,
        447.2899, 447.2863, 447.2963, 447.4499, 447.2836, 447.2901, 448.0295,
        447.2708, 447.2918], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([410.1737], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8210],
             [111.8208],
             [111.8210],
             [111.8266]],

            [[111.8147],
             [111.8239],
             [111.8224],
             [111.8227]],

            [[111.9137],
             [112.0205],
             [112.0211],
             [111.9086]],

            ...,

            [[111.8166],
             [111.8166],
             [111.8254],
             [111.8254]],

            [[112.0274],
             [112.0266],
             [112.0276],
             [112.0263]],

            [[111.7604],
             [111.7604],
             [111.7574],
             [111.7574]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2894, 447.2836, 447.8638,  ..., 447.2839, 448.1078, 447.0356],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2894, 447.2836, 447.8638,  ..., 447.2839, 448.1078, 447.0356],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7717],
             [111.8371],
             [111.8533],
             [111.9702]],

            [[111.9065],
             [111.8228],
             [111.7715],
             [111.7715]],

            [[111.8421],
             [111.8645],
             [111.8606],
             [111.8635]],

            ...,

            [[112.0113],
             [112.0113],
             [112.0094],
             [112.0094]],

            [[111.8637],
             [111.8637],
             [111.8632],
             [111.8632]],

            [[111.8543],
             [111.8632],
             [111.8567],
             [111.8630]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4323, 447.2724, 447.4307,  ..., 448.0413, 447.4537, 447.4373],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4323, 447.2724, 447.4307,  ..., 448.0413, 447.4537, 447.4373],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8844],
             [111.8814],
             [111.8821],
             [111.8838]],

            [[111.9718],
             [111.9718],
             [111.9641],
             [111.9641]],

            [[111.8672],
             [111.8841],
             [111.8658],
             [111.8839]],

            ...,

            [[111.8819],
             [111.8842],
             [111.8832],
             [111.8822]],

            [[111.9113],
             [111.9113],
             [111.8835],
             [111.8835]],

            [[111.8372],
             [111.8555],
             [111.7917],
             [111.7917]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5317, 447.8718, 447.5009,  ..., 447.5315, 447.5895, 447.2762],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5317, 447.8718, 447.5009,  ..., 447.5315, 447.5895, 447.2762],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9335],
             [111.8194],
             [111.9330],
             [111.8188]],

            [[111.9142],
             [111.9135],
             [111.9166],
             [111.9160]],

            [[111.9455],
             [111.9645],
             [111.9674],
             [111.9161]],

            ...,

            [[111.9178],
             [111.9166],
             [111.9178],
             [111.9170]],

            [[111.8042],
             [111.9556],
             [111.8015],
             [111.9454]],

            [[111.9697],
             [111.9697],
             [111.9565],
             [111.9565]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5048, 447.6604, 447.7936,  ..., 447.6693, 447.5067, 447.8524],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5048, 447.6604, 447.7936,  ..., 447.6693, 447.5067, 447.8524],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8829],
             [111.8941],
             [111.9002],
             [111.8876]],

            [[111.9442],
             [111.9473],
             [111.9432],
             [111.9473]],

            [[111.9473],
             [111.9473],
             [111.9429],
             [111.9463]],

            ...,

            [[111.9520],
             [111.9064],
             [111.9064],
             [111.9554]],

            [[111.9440],
             [111.9440],
             [111.9472],
             [111.9472]],

            [[111.9466],
             [111.9386],
             [111.9412],
             [111.9473]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5648, 447.7820, 447.7838,  ..., 447.7202, 447.7825, 447.7736],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5648, 447.7820, 447.7838,  ..., 447.7202, 447.7825, 447.7736],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9724],
             [111.9625],
             [111.9685],
             [111.9752]],

            [[111.9082],
             [111.9240],
             [111.9297],
             [111.8971]],

            [[111.9365],
             [111.8652],
             [111.8653],
             [111.9425]],

            ...,

            [[111.9455],
             [111.9557],
             [111.9708],
             [111.9701]],

            [[111.9188],
             [111.9188],
             [111.9130],
             [111.9130]],

            [[111.9212],
             [111.9713],
             [111.9712],
             [111.9741]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8787, 447.6590, 447.6095,  ..., 447.8420, 447.6638, 447.8378],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8787, 447.6590, 447.6095,  ..., 447.8420, 447.6638, 447.8378],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0054],
             [111.9968],
             [112.0063],
             [111.9941]],

            [[111.9869],
             [111.9869],
             [112.0018],
             [112.0018]],

            [[111.9308],
             [111.9308],
             [111.9308],
             [111.9309]],

            ...,

            [[111.9918],
             [112.0017],
             [112.0049],
             [112.0049]],

            [[112.0030],
             [112.0030],
             [112.0065],
             [112.0065]],

            [[111.9285],
             [111.9285],
             [111.8885],
             [111.8885]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0026, 447.9773, 447.7233,  ..., 448.0032, 448.0190, 447.6340],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0026, 447.9773, 447.7233,  ..., 448.0032, 448.0190, 447.6340],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9998],
             [112.0041],
             [111.9659],
             [111.9653]],

            [[111.9529],
             [111.9980],
             [111.9507],
             [111.9979]],

            [[112.0086],
             [112.0087],
             [111.9992],
             [112.0073]],

            ...,

            [[111.9965],
             [111.9965],
             [111.9931],
             [111.9982]],

            [[112.0031],
             [112.0047],
             [112.0052],
             [112.0040]],

            [[111.9234],
             [111.9225],
             [111.9229],
             [111.9229]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9352, 447.8996, 448.0238,  ..., 447.9843, 448.0171, 447.6916],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9352, 447.8996, 448.0238,  ..., 447.9843, 448.0171, 447.6916],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9013],
             [111.8980],
             [111.8536],
             [111.8536]],

            [[111.8656],
             [111.9482],
             [111.8646],
             [111.9485]],

            [[111.9941],
             [111.9941],
             [112.0005],
             [112.0005]],

            ...,

            [[111.9170],
             [111.9155],
             [111.9166],
             [111.9166]],

            [[111.9104],
             [111.8451],
             [111.9121],
             [111.8500]],

            [[111.9828],
             [111.9978],
             [111.9964],
             [111.9964]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5064, 447.6270, 447.9893,  ..., 447.6656, 447.5176, 447.9735],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5064, 447.6270, 447.9893,  ..., 447.6656, 447.5176, 447.9735],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8571],
             [111.9734],
             [111.8570],
             [111.9734]],

            [[111.9763],
             [111.9763],
             [111.9795],
             [111.9795]],

            [[111.8144],
             [111.9613],
             [111.8159],
             [111.9607]],

            ...,

            [[111.9825],
             [111.9916],
             [111.9731],
             [111.9785]],

            [[111.8973],
             [111.8973],
             [111.8971],
             [111.8971]],

            [[111.9773],
             [111.9859],
             [111.9793],
             [111.9847]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6609, 447.9117, 447.5523,  ..., 447.9257, 447.5887, 447.9272],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6609, 447.9117, 447.5523,  ..., 447.9257, 447.5887, 447.9272],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7949],
             [111.9302],
             [111.7952],
             [111.9454]],

            [[111.8801],
             [111.8801],
             [111.8800],
             [111.8800]],

            [[111.8798],
             [111.8798],
             [111.8797],
             [111.8797]],

            ...,

            [[111.9723],
             [111.9731],
             [111.9761],
             [111.9817]],

            [[111.9112],
             [111.9112],
             [111.9366],
             [111.9366]],

            [[111.9815],
             [111.9823],
             [111.9823],
             [111.9823]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4658, 447.5203, 447.5191,  ..., 447.9032, 447.6955, 447.9284],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4658, 447.5203, 447.5191,  ..., 447.9032, 447.6955, 447.9284],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9748],
             [111.9714],
             [111.9711],
             [111.9805]],

            [[111.8651],
             [111.8608],
             [111.8648],
             [111.8648]],

            [[111.9720],
             [111.9803],
             [111.9754],
             [111.9768]],

            ...,

            [[111.9497],
             [111.9720],
             [111.9445],
             [111.9712]],

            [[111.9536],
             [111.9536],
             [111.9528],
             [111.9528]],

            [[111.8552],
             [111.8500],
             [111.9635],
             [111.9635]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8978, 447.4555, 447.9044,  ..., 447.8373, 447.8127, 447.6321],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8978, 447.4555, 447.9044,  ..., 447.8373, 447.8127, 447.6321],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9417],
             [111.9629],
             [111.9222],
             [111.9527]],

            [[111.8579],
             [111.8579],
             [111.9161],
             [111.9161]],

            [[111.7704],
             [111.8867],
             [111.7704],
             [111.9323]],

            ...,

            [[111.9578],
             [111.9725],
             [111.9735],
             [111.9735]],

            [[111.9019],
             [111.9609],
             [111.9436],
             [111.9436]],

            [[111.9624],
             [111.9762],
             [111.9623],
             [111.9645]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7795, 447.5480, 447.3597,  ..., 447.8773, 447.7501, 447.8654],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7795, 447.5480, 447.3597,  ..., 447.8773, 447.7501, 447.8654],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9315],
             [111.9581],
             [111.9335],
             [111.9585]],

            [[111.8249],
             [111.8249],
             [111.7648],
             [111.7648]],

            [[111.9429],
             [111.8139],
             [111.9452],
             [111.9452]],

            ...,

            [[111.9452],
             [111.9452],
             [111.9580],
             [111.9580]],

            [[111.9491],
             [111.9627],
             [111.9495],
             [111.9387]],

            [[111.9515],
             [111.9538],
             [111.9304],
             [111.9304]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7816, 447.1795, 447.6473,  ..., 447.8065, 447.8000, 447.7660],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7816, 447.1795, 447.6473,  ..., 447.8065, 447.8000, 447.7660],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7922],
             [111.7922],
             [111.7908],
             [111.7908]],

            [[111.9424],
             [111.9599],
             [111.9475],
             [111.9624]],

            [[111.8252],
             [111.7865],
             [111.7876],
             [111.8283]],

            ...,

            [[111.9294],
             [111.9307],
             [111.9549],
             [111.9617]],

            [[111.8274],
             [111.8274],
             [111.8244],
             [111.8244]],

            [[111.8256],
             [111.8256],
             [111.8234],
             [111.8234]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.1660, 447.8123, 447.2275,  ..., 447.7766, 447.3036, 447.2980],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.1660, 447.8123, 447.2275,  ..., 447.7766, 447.3036, 447.2980],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8263],
             [111.8258],
             [111.8261],
             [111.8261]],

            [[111.9090],
             [111.9605],
             [111.9610],
             [111.9084]],

            [[111.9674],
             [111.9221],
             [111.9423],
             [111.9727]],

            ...,

            [[111.8244],
             [111.8008],
             [111.8250],
             [111.8046]],

            [[111.9686],
             [111.9686],
             [111.9686],
             [111.9686]],

            [[111.9691],
             [111.9730],
             [111.9721],
             [111.9721]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3043, 447.7388, 447.8044,  ..., 447.2547, 447.8744, 447.8864],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3043, 447.7388, 447.8044,  ..., 447.2547, 447.8744, 447.8864],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9634],
             [111.9693],
             [111.9778],
             [111.9778]],

            [[111.9804],
             [111.9816],
             [111.9814],
             [111.9814]],

            [[111.9712],
             [111.9597],
             [111.9681],
             [111.9809]],

            ...,

            [[111.9828],
             [111.9820],
             [111.9786],
             [111.9744]],

            [[111.9717],
             [111.9715],
             [111.9733],
             [111.9828]],

            [[111.9704],
             [111.9791],
             [111.9739],
             [111.9813]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8883, 447.9247, 447.8799,  ..., 447.9177, 447.8993, 447.9047],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8883, 447.9247, 447.8799,  ..., 447.9177, 447.8993, 447.9047],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0094],
             [112.0094],
             [112.0189],
             [112.0189]],

            [[111.9907],
             [111.8192],
             [111.9920],
             [111.8093]],

            [[112.0079],
             [111.9948],
             [112.0136],
             [111.9780]],

            ...,

            [[111.9975],
             [111.9975],
             [112.0135],
             [112.0135]],

            [[112.0067],
             [112.0067],
             [112.0082],
             [112.0082]],

            [[111.7993],
             [111.7993],
             [111.8200],
             [111.8200]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0565, 447.6113, 447.9943,  ..., 448.0221, 448.0298, 447.2386],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0565, 447.6113, 447.9943,  ..., 448.0221, 448.0298, 447.2386],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0049e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0345],
             [112.0347],
             [112.0305],
             [112.0512]],

            [[111.8514],
             [111.8514],
             [112.0229],
             [112.0229]],

            [[111.8235],
             [111.8235],
             [111.8235],
             [111.8236]],

            ...,

            [[112.0411],
             [112.0497],
             [112.0411],
             [112.0497]],

            [[112.0401],
             [112.0401],
             [112.0443],
             [112.0443]],

            [[111.7953],
             [111.9707],
             [111.7986],
             [111.9341]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1510, 447.7486, 447.2942,  ..., 448.1817, 448.1687, 447.4988],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1510, 447.7486, 447.2942,  ..., 448.1817, 448.1687, 447.4988],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8211],
             [111.7971],
             [111.8152],
             [111.8152]],

            [[112.0351],
             [112.0367],
             [112.0427],
             [112.0497]],

            [[111.7989],
             [111.7958],
             [111.8013],
             [111.8034]],

            ...,

            [[112.0354],
             [112.0439],
             [112.0257],
             [112.0468]],

            [[112.0489],
             [112.0489],
             [112.0509],
             [112.0509]],

            [[112.0358],
             [112.0425],
             [112.0504],
             [112.0366]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2486, 448.1642, 447.1994,  ..., 448.1517, 448.1997, 448.1653],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2486, 448.1642, 447.1994,  ..., 448.1517, 448.1997, 448.1653],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9196],
             [111.9196],
             [111.9158],
             [111.9158]],

            [[112.0508],
             [112.0517],
             [112.0456],
             [112.0460]],

            [[112.0376],
             [112.0432],
             [112.0467],
             [112.0409]],

            ...,

            [[111.9917],
             [112.0371],
             [112.0078],
             [112.0379]],

            [[111.9977],
             [112.0104],
             [112.0386],
             [112.0375]],

            [[112.0404],
             [112.0429],
             [112.0481],
             [112.0500]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6707, 448.1942, 448.1685, 447.5567, 447.7474, 448.1646, 447.2534,
            448.1260, 448.1674, 447.4921, 448.0309, 447.7776, 448.1488, 448.1519,
            448.1715, 448.1909, 448.1272, 447.7919, 448.1883, 448.1366, 447.1859,
            448.1024, 448.1854, 448.2012, 447.7238, 447.7280, 448.1628, 448.1185,
            448.1607, 447.2903, 447.2402, 448.1839, 447.2479, 447.8329, 447.2560,
            447.2666, 448.1561, 448.1610, 448.1434, 448.0744, 448.1725, 448.8496,
            448.1568, 448.1160, 447.5408, 447.5132, 448.1530, 447.7479, 448.1387,
            447.3466, 448.0914, 447.2814, 447.2878, 447.2737, 448.1705, 448.1700,
            448.1572, 448.1589, 448.1747, 447.3128, 448.1674, 448.1300, 447.2543,
            448.1900, 447.6949, 447.7599, 448.1652, 448.1750, 448.1600, 447.5529,
            447.3281, 448.1548, 448.1772, 448.1466, 447.2237, 447.5112, 448.1490,
            447.2922, 448.1617, 448.1710, 447.2943, 448.0984, 448.1811, 448.1648,
            447.5369, 448.1208, 448.1250, 447.8361, 448.1735, 447.8268, 448.1664,
            448.1487, 447.7841, 448.1434, 448.1558, 448.0606, 448.1581, 447.8744,
            447.8814, 447.6069, 447.2322, 447.2593, 448.1622, 448.1208, 448.1661,
            448.1526, 447.2728, 448.1953, 447.2943, 448.1774, 447.5792, 447.2551,
            448.1656, 448.1309, 447.2403, 448.0588, 447.7178, 448.1627, 447.2939,
            448.1583, 448.1417, 448.1840, 448.1675, 447.7236, 447.2356, 447.2504,
            447.8713, 448.1865, 447.2341, 448.1744, 447.2532, 447.2925, 448.2008,
            447.2407, 448.1925, 447.6990, 447.2404, 448.1578, 447.2783, 448.0613,
            447.5223, 448.1670, 448.1592, 448.1743, 448.1795, 447.2137, 448.1683,
            448.1693, 447.5546, 448.1674, 448.1671, 447.2672, 447.5870, 447.2939,
            447.5730, 448.1908, 447.2803, 448.1518, 447.3743, 447.2784, 447.2649,
            448.1698, 448.1623, 448.1563, 447.2474, 448.1889, 448.1538, 448.2004,
            447.4637, 448.1736, 448.1522, 447.2544, 447.2905, 447.2852, 448.0994,
            448.1436, 448.1799, 448.1907, 448.1008, 448.1838, 448.1904, 448.1955,
            448.1548, 447.2878, 447.7683, 447.2942, 447.2942, 448.1455, 447.9611,
            448.1377, 448.1563, 448.1184, 448.0860, 447.2908, 448.1113, 448.1556,
            448.1317, 447.2336, 448.0745, 448.1526, 447.2883, 448.1891, 447.6935,
            448.1651, 447.1900, 448.1693, 447.4407, 448.0639, 448.1837, 447.5757,
            448.1288, 448.1750, 448.1813, 448.1598, 448.1454, 448.1613, 448.1104,
            448.1606, 447.8653, 448.1739, 448.0109, 448.1328, 448.1787, 448.1686,
            447.9861, 448.1713, 448.1906, 448.0658, 447.6853, 448.1392, 448.1564,
            448.1976, 448.1673, 448.0955, 447.1819, 448.1943, 448.1989, 448.1689,
            448.1386, 447.2861, 447.2922, 447.2622, 448.0697, 447.2070, 448.1630,
            448.1390, 448.1343, 448.0332, 448.1351, 447.5611, 447.3515, 447.2350,
            448.1459, 448.1658, 448.1310, 448.1019, 447.2557, 447.2835, 447.2866,
            448.1669, 448.0506, 448.1687, 448.1221, 447.3344, 448.1715, 448.1844,
            448.1190, 448.1522, 448.1927, 448.1620, 447.9784, 448.1830, 448.1487,
            448.1366, 448.0235, 448.1369, 448.1194, 448.1681, 448.1789, 448.0741,
            447.9780, 448.2000, 447.2939, 448.1678, 448.1708, 447.2940, 447.2874,
            447.2256, 448.1083, 448.1832, 447.2943, 448.1817, 448.1923, 447.2384,
            447.8825, 447.2600, 448.1908, 448.1158, 447.2940, 448.1800, 448.1877,
            448.1607, 448.1124, 448.1694, 447.2177, 448.0042, 448.1581, 448.1369,
            447.2423, 448.1545, 447.5946, 448.1672, 448.1801, 447.2407, 448.1396,
            448.1723, 448.1851, 447.5567, 448.1390, 448.0754, 447.2937, 447.2776,
            447.8119, 447.3154, 447.9340, 447.2338, 448.0592, 447.3356, 448.1659,
            447.2878, 448.1383, 447.2773, 448.0668, 447.3375, 448.1899, 448.1255,
            448.1885, 447.2354, 448.1815, 448.1258, 448.1504, 447.2789, 447.1802,
            448.1511, 448.1125, 448.1678, 448.1245, 448.1393, 448.1887, 448.1033,
            448.1610, 447.4439, 448.1372, 448.1683, 448.1801, 448.1656, 448.1213,
            448.0632, 447.8962, 448.1561, 448.1886, 448.1522, 448.1248, 448.1374,
            448.1612, 448.1826, 448.1559, 448.1830, 447.2969, 448.1598, 448.1573,
            447.4319, 448.1676, 448.0533, 448.1721, 448.1323, 448.1671, 448.1608,
            448.1835, 448.1553, 448.1233, 447.5568, 448.1475, 447.2388, 447.2941,
            447.2439, 447.8705, 447.8646, 447.2297, 448.1576, 448.1810, 447.2880,
            448.1829, 448.0766, 448.1574, 448.1543, 448.1059, 447.5567, 448.1732,
            447.2762, 448.1525, 447.5568, 447.5616, 448.1483, 447.7109, 448.1803,
            448.1129, 448.1677, 448.1564, 447.2757, 447.9976, 448.1435, 447.2943,
            448.1077, 448.1628, 448.2014, 448.1898, 448.1685, 447.4978, 448.2010,
            448.1896, 448.1743, 448.1626, 448.8367, 448.1742, 447.2384, 448.1882,
            447.5016, 447.2318, 447.2744, 448.1622, 447.2948, 448.1583, 448.2869,
            448.0109, 447.2939, 447.2939, 448.1782, 447.2938, 447.2609, 448.1770,
            448.1739, 448.1649, 448.1404, 447.2750, 448.0706, 447.2830, 448.1696,
            448.1531, 447.3335, 447.8482, 447.8967, 447.6391, 448.0334, 448.1906,
            447.2184, 447.3750, 448.1956, 447.9036, 448.1632, 447.2928, 447.5578,
            447.2942, 448.1938, 448.1721, 448.1113, 448.1519, 448.1245, 448.0798,
            447.7256, 448.0926, 448.1153, 448.1841, 448.1042, 448.1626, 448.1425,
            448.1202, 447.5883, 447.7486, 448.0686, 448.1467, 447.3836, 447.7080,
            448.1551, 448.1984, 448.1653, 448.1840, 448.1829, 448.1940, 447.3000,
            448.1625, 448.1732, 447.2931, 448.0140, 447.2934, 448.0819, 448.1710,
            447.2874, 447.2404, 448.1420, 448.1621, 448.1699, 448.1000, 448.1859,
            447.3323, 448.1714, 448.1674, 448.1870, 448.0965, 448.1745, 448.1674,
            448.1223, 447.2668, 448.0992, 448.1496, 448.1855, 448.8479, 447.2850,
            448.1920, 448.1696, 448.1564, 448.1701, 448.1989, 448.1802, 448.1570,
            448.1618, 448.1569, 448.1033, 448.1558, 448.1943, 447.5439, 448.1735,
            448.1558, 448.0202, 447.8463, 448.1682, 447.2943, 447.4192, 448.0081,
            448.1538, 448.1286, 448.1664, 448.1959, 448.1677, 448.0197, 447.2928,
            448.1883, 447.2925, 448.1418, 448.1129, 448.1685, 448.1353, 447.2942,
            447.2932, 448.1919, 448.1180, 448.1259, 448.1965, 448.1606, 448.1708,
            447.2942, 447.2942, 447.3234, 448.1688, 448.1917, 447.2943, 448.1631,
            448.1404, 448.1204, 448.1570, 447.2943, 448.1847, 447.2941, 447.2508,
            448.1591, 448.1009, 447.2803, 447.2932, 448.1168, 448.1559, 447.2933,
            448.1762, 448.1303, 447.9504, 448.1458, 447.9081, 447.6181, 448.1423,
            448.1414, 448.1139, 447.2912, 448.1877, 447.2937, 448.1628, 448.1640,
            447.8082, 448.1627, 448.0682, 448.1912, 447.2932, 448.1943, 447.2435,
            447.8962, 448.1639, 448.1815, 447.2820, 448.1530, 447.2249, 448.1096,
            448.1535, 448.1559, 447.6000, 448.1569, 448.1016, 448.1773, 447.2941,
            448.1777, 448.1429, 447.9464, 447.5437, 448.1719, 448.1502, 447.2041,
            447.6114, 447.6906, 447.2593, 447.2943, 448.1697, 448.1426, 448.1871,
            448.1880, 447.8904, 447.4560, 448.1713, 447.2911, 448.1697, 447.2315,
            447.2201, 448.1938, 448.1775, 447.2861, 448.1975, 448.8480, 447.7114,
            448.1004, 448.0646, 448.0054, 447.8713, 447.2884, 448.1782, 447.2767,
            447.2718, 448.1647, 448.1250, 448.1784, 448.1569, 448.1216, 448.1871,
            448.1198, 447.7332, 448.1764, 447.8302, 447.2632, 447.9761, 447.7347,
            447.9131, 447.5578, 447.3933, 447.2901, 448.1703, 448.0916, 448.1631,
            448.1715, 448.1631, 448.1651, 448.0768, 447.2444, 447.2943, 448.1739,
            448.1708, 448.1784, 448.1046, 447.2745, 447.2869, 448.1405, 448.1159,
            447.2831, 448.1024, 448.1606, 447.2933, 448.0884, 447.2580, 448.8470,
            448.1573, 448.0657, 447.2425, 447.2267, 448.1544, 447.2405, 447.2930,
            448.1321, 447.2287, 447.2940, 447.6373, 448.1802, 448.1888, 448.1569,
            447.7895, 448.1448, 448.1660, 448.1754, 447.7838, 447.7700, 447.5138,
            447.2903, 448.1504, 447.1959, 448.1837, 448.1629, 447.2922, 448.1639,
            447.5253, 447.2942, 447.2944, 448.1531, 448.1694, 447.2854, 448.1645,
            447.8371, 448.1732, 448.1729, 447.5412, 448.1609, 448.1654, 447.9506,
            448.1718, 447.2761, 448.1749, 447.2940, 448.1525, 448.1501, 447.3188,
            448.1647, 448.1830, 448.1671, 448.1550, 448.1730, 447.5376, 448.1273,
            448.1685, 447.2693, 448.1645, 448.1736, 448.0627, 447.4802, 448.1118,
            447.2938, 448.1901, 448.1111, 448.1855, 448.1117, 448.1854, 448.0909,
            448.1638, 448.1969, 447.2942, 448.1573, 448.1902, 448.1265, 448.1602,
            448.1743, 448.1952, 448.1480, 448.1511, 448.1858, 447.5380, 448.1612,
            447.2899, 448.1627, 448.1700, 448.1625, 447.2699, 448.1396, 447.3567,
            448.1610, 447.2333, 448.1592, 447.2943, 448.1688, 448.1689, 448.0994,
            447.2810, 448.1137, 447.5641, 448.1899, 448.1378, 448.1769, 448.1654,
            448.0281, 448.1724, 448.1701, 448.1681, 448.1646, 448.1680, 448.1508,
            448.1111, 448.1768, 447.2940, 448.1372, 447.2164, 448.1844, 447.5374,
            447.2941, 447.3638, 447.2738, 447.3662, 448.1548, 447.5717, 447.2913,
            448.1269, 448.1470, 448.1600, 447.2513, 448.1743, 448.1887, 447.2696,
            448.1922, 448.1644, 448.1573, 448.1838, 447.2943, 448.1990, 448.1824,
            448.1758, 447.2940, 448.0460, 448.1636, 448.1558, 448.1637, 448.1319,
            448.1686, 447.5334, 447.2399, 448.1903, 448.0570, 448.1224, 447.2942,
            448.1736, 448.8252, 448.1408, 448.1431, 447.1939, 448.1570, 448.1519,
            448.1557, 447.2888, 447.3285, 448.1722, 447.2645, 448.1449, 448.1703,
            448.1518, 448.1643, 448.1940, 447.2943, 447.6932, 448.1185, 448.1656,
            448.1823, 447.2943, 448.1515, 448.0423, 447.2726, 448.1424, 448.1454,
            447.2894, 448.1698, 448.0707, 448.1751, 447.2941, 448.1709, 448.1483,
            448.0766, 448.8004, 447.2897, 448.1930, 447.2416, 447.2913, 448.1374,
            448.1417, 448.1637, 448.1647, 447.2873, 447.3242, 448.1825, 448.1475,
            447.2806, 447.2795, 447.6089, 447.2073, 448.1380, 448.1782, 448.1129,
            448.1759, 448.1562, 448.1802, 447.8857, 447.2456, 448.1622, 448.1419,
            448.1724, 447.3162, 447.2941, 448.1329, 448.1733, 448.4596, 448.1717,
            447.6794, 447.2304, 448.1083, 447.2943, 447.2935, 448.1680, 448.0746,
            448.0841, 448.1815], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6707, 448.1942, 448.1685, 447.5567, 447.7474, 448.1646, 447.2534,
        448.1260, 448.1674, 447.4921, 448.0309, 447.7776, 448.1488, 448.1519,
        448.1715, 448.1909, 448.1272, 447.7919, 448.1883, 448.1366, 447.1859,
        448.1024, 448.1854, 448.2012, 447.7238, 447.7280, 448.1628, 448.1185,
        448.1607, 447.2903, 447.2402, 448.1839, 447.2479, 447.8329, 447.2560,
        447.2666, 448.1561, 448.1610, 448.1434, 448.0744, 448.1725, 448.8496,
        448.1568, 448.1160, 447.5408, 447.5132, 448.1530, 447.7479, 448.1387,
        447.3466, 448.0914, 447.2814, 447.2878, 447.2737, 448.1705, 448.1700,
        448.1572, 448.1589, 448.1747, 447.3128, 448.1674, 448.1300, 447.2543,
        448.1900, 447.6949, 447.7599, 448.1652, 448.1750, 448.1600, 447.5529,
        447.3281, 448.1548, 448.1772, 448.1466, 447.2237, 447.5112, 448.1490,
        447.2922, 448.1617, 448.1710, 447.2943, 448.0984, 448.1811, 448.1648,
        447.5369, 448.1208, 448.1250, 447.8361, 448.1735, 447.8268, 448.1664,
        448.1487, 447.7841, 448.1434, 448.1558, 448.0606, 448.1581, 447.8744,
        447.8814, 447.6069, 447.2322, 447.2593, 448.1622, 448.1208, 448.1661,
        448.1526, 447.2728, 448.1953, 447.2943, 448.1774, 447.5792, 447.2551,
        448.1656, 448.1309, 447.2403, 448.0588, 447.7178, 448.1627, 447.2939,
        448.1583, 448.1417, 448.1840, 448.1675, 447.7236, 447.2356, 447.2504,
        447.8713, 448.1865, 447.2341, 448.1744, 447.2532, 447.2925, 448.2008,
        447.2407, 448.1925, 447.6990, 447.2404, 448.1578, 447.2783, 448.0613,
        447.5223, 448.1670, 448.1592, 448.1743, 448.1795, 447.2137, 448.1683,
        448.1693, 447.5546, 448.1674, 448.1671, 447.2672, 447.5870, 447.2939,
        447.5730, 448.1908, 447.2803, 448.1518, 447.3743, 447.2784, 447.2649,
        448.1698, 448.1623, 448.1563, 447.2474, 448.1889, 448.1538, 448.2004,
        447.4637, 448.1736, 448.1522, 447.2544, 447.2905, 447.2852, 448.0994,
        448.1436, 448.1799, 448.1907, 448.1008, 448.1838, 448.1904, 448.1955,
        448.1548, 447.2878, 447.7683, 447.2942, 447.2942, 448.1455, 447.9611,
        448.1377, 448.1563, 448.1184, 448.0860, 447.2908, 448.1113, 448.1556,
        448.1317, 447.2336, 448.0745, 448.1526, 447.2883, 448.1891, 447.6935,
        448.1651, 447.1900, 448.1693, 447.4407, 448.0639, 448.1837, 447.5757,
        448.1288, 448.1750, 448.1813, 448.1598, 448.1454, 448.1613, 448.1104,
        448.1606, 447.8653, 448.1739, 448.0109, 448.1328, 448.1787, 448.1686,
        447.9861, 448.1713, 448.1906, 448.0658, 447.6853, 448.1392, 448.1564,
        448.1976, 448.1673, 448.0955, 447.1819, 448.1943, 448.1989, 448.1689,
        448.1386, 447.2861, 447.2922, 447.2622, 448.0697, 447.2070, 448.1630,
        448.1390, 448.1343, 448.0332, 448.1351, 447.5611, 447.3515, 447.2350,
        448.1459, 448.1658, 448.1310, 448.1019, 447.2557, 447.2835, 447.2866,
        448.1669, 448.0506, 448.1687, 448.1221, 447.3344, 448.1715, 448.1844,
        448.1190, 448.1522, 448.1927, 448.1620, 447.9784, 448.1830, 448.1487,
        448.1366, 448.0235, 448.1369, 448.1194, 448.1681, 448.1789, 448.0741,
        447.9780, 448.2000, 447.2939, 448.1678, 448.1708, 447.2940, 447.2874,
        447.2256, 448.1083, 448.1832, 447.2943, 448.1817, 448.1923, 447.2384,
        447.8825, 447.2600, 448.1908, 448.1158, 447.2940, 448.1800, 448.1877,
        448.1607, 448.1124, 448.1694, 447.2177, 448.0042, 448.1581, 448.1369,
        447.2423, 448.1545, 447.5946, 448.1672, 448.1801, 447.2407, 448.1396,
        448.1723, 448.1851, 447.5567, 448.1390, 448.0754, 447.2937, 447.2776,
        447.8119, 447.3154, 447.9340, 447.2338, 448.0592, 447.3356, 448.1659,
        447.2878, 448.1383, 447.2773, 448.0668, 447.3375, 448.1899, 448.1255,
        448.1885, 447.2354, 448.1815, 448.1258, 448.1504, 447.2789, 447.1802,
        448.1511, 448.1125, 448.1678, 448.1245, 448.1393, 448.1887, 448.1033,
        448.1610, 447.4439, 448.1372, 448.1683, 448.1801, 448.1656, 448.1213,
        448.0632, 447.8962, 448.1561, 448.1886, 448.1522, 448.1248, 448.1374,
        448.1612, 448.1826, 448.1559, 448.1830, 447.2969, 448.1598, 448.1573,
        447.4319, 448.1676, 448.0533, 448.1721, 448.1323, 448.1671, 448.1608,
        448.1835, 448.1553, 448.1233, 447.5568, 448.1475, 447.2388, 447.2941,
        447.2439, 447.8705, 447.8646, 447.2297, 448.1576, 448.1810, 447.2880,
        448.1829, 448.0766, 448.1574, 448.1543, 448.1059, 447.5567, 448.1732,
        447.2762, 448.1525, 447.5568, 447.5616, 448.1483, 447.7109, 448.1803,
        448.1129, 448.1677, 448.1564, 447.2757, 447.9976, 448.1435, 447.2943,
        448.1077, 448.1628, 448.2014, 448.1898, 448.1685, 447.4978, 448.2010,
        448.1896, 448.1743, 448.1626, 448.8367, 448.1742, 447.2384, 448.1882,
        447.5016, 447.2318, 447.2744, 448.1622, 447.2948, 448.1583, 448.2869,
        448.0109, 447.2939, 447.2939, 448.1782, 447.2938, 447.2609, 448.1770,
        448.1739, 448.1649, 448.1404, 447.2750, 448.0706, 447.2830, 448.1696,
        448.1531, 447.3335, 447.8482, 447.8967, 447.6391, 448.0334, 448.1906,
        447.2184, 447.3750, 448.1956, 447.9036, 448.1632, 447.2928, 447.5578,
        447.2942, 448.1938, 448.1721, 448.1113, 448.1519, 448.1245, 448.0798,
        447.7256, 448.0926, 448.1153, 448.1841, 448.1042, 448.1626, 448.1425,
        448.1202, 447.5883, 447.7486, 448.0686, 448.1467, 447.3836, 447.7080,
        448.1551, 448.1984, 448.1653, 448.1840, 448.1829, 448.1940, 447.3000,
        448.1625, 448.1732, 447.2931, 448.0140, 447.2934, 448.0819, 448.1710,
        447.2874, 447.2404, 448.1420, 448.1621, 448.1699, 448.1000, 448.1859,
        447.3323, 448.1714, 448.1674, 448.1870, 448.0965, 448.1745, 448.1674,
        448.1223, 447.2668, 448.0992, 448.1496, 448.1855, 448.8479, 447.2850,
        448.1920, 448.1696, 448.1564, 448.1701, 448.1989, 448.1802, 448.1570,
        448.1618, 448.1569, 448.1033, 448.1558, 448.1943, 447.5439, 448.1735,
        448.1558, 448.0202, 447.8463, 448.1682, 447.2943, 447.4192, 448.0081,
        448.1538, 448.1286, 448.1664, 448.1959, 448.1677, 448.0197, 447.2928,
        448.1883, 447.2925, 448.1418, 448.1129, 448.1685, 448.1353, 447.2942,
        447.2932, 448.1919, 448.1180, 448.1259, 448.1965, 448.1606, 448.1708,
        447.2942, 447.2942, 447.3234, 448.1688, 448.1917, 447.2943, 448.1631,
        448.1404, 448.1204, 448.1570, 447.2943, 448.1847, 447.2941, 447.2508,
        448.1591, 448.1009, 447.2803, 447.2932, 448.1168, 448.1559, 447.2933,
        448.1762, 448.1303, 447.9504, 448.1458, 447.9081, 447.6181, 448.1423,
        448.1414, 448.1139, 447.2912, 448.1877, 447.2937, 448.1628, 448.1640,
        447.8082, 448.1627, 448.0682, 448.1912, 447.2932, 448.1943, 447.2435,
        447.8962, 448.1639, 448.1815, 447.2820, 448.1530, 447.2249, 448.1096,
        448.1535, 448.1559, 447.6000, 448.1569, 448.1016, 448.1773, 447.2941,
        448.1777, 448.1429, 447.9464, 447.5437, 448.1719, 448.1502, 447.2041,
        447.6114, 447.6906, 447.2593, 447.2943, 448.1697, 448.1426, 448.1871,
        448.1880, 447.8904, 447.4560, 448.1713, 447.2911, 448.1697, 447.2315,
        447.2201, 448.1938, 448.1775, 447.2861, 448.1975, 448.8480, 447.7114,
        448.1004, 448.0646, 448.0054, 447.8713, 447.2884, 448.1782, 447.2767,
        447.2718, 448.1647, 448.1250, 448.1784, 448.1569, 448.1216, 448.1871,
        448.1198, 447.7332, 448.1764, 447.8302, 447.2632, 447.9761, 447.7347,
        447.9131, 447.5578, 447.3933, 447.2901, 448.1703, 448.0916, 448.1631,
        448.1715, 448.1631, 448.1651, 448.0768, 447.2444, 447.2943, 448.1739,
        448.1708, 448.1784, 448.1046, 447.2745, 447.2869, 448.1405, 448.1159,
        447.2831, 448.1024, 448.1606, 447.2933, 448.0884, 447.2580, 448.8470,
        448.1573, 448.0657, 447.2425, 447.2267, 448.1544, 447.2405, 447.2930,
        448.1321, 447.2287, 447.2940, 447.6373, 448.1802, 448.1888, 448.1569,
        447.7895, 448.1448, 448.1660, 448.1754, 447.7838, 447.7700, 447.5138,
        447.2903, 448.1504, 447.1959, 448.1837, 448.1629, 447.2922, 448.1639,
        447.5253, 447.2942, 447.2944, 448.1531, 448.1694, 447.2854, 448.1645,
        447.8371, 448.1732, 448.1729, 447.5412, 448.1609, 448.1654, 447.9506,
        448.1718, 447.2761, 448.1749, 447.2940, 448.1525, 448.1501, 447.3188,
        448.1647, 448.1830, 448.1671, 448.1550, 448.1730, 447.5376, 448.1273,
        448.1685, 447.2693, 448.1645, 448.1736, 448.0627, 447.4802, 448.1118,
        447.2938, 448.1901, 448.1111, 448.1855, 448.1117, 448.1854, 448.0909,
        448.1638, 448.1969, 447.2942, 448.1573, 448.1902, 448.1265, 448.1602,
        448.1743, 448.1952, 448.1480, 448.1511, 448.1858, 447.5380, 448.1612,
        447.2899, 448.1627, 448.1700, 448.1625, 447.2699, 448.1396, 447.3567,
        448.1610, 447.2333, 448.1592, 447.2943, 448.1688, 448.1689, 448.0994,
        447.2810, 448.1137, 447.5641, 448.1899, 448.1378, 448.1769, 448.1654,
        448.0281, 448.1724, 448.1701, 448.1681, 448.1646, 448.1680, 448.1508,
        448.1111, 448.1768, 447.2940, 448.1372, 447.2164, 448.1844, 447.5374,
        447.2941, 447.3638, 447.2738, 447.3662, 448.1548, 447.5717, 447.2913,
        448.1269, 448.1470, 448.1600, 447.2513, 448.1743, 448.1887, 447.2696,
        448.1922, 448.1644, 448.1573, 448.1838, 447.2943, 448.1990, 448.1824,
        448.1758, 447.2940, 448.0460, 448.1636, 448.1558, 448.1637, 448.1319,
        448.1686, 447.5334, 447.2399, 448.1903, 448.0570, 448.1224, 447.2942,
        448.1736, 448.8252, 448.1408, 448.1431, 447.1939, 448.1570, 448.1519,
        448.1557, 447.2888, 447.3285, 448.1722, 447.2645, 448.1449, 448.1703,
        448.1518, 448.1643, 448.1940, 447.2943, 447.6932, 448.1185, 448.1656,
        448.1823, 447.2943, 448.1515, 448.0423, 447.2726, 448.1424, 448.1454,
        447.2894, 448.1698, 448.0707, 448.1751, 447.2941, 448.1709, 448.1483,
        448.0766, 448.8004, 447.2897, 448.1930, 447.2416, 447.2913, 448.1374,
        448.1417, 448.1637, 448.1647, 447.2873, 447.3242, 448.1825, 448.1475,
        447.2806, 447.2795, 447.6089, 447.2073, 448.1380, 448.1782, 448.1129,
        448.1759, 448.1562, 448.1802, 447.8857, 447.2456, 448.1622, 448.1419,
        448.1724, 447.3162, 447.2941, 448.1329, 448.1733, 448.4596, 448.1717,
        447.6794, 447.2304, 448.1083, 447.2943, 447.2935, 448.1680, 448.0746,
        448.0841, 448.1815], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([406.2318], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0382],
             [112.0382],
             [112.0507],
             [112.0507]],

            [[112.0478],
             [112.0436],
             [112.0508],
             [112.0378]],

            [[111.7945],
             [111.9859],
             [111.8421],
             [111.8421]],

            ...,

            [[111.8154],
             [111.8049],
             [111.8163],
             [111.8430]],

            [[112.0454],
             [112.0467],
             [112.0490],
             [112.0490]],

            [[111.8230],
             [111.8175],
             [111.8230],
             [111.8175]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1776, 448.1801, 447.4645,  ..., 447.2796, 448.1900, 447.2810],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1776, 448.1801, 447.4645,  ..., 447.2796, 448.1900, 447.2810],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0825],
             [112.0825],
             [112.0882],
             [112.0882]],

            [[112.0546],
             [112.0830],
             [112.0670],
             [112.0842]],

            [[112.0764],
             [112.0912],
             [112.0851],
             [112.0838]],

            ...,

            [[111.8233],
             [111.8117],
             [111.8119],
             [111.8246]],

            [[111.8199],
             [111.8238],
             [111.8169],
             [111.8240]],

            [[112.0714],
             [112.0769],
             [111.9962],
             [111.9962]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3414, 448.2888, 448.3364,  ..., 447.2715, 447.2847, 448.1408],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3414, 448.2888, 448.3364,  ..., 447.2715, 447.2847, 448.1408],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1120],
             [112.1120],
             [112.1193],
             [112.1193]],

            [[112.1064],
             [112.1159],
             [112.1159],
             [112.1220]],

            [[112.0973],
             [112.1128],
             [112.0997],
             [112.1144]],

            ...,

            [[112.1107],
             [112.1070],
             [112.1130],
             [112.1229]],

            [[111.8252],
             [111.8252],
             [111.8252],
             [111.8252]],

            [[111.8237],
             [111.8261],
             [111.8261],
             [111.8253]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4626, 448.4602, 448.4242,  ..., 448.4536, 447.3009, 447.3013],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4626, 448.4602, 448.4242,  ..., 448.4536, 447.3009, 447.3013],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8265],
             [111.8265],
             [111.8263],
             [111.8263]],

            [[112.1617],
             [112.1589],
             [112.1658],
             [112.1658]],

            [[111.8262],
             [111.8262],
             [111.8262],
             [111.8262]],

            ...,

            [[112.1221],
             [112.1508],
             [112.1286],
             [112.1525]],

            [[112.0360],
             [112.1467],
             [112.1318],
             [112.1318]],

            [[111.8262],
             [111.8278],
             [111.8264],
             [111.8264]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3055, 448.6523, 447.3049,  ..., 448.5540, 448.4462, 447.3069],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3055, 448.6523, 447.3049,  ..., 448.5540, 448.4462, 447.3069],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1850],
             [112.2041],
             [112.1878],
             [112.2024]],

            [[112.1791],
             [112.1791],
             [112.1953],
             [112.1953]],

            [[111.8361],
             [111.9850],
             [112.0145],
             [111.8321]],

            ...,

            [[112.1785],
             [112.1785],
             [112.1951],
             [112.1951]],

            [[111.8310],
             [111.8313],
             [111.8311],
             [111.8311]],

            [[111.8312],
             [111.8311],
             [111.8311],
             [111.8313]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7793, 448.7488, 447.6677,  ..., 448.7472, 447.3245, 447.3246],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7793, 448.7488, 447.6677,  ..., 448.7472, 447.3245, 447.3246],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8352],
             [111.8352],
             [111.8352],
             [111.8352]],

            [[112.2173],
             [112.2073],
             [112.2142],
             [112.2257]],

            [[112.2055],
             [112.2096],
             [112.2055],
             [112.2096]],

            ...,

            [[112.2071],
             [112.2073],
             [112.2134],
             [112.2214]],

            [[112.2104],
             [112.2104],
             [112.2116],
             [112.2116]],

            [[111.8353],
             [111.8353],
             [111.8353],
             [111.8353]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3408, 448.8646, 448.8300,  ..., 448.8492, 448.8439, 447.3410],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3408, 448.8646, 448.8300,  ..., 448.8492, 448.8439, 447.3410],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2327],
             [112.2472],
             [112.2301],
             [112.2301]],

            [[112.1539],
             [112.2877],
             [112.1620],
             [112.2866]],

            [[112.0865],
             [112.2220],
             [112.0465],
             [112.2210]],

            ...,

            [[112.2343],
             [112.2273],
             [112.2267],
             [112.2467]],

            [[112.2388],
             [112.2306],
             [112.2334],
             [112.2471]],

            [[111.8545],
             [111.8545],
             [111.8545],
             [111.8545]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9402, 448.8903, 448.5761,  ..., 448.9350, 448.9498, 447.4181],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9402, 448.8903, 448.5761,  ..., 448.9350, 448.9498, 447.4181],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8750],
             [111.8723],
             [111.8723],
             [111.8748]],

            [[112.1697],
             [112.1697],
             [112.2392],
             [112.2392]],

            [[111.9784],
             [112.2223],
             [111.9793],
             [112.2220]],

            ...,

            [[112.2505],
             [112.2505],
             [112.2660],
             [112.2660]],

            [[112.2438],
             [112.2454],
             [112.2430],
             [112.2618]],

            [[112.2381],
             [112.2516],
             [112.2411],
             [112.2411]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4945, 448.8178, 448.4019,  ..., 449.0330, 448.9939, 448.9719],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4945, 448.8178, 448.4019,  ..., 449.0330, 448.9939, 448.9719],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2586],
             [112.2586],
             [112.2690],
             [112.2690]],

            [[112.2504],
             [112.2573],
             [112.2497],
             [112.2642]],

            [[112.2719],
             [112.2518],
             [112.2679],
             [112.2669]],

            ...,

            [[112.2670],
             [112.2467],
             [112.2468],
             [112.2671]],

            [[112.2655],
             [112.2707],
             [112.2666],
             [112.2712]],

            [[112.1887],
             [112.2344],
             [112.2486],
             [112.2539]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0553, 449.0216, 449.0584,  ..., 449.0275, 449.0739, 448.9257],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0553, 449.0216, 449.0584,  ..., 449.0275, 449.0739, 448.9257],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9167],
             [111.9144],
             [111.9188],
             [111.9147]],

            [[111.9142],
             [111.9142],
             [111.9142],
             [111.9142]],

            [[112.2644],
             [112.2673],
             [112.2644],
             [112.2673]],

            ...,

            [[112.2526],
             [112.0843],
             [112.0415],
             [112.2582]],

            [[112.2304],
             [112.2308],
             [112.2180],
             [111.9843]],

            [[112.0929],
             [112.2099],
             [112.2254],
             [112.2585]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6647, 447.6569, 449.0634,  ..., 448.6366, 448.6635, 448.7867],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6647, 447.6569, 449.0634,  ..., 448.6366, 448.6635, 448.7867],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2802],
             [112.2802],
             [112.2824],
             [112.2824]],

            [[112.2837],
             [112.2837],
             [112.2827],
             [112.3058]],

            [[111.9278],
             [111.9278],
             [111.9277],
             [111.9277]],

            ...,

            [[112.2815],
             [112.2959],
             [112.2813],
             [112.2981]],

            [[111.9272],
             [111.9282],
             [111.9276],
             [111.9276]],

            [[112.2887],
             [112.3010],
             [112.3032],
             [112.2850]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1252, 449.1559, 447.7109,  ..., 449.1569, 447.7107, 449.1779],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1252, 449.1559, 447.7109,  ..., 449.1569, 447.7107, 449.1779],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2820],
             [112.2909],
             [112.3065],
             [112.3065]],

            [[111.9377],
             [111.9377],
             [111.9377],
             [111.9377]],

            [[111.9381],
             [111.9381],
             [111.9380],
             [111.9380]],

            ...,

            [[112.2820],
             [112.2913],
             [112.2742],
             [112.2856]],

            [[112.2997],
             [112.2997],
             [112.3129],
             [112.3129]],

            [[112.2887],
             [112.2887],
             [112.2914],
             [112.2914]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1859, 447.7509, 447.7522,  ..., 449.1329, 449.2252, 449.1603],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1859, 447.7509, 447.7522,  ..., 449.1329, 449.2252, 449.1603],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2970],
             [112.3242],
             [112.3146],
             [112.3146]],

            [[112.3148],
             [112.3047],
             [112.3180],
             [112.3180]],

            [[112.2911],
             [112.3016],
             [112.2936],
             [112.2936]],

            ...,

            [[112.2969],
             [112.2968],
             [112.2924],
             [112.2991]],

            [[112.2971],
             [112.3196],
             [112.2976],
             [112.3085]],

            [[111.9570],
             [112.1207],
             [111.9781],
             [111.9781]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2504, 449.2556, 449.1798,  ..., 449.1853, 449.2228, 448.0339],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2504, 449.2556, 449.1798,  ..., 449.1853, 449.2228, 448.0339],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0336],
             [112.2825],
             [112.0063],
             [112.2760]],

            [[112.3158],
             [112.3158],
             [112.3296],
             [112.3296]],

            [[112.3114],
             [112.3327],
             [112.3238],
             [112.3238]],

            ...,

            [[112.0945],
             [111.9655],
             [111.9664],
             [112.1156]],

            [[112.3082],
             [112.3106],
             [112.3163],
             [112.3386]],

            [[111.9662],
             [111.9662],
             [111.9682],
             [111.9682]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5983, 449.2907, 449.2916,  ..., 448.1420, 449.2737, 447.8689],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5983, 449.2907, 449.2916,  ..., 448.1420, 449.2737, 447.8689],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1494],
             [112.2830],
             [112.1098],
             [112.2803]],

            [[112.3101],
             [112.3204],
             [112.3104],
             [112.3217]],

            [[112.3092],
             [112.3223],
             [112.3160],
             [112.3271]],

            ...,

            [[111.9899],
             [112.2218],
             [111.9900],
             [112.2220]],

            [[112.3130],
             [112.2956],
             [112.3113],
             [112.3191]],

            [[112.3263],
             [112.3214],
             [112.3289],
             [112.3495]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8225, 449.2626, 449.2747,  ..., 448.4238, 449.2390, 449.3260],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8225, 449.2626, 449.2747,  ..., 448.4238, 449.2390, 449.3260],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2986],
             [112.3390],
             [112.3004],
             [112.3390]],

            [[112.3596],
             [112.3596],
             [112.3685],
             [112.3685]],

            [[112.0008],
             [112.0841],
             [112.0812],
             [111.9954]],

            ...,

            [[112.0531],
             [112.0531],
             [112.0564],
             [112.0564]],

            [[112.3396],
             [112.3393],
             [112.3566],
             [112.3566]],

            [[112.2871],
             [112.0705],
             [112.3177],
             [112.0623]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2770, 449.4562, 448.1614,  ..., 448.2191, 449.3921, 448.7375],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2770, 449.4562, 448.1614,  ..., 448.2191, 449.3921, 448.7375],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3351],
             [112.3449],
             [112.3230],
             [112.3442]],

            [[112.0143],
             [112.0141],
             [112.0141],
             [112.0140]],

            [[112.3474],
             [112.3512],
             [112.3467],
             [112.3786]],

            ...,

            [[112.3373],
             [112.3373],
             [112.3460],
             [112.3460]],

            [[112.0146],
             [112.0234],
             [112.0247],
             [112.0247]],

            [[112.3418],
             [112.3418],
             [112.3540],
             [112.3540]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3472, 448.0566, 449.4240,  ..., 449.3666, 448.0873, 449.3916],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3472, 448.0566, 449.4240,  ..., 449.3666, 448.0873, 449.3916],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3359],
             [112.3597],
             [112.3346],
             [112.3385]],

            [[112.3406],
             [112.3309],
             [112.3418],
             [112.3331]],

            [[112.3194],
             [112.3194],
             [112.3254],
             [112.3254]],

            ...,

            [[112.0472],
             [112.0472],
             [112.0910],
             [112.0910]],

            [[112.3448],
             [112.3649],
             [112.3547],
             [112.3592]],

            [[112.3417],
             [112.3628],
             [112.3534],
             [112.3534]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3687, 449.3464, 449.2897,  ..., 448.2764, 449.4236, 449.4113],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3687, 449.3464, 449.2897,  ..., 448.2764, 449.4236, 449.4113],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0234e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0421],
             [112.0408],
             [112.0408],
             [112.0422]],

            [[112.3204],
             [112.2465],
             [112.2003],
             [112.3216]],

            [[112.0427],
             [112.0780],
             [112.0491],
             [112.0491]],

            ...,

            [[112.3282],
             [112.3283],
             [112.3597],
             [112.3246]],

            [[112.3066],
             [112.3040],
             [112.3238],
             [112.3238]],

            [[112.3449],
             [112.3449],
             [112.3439],
             [112.3439]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1660, 449.0888, 448.2188,  ..., 449.3408, 449.2582, 449.3777],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1660, 449.0888, 448.2188,  ..., 449.3408, 449.2582, 449.3777],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3240],
             [112.3240],
             [112.3219],
             [112.3264]],

            [[112.3458],
             [112.3525],
             [112.3384],
             [112.3546]],

            [[112.3233],
             [112.3233],
             [112.3269],
             [112.3269]],

            ...,

            [[112.3318],
             [112.3318],
             [112.3499],
             [112.3499]],

            [[112.0414],
             [112.0531],
             [112.0438],
             [112.0438]],

            [[112.0408],
             [112.0408],
             [112.0408],
             [112.0408]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2962, 449.3912, 449.3003,  ..., 449.3632, 448.1821, 448.1631],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2962, 449.3912, 449.3003,  ..., 449.3632, 448.1821, 448.1631],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3207],
             [112.3342],
             [112.3217],
             [112.3334]],

            [[112.3448],
             [112.3368],
             [112.3499],
             [112.3499]],

            [[112.3249],
             [112.3130],
             [112.3062],
             [112.3246]],

            ...,

            [[112.3442],
             [112.3442],
             [112.3469],
             [112.3469]],

            [[112.0407],
             [112.0407],
             [112.0408],
             [112.0408]],

            [[112.3359],
             [112.3253],
             [112.3264],
             [112.3571]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3100, 449.3813, 449.2687, 449.3436, 449.2407, 448.1753, 449.3333,
            449.0276, 448.5341, 449.3264, 448.2012, 449.3473, 449.3920, 448.3412,
            448.5862, 449.3570, 448.7070, 449.3403, 449.3326, 449.3573, 449.3262,
            449.3227, 449.3357, 449.3429, 449.2558, 449.3328, 448.1651, 448.2928,
            448.9886, 449.3674, 449.1766, 449.2784, 449.1998, 449.3606, 449.2539,
            449.2484, 449.3493, 448.1659, 448.6929, 448.1633, 449.2555, 449.2947,
            449.3402, 448.7020, 449.3745, 449.3345, 448.4181, 449.2198, 449.3492,
            449.3384, 449.3327, 449.3436, 449.3237, 448.3442, 448.1629, 448.6744,
            449.3738, 449.3454, 449.3465, 449.2743, 449.3519, 449.3365, 448.1643,
            448.1631, 449.3830, 448.1774, 448.8011, 449.2870, 449.3962, 449.0659,
            449.2988, 449.0348, 449.3914, 449.3213, 449.3672, 448.8348, 449.3353,
            449.3934, 449.3260, 449.3167, 449.3306, 449.2888, 448.1716, 448.4803,
            449.3436, 449.3888, 448.1631, 448.4034, 448.8788, 449.3259, 449.2949,
            449.3438, 449.1182, 449.2860, 449.1878, 449.2888, 449.3409, 448.2546,
            449.3203, 449.3400, 449.3386, 449.2609, 448.8477, 449.3286, 449.3766,
            449.2288, 448.4963, 449.4073, 448.2891, 449.3283, 449.0903, 449.3058,
            449.1783, 448.1992, 449.2962, 448.9297, 449.3461, 449.3402, 449.3753,
            448.3079, 449.3223, 449.3058, 449.2294, 449.0363, 449.3246, 449.3201,
            448.7691, 449.3442, 449.3265, 449.3516, 449.3395, 449.3726, 448.1656,
            449.3482, 448.8836, 449.2910, 448.4967, 448.7749, 448.1637, 449.3186,
            449.3078, 449.2959, 448.1633, 449.4120, 449.3358, 449.3102, 448.2665,
            448.1882, 449.2812, 448.7653, 449.2971, 449.3409, 449.2956, 449.4150,
            449.3619, 448.8952, 449.1035, 449.2949, 449.2960, 449.3174, 449.3574,
            448.4851, 448.3933, 449.3368, 449.0997, 449.4034, 449.3906, 449.3144,
            449.3012, 449.2992, 449.3029, 448.7158, 449.3147, 449.3749, 449.2867,
            449.3307, 448.3757, 449.3060, 448.3490, 449.3849, 449.3338, 449.3505,
            449.3895, 449.7137, 449.4114, 449.3416, 449.4116, 448.1629, 449.2678,
            449.3499, 448.2055, 448.1630, 449.3115, 448.1639, 449.4084, 449.1258,
            449.8365, 449.3787, 448.1703, 449.3283, 449.3088, 448.2024, 449.3206,
            449.3040, 449.3431, 449.3260, 449.3263, 449.3672, 448.2825, 448.9792,
            449.3005, 449.3905, 449.2949, 448.1636, 449.3784, 449.3116, 449.3081,
            449.3713, 448.4443, 449.2900, 448.1632, 449.3438, 449.0386, 448.8230,
            449.3749, 449.3179, 448.9749, 449.3724, 449.3466, 449.1634, 448.3575,
            449.3965, 449.3367, 449.0742, 448.2740, 449.3283, 449.3303, 448.2758,
            449.3817, 449.3229, 449.3490, 449.2796, 449.3577, 449.3048, 449.2800,
            448.9458, 448.4206, 449.3335, 448.6350, 449.3438, 449.2941, 449.3377,
            448.1698, 449.3076, 449.3146, 449.3409, 448.7545, 449.3010, 449.2889,
            449.3787, 449.3234, 449.3633, 449.2028, 449.3215, 449.3094, 449.3402,
            449.3301, 449.3346, 449.1074, 449.3451, 449.4089, 449.3323, 449.3923,
            449.2795, 449.3326, 449.3456, 448.1641, 448.5980, 448.3867, 449.4049,
            449.3867, 449.2654, 449.3462, 448.1790, 449.3643, 448.1630, 449.3249,
            448.1635, 449.4101, 448.4235, 449.2194, 449.3198, 448.7911, 449.2184,
            449.3264, 448.1755, 449.3132, 449.4018, 449.3647, 449.3404, 448.3808,
            449.3575, 449.3201, 449.2903, 449.3182, 449.2594, 449.1744, 449.3123,
            448.1629, 449.3769, 448.3630, 448.3991, 449.3340, 449.3276, 448.3730,
            449.3306, 449.2048, 449.3733, 449.1471, 449.2965, 448.8574, 448.2384,
            449.3535, 448.9656, 449.3855, 449.3041, 448.1630, 449.3315, 449.3173,
            448.2977, 449.3857, 449.1417, 449.3194, 449.2964, 449.3737, 449.2939,
            448.1642, 448.2570, 449.2967, 448.6447, 449.3295, 449.2957, 449.2967,
            448.4838, 449.3802, 449.3032, 449.3138, 449.3615, 449.0074, 449.2111,
            449.3298, 449.4117, 449.3016, 449.0358, 448.5917, 448.3681, 449.2816,
            449.0406, 448.1639, 449.2983, 449.4116, 448.1631, 449.3298, 449.3599,
            449.2769, 449.3362, 449.3436, 449.3492, 449.3001, 449.3677, 448.1661,
            448.9245, 449.3062, 449.3411, 448.1666, 448.1830, 448.8943, 448.5615,
            449.2919, 449.3231, 449.3506, 448.1651, 449.2589, 449.1082, 448.6199,
            449.0559, 449.2000, 448.1629, 448.4969, 448.1827, 449.3874, 448.1634,
            448.2274, 449.2286, 448.2201, 449.3327, 449.3403, 449.1458, 449.3148,
            449.2863, 448.8536, 449.3034, 449.3459, 449.3361, 449.2936, 449.1367,
            448.1685, 449.3586, 449.3405, 449.3840, 448.1629, 449.1097, 449.3739,
            449.3404, 448.9258, 448.1711, 449.3378, 448.1882, 449.3066, 449.3141,
            448.1702, 449.3234, 448.2255, 449.3151, 449.8223, 449.2678, 449.3465,
            449.3343, 449.3386, 449.3223, 449.3347, 449.3432, 449.3062, 449.3423,
            449.3042, 449.2868, 449.3499, 449.3141, 449.8223, 448.2557, 449.3781,
            448.3334, 449.3095, 449.1096, 448.5368, 448.7215, 448.9697, 449.3368,
            449.3549, 449.3134, 449.3348, 449.3265, 449.3167, 449.3181, 449.3528,
            449.3015, 449.3102, 449.3508, 449.2972, 449.2899, 449.3331, 448.1692,
            449.3304, 449.1095, 449.3674, 449.3438, 449.1891, 449.3284, 449.3258,
            449.2985, 449.3492, 449.3278, 449.2872, 448.1636, 449.3374, 449.2299,
            449.2949, 449.3480, 448.1945, 449.3795, 449.3456, 448.1644, 449.2556,
            449.3416, 449.3342, 448.6006, 448.2033, 449.2958, 449.3433, 449.3361,
            449.3634, 449.0512, 449.3340, 448.4478, 449.3875, 448.1678, 449.3465,
            449.3689, 449.3719, 448.4094, 449.3098, 449.0522, 449.3950, 449.8393,
            448.8194, 448.1847, 449.3330, 449.3539, 449.3315, 448.2277, 449.3940,
            448.1859, 449.2581, 449.3571, 448.6729, 449.2400, 448.1712, 449.2296,
            449.3310, 449.3538, 449.3434, 449.2942, 449.3542, 449.2919, 448.2465,
            449.3605, 448.2193, 448.1727, 449.4146, 448.2196, 449.3491, 449.3436,
            449.3110, 448.1876, 449.2094, 449.2804, 448.1656, 449.3400, 449.2162,
            448.1635, 449.3251, 449.3319, 448.6602, 448.1708, 448.1903, 449.3176,
            449.3698, 449.2870, 449.3278, 449.3032, 449.3396, 448.3523, 449.3558,
            449.3192, 448.1828, 449.3155, 449.8248, 449.3032, 449.3636, 449.3795,
            449.3411, 448.1853, 449.1812, 449.3246, 449.0617, 449.3504, 449.3259,
            449.3733, 449.3389, 449.2721, 448.6199, 449.3308, 449.3233, 449.3951,
            449.3469, 449.3483, 449.3418, 449.3469, 449.3641, 449.3195, 449.2140,
            449.3777, 449.3584, 449.3871, 449.2707, 449.3881, 448.1688, 449.3188,
            449.3696, 449.2849, 449.3557, 448.1674, 449.3403, 449.3390, 449.4087,
            449.2495, 448.1630, 448.7478, 449.3268, 449.2957, 448.3798, 448.1695,
            449.3279, 449.3133, 449.3547, 449.3021, 448.4230, 449.8704, 449.3784,
            449.3958, 448.7288, 448.6343, 449.3707, 449.3361, 449.3326, 449.3228,
            449.3370, 449.3149, 449.3517, 448.3338, 448.5340, 449.3635, 449.2042,
            449.3470, 449.2486, 448.1779, 449.0994, 449.3389, 449.3509, 449.3291,
            449.3198, 448.9760, 449.3539, 449.3431, 449.3225, 449.1384, 449.3515,
            449.3784, 449.2493, 448.7156, 449.3533, 449.4162, 448.6749, 449.1732,
            449.3500, 449.3536, 449.3194, 448.6750, 449.2978, 448.1636, 448.9268,
            449.3226, 448.1687, 448.9219, 449.2946, 448.2274, 448.2052, 449.3448,
            449.3328, 449.3215, 449.3600, 448.1837, 448.1641, 449.3557, 449.3390,
            449.3659, 449.2901, 449.3593, 449.3370, 448.2039, 449.3946, 449.3467,
            449.8191, 449.3289, 449.3476, 448.1995, 449.3396, 448.2167, 449.3132,
            448.5759, 449.2755, 449.3675, 449.3161, 449.3449, 449.0600, 449.3350,
            448.6817, 449.3396, 449.4069, 449.3495, 449.2623, 449.3116, 449.3387,
            449.2520, 449.2042, 449.3257, 449.3231, 449.3260, 448.8015, 448.9615,
            448.7007, 449.3961, 449.3194, 449.3596, 449.3376, 448.5341, 449.3546,
            449.2242, 449.1710, 448.1717, 449.3380, 449.3506, 449.3536, 449.3701,
            449.3233, 448.5097, 449.2733, 448.4860, 449.3555, 449.1811, 449.3451,
            449.3314, 449.3944, 449.3408, 448.7865, 448.4001, 449.2970, 449.3246,
            449.3433, 449.3659, 448.4728, 449.8391, 449.3408, 448.2068, 449.3379,
            449.3401, 448.2938, 449.3115, 449.3276, 449.1573, 449.3259, 449.4089,
            449.3351, 449.3059, 448.1633, 448.1629, 449.3540, 449.3113, 448.9833,
            449.3350, 449.3404, 449.2876, 449.3727, 449.3496, 448.1650, 448.1993,
            448.9570, 448.9268, 449.3423, 448.1642, 448.3457, 449.3387, 449.3564,
            448.3811, 448.4200, 449.0256, 449.0722, 448.8652, 449.3810, 449.3847,
            449.3649, 449.3945, 448.1660, 449.3509, 449.3570, 448.1790, 449.1443,
            449.3890, 449.3071, 449.2977, 449.3587, 449.3767, 449.3404, 449.3254,
            449.2049, 449.3528, 448.1662, 449.3655, 449.3022, 449.2712, 449.2864,
            449.3412, 449.3436, 448.5472, 449.3531, 449.3146, 449.1543, 449.3019,
            449.3493, 449.2893, 448.4289, 449.3102, 448.1659, 449.3276, 449.3313,
            449.1378, 449.3081, 449.3647, 449.3456, 449.3417, 449.8223, 449.3484,
            449.3425, 449.3658, 448.6319, 449.3883, 448.2361, 449.3273, 449.4064,
            448.1691, 448.9149, 449.3249, 449.3721, 449.3811, 448.3478, 449.3777,
            448.1709, 449.2717, 449.3724, 449.3284, 449.2448, 449.3049, 449.2587,
            449.3461, 449.3312, 449.3004, 449.3947, 449.3749, 448.8475, 448.9273,
            449.3613, 449.3705, 449.2824, 449.3503, 449.2892, 449.3977, 449.3412,
            448.1629, 449.4050, 449.2982, 449.3430, 448.3505, 449.3400, 449.1190,
            449.3846, 449.3400, 449.3367, 449.2416, 449.3677, 449.4041, 448.3782,
            448.7132, 448.4623, 449.3953, 449.3104, 449.3339, 449.0995, 449.0337,
            448.5655, 449.3259, 448.1710, 449.3392, 449.2866, 449.3391, 449.2189,
            449.3457, 449.2316, 449.2913, 448.1633, 449.2770, 449.2893, 449.3446,
            449.3040, 448.4747, 448.1636, 449.3489, 449.3694, 449.3356, 449.3469,
            449.3167, 448.3792, 449.1723, 449.2959, 449.3314, 449.3600, 449.1095,
            449.3010, 449.3204, 448.2087, 448.9655, 448.1676, 448.8804, 449.3813,
            449.3553, 449.3448, 448.3505, 449.3867, 448.1680, 449.3109, 449.4095,
            449.3063, 449.3961, 449.2874, 449.2822, 448.4321, 448.1943, 448.9045,
            449.3757, 449.3419, 448.1995, 449.3600, 449.3013, 449.3564, 449.3822,
            448.1630, 449.3447], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3100, 449.3813, 449.2687, 449.3436, 449.2407, 448.1753, 449.3333,
        449.0276, 448.5341, 449.3264, 448.2012, 449.3473, 449.3920, 448.3412,
        448.5862, 449.3570, 448.7070, 449.3403, 449.3326, 449.3573, 449.3262,
        449.3227, 449.3357, 449.3429, 449.2558, 449.3328, 448.1651, 448.2928,
        448.9886, 449.3674, 449.1766, 449.2784, 449.1998, 449.3606, 449.2539,
        449.2484, 449.3493, 448.1659, 448.6929, 448.1633, 449.2555, 449.2947,
        449.3402, 448.7020, 449.3745, 449.3345, 448.4181, 449.2198, 449.3492,
        449.3384, 449.3327, 449.3436, 449.3237, 448.3442, 448.1629, 448.6744,
        449.3738, 449.3454, 449.3465, 449.2743, 449.3519, 449.3365, 448.1643,
        448.1631, 449.3830, 448.1774, 448.8011, 449.2870, 449.3962, 449.0659,
        449.2988, 449.0348, 449.3914, 449.3213, 449.3672, 448.8348, 449.3353,
        449.3934, 449.3260, 449.3167, 449.3306, 449.2888, 448.1716, 448.4803,
        449.3436, 449.3888, 448.1631, 448.4034, 448.8788, 449.3259, 449.2949,
        449.3438, 449.1182, 449.2860, 449.1878, 449.2888, 449.3409, 448.2546,
        449.3203, 449.3400, 449.3386, 449.2609, 448.8477, 449.3286, 449.3766,
        449.2288, 448.4963, 449.4073, 448.2891, 449.3283, 449.0903, 449.3058,
        449.1783, 448.1992, 449.2962, 448.9297, 449.3461, 449.3402, 449.3753,
        448.3079, 449.3223, 449.3058, 449.2294, 449.0363, 449.3246, 449.3201,
        448.7691, 449.3442, 449.3265, 449.3516, 449.3395, 449.3726, 448.1656,
        449.3482, 448.8836, 449.2910, 448.4967, 448.7749, 448.1637, 449.3186,
        449.3078, 449.2959, 448.1633, 449.4120, 449.3358, 449.3102, 448.2665,
        448.1882, 449.2812, 448.7653, 449.2971, 449.3409, 449.2956, 449.4150,
        449.3619, 448.8952, 449.1035, 449.2949, 449.2960, 449.3174, 449.3574,
        448.4851, 448.3933, 449.3368, 449.0997, 449.4034, 449.3906, 449.3144,
        449.3012, 449.2992, 449.3029, 448.7158, 449.3147, 449.3749, 449.2867,
        449.3307, 448.3757, 449.3060, 448.3490, 449.3849, 449.3338, 449.3505,
        449.3895, 449.7137, 449.4114, 449.3416, 449.4116, 448.1629, 449.2678,
        449.3499, 448.2055, 448.1630, 449.3115, 448.1639, 449.4084, 449.1258,
        449.8365, 449.3787, 448.1703, 449.3283, 449.3088, 448.2024, 449.3206,
        449.3040, 449.3431, 449.3260, 449.3263, 449.3672, 448.2825, 448.9792,
        449.3005, 449.3905, 449.2949, 448.1636, 449.3784, 449.3116, 449.3081,
        449.3713, 448.4443, 449.2900, 448.1632, 449.3438, 449.0386, 448.8230,
        449.3749, 449.3179, 448.9749, 449.3724, 449.3466, 449.1634, 448.3575,
        449.3965, 449.3367, 449.0742, 448.2740, 449.3283, 449.3303, 448.2758,
        449.3817, 449.3229, 449.3490, 449.2796, 449.3577, 449.3048, 449.2800,
        448.9458, 448.4206, 449.3335, 448.6350, 449.3438, 449.2941, 449.3377,
        448.1698, 449.3076, 449.3146, 449.3409, 448.7545, 449.3010, 449.2889,
        449.3787, 449.3234, 449.3633, 449.2028, 449.3215, 449.3094, 449.3402,
        449.3301, 449.3346, 449.1074, 449.3451, 449.4089, 449.3323, 449.3923,
        449.2795, 449.3326, 449.3456, 448.1641, 448.5980, 448.3867, 449.4049,
        449.3867, 449.2654, 449.3462, 448.1790, 449.3643, 448.1630, 449.3249,
        448.1635, 449.4101, 448.4235, 449.2194, 449.3198, 448.7911, 449.2184,
        449.3264, 448.1755, 449.3132, 449.4018, 449.3647, 449.3404, 448.3808,
        449.3575, 449.3201, 449.2903, 449.3182, 449.2594, 449.1744, 449.3123,
        448.1629, 449.3769, 448.3630, 448.3991, 449.3340, 449.3276, 448.3730,
        449.3306, 449.2048, 449.3733, 449.1471, 449.2965, 448.8574, 448.2384,
        449.3535, 448.9656, 449.3855, 449.3041, 448.1630, 449.3315, 449.3173,
        448.2977, 449.3857, 449.1417, 449.3194, 449.2964, 449.3737, 449.2939,
        448.1642, 448.2570, 449.2967, 448.6447, 449.3295, 449.2957, 449.2967,
        448.4838, 449.3802, 449.3032, 449.3138, 449.3615, 449.0074, 449.2111,
        449.3298, 449.4117, 449.3016, 449.0358, 448.5917, 448.3681, 449.2816,
        449.0406, 448.1639, 449.2983, 449.4116, 448.1631, 449.3298, 449.3599,
        449.2769, 449.3362, 449.3436, 449.3492, 449.3001, 449.3677, 448.1661,
        448.9245, 449.3062, 449.3411, 448.1666, 448.1830, 448.8943, 448.5615,
        449.2919, 449.3231, 449.3506, 448.1651, 449.2589, 449.1082, 448.6199,
        449.0559, 449.2000, 448.1629, 448.4969, 448.1827, 449.3874, 448.1634,
        448.2274, 449.2286, 448.2201, 449.3327, 449.3403, 449.1458, 449.3148,
        449.2863, 448.8536, 449.3034, 449.3459, 449.3361, 449.2936, 449.1367,
        448.1685, 449.3586, 449.3405, 449.3840, 448.1629, 449.1097, 449.3739,
        449.3404, 448.9258, 448.1711, 449.3378, 448.1882, 449.3066, 449.3141,
        448.1702, 449.3234, 448.2255, 449.3151, 449.8223, 449.2678, 449.3465,
        449.3343, 449.3386, 449.3223, 449.3347, 449.3432, 449.3062, 449.3423,
        449.3042, 449.2868, 449.3499, 449.3141, 449.8223, 448.2557, 449.3781,
        448.3334, 449.3095, 449.1096, 448.5368, 448.7215, 448.9697, 449.3368,
        449.3549, 449.3134, 449.3348, 449.3265, 449.3167, 449.3181, 449.3528,
        449.3015, 449.3102, 449.3508, 449.2972, 449.2899, 449.3331, 448.1692,
        449.3304, 449.1095, 449.3674, 449.3438, 449.1891, 449.3284, 449.3258,
        449.2985, 449.3492, 449.3278, 449.2872, 448.1636, 449.3374, 449.2299,
        449.2949, 449.3480, 448.1945, 449.3795, 449.3456, 448.1644, 449.2556,
        449.3416, 449.3342, 448.6006, 448.2033, 449.2958, 449.3433, 449.3361,
        449.3634, 449.0512, 449.3340, 448.4478, 449.3875, 448.1678, 449.3465,
        449.3689, 449.3719, 448.4094, 449.3098, 449.0522, 449.3950, 449.8393,
        448.8194, 448.1847, 449.3330, 449.3539, 449.3315, 448.2277, 449.3940,
        448.1859, 449.2581, 449.3571, 448.6729, 449.2400, 448.1712, 449.2296,
        449.3310, 449.3538, 449.3434, 449.2942, 449.3542, 449.2919, 448.2465,
        449.3605, 448.2193, 448.1727, 449.4146, 448.2196, 449.3491, 449.3436,
        449.3110, 448.1876, 449.2094, 449.2804, 448.1656, 449.3400, 449.2162,
        448.1635, 449.3251, 449.3319, 448.6602, 448.1708, 448.1903, 449.3176,
        449.3698, 449.2870, 449.3278, 449.3032, 449.3396, 448.3523, 449.3558,
        449.3192, 448.1828, 449.3155, 449.8248, 449.3032, 449.3636, 449.3795,
        449.3411, 448.1853, 449.1812, 449.3246, 449.0617, 449.3504, 449.3259,
        449.3733, 449.3389, 449.2721, 448.6199, 449.3308, 449.3233, 449.3951,
        449.3469, 449.3483, 449.3418, 449.3469, 449.3641, 449.3195, 449.2140,
        449.3777, 449.3584, 449.3871, 449.2707, 449.3881, 448.1688, 449.3188,
        449.3696, 449.2849, 449.3557, 448.1674, 449.3403, 449.3390, 449.4087,
        449.2495, 448.1630, 448.7478, 449.3268, 449.2957, 448.3798, 448.1695,
        449.3279, 449.3133, 449.3547, 449.3021, 448.4230, 449.8704, 449.3784,
        449.3958, 448.7288, 448.6343, 449.3707, 449.3361, 449.3326, 449.3228,
        449.3370, 449.3149, 449.3517, 448.3338, 448.5340, 449.3635, 449.2042,
        449.3470, 449.2486, 448.1779, 449.0994, 449.3389, 449.3509, 449.3291,
        449.3198, 448.9760, 449.3539, 449.3431, 449.3225, 449.1384, 449.3515,
        449.3784, 449.2493, 448.7156, 449.3533, 449.4162, 448.6749, 449.1732,
        449.3500, 449.3536, 449.3194, 448.6750, 449.2978, 448.1636, 448.9268,
        449.3226, 448.1687, 448.9219, 449.2946, 448.2274, 448.2052, 449.3448,
        449.3328, 449.3215, 449.3600, 448.1837, 448.1641, 449.3557, 449.3390,
        449.3659, 449.2901, 449.3593, 449.3370, 448.2039, 449.3946, 449.3467,
        449.8191, 449.3289, 449.3476, 448.1995, 449.3396, 448.2167, 449.3132,
        448.5759, 449.2755, 449.3675, 449.3161, 449.3449, 449.0600, 449.3350,
        448.6817, 449.3396, 449.4069, 449.3495, 449.2623, 449.3116, 449.3387,
        449.2520, 449.2042, 449.3257, 449.3231, 449.3260, 448.8015, 448.9615,
        448.7007, 449.3961, 449.3194, 449.3596, 449.3376, 448.5341, 449.3546,
        449.2242, 449.1710, 448.1717, 449.3380, 449.3506, 449.3536, 449.3701,
        449.3233, 448.5097, 449.2733, 448.4860, 449.3555, 449.1811, 449.3451,
        449.3314, 449.3944, 449.3408, 448.7865, 448.4001, 449.2970, 449.3246,
        449.3433, 449.3659, 448.4728, 449.8391, 449.3408, 448.2068, 449.3379,
        449.3401, 448.2938, 449.3115, 449.3276, 449.1573, 449.3259, 449.4089,
        449.3351, 449.3059, 448.1633, 448.1629, 449.3540, 449.3113, 448.9833,
        449.3350, 449.3404, 449.2876, 449.3727, 449.3496, 448.1650, 448.1993,
        448.9570, 448.9268, 449.3423, 448.1642, 448.3457, 449.3387, 449.3564,
        448.3811, 448.4200, 449.0256, 449.0722, 448.8652, 449.3810, 449.3847,
        449.3649, 449.3945, 448.1660, 449.3509, 449.3570, 448.1790, 449.1443,
        449.3890, 449.3071, 449.2977, 449.3587, 449.3767, 449.3404, 449.3254,
        449.2049, 449.3528, 448.1662, 449.3655, 449.3022, 449.2712, 449.2864,
        449.3412, 449.3436, 448.5472, 449.3531, 449.3146, 449.1543, 449.3019,
        449.3493, 449.2893, 448.4289, 449.3102, 448.1659, 449.3276, 449.3313,
        449.1378, 449.3081, 449.3647, 449.3456, 449.3417, 449.8223, 449.3484,
        449.3425, 449.3658, 448.6319, 449.3883, 448.2361, 449.3273, 449.4064,
        448.1691, 448.9149, 449.3249, 449.3721, 449.3811, 448.3478, 449.3777,
        448.1709, 449.2717, 449.3724, 449.3284, 449.2448, 449.3049, 449.2587,
        449.3461, 449.3312, 449.3004, 449.3947, 449.3749, 448.8475, 448.9273,
        449.3613, 449.3705, 449.2824, 449.3503, 449.2892, 449.3977, 449.3412,
        448.1629, 449.4050, 449.2982, 449.3430, 448.3505, 449.3400, 449.1190,
        449.3846, 449.3400, 449.3367, 449.2416, 449.3677, 449.4041, 448.3782,
        448.7132, 448.4623, 449.3953, 449.3104, 449.3339, 449.0995, 449.0337,
        448.5655, 449.3259, 448.1710, 449.3392, 449.2866, 449.3391, 449.2189,
        449.3457, 449.2316, 449.2913, 448.1633, 449.2770, 449.2893, 449.3446,
        449.3040, 448.4747, 448.1636, 449.3489, 449.3694, 449.3356, 449.3469,
        449.3167, 448.3792, 449.1723, 449.2959, 449.3314, 449.3600, 449.1095,
        449.3010, 449.3204, 448.2087, 448.9655, 448.1676, 448.8804, 449.3813,
        449.3553, 449.3448, 448.3505, 449.3867, 448.1680, 449.3109, 449.4095,
        449.3063, 449.3961, 449.2874, 449.2822, 448.4321, 448.1943, 448.9045,
        449.3757, 449.3419, 448.1995, 449.3600, 449.3013, 449.3564, 449.3822,
        448.1630, 449.3447], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([398.5441], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3204],
             [112.3285],
             [112.3230],
             [112.3230]],

            [[112.3472],
             [112.3341],
             [112.3571],
             [112.3571]],

            [[112.3490],
             [112.3322],
             [112.3295],
             [112.3538]],

            ...,

            [[112.3308],
             [112.3578],
             [112.3413],
             [112.3413]],

            [[112.2788],
             [112.3160],
             [112.3212],
             [112.3243]],

            [[112.3077],
             [112.3077],
             [112.3065],
             [112.3065]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2949, 449.3956, 449.3646,  ..., 449.3712, 449.2402, 449.2285],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2949, 449.3956, 449.3646,  ..., 449.3712, 449.2402, 449.2285],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0511],
             [112.0516],
             [112.0513],
             [112.0513]],

            [[112.3289],
             [112.3289],
             [112.3423],
             [112.3423]],

            [[112.3123],
             [112.3334],
             [112.3143],
             [112.3283]],

            ...,

            [[112.1580],
             [112.0614],
             [112.0605],
             [112.1381]],

            [[112.3220],
             [112.3220],
             [112.3443],
             [112.3443]],

            [[112.0588],
             [112.1665],
             [112.1636],
             [112.0511]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2052, 449.3423, 449.2885,  ..., 448.4181, 449.3327, 448.4400],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2052, 449.3423, 449.2885,  ..., 448.4181, 449.3327, 448.4400],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3140],
             [112.3385],
             [112.3352],
             [112.3101]],

            [[112.3048],
             [112.3048],
             [112.3088],
             [112.3409]],

            [[112.2967],
             [112.1266],
             [112.3055],
             [112.3043]],

            ...,

            [[112.3083],
             [112.3177],
             [112.3402],
             [112.3090]],

            [[112.1939],
             [112.1939],
             [112.2331],
             [112.2331]],

            [[112.3260],
             [112.3273],
             [112.3274],
             [112.3263]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2977, 449.2593, 449.0330,  ..., 449.2752, 448.8539, 449.3070],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2977, 449.2593, 449.0330,  ..., 449.2752, 448.8539, 449.3070],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2919],
             [112.2919],
             [112.2919],
             [112.2919]],

            [[112.2899],
             [112.2899],
             [112.3094],
             [112.3094]],

            [[112.2770],
             [112.2884],
             [112.2934],
             [112.2955]],

            ...,

            [[112.2801],
             [112.2877],
             [112.2888],
             [112.2339]],

            [[112.2893],
             [112.2889],
             [112.2930],
             [112.3257]],

            [[112.2878],
             [112.2878],
             [112.2878],
             [112.2878]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1674, 449.1985, 449.1543,  ..., 449.0905, 449.1969, 449.1512],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1674, 449.1985, 449.1543,  ..., 449.0905, 449.1969, 449.1512],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1017],
             [112.1017],
             [112.1017],
             [112.1017]],

            [[112.2207],
             [112.2207],
             [112.2511],
             [112.2511]],

            [[112.1821],
             [112.2699],
             [112.2449],
             [112.2449]],

            ...,

            [[112.2726],
             [112.2726],
             [112.2732],
             [112.2732]],

            [[112.2754],
             [112.2754],
             [112.2881],
             [112.2881]],

            [[112.2835],
             [112.3013],
             [112.2868],
             [112.2984]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4068, 448.9435, 448.9419,  ..., 449.0916, 449.1268, 449.1700],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4068, 448.9435, 448.9419,  ..., 449.0916, 449.1268, 449.1700],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1519],
             [112.1423],
             [112.1419],
             [112.1553]],

            [[112.2640],
             [112.2642],
             [112.2833],
             [112.2833]],

            [[112.2954],
             [112.2655],
             [112.2894],
             [112.2653]],

            ...,

            [[112.2730],
             [112.2812],
             [112.2640],
             [112.2640]],

            [[112.2643],
             [112.2716],
             [112.2975],
             [112.2625]],

            [[112.2940],
             [112.2975],
             [112.2966],
             [112.2966]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5914, 449.0948, 449.1156,  ..., 449.0822, 449.0959, 449.1848],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5914, 449.0948, 449.1156,  ..., 449.0822, 449.0959, 449.1848],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2889],
             [112.2675],
             [112.2639],
             [112.2639]],

            [[112.2658],
             [112.2776],
             [112.2756],
             [112.3011]],

            [[112.1709],
             [112.2268],
             [112.2268],
             [112.1647]],

            ...,

            [[112.2905],
             [112.2582],
             [112.2631],
             [112.2613]],

            [[112.2564],
             [112.2566],
             [112.2342],
             [112.2342]],

            [[112.2775],
             [112.2585],
             [112.2591],
             [112.2926]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0842, 449.1201, 448.7893,  ..., 449.0732, 448.9814, 449.0876],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0842, 449.1201, 448.7893,  ..., 449.0732, 448.9814, 449.0876],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2554],
             [112.2554],
             [112.2752],
             [112.2752]],

            [[112.2642],
             [112.2634],
             [112.2623],
             [112.2997]],

            [[112.2544],
             [112.2415],
             [112.2562],
             [112.2521]],

            ...,

            [[112.2552],
             [112.2552],
             [112.2551],
             [112.2551]],

            [[112.2561],
             [112.2551],
             [112.2564],
             [112.2569]],

            [[112.1940],
             [112.1940],
             [112.1936],
             [112.1936]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0613, 449.0895, 449.0042,  ..., 449.0205, 449.0246, 448.7751],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0613, 449.0895, 449.0042,  ..., 449.0205, 449.0246, 448.7751],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2485],
             [112.2513],
             [112.2514],
             [112.2490]],

            [[112.2589],
             [112.2589],
             [112.2892],
             [112.2892]],

            [[112.2198],
             [112.2198],
             [112.2210],
             [112.2210]],

            ...,

            [[112.2509],
             [112.2557],
             [112.2941],
             [112.2509]],

            [[112.2670],
             [112.2697],
             [112.2732],
             [112.2756]],

            [[112.2642],
             [112.2513],
             [112.2883],
             [112.2498]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0002, 449.0961, 448.8816,  ..., 449.0515, 449.0854, 449.0536],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0002, 449.0961, 448.8816,  ..., 449.0515, 449.0854, 449.0536],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2258],
             [112.2258],
             [112.2258],
             [112.2258]],

            [[112.2259],
             [112.2234],
             [112.2250],
             [112.2250]],

            [[112.2053],
             [112.2058],
             [112.2054],
             [112.2054]],

            ...,

            [[112.2668],
             [112.2501],
             [112.2338],
             [112.2255]],

            [[112.2619],
             [112.2592],
             [112.2350],
             [112.2560]],

            [[112.2071],
             [112.2229],
             [112.2229],
             [112.2053]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9033, 448.8994, 448.8219,  ..., 448.9763, 449.0121, 448.8581],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9033, 448.8994, 448.8219,  ..., 448.9763, 449.0121, 448.8581],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1978],
             [112.1978],
             [112.2133],
             [112.2133]],

            [[112.1806],
             [112.1784],
             [112.1855],
             [112.1855]],

            [[112.1794],
             [112.1853],
             [112.1818],
             [112.1818]],

            ...,

            [[112.1798],
             [112.2195],
             [112.1786],
             [112.1886]],

            [[112.1959],
             [112.1959],
             [112.2245],
             [112.2245]],

            [[112.1954],
             [112.1789],
             [112.1810],
             [112.2204]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8221, 448.7299, 448.7283,  ..., 448.7664, 448.8409, 448.7757],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8221, 448.7299, 448.7283,  ..., 448.7664, 448.8409, 448.7757],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1794],
             [112.1794],
             [112.1918],
             [112.1918]],

            [[112.1627],
             [112.1625],
             [112.1676],
             [112.2091]],

            [[112.1747],
             [112.2104],
             [112.1893],
             [112.1893]],

            ...,

            [[112.1838],
             [112.2071],
             [112.1635],
             [112.1635]],

            [[112.1828],
             [112.1655],
             [112.2070],
             [112.1646]],

            [[112.1657],
             [112.1645],
             [112.1661],
             [112.1647]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7424, 448.7019, 448.7636,  ..., 448.7179, 448.7200, 448.6609],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7424, 448.7019, 448.7636,  ..., 448.7179, 448.7200, 448.6609],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1676],
             [112.1676],
             [112.2094],
             [112.2094]],

            [[112.1798],
             [112.1798],
             [112.2134],
             [112.2134]],

            [[112.1684],
             [112.1684],
             [112.1820],
             [112.1820]],

            ...,

            [[112.1744],
             [112.2115],
             [112.1960],
             [112.1960]],

            [[112.1625],
             [112.1616],
             [112.1684],
             [112.1684]],

            [[112.1678],
             [112.2157],
             [112.1675],
             [112.1608]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7541, 448.7865, 448.7007,  ..., 448.7779, 448.6609, 448.7118],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7541, 448.7865, 448.7007,  ..., 448.7779, 448.6609, 448.7118],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1619],
             [112.1532],
             [112.1560],
             [112.1560]],

            [[112.1700],
             [112.1700],
             [112.1590],
             [112.1590]],

            [[112.1526],
             [112.1897],
             [112.1671],
             [112.1666]],

            ...,

            [[112.1548],
             [112.1706],
             [112.1758],
             [112.2096]],

            [[112.1849],
             [112.1898],
             [112.2102],
             [112.2102]],

            [[112.1706],
             [112.1706],
             [112.1706],
             [112.1706]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6270, 448.6578, 448.6760,  ..., 448.7109, 448.7950, 448.6824],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6270, 448.6578, 448.6760,  ..., 448.7109, 448.7950, 448.6824],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1734],
             [112.1551],
             [112.1875],
             [112.1875]],

            [[112.1556],
             [112.1556],
             [112.1736],
             [112.1736]],

            [[112.1770],
             [112.1587],
             [112.2068],
             [112.1578]],

            ...,

            [[112.1559],
             [112.1530],
             [112.1794],
             [112.1794]],

            [[112.1735],
             [112.1735],
             [112.1735],
             [112.1735]],

            [[112.1562],
             [112.1731],
             [112.1554],
             [112.1921]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7035, 448.6584, 448.7003,  ..., 448.6678, 448.6939, 448.6768],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7035, 448.6584, 448.7003,  ..., 448.6678, 448.6939, 448.6768],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1798],
             [112.1578],
             [112.2030],
             [112.1580]],

            [[112.1571],
             [112.1923],
             [112.1558],
             [112.1718]],

            [[112.1596],
             [112.1656],
             [112.1831],
             [112.2162]],

            ...,

            [[112.2070],
             [112.1740],
             [112.2125],
             [112.1688]],

            [[112.1758],
             [112.1597],
             [112.1698],
             [112.1698]],

            [[112.1632],
             [112.2186],
             [112.1630],
             [112.1649]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6986, 448.6770, 448.7245,  ..., 448.7623, 448.6751, 448.7098],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6986, 448.6770, 448.7245,  ..., 448.7623, 448.6751, 448.7098],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1541],
             [112.1780],
             [112.1530],
             [112.1946]],

            [[112.1587],
             [112.1544],
             [112.1510],
             [112.1519]],

            [[112.1921],
             [112.1921],
             [112.2080],
             [112.2080]],

            ...,

            [[112.1716],
             [112.2075],
             [112.2003],
             [112.2003]],

            [[112.1544],
             [112.1730],
             [112.2084],
             [112.1569]],

            [[112.1759],
             [112.1759],
             [112.1756],
             [112.1756]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6797, 448.6160, 448.8001,  ..., 448.7797, 448.6927, 448.7029],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6797, 448.6160, 448.8001,  ..., 448.7797, 448.6927, 448.7029],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1902],
             [112.1994],
             [112.1943],
             [112.2011]],

            [[112.1729],
             [112.1625],
             [112.1728],
             [112.1619]],

            [[112.1557],
             [112.1675],
             [112.2030],
             [112.1550]],

            ...,

            [[112.1480],
             [112.1466],
             [112.1455],
             [112.1733]],

            [[112.1579],
             [112.1740],
             [112.1520],
             [112.2043]],

            [[112.1735],
             [112.1735],
             [112.1735],
             [112.1736]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7850, 448.6700, 448.6812,  ..., 448.6134, 448.6881, 448.6942],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7850, 448.6700, 448.6812,  ..., 448.6134, 448.6881, 448.6942],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0228e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1576],
             [112.1453],
             [112.1374],
             [112.1374]],

            [[112.1509],
             [112.1656],
             [112.1656],
             [112.1503]],

            [[112.1641],
             [112.1367],
             [112.1369],
             [112.1828]],

            ...,

            [[112.1503],
             [112.1368],
             [112.1503],
             [112.1368]],

            [[112.1476],
             [112.1476],
             [112.1849],
             [112.1849]],

            [[112.1667],
             [112.1663],
             [112.1667],
             [112.1664]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5776, 448.6323, 448.6205,  ..., 448.5743, 448.6650, 448.6660],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5776, 448.6323, 448.6205,  ..., 448.5743, 448.6650, 448.6660],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1381],
             [112.1381],
             [112.1788],
             [112.1788]],

            [[112.1580],
             [112.1660],
             [112.1580],
             [112.1661]],

            [[112.1386],
             [112.1371],
             [112.1405],
             [112.1399]],

            ...,

            [[112.1669],
             [112.1669],
             [112.1668],
             [112.1668]],

            [[112.1718],
             [112.1760],
             [112.1917],
             [112.1917]],

            [[112.1428],
             [112.1544],
             [112.1929],
             [112.1929]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6339, 448.6481, 448.5561,  ..., 448.6674, 448.7313, 448.6828],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6339, 448.6481, 448.5561,  ..., 448.6674, 448.7313, 448.6828],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1660],
             [112.1660],
             [112.1660],
             [112.1660]],

            [[112.1873],
             [112.1934],
             [112.1875],
             [112.1937]],

            [[112.1409],
             [112.1430],
             [112.1609],
             [112.2001]],

            ...,

            [[112.1889],
             [112.1602],
             [112.1541],
             [112.1943]],

            [[112.1382],
             [112.1599],
             [112.1375],
             [112.1584]],

            [[112.1369],
             [112.1735],
             [112.1571],
             [112.1571]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6640, 448.7619, 448.6450, 448.5602, 448.5933, 448.6812, 448.6607,
            448.6205, 448.6570, 448.7612, 448.6530, 448.5710, 448.6253, 448.5837,
            448.5611, 448.5895, 448.6190, 448.6343, 448.6365, 448.6834, 448.5742,
            448.6589, 448.6623, 448.6677, 448.6562, 448.6449, 448.7123, 448.6623,
            448.7011, 448.5582, 448.6233, 448.6157, 448.6651, 448.6011, 448.6512,
            448.6212, 448.6659, 448.6748, 448.6508, 448.6301, 448.6643, 448.7599,
            448.7407, 448.5729, 448.5906, 448.5917, 448.6433, 448.6635, 448.6525,
            448.6762, 448.6662, 448.5583, 448.6486, 448.5508, 448.7175, 448.7169,
            448.7324, 448.5553, 448.5948, 448.6369, 448.6897, 448.5604, 448.5998,
            448.6601, 448.6509, 448.6451, 448.6779, 448.5953, 448.5845, 448.6414,
            448.6008, 448.5934, 448.6557, 448.6125, 448.5836, 448.6669, 448.5594,
            448.6675, 448.7231, 448.5656, 448.6222, 448.7241, 448.5988, 448.6425,
            448.6520, 448.6678, 448.6698, 448.5636, 448.5805, 448.6094, 448.6386,
            448.5665, 448.6265, 448.6070, 448.6066, 448.6667, 448.6182, 448.6563,
            448.6023, 448.6384, 448.6544, 448.6660, 448.6050, 448.6041, 448.6682,
            448.7332, 448.6322, 448.6678, 448.5904, 448.5688, 448.5962, 448.7590,
            448.6942, 448.6265, 448.6006, 448.6275, 448.6598, 448.6679, 448.6658,
            448.5663, 448.5826, 448.6588, 448.5865, 448.6682, 448.6167, 448.6589,
            448.6454, 448.7639, 448.5543, 448.7360, 448.5643, 448.6284, 448.6987,
            448.7195, 448.6164, 448.6679, 448.6620, 448.6256, 448.5626, 448.5893,
            448.7462, 448.6134, 448.6381, 448.5825, 448.6315, 448.6394, 448.7720,
            448.5754, 448.6215, 448.7486, 448.6310, 448.5590, 448.6383, 448.5466,
            448.7422, 448.6631, 448.6024, 448.6677, 448.6171, 448.5546, 448.6428,
            448.7543, 448.7361, 448.6657, 448.6316, 448.6411, 448.6333, 448.6248,
            448.6295, 448.6335, 448.7207, 448.7397, 448.7426, 448.6165, 448.6677,
            448.6645, 448.7314, 448.6379, 448.6105, 448.6187, 448.6708, 448.7433,
            448.7119, 448.6450, 448.5708, 448.6536, 448.5544, 448.6502, 448.6807,
            448.6644, 448.7439, 448.6307, 448.6412, 448.5934, 448.7499, 448.6251,
            448.6371, 448.6036, 448.5823, 448.6076, 448.5786, 448.6354, 448.5505,
            448.6047, 448.6313, 448.7355, 448.6147, 448.5917, 448.5981, 448.5919,
            448.5957, 448.6421, 448.5732, 448.5626, 448.6361, 448.5551, 448.5762,
            448.5997, 448.5675, 448.6341, 448.6658, 448.6448, 448.5535, 448.6758,
            448.6423, 448.6287, 448.7034, 448.6814, 448.6490, 448.6348, 448.5698,
            448.6327, 448.6352, 448.6534, 448.5656, 448.6678, 448.6457, 448.6351,
            448.6064, 448.7190, 448.6565, 448.6164, 448.5683, 448.5595, 448.5615,
            448.5561, 448.6453, 448.6446, 448.6352, 448.6405, 448.6646, 448.6636,
            448.5933, 448.5615, 448.6672, 448.5571, 448.7102, 448.6577, 448.5470,
            448.6344, 448.6455, 448.5662, 448.5558, 448.6396, 448.6666, 448.6290,
            448.5928, 448.6458, 448.5739, 448.6253, 450.3980, 448.5559, 448.6271,
            448.5662, 448.6602, 448.5787, 448.5904, 448.7249, 448.5881, 448.6570,
            448.5649, 448.6877, 448.7258, 448.6250, 448.6299, 448.6020, 448.5747,
            448.5725, 448.6232, 448.6205, 448.6679, 448.5667, 448.6260, 448.6336,
            448.6091, 448.5817, 448.6032, 448.5919, 448.6506, 448.6932, 448.6329,
            448.5558, 448.6320, 448.6456, 448.6324, 448.6243, 448.6039, 448.6125,
            448.6007, 448.5955, 448.6668, 448.6194, 448.5551, 448.6595, 448.6208,
            448.5605, 448.5645, 448.7155, 448.6468, 448.5583, 448.6397, 448.6669,
            448.5651, 448.7408, 448.5646, 448.6386, 448.6168, 448.6213, 448.6584,
            448.6541, 448.7608, 448.6170, 448.6679, 448.6379, 448.7072, 448.7755,
            448.7042, 448.6333, 448.6287, 448.5616, 448.5614, 448.5487, 448.6392,
            448.6365, 450.3612, 448.5707, 448.5657, 448.5957, 448.7380, 448.6552,
            448.5669, 448.6580, 448.6078, 448.7456, 448.6072, 448.6352, 448.6454,
            448.6387, 448.6605, 448.6062, 448.6544, 448.6181, 448.5912, 448.5587,
            448.5881, 448.6701, 448.5548, 448.6224, 448.6111, 448.6663, 448.5908,
            448.5507, 448.5741, 448.6356, 448.5784, 448.6460, 448.5734, 448.6457,
            448.6531, 448.6304, 448.6004, 448.7660, 448.6443, 448.6282, 448.6526,
            448.7380, 448.5961, 448.6219, 448.5580, 448.6678, 448.6495, 448.6294,
            448.5928, 448.6536, 448.5929, 448.6355, 448.5689, 448.7671, 448.5824,
            448.5945, 448.6378, 448.5922, 448.5932, 448.6062, 448.6611, 448.6677,
            448.5567, 448.7546, 448.7253, 448.5559, 448.6424, 448.5914, 448.6521,
            448.7664, 448.6830, 448.6400, 448.6337, 448.5848, 448.6232, 448.7403,
            448.6141, 448.6405, 448.6664, 448.6555, 448.6646, 448.6187, 448.5938,
            448.6384, 448.6093, 448.6181, 448.6330, 448.6509, 448.6184, 448.5689,
            448.6149, 448.5465, 448.5646, 448.6455, 448.5683, 448.6670, 448.5723,
            448.5620, 448.5490, 448.6465, 448.5750, 448.5931, 448.5756, 448.5713,
            448.6060, 448.5848, 448.5824, 448.5906, 448.6342, 448.6412, 448.6495,
            448.6656, 448.6674, 448.6154, 448.6106, 448.6481, 448.6279, 448.6570,
            448.6442, 448.5708, 448.6669, 448.6679, 448.5714, 448.6285, 448.6342,
            448.5763, 448.5884, 448.6261, 448.6669, 448.5580, 448.5774, 448.6263,
            448.5909, 448.6411, 448.7245, 448.6137, 448.6389, 448.7089, 448.6523,
            448.6517, 448.6208, 448.6424, 448.6440, 448.5904, 448.6162, 448.6501,
            448.5708, 448.7202, 448.6219, 448.6598, 448.5922, 448.6666, 448.6527,
            448.6036, 448.5894, 448.6239, 448.6366, 448.5516, 448.6461, 448.7380,
            448.6512, 448.6508, 448.6151, 448.5841, 448.6145, 448.7116, 448.7489,
            448.6909, 448.7556, 448.6942, 448.6457, 448.7338, 448.5881, 448.6064,
            448.5595, 448.5502, 448.6146, 448.6357, 448.6347, 448.7761, 448.5864,
            448.6104, 448.6151, 448.6650, 448.6497, 448.6644, 448.7155, 448.6029,
            448.6189, 448.7730, 448.5698, 448.6519, 448.7252, 448.6378, 448.6220,
            448.7296, 448.5596, 448.6281, 448.6193, 448.7180, 448.6739, 448.6262,
            448.5999, 448.6311, 448.5627, 448.6434, 448.6679, 448.5493, 448.6476,
            448.6227, 448.7511, 448.6653, 448.6484, 448.5605, 448.7391, 448.6160,
            448.6679, 448.5772, 448.6133, 448.6555, 448.6438, 448.5588, 448.6679,
            448.5648, 448.5898, 448.6699, 448.5753, 448.6414, 448.7225, 448.6152,
            448.6578, 448.5647, 448.6172, 448.6180, 448.6776, 448.5623, 448.6274,
            448.5860, 448.5795, 448.6036, 448.6295, 448.6240, 448.6398, 448.6696,
            448.6388, 448.6379, 448.6508, 448.5698, 448.6179, 448.6608, 448.5929,
            448.6298, 448.5933, 448.5556, 448.6351, 448.7364, 448.7013, 448.7412,
            448.5667, 448.6668, 448.6440, 448.6591, 449.9731, 448.6639, 448.7759,
            448.5599, 448.6670, 448.6673, 448.7754, 448.5770, 448.6593, 448.6658,
            448.5726, 448.6077, 448.6669, 448.6677, 448.6400, 448.6503, 448.6644,
            448.5614, 448.5744, 448.6336, 448.6194, 448.6293, 448.7108, 448.5719,
            448.6679, 448.5817, 448.6283, 448.6338, 448.6567, 448.6009, 448.6625,
            448.6530, 448.6152, 448.5640, 448.7387, 448.6932, 448.5958, 448.6519,
            448.5753, 448.6420, 448.7394, 448.5684, 448.7296, 448.5929, 448.6267,
            448.6780, 448.6830, 448.6474, 448.6465, 448.6460, 448.6676, 448.5890,
            448.6386, 448.6385, 448.5826, 448.6174, 448.6531, 448.5511, 448.5989,
            448.6165, 448.6781, 448.6796, 448.7465, 448.6835, 448.7311, 448.5593,
            448.5701, 448.6583, 448.6252, 448.7646, 448.5698, 448.6808, 448.7435,
            448.6678, 448.7335, 448.6689, 448.6182, 448.6353, 448.6471, 448.5659,
            448.6259, 448.6516, 448.7100, 448.7048, 448.6669, 448.5931, 448.6082,
            448.6027, 448.6109, 448.5565, 448.6465, 448.6138, 448.6653, 448.6675,
            448.5900, 448.6655, 448.5563, 448.6292, 448.6356, 448.5954, 448.5934,
            448.6175, 448.5931, 448.6220, 448.6104, 448.5818, 448.7669, 448.6453,
            448.5636, 448.6266, 448.6335, 448.6467, 448.6447, 448.6692, 448.6597,
            448.6347, 448.6916, 448.6470, 448.5870, 448.6927, 448.5547, 448.6027,
            448.6650, 448.6300, 448.6403, 448.5967, 448.7336, 448.6177, 448.6677,
            448.5624, 448.7045, 448.6406, 448.6581, 448.5801, 448.6679, 448.5661,
            448.5731, 448.5598, 448.6678, 448.5919, 448.6679, 448.6843, 448.5590,
            448.5884, 448.6175, 448.5858, 448.6028, 448.6170, 448.6672, 448.5613,
            448.6901, 448.6675, 448.6656, 448.6764, 448.5667, 448.5542, 448.6275,
            448.6370, 448.6799, 448.6501, 448.6666, 448.6642, 448.6659, 448.6594,
            448.5931, 448.6531, 448.6199, 448.5823, 448.6501, 448.6466, 448.7207,
            448.5632, 448.5578, 448.5654, 448.5751, 448.5882, 448.6129, 448.7229,
            448.6190, 448.7120, 448.6314, 448.5547, 448.6531, 448.5708, 448.6385,
            448.6107, 448.5580, 448.7641, 448.5693, 448.7729, 448.6077, 448.5560,
            448.7748, 448.7504, 448.7324, 448.6681, 448.7057, 448.5640, 448.6435,
            448.6465, 448.5745, 448.6430, 448.6445, 448.6149, 448.6679, 448.6233,
            448.6665, 448.5569, 448.6647, 450.2876, 448.6667, 448.6151, 448.5751,
            448.7282, 448.7205, 448.6365, 448.6679, 448.5903, 448.5582, 448.7536,
            448.6226, 448.7626, 448.6464, 448.6425, 448.5896, 448.6031, 448.6496,
            448.6177, 448.5904, 448.7255, 448.5933, 448.5652, 448.6659, 448.5980,
            448.6503, 448.6138, 448.6964, 448.6210, 448.7474, 448.7293, 448.7585,
            448.5667, 448.5730, 448.6098, 448.7630, 448.6675, 448.6882, 448.5930,
            448.6417, 448.6632, 448.6692, 448.5736, 448.5827, 448.6396, 448.5812,
            448.6679, 448.5748, 448.6801, 448.7415, 448.6500, 448.6413, 448.5605,
            448.6401, 448.5594, 448.6073, 448.6060, 448.5545, 448.5621, 448.5754,
            448.5909, 448.6125, 448.5664, 448.6420, 448.6153, 448.6069, 448.6598,
            448.5580, 448.7784, 448.5759, 448.6977, 448.5676, 448.6545, 448.6298,
            448.6679, 448.7116, 448.6557, 448.6037, 448.6493, 448.6290, 448.6602,
            448.6341, 448.7216, 448.6219, 448.6166, 448.5667, 448.6660, 448.5679,
            448.6158, 448.6625, 448.6098, 448.7231, 448.5647, 448.5942, 448.6678,
            448.6610, 448.5896, 448.5703, 448.6407, 448.5620, 448.7181, 448.5757,
            448.6073, 448.6675, 448.6400, 448.7060, 448.5731, 448.6429, 448.6976,
            448.5940, 448.6247], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6640, 448.7619, 448.6450, 448.5602, 448.5933, 448.6812, 448.6607,
        448.6205, 448.6570, 448.7612, 448.6530, 448.5710, 448.6253, 448.5837,
        448.5611, 448.5895, 448.6190, 448.6343, 448.6365, 448.6834, 448.5742,
        448.6589, 448.6623, 448.6677, 448.6562, 448.6449, 448.7123, 448.6623,
        448.7011, 448.5582, 448.6233, 448.6157, 448.6651, 448.6011, 448.6512,
        448.6212, 448.6659, 448.6748, 448.6508, 448.6301, 448.6643, 448.7599,
        448.7407, 448.5729, 448.5906, 448.5917, 448.6433, 448.6635, 448.6525,
        448.6762, 448.6662, 448.5583, 448.6486, 448.5508, 448.7175, 448.7169,
        448.7324, 448.5553, 448.5948, 448.6369, 448.6897, 448.5604, 448.5998,
        448.6601, 448.6509, 448.6451, 448.6779, 448.5953, 448.5845, 448.6414,
        448.6008, 448.5934, 448.6557, 448.6125, 448.5836, 448.6669, 448.5594,
        448.6675, 448.7231, 448.5656, 448.6222, 448.7241, 448.5988, 448.6425,
        448.6520, 448.6678, 448.6698, 448.5636, 448.5805, 448.6094, 448.6386,
        448.5665, 448.6265, 448.6070, 448.6066, 448.6667, 448.6182, 448.6563,
        448.6023, 448.6384, 448.6544, 448.6660, 448.6050, 448.6041, 448.6682,
        448.7332, 448.6322, 448.6678, 448.5904, 448.5688, 448.5962, 448.7590,
        448.6942, 448.6265, 448.6006, 448.6275, 448.6598, 448.6679, 448.6658,
        448.5663, 448.5826, 448.6588, 448.5865, 448.6682, 448.6167, 448.6589,
        448.6454, 448.7639, 448.5543, 448.7360, 448.5643, 448.6284, 448.6987,
        448.7195, 448.6164, 448.6679, 448.6620, 448.6256, 448.5626, 448.5893,
        448.7462, 448.6134, 448.6381, 448.5825, 448.6315, 448.6394, 448.7720,
        448.5754, 448.6215, 448.7486, 448.6310, 448.5590, 448.6383, 448.5466,
        448.7422, 448.6631, 448.6024, 448.6677, 448.6171, 448.5546, 448.6428,
        448.7543, 448.7361, 448.6657, 448.6316, 448.6411, 448.6333, 448.6248,
        448.6295, 448.6335, 448.7207, 448.7397, 448.7426, 448.6165, 448.6677,
        448.6645, 448.7314, 448.6379, 448.6105, 448.6187, 448.6708, 448.7433,
        448.7119, 448.6450, 448.5708, 448.6536, 448.5544, 448.6502, 448.6807,
        448.6644, 448.7439, 448.6307, 448.6412, 448.5934, 448.7499, 448.6251,
        448.6371, 448.6036, 448.5823, 448.6076, 448.5786, 448.6354, 448.5505,
        448.6047, 448.6313, 448.7355, 448.6147, 448.5917, 448.5981, 448.5919,
        448.5957, 448.6421, 448.5732, 448.5626, 448.6361, 448.5551, 448.5762,
        448.5997, 448.5675, 448.6341, 448.6658, 448.6448, 448.5535, 448.6758,
        448.6423, 448.6287, 448.7034, 448.6814, 448.6490, 448.6348, 448.5698,
        448.6327, 448.6352, 448.6534, 448.5656, 448.6678, 448.6457, 448.6351,
        448.6064, 448.7190, 448.6565, 448.6164, 448.5683, 448.5595, 448.5615,
        448.5561, 448.6453, 448.6446, 448.6352, 448.6405, 448.6646, 448.6636,
        448.5933, 448.5615, 448.6672, 448.5571, 448.7102, 448.6577, 448.5470,
        448.6344, 448.6455, 448.5662, 448.5558, 448.6396, 448.6666, 448.6290,
        448.5928, 448.6458, 448.5739, 448.6253, 450.3980, 448.5559, 448.6271,
        448.5662, 448.6602, 448.5787, 448.5904, 448.7249, 448.5881, 448.6570,
        448.5649, 448.6877, 448.7258, 448.6250, 448.6299, 448.6020, 448.5747,
        448.5725, 448.6232, 448.6205, 448.6679, 448.5667, 448.6260, 448.6336,
        448.6091, 448.5817, 448.6032, 448.5919, 448.6506, 448.6932, 448.6329,
        448.5558, 448.6320, 448.6456, 448.6324, 448.6243, 448.6039, 448.6125,
        448.6007, 448.5955, 448.6668, 448.6194, 448.5551, 448.6595, 448.6208,
        448.5605, 448.5645, 448.7155, 448.6468, 448.5583, 448.6397, 448.6669,
        448.5651, 448.7408, 448.5646, 448.6386, 448.6168, 448.6213, 448.6584,
        448.6541, 448.7608, 448.6170, 448.6679, 448.6379, 448.7072, 448.7755,
        448.7042, 448.6333, 448.6287, 448.5616, 448.5614, 448.5487, 448.6392,
        448.6365, 450.3612, 448.5707, 448.5657, 448.5957, 448.7380, 448.6552,
        448.5669, 448.6580, 448.6078, 448.7456, 448.6072, 448.6352, 448.6454,
        448.6387, 448.6605, 448.6062, 448.6544, 448.6181, 448.5912, 448.5587,
        448.5881, 448.6701, 448.5548, 448.6224, 448.6111, 448.6663, 448.5908,
        448.5507, 448.5741, 448.6356, 448.5784, 448.6460, 448.5734, 448.6457,
        448.6531, 448.6304, 448.6004, 448.7660, 448.6443, 448.6282, 448.6526,
        448.7380, 448.5961, 448.6219, 448.5580, 448.6678, 448.6495, 448.6294,
        448.5928, 448.6536, 448.5929, 448.6355, 448.5689, 448.7671, 448.5824,
        448.5945, 448.6378, 448.5922, 448.5932, 448.6062, 448.6611, 448.6677,
        448.5567, 448.7546, 448.7253, 448.5559, 448.6424, 448.5914, 448.6521,
        448.7664, 448.6830, 448.6400, 448.6337, 448.5848, 448.6232, 448.7403,
        448.6141, 448.6405, 448.6664, 448.6555, 448.6646, 448.6187, 448.5938,
        448.6384, 448.6093, 448.6181, 448.6330, 448.6509, 448.6184, 448.5689,
        448.6149, 448.5465, 448.5646, 448.6455, 448.5683, 448.6670, 448.5723,
        448.5620, 448.5490, 448.6465, 448.5750, 448.5931, 448.5756, 448.5713,
        448.6060, 448.5848, 448.5824, 448.5906, 448.6342, 448.6412, 448.6495,
        448.6656, 448.6674, 448.6154, 448.6106, 448.6481, 448.6279, 448.6570,
        448.6442, 448.5708, 448.6669, 448.6679, 448.5714, 448.6285, 448.6342,
        448.5763, 448.5884, 448.6261, 448.6669, 448.5580, 448.5774, 448.6263,
        448.5909, 448.6411, 448.7245, 448.6137, 448.6389, 448.7089, 448.6523,
        448.6517, 448.6208, 448.6424, 448.6440, 448.5904, 448.6162, 448.6501,
        448.5708, 448.7202, 448.6219, 448.6598, 448.5922, 448.6666, 448.6527,
        448.6036, 448.5894, 448.6239, 448.6366, 448.5516, 448.6461, 448.7380,
        448.6512, 448.6508, 448.6151, 448.5841, 448.6145, 448.7116, 448.7489,
        448.6909, 448.7556, 448.6942, 448.6457, 448.7338, 448.5881, 448.6064,
        448.5595, 448.5502, 448.6146, 448.6357, 448.6347, 448.7761, 448.5864,
        448.6104, 448.6151, 448.6650, 448.6497, 448.6644, 448.7155, 448.6029,
        448.6189, 448.7730, 448.5698, 448.6519, 448.7252, 448.6378, 448.6220,
        448.7296, 448.5596, 448.6281, 448.6193, 448.7180, 448.6739, 448.6262,
        448.5999, 448.6311, 448.5627, 448.6434, 448.6679, 448.5493, 448.6476,
        448.6227, 448.7511, 448.6653, 448.6484, 448.5605, 448.7391, 448.6160,
        448.6679, 448.5772, 448.6133, 448.6555, 448.6438, 448.5588, 448.6679,
        448.5648, 448.5898, 448.6699, 448.5753, 448.6414, 448.7225, 448.6152,
        448.6578, 448.5647, 448.6172, 448.6180, 448.6776, 448.5623, 448.6274,
        448.5860, 448.5795, 448.6036, 448.6295, 448.6240, 448.6398, 448.6696,
        448.6388, 448.6379, 448.6508, 448.5698, 448.6179, 448.6608, 448.5929,
        448.6298, 448.5933, 448.5556, 448.6351, 448.7364, 448.7013, 448.7412,
        448.5667, 448.6668, 448.6440, 448.6591, 449.9731, 448.6639, 448.7759,
        448.5599, 448.6670, 448.6673, 448.7754, 448.5770, 448.6593, 448.6658,
        448.5726, 448.6077, 448.6669, 448.6677, 448.6400, 448.6503, 448.6644,
        448.5614, 448.5744, 448.6336, 448.6194, 448.6293, 448.7108, 448.5719,
        448.6679, 448.5817, 448.6283, 448.6338, 448.6567, 448.6009, 448.6625,
        448.6530, 448.6152, 448.5640, 448.7387, 448.6932, 448.5958, 448.6519,
        448.5753, 448.6420, 448.7394, 448.5684, 448.7296, 448.5929, 448.6267,
        448.6780, 448.6830, 448.6474, 448.6465, 448.6460, 448.6676, 448.5890,
        448.6386, 448.6385, 448.5826, 448.6174, 448.6531, 448.5511, 448.5989,
        448.6165, 448.6781, 448.6796, 448.7465, 448.6835, 448.7311, 448.5593,
        448.5701, 448.6583, 448.6252, 448.7646, 448.5698, 448.6808, 448.7435,
        448.6678, 448.7335, 448.6689, 448.6182, 448.6353, 448.6471, 448.5659,
        448.6259, 448.6516, 448.7100, 448.7048, 448.6669, 448.5931, 448.6082,
        448.6027, 448.6109, 448.5565, 448.6465, 448.6138, 448.6653, 448.6675,
        448.5900, 448.6655, 448.5563, 448.6292, 448.6356, 448.5954, 448.5934,
        448.6175, 448.5931, 448.6220, 448.6104, 448.5818, 448.7669, 448.6453,
        448.5636, 448.6266, 448.6335, 448.6467, 448.6447, 448.6692, 448.6597,
        448.6347, 448.6916, 448.6470, 448.5870, 448.6927, 448.5547, 448.6027,
        448.6650, 448.6300, 448.6403, 448.5967, 448.7336, 448.6177, 448.6677,
        448.5624, 448.7045, 448.6406, 448.6581, 448.5801, 448.6679, 448.5661,
        448.5731, 448.5598, 448.6678, 448.5919, 448.6679, 448.6843, 448.5590,
        448.5884, 448.6175, 448.5858, 448.6028, 448.6170, 448.6672, 448.5613,
        448.6901, 448.6675, 448.6656, 448.6764, 448.5667, 448.5542, 448.6275,
        448.6370, 448.6799, 448.6501, 448.6666, 448.6642, 448.6659, 448.6594,
        448.5931, 448.6531, 448.6199, 448.5823, 448.6501, 448.6466, 448.7207,
        448.5632, 448.5578, 448.5654, 448.5751, 448.5882, 448.6129, 448.7229,
        448.6190, 448.7120, 448.6314, 448.5547, 448.6531, 448.5708, 448.6385,
        448.6107, 448.5580, 448.7641, 448.5693, 448.7729, 448.6077, 448.5560,
        448.7748, 448.7504, 448.7324, 448.6681, 448.7057, 448.5640, 448.6435,
        448.6465, 448.5745, 448.6430, 448.6445, 448.6149, 448.6679, 448.6233,
        448.6665, 448.5569, 448.6647, 450.2876, 448.6667, 448.6151, 448.5751,
        448.7282, 448.7205, 448.6365, 448.6679, 448.5903, 448.5582, 448.7536,
        448.6226, 448.7626, 448.6464, 448.6425, 448.5896, 448.6031, 448.6496,
        448.6177, 448.5904, 448.7255, 448.5933, 448.5652, 448.6659, 448.5980,
        448.6503, 448.6138, 448.6964, 448.6210, 448.7474, 448.7293, 448.7585,
        448.5667, 448.5730, 448.6098, 448.7630, 448.6675, 448.6882, 448.5930,
        448.6417, 448.6632, 448.6692, 448.5736, 448.5827, 448.6396, 448.5812,
        448.6679, 448.5748, 448.6801, 448.7415, 448.6500, 448.6413, 448.5605,
        448.6401, 448.5594, 448.6073, 448.6060, 448.5545, 448.5621, 448.5754,
        448.5909, 448.6125, 448.5664, 448.6420, 448.6153, 448.6069, 448.6598,
        448.5580, 448.7784, 448.5759, 448.6977, 448.5676, 448.6545, 448.6298,
        448.6679, 448.7116, 448.6557, 448.6037, 448.6493, 448.6290, 448.6602,
        448.6341, 448.7216, 448.6219, 448.6166, 448.5667, 448.6660, 448.5679,
        448.6158, 448.6625, 448.6098, 448.7231, 448.5647, 448.5942, 448.6678,
        448.6610, 448.5896, 448.5703, 448.6407, 448.5620, 448.7181, 448.5757,
        448.6073, 448.6675, 448.6400, 448.7060, 448.5731, 448.6429, 448.6976,
        448.5940, 448.6247], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([398.7796], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1402],
             [112.1910],
             [112.1542],
             [112.1542]],

            [[112.1662],
             [112.1556],
             [112.1556],
             [112.1670]],

            [[112.1370],
             [112.1563],
             [112.1366],
             [112.1452]],

            ...,

            [[112.1490],
             [112.1930],
             [112.1889],
             [112.1424]],

            [[112.1669],
             [112.1669],
             [112.1669],
             [112.1669]],

            [[112.1723],
             [112.1369],
             [112.1395],
             [112.1892]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6396, 448.6443, 448.5751,  ..., 448.6733, 448.6675, 448.6379],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6396, 448.6443, 448.5751,  ..., 448.6733, 448.6675, 448.6379],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1641],
             [112.1288],
             [112.1771],
             [112.1270]],

            [[112.1519],
             [112.1519],
             [112.1776],
             [112.1776]],

            [[112.1267],
             [112.1884],
             [112.1713],
             [112.1713]],

            ...,

            [[112.1268],
             [112.1389],
             [112.1431],
             [112.1431]],

            [[112.1597],
             [112.1597],
             [112.1597],
             [112.1597]],

            [[112.1434],
             [112.1434],
             [112.1758],
             [112.1758]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5970, 448.6591, 448.6576,  ..., 448.5519, 448.6387, 448.6384],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5970, 448.6591, 448.6576,  ..., 448.5519, 448.6387, 448.6384],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0987],
             [112.1435],
             [112.1072],
             [112.1294]],

            [[112.0975],
             [112.1488],
             [112.1181],
             [112.1180]],

            [[112.1574],
             [112.1334],
             [112.1517],
             [112.1369]],

            ...,

            [[112.1366],
             [112.1366],
             [112.1366],
             [112.1366]],

            [[112.1000],
             [112.1000],
             [112.0998],
             [112.0998]],

            [[112.1501],
             [112.1385],
             [112.1607],
             [112.1607]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4789, 448.4825, 448.5794,  ..., 448.5464, 448.3997, 448.6100],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4789, 448.4825, 448.5794,  ..., 448.5464, 448.3997, 448.6100],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0963],
             [112.1019],
             [112.1118],
             [112.1493]],

            [[112.0880],
             [112.1204],
             [112.0852],
             [112.1251]],

            [[112.1078],
             [112.0966],
             [112.0948],
             [112.1461]],

            ...,

            [[112.0893],
             [112.0878],
             [112.0864],
             [112.0890]],

            [[112.0843],
             [112.0843],
             [112.1037],
             [112.1037]],

            [[112.0993],
             [112.1012],
             [112.0963],
             [112.1432]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4593, 448.4187, 448.4453,  ..., 448.3526, 448.3759, 448.4400],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4593, 448.4187, 448.4453,  ..., 448.3526, 448.3759, 448.4400],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1104],
             [112.1102],
             [112.1104],
             [112.1104]],

            [[112.0827],
             [112.0827],
             [112.0862],
             [112.0862]],

            [[112.0838],
             [112.0838],
             [112.0823],
             [112.0823]],

            ...,

            [[112.1037],
             [112.1037],
             [112.0734],
             [112.0734]],

            [[112.1097],
             [112.0982],
             [112.1099],
             [112.1000]],

            [[112.0755],
             [112.0755],
             [112.0820],
             [112.0820]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4414, 448.3380, 448.3323,  ..., 448.3542, 448.4178, 448.3151],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4414, 448.3380, 448.3323,  ..., 448.3542, 448.4178, 448.3151],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0644],
             [112.0816],
             [112.0644],
             [112.0822]],

            [[112.0644],
             [112.0643],
             [112.0857],
             [112.0803]],

            [[112.0839],
             [112.1043],
             [112.0756],
             [112.1275]],

            ...,

            [[112.0916],
             [112.0634],
             [112.0632],
             [112.0851]],

            [[112.0641],
             [112.1150],
             [112.1167],
             [112.0951]],

            [[112.0643],
             [112.0643],
             [112.0640],
             [112.0640]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2926, 448.2947, 448.3914,  ..., 448.3033, 448.3910, 448.2566],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2926, 448.2947, 448.3914,  ..., 448.3033, 448.3910, 448.2566],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1093],
             [112.1093],
             [112.1088],
             [112.1088]],

            [[112.0546],
             [112.1085],
             [112.0768],
             [112.0766]],

            [[112.6137],
             [112.6253],
             [112.5458],
             [112.6075]],

            ...,

            [[112.1772],
             [112.2219],
             [112.1058],
             [112.1568]],

            [[112.0977],
             [112.0977],
             [112.1116],
             [112.1116]],

            [[112.0664],
             [112.0801],
             [112.0907],
             [112.1235]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4362, 448.3165, 450.3924,  ..., 448.6617, 448.4186, 448.3607],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4362, 448.3165, 450.3924,  ..., 448.6617, 448.4186, 448.3607],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0729],
             [112.0729],
             [112.0969],
             [112.0969]],

            [[112.1027],
             [112.1031],
             [112.0581],
             [112.0581]],

            [[112.0769],
             [112.1241],
             [112.0578],
             [112.0730]],

            ...,

            [[112.0988],
             [112.0988],
             [112.1254],
             [112.1254]],

            [[112.0621],
             [112.0973],
             [112.0559],
             [112.1087]],

            [[112.0655],
             [112.0818],
             [112.0775],
             [112.1225]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3396, 448.3220, 448.3316,  ..., 448.4482, 448.3239, 448.3472],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3396, 448.3220, 448.3316,  ..., 448.4482, 448.3239, 448.3472],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0612],
             [112.0612],
             [112.0612],
             [112.0612]],

            [[112.1284],
             [112.1287],
             [112.0766],
             [112.0766]],

            [[112.1093],
             [112.1093],
             [112.1233],
             [112.1233]],

            ...,

            [[112.1109],
             [112.0623],
             [112.1110],
             [112.0623]],

            [[112.0844],
             [112.0844],
             [112.0647],
             [112.0647]],

            [[112.0627],
             [112.0671],
             [112.0782],
             [112.0734]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2448, 448.4103, 448.4653,  ..., 448.3465, 448.2982, 448.2814],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2448, 448.4103, 448.4653,  ..., 448.3465, 448.2982, 448.2814],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0633],
             [112.0943],
             [112.0635],
             [112.1261]],

            [[112.1221],
             [112.1268],
             [112.1245],
             [112.1245]],

            [[112.1423],
             [112.1385],
             [112.1425],
             [112.1425]],

            ...,

            [[112.0682],
             [112.0643],
             [112.0940],
             [112.0647]],

            [[112.0653],
             [112.1230],
             [112.0592],
             [112.0738]],

            [[112.0823],
             [112.1149],
             [112.0733],
             [112.1299]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3472, 448.4979, 448.5657,  ..., 448.2911, 448.3213, 448.4004],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3472, 448.4979, 448.5657,  ..., 448.2911, 448.3213, 448.4004],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1403],
             [112.1403],
             [112.1400],
             [112.1400]],

            [[112.1281],
             [112.1281],
             [112.1267],
             [112.1267]],

            [[112.1497],
             [112.1497],
             [112.1497],
             [112.1497]],

            ...,

            [[112.0884],
             [112.0884],
             [112.0871],
             [112.0871]],

            [[112.0925],
             [112.0793],
             [112.1315],
             [112.0654]],

            [[112.0883],
             [112.0563],
             [112.0670],
             [112.1279]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5605, 448.5097, 448.5989,  ..., 448.3511, 448.3687, 448.3395],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5605, 448.5097, 448.5989,  ..., 448.3511, 448.3687, 448.3395],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0698],
             [112.0939],
             [112.0809],
             [112.0728]],

            [[112.1738],
             [112.1738],
             [112.1744],
             [112.1744]],

            [[112.1674],
             [112.1674],
             [112.1680],
             [112.1680]],

            ...,

            [[112.1787],
             [112.1785],
             [112.1787],
             [112.1787]],

            [[112.0953],
             [112.0693],
             [112.0851],
             [112.0708]],

            [[112.1229],
             [112.1117],
             [112.0684],
             [112.0683]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3174, 448.6965, 448.6708,  ..., 448.7145, 448.3205, 448.3713],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3174, 448.6965, 448.6708,  ..., 448.7145, 448.3205, 448.3713],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2027],
             [112.1441],
             [112.1441],
             [112.2082]],

            [[112.0826],
             [112.0969],
             [112.1575],
             [112.1575]],

            [[112.0820],
             [112.1266],
             [112.1465],
             [112.1465]],

            ...,

            [[112.0818],
             [112.1226],
             [112.1050],
             [112.1663]],

            [[112.0818],
             [112.1047],
             [112.1410],
             [112.1410]],

            [[112.0920],
             [112.0864],
             [112.0835],
             [112.0835]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6990, 448.4944, 448.5016,  ..., 448.4756, 448.4684, 448.3455],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6990, 448.4944, 448.5016,  ..., 448.4756, 448.4684, 448.3455],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2407],
             [112.2407],
             [112.2407],
             [112.2407]],

            [[112.1071],
             [112.1475],
             [112.1091],
             [112.1878]],

            [[112.2129],
             [112.2136],
             [112.1024],
             [112.1929]],

            ...,

            [[112.1787],
             [112.0993],
             [112.0988],
             [112.1667]],

            [[112.1494],
             [112.0975],
             [112.0978],
             [112.1629]],

            [[112.0966],
             [112.1633],
             [112.1010],
             [112.1802]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9627, 448.5515, 448.7218,  ..., 448.5435, 448.5076, 448.5410],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9627, 448.5515, 448.7218,  ..., 448.5435, 448.5076, 448.5410],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1472],
             [112.1323],
             [112.1267],
             [112.2017]],

            [[112.1068],
             [112.1743],
             [112.1312],
             [112.1312]],

            [[112.1098],
             [112.1067],
             [112.1211],
             [112.2005]],

            ...,

            [[112.2597],
             [112.2465],
             [112.2598],
             [112.2477]],

            [[112.1615],
             [112.1615],
             [112.2043],
             [112.2043]],

            [[112.1092],
             [112.1092],
             [112.1082],
             [112.1082]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6079, 448.5436, 448.5381,  ..., 449.0138, 448.7314, 448.4346],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6079, 448.5436, 448.5381,  ..., 449.0138, 448.7314, 448.4346],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1267],
             [112.1335],
             [112.1179],
             [112.1179]],

            [[112.1167],
             [112.1887],
             [112.1187],
             [112.2076]],

            [[112.1663],
             [112.2203],
             [112.1546],
             [112.1546]],

            ...,

            [[112.1357],
             [112.1357],
             [112.1212],
             [112.1212]],

            [[112.1236],
             [112.1170],
             [112.1478],
             [112.1837]],

            [[112.2112],
             [112.1571],
             [112.1976],
             [112.1179]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4960, 448.6317, 448.6959,  ..., 448.5138, 448.5721, 448.6838],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4960, 448.6317, 448.6959,  ..., 448.5138, 448.5721, 448.6838],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2838],
             [112.2412],
             [112.2412],
             [112.2867]],

            [[112.2003],
             [112.2039],
             [112.2056],
             [112.2056]],

            [[112.2796],
             [112.1855],
             [112.2130],
             [112.2130]],

            ...,

            [[112.2837],
             [112.2396],
             [112.2839],
             [112.2408]],

            [[112.1481],
             [112.1481],
             [112.1590],
             [112.1590]],

            [[112.1821],
             [112.1821],
             [112.1091],
             [112.1091]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0529, 448.8154, 448.8911,  ..., 449.0479, 448.6142, 448.5824],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0529, 448.8154, 448.8911,  ..., 449.0479, 448.6142, 448.5824],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1146],
             [112.1025],
             [112.0933],
             [112.1933]],

            [[112.0949],
             [112.1182],
             [112.1863],
             [112.1863]],

            [[112.1458],
             [112.2045],
             [112.1330],
             [112.1330]],

            ...,

            [[112.1638],
             [112.1732],
             [112.1638],
             [112.1732]],

            [[112.1006],
             [112.1045],
             [112.0951],
             [112.1678]],

            [[112.1318],
             [112.1558],
             [112.1824],
             [112.1929]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5038, 448.5858, 448.6163,  ..., 448.6740, 448.4680, 448.6629],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5038, 448.5858, 448.6163,  ..., 448.6740, 448.4680, 448.6629],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0218e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1665],
             [112.0888],
             [112.0887],
             [112.1698]],

            [[112.1210],
             [112.2449],
             [112.1050],
             [112.2367]],

            [[112.1348],
             [112.1683],
             [112.1983],
             [112.1983]],

            ...,

            [[112.0963],
             [112.0951],
             [112.1081],
             [112.0978]],

            [[112.0928],
             [112.0928],
             [112.1195],
             [112.1195]],

            [[112.1005],
             [112.1053],
             [112.0935],
             [112.1108]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5138, 448.7075, 448.6997,  ..., 448.3973, 448.4246, 448.4100],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5138, 448.7075, 448.6997,  ..., 448.3973, 448.4246, 448.4100],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1813],
             [112.1846],
             [112.1622],
             [112.1622]],

            [[112.1879],
             [112.1879],
             [112.1897],
             [112.1897]],

            [[112.1615],
             [112.2561],
             [112.1602],
             [112.2599]],

            ...,

            [[112.1246],
             [112.0909],
             [112.1224],
             [112.0910]],

            [[112.0913],
             [112.0913],
             [112.1579],
             [112.1579]],

            [[112.1388],
             [112.1388],
             [112.1569],
             [112.1569]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6903, 448.7552, 448.8377,  ..., 448.4289, 448.4984, 448.5913],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6903, 448.7552, 448.8377,  ..., 448.4289, 448.4984, 448.5913],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0963],
             [112.1423],
             [112.0958],
             [112.1873]],

            [[112.0926],
             [112.1522],
             [112.1904],
             [112.0944]],

            [[112.1129],
             [112.1076],
             [112.1996],
             [112.1276]],

            ...,

            [[112.0892],
             [112.0980],
             [112.0930],
             [112.0926]],

            [[112.1992],
             [112.1782],
             [112.1573],
             [112.1261]],

            [[112.2580],
             [112.2580],
             [112.1558],
             [112.1558]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5218, 448.5296, 448.5477, 448.7015, 448.4783, 448.5085, 448.5296,
            448.5052, 448.7537, 448.5475, 448.7490, 449.9991, 448.4927, 448.5578,
            448.5952, 448.4256, 448.5229, 448.5144, 448.5475, 448.4974, 448.5491,
            448.9159, 450.1737, 448.6541, 448.5043, 448.4948, 448.4841, 448.4047,
            448.4731, 448.5565, 448.5802, 448.4724, 448.4675, 448.5338, 448.5182,
            449.0813, 448.5501, 448.4390, 448.4928, 449.0280, 448.4005, 448.3857,
            448.4771, 448.4716, 448.5537, 448.4966, 448.8513, 448.5855, 448.5367,
            448.9109, 448.4363, 448.5485, 449.0741, 449.0733, 448.7750, 448.5114,
            448.5205, 449.0809, 448.3954, 448.7556, 448.6783, 448.5001, 448.4391,
            448.6408, 448.6276, 448.5549, 449.0795, 449.0815, 448.5659, 448.5021,
            448.6121, 448.8395, 449.0799, 448.5219, 448.4104, 448.9952, 448.4024,
            448.5207, 448.4669, 448.5312, 448.8492, 449.0809, 448.5229, 448.5299,
            448.7543, 449.0702, 449.0815, 448.4753, 448.8202, 448.5189, 451.4263,
            448.4276, 448.4344, 448.4817, 448.5143, 448.5324, 448.4050, 448.5703,
            448.4837, 448.3804, 448.5358, 449.0811, 448.5392, 448.7102, 448.5783,
            448.6613, 448.5107, 448.5278, 449.0692, 448.5605, 448.6218, 448.7540,
            448.5425, 448.7222, 448.4865, 448.6148, 448.4607, 448.5779, 448.6257,
            448.4001, 448.5799, 448.3900, 448.4673, 448.5266, 448.4068, 448.5660,
            448.5300, 448.4958, 448.6313, 448.5396, 449.0814, 448.5393, 448.6997,
            448.5503, 448.5397, 448.9311, 449.0426, 448.4967, 448.5236, 448.5725,
            449.0813, 448.5027, 448.6340, 448.6049, 448.6228, 449.0637, 448.4088,
            448.7501, 448.5218, 448.4376, 448.4913, 448.4800, 448.5223, 448.6208,
            448.7102, 448.4342, 448.8595, 448.4054, 448.6293, 448.5007, 448.4750,
            448.6014, 448.6467, 448.4262, 448.8130, 448.3657, 448.4609, 448.6843,
            448.5563, 448.4808, 448.4771, 448.4884, 449.0811, 448.4817, 448.3986,
            448.4913, 448.5209, 449.0815, 448.4665, 448.5631, 448.7178, 448.7907,
            448.4246, 448.4250, 448.8413, 448.5184, 448.4288, 448.5771, 448.7531,
            448.5031, 448.6623, 448.4451, 448.3626, 448.4904, 448.9119, 448.7330,
            448.6366, 448.6267, 448.3560, 448.7569, 448.5109, 448.4704, 449.1517,
            448.6965, 448.4169, 448.5675, 448.3991, 448.4006, 449.0464, 448.7568,
            448.5178, 448.9902, 448.8836, 448.6786, 448.4547, 448.5298, 448.5945,
            448.7128, 448.4600, 448.5193, 448.5018, 448.4726, 448.5530, 448.9850,
            448.4929, 448.8689, 448.6345, 448.5537, 448.6647, 448.4034, 448.5042,
            448.5479, 448.9907, 448.5964, 449.0516, 449.0173, 448.4034, 449.0265,
            448.5366, 448.9651, 448.6944, 448.6390, 448.5284, 448.5356, 448.5080,
            448.6176, 448.8474, 448.4711, 449.0704, 448.8920, 448.4894, 448.4766,
            448.5798, 448.4176, 448.4106, 448.4673, 448.5495, 448.4228, 448.6238,
            448.6035, 448.5596, 448.4478, 448.5424, 448.3800, 448.6226, 448.4013,
            448.5583, 448.7122, 448.5330, 449.0714, 449.0308, 448.4229, 449.0813,
            448.5878, 448.5206, 448.4897, 448.5018, 449.0797, 448.4759, 448.4021,
            448.9114, 448.3934, 448.5234, 448.5319, 448.3767, 448.6246, 448.7535,
            449.0109, 448.5385, 448.7218, 448.5225, 448.4948, 448.9777, 448.4575,
            448.4961, 448.4584, 448.6092, 448.5099, 448.6781, 448.5423, 448.5229,
            448.4961, 448.6997, 448.5004, 448.4438, 448.6635, 448.5370, 448.5534,
            448.3873, 448.3828, 448.5792, 448.4571, 448.9522, 451.5146, 448.4406,
            448.4010, 448.6014, 448.4453, 448.6376, 448.5963, 448.7252, 448.4902,
            448.6425, 448.4090, 449.0682, 448.5200, 448.5689, 448.6287, 448.4556,
            448.4839, 448.7905, 448.4526, 448.4968, 448.5332, 448.4553, 448.6635,
            448.6268, 448.6012, 449.0690, 448.4953, 448.5793, 448.5629, 448.5692,
            448.5205, 448.7875, 448.6486, 448.4357, 448.4985, 448.5267, 448.6366,
            448.6548, 448.4411, 449.0811, 449.0308, 448.3601, 448.5492, 448.5384,
            448.9212, 448.7585, 448.5879, 448.5468, 448.6004, 448.7445, 448.4288,
            448.9531, 448.6620, 448.5302, 449.0809, 448.4298, 448.7532, 448.5778,
            448.5149, 448.4120, 449.0809, 448.6376, 448.3990, 449.0809, 448.7559,
            448.4752, 448.5235, 448.5422, 448.4571, 449.0225, 449.0796, 448.7403,
            448.5162, 448.4298, 448.7840, 448.5263, 448.5486, 449.0773, 448.6678,
            449.0214, 448.5648, 448.4607, 448.4948, 448.6900, 451.3405, 448.5229,
            449.0534, 449.0783, 448.3992, 448.7430, 448.7195, 448.5792, 448.6548,
            448.7070, 448.5407, 448.7248, 448.5771, 448.7107, 448.4346, 448.9315,
            448.4753, 448.5020, 448.5999, 448.4212, 448.4838, 448.3822, 448.7480,
            448.7239, 448.6312, 448.5515, 449.0773, 448.5145, 448.5263, 448.5236,
            448.5145, 448.4980, 448.5744, 448.8237, 448.7016, 448.4528, 449.0646,
            448.3874, 448.7369, 448.6257, 448.7455, 448.6199, 448.6151, 448.5543,
            448.5118, 448.5001, 448.4872, 448.3869, 448.4128, 448.9805, 451.4908,
            448.3807, 448.4705, 449.0308, 448.5249, 448.5031, 448.4753, 448.5085,
            448.7198, 448.3899, 449.0614, 448.5716, 448.4839, 448.3853, 448.6092,
            448.6952, 448.9343, 448.6702, 448.6940, 448.6227, 448.4787, 448.4910,
            448.5440, 449.0804, 448.4467, 448.3956, 448.5046, 448.4635, 448.8837,
            448.6844, 448.8159, 448.5647, 448.5744, 448.3557, 448.7307, 448.4537,
            448.4680, 448.4144, 448.5135, 448.6152, 448.8958, 448.5361, 448.5679,
            449.0605, 448.4087, 448.6743, 449.0811, 448.5843, 448.4371, 449.0500,
            448.6865, 448.7556, 448.4687, 448.4999, 448.5369, 448.5223, 448.5172,
            448.3607, 448.5136, 448.3748, 448.3881, 448.4175, 448.3758, 448.5718,
            448.6338, 448.5611, 448.5640, 448.4355, 448.7198, 448.5159, 448.5187,
            448.7360, 448.5170, 448.6886, 448.8318, 448.9332, 448.5244, 448.5167,
            448.7164, 448.3988, 448.5171, 448.4119, 448.5674, 448.4973, 448.3908,
            448.8735, 449.0776, 448.7141, 448.4460, 448.4583, 448.4773, 448.7061,
            448.5343, 448.9691, 449.0748, 448.4244, 448.4558, 449.0810, 448.4955,
            448.9788, 448.5547, 448.4660, 448.5596, 448.3948, 448.5848, 448.4028,
            448.5013, 448.7106, 449.0809, 448.5273, 449.0498, 448.7146, 448.6756,
            448.6665, 448.7611, 448.6151, 448.4158, 448.6614, 448.4171, 448.3792,
            448.4766, 448.3806, 448.6128, 448.5179, 448.7077, 448.6569, 448.4918,
            448.5484, 448.6896, 448.5218, 448.6346, 449.0809, 448.4803, 448.3628,
            448.4167, 448.5007, 448.4973, 448.9647, 448.6830, 449.0786, 448.5061,
            448.4296, 448.6292, 449.0432, 449.0811, 449.0820, 448.5251, 448.3704,
            448.6677, 448.4252, 448.4134, 448.7338, 448.5081, 448.5952, 449.0659,
            448.4691, 448.4186, 449.0737, 448.4601, 448.9120, 448.8692, 448.5454,
            448.3563, 448.4582, 448.5244, 448.8094, 448.4133, 448.6512, 449.0719,
            448.5653, 449.0815, 448.6937, 448.7443, 449.0814, 448.6880, 448.4753,
            448.5402, 449.0814, 448.3705, 448.4438, 448.9485, 448.3975, 448.4008,
            448.5127, 448.4786, 448.5294, 449.0164, 448.6826, 448.5958, 448.4646,
            448.4419, 448.5123, 448.6508, 448.3991, 448.4058, 448.6987, 449.0197,
            448.4760, 448.5842, 448.8595, 448.5283, 448.4608, 448.4580, 448.7209,
            449.0134, 448.4916, 448.7593, 448.5538, 448.3698, 448.5083, 448.3786,
            448.4119, 448.5159, 448.5119, 448.6238, 448.5427, 448.8790, 449.0686,
            448.5267, 449.0476, 449.0807, 448.4957, 449.0516, 448.3553, 448.4448,
            448.5054, 448.4623, 448.4477, 448.5426, 448.4846, 448.7298, 448.5180,
            448.5473, 448.7014, 448.7859, 448.4907, 448.6564, 448.5557, 448.7383,
            448.5298, 448.5614, 449.0762, 448.5841, 448.7086, 448.5206, 448.6525,
            448.4958, 448.6078, 448.5027, 448.4120, 448.4192, 448.8401, 448.4665,
            451.2013, 448.6856, 448.3997, 448.4339, 448.5612, 448.7479, 448.6933,
            448.4804, 449.0464, 448.5375, 448.5151, 448.5038, 448.4137, 448.5359,
            448.5142, 448.4417, 448.6043, 448.9681, 448.4731, 448.5207, 448.7823,
            448.4055, 448.4680, 448.7338, 448.5530, 449.0812, 448.4885, 449.0811,
            448.4490, 449.0708, 448.3571, 448.7438, 449.0815, 448.4962, 449.0374,
            448.4348, 448.5275, 448.7567, 448.4127, 448.6354, 448.5144, 448.6155,
            448.7032, 448.5762, 448.5060, 448.3708, 448.8393, 448.4237, 448.6513,
            448.4269, 448.4094, 448.3572, 448.5903, 448.5776, 448.6998, 448.4417,
            448.5445, 448.5661, 448.4637, 448.7877, 448.5576, 448.7547, 448.5376,
            448.5491, 448.5217, 448.3584, 448.5150, 448.3870, 448.5363, 448.4521,
            448.3705, 448.5643, 448.4085, 448.5092, 449.0430, 448.4145, 448.3675,
            448.6273, 448.5452, 448.5604, 448.7368, 448.7549, 448.5836, 448.4612,
            448.5013, 448.4005, 448.9061, 448.3916, 448.6327, 448.5404, 448.8713,
            448.5332, 448.6885, 448.4752, 448.5425, 448.5086, 448.4068, 448.3846,
            448.5004, 448.5495, 448.6180, 448.6289, 448.6647, 448.6252, 448.5369,
            449.0663, 448.5466, 448.7566, 448.8849, 448.4093, 448.5874, 448.5637,
            448.4994, 448.4584, 448.3798, 449.0815, 448.4812, 448.5958, 448.6633,
            448.6027, 448.5599, 448.5627, 449.0228, 448.3980, 448.3886, 449.0327,
            448.8953, 448.4301, 448.3962, 448.5551, 448.7006, 448.4733, 448.4631,
            448.5351, 448.5532, 448.6315, 448.9141, 448.4463, 448.4343, 449.8427,
            449.0504, 448.6472, 448.6584, 448.5991, 448.5305, 448.6049, 449.0764,
            448.6237, 448.5791, 448.3929, 448.5276, 448.4937, 448.5843, 448.5030,
            448.4066, 448.9120, 449.0814, 448.6298, 448.5757, 448.4186, 448.6624,
            448.6178, 448.6503, 448.5862, 448.5787, 448.6780, 448.5579, 448.6713,
            448.4808, 448.9185, 448.5313, 448.4417, 448.4886, 448.5022, 448.5315,
            448.5079, 449.0593, 448.5176, 448.5021, 448.5473, 448.5414, 448.9314,
            448.6828, 448.6884, 448.5834, 448.4417, 449.0870, 448.9285, 449.0813,
            448.5214, 448.7148, 448.4114, 448.3991, 448.5835, 448.7109, 448.6227,
            448.5069, 448.3981, 448.5344, 448.6923, 448.3987, 448.5690, 449.0807,
            448.5147, 448.5164, 449.0745, 449.0805, 449.0766, 448.7181, 449.0815,
            448.4029, 448.5295, 448.7166, 448.6622, 448.5162, 448.3729, 448.5308,
            448.6294, 448.3530, 448.5725, 448.3676, 448.7422, 449.0672, 448.3728,
            448.6608, 448.8276], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5218, 448.5296, 448.5477, 448.7015, 448.4783, 448.5085, 448.5296,
        448.5052, 448.7537, 448.5475, 448.7490, 449.9991, 448.4927, 448.5578,
        448.5952, 448.4256, 448.5229, 448.5144, 448.5475, 448.4974, 448.5491,
        448.9159, 450.1737, 448.6541, 448.5043, 448.4948, 448.4841, 448.4047,
        448.4731, 448.5565, 448.5802, 448.4724, 448.4675, 448.5338, 448.5182,
        449.0813, 448.5501, 448.4390, 448.4928, 449.0280, 448.4005, 448.3857,
        448.4771, 448.4716, 448.5537, 448.4966, 448.8513, 448.5855, 448.5367,
        448.9109, 448.4363, 448.5485, 449.0741, 449.0733, 448.7750, 448.5114,
        448.5205, 449.0809, 448.3954, 448.7556, 448.6783, 448.5001, 448.4391,
        448.6408, 448.6276, 448.5549, 449.0795, 449.0815, 448.5659, 448.5021,
        448.6121, 448.8395, 449.0799, 448.5219, 448.4104, 448.9952, 448.4024,
        448.5207, 448.4669, 448.5312, 448.8492, 449.0809, 448.5229, 448.5299,
        448.7543, 449.0702, 449.0815, 448.4753, 448.8202, 448.5189, 451.4263,
        448.4276, 448.4344, 448.4817, 448.5143, 448.5324, 448.4050, 448.5703,
        448.4837, 448.3804, 448.5358, 449.0811, 448.5392, 448.7102, 448.5783,
        448.6613, 448.5107, 448.5278, 449.0692, 448.5605, 448.6218, 448.7540,
        448.5425, 448.7222, 448.4865, 448.6148, 448.4607, 448.5779, 448.6257,
        448.4001, 448.5799, 448.3900, 448.4673, 448.5266, 448.4068, 448.5660,
        448.5300, 448.4958, 448.6313, 448.5396, 449.0814, 448.5393, 448.6997,
        448.5503, 448.5397, 448.9311, 449.0426, 448.4967, 448.5236, 448.5725,
        449.0813, 448.5027, 448.6340, 448.6049, 448.6228, 449.0637, 448.4088,
        448.7501, 448.5218, 448.4376, 448.4913, 448.4800, 448.5223, 448.6208,
        448.7102, 448.4342, 448.8595, 448.4054, 448.6293, 448.5007, 448.4750,
        448.6014, 448.6467, 448.4262, 448.8130, 448.3657, 448.4609, 448.6843,
        448.5563, 448.4808, 448.4771, 448.4884, 449.0811, 448.4817, 448.3986,
        448.4913, 448.5209, 449.0815, 448.4665, 448.5631, 448.7178, 448.7907,
        448.4246, 448.4250, 448.8413, 448.5184, 448.4288, 448.5771, 448.7531,
        448.5031, 448.6623, 448.4451, 448.3626, 448.4904, 448.9119, 448.7330,
        448.6366, 448.6267, 448.3560, 448.7569, 448.5109, 448.4704, 449.1517,
        448.6965, 448.4169, 448.5675, 448.3991, 448.4006, 449.0464, 448.7568,
        448.5178, 448.9902, 448.8836, 448.6786, 448.4547, 448.5298, 448.5945,
        448.7128, 448.4600, 448.5193, 448.5018, 448.4726, 448.5530, 448.9850,
        448.4929, 448.8689, 448.6345, 448.5537, 448.6647, 448.4034, 448.5042,
        448.5479, 448.9907, 448.5964, 449.0516, 449.0173, 448.4034, 449.0265,
        448.5366, 448.9651, 448.6944, 448.6390, 448.5284, 448.5356, 448.5080,
        448.6176, 448.8474, 448.4711, 449.0704, 448.8920, 448.4894, 448.4766,
        448.5798, 448.4176, 448.4106, 448.4673, 448.5495, 448.4228, 448.6238,
        448.6035, 448.5596, 448.4478, 448.5424, 448.3800, 448.6226, 448.4013,
        448.5583, 448.7122, 448.5330, 449.0714, 449.0308, 448.4229, 449.0813,
        448.5878, 448.5206, 448.4897, 448.5018, 449.0797, 448.4759, 448.4021,
        448.9114, 448.3934, 448.5234, 448.5319, 448.3767, 448.6246, 448.7535,
        449.0109, 448.5385, 448.7218, 448.5225, 448.4948, 448.9777, 448.4575,
        448.4961, 448.4584, 448.6092, 448.5099, 448.6781, 448.5423, 448.5229,
        448.4961, 448.6997, 448.5004, 448.4438, 448.6635, 448.5370, 448.5534,
        448.3873, 448.3828, 448.5792, 448.4571, 448.9522, 451.5146, 448.4406,
        448.4010, 448.6014, 448.4453, 448.6376, 448.5963, 448.7252, 448.4902,
        448.6425, 448.4090, 449.0682, 448.5200, 448.5689, 448.6287, 448.4556,
        448.4839, 448.7905, 448.4526, 448.4968, 448.5332, 448.4553, 448.6635,
        448.6268, 448.6012, 449.0690, 448.4953, 448.5793, 448.5629, 448.5692,
        448.5205, 448.7875, 448.6486, 448.4357, 448.4985, 448.5267, 448.6366,
        448.6548, 448.4411, 449.0811, 449.0308, 448.3601, 448.5492, 448.5384,
        448.9212, 448.7585, 448.5879, 448.5468, 448.6004, 448.7445, 448.4288,
        448.9531, 448.6620, 448.5302, 449.0809, 448.4298, 448.7532, 448.5778,
        448.5149, 448.4120, 449.0809, 448.6376, 448.3990, 449.0809, 448.7559,
        448.4752, 448.5235, 448.5422, 448.4571, 449.0225, 449.0796, 448.7403,
        448.5162, 448.4298, 448.7840, 448.5263, 448.5486, 449.0773, 448.6678,
        449.0214, 448.5648, 448.4607, 448.4948, 448.6900, 451.3405, 448.5229,
        449.0534, 449.0783, 448.3992, 448.7430, 448.7195, 448.5792, 448.6548,
        448.7070, 448.5407, 448.7248, 448.5771, 448.7107, 448.4346, 448.9315,
        448.4753, 448.5020, 448.5999, 448.4212, 448.4838, 448.3822, 448.7480,
        448.7239, 448.6312, 448.5515, 449.0773, 448.5145, 448.5263, 448.5236,
        448.5145, 448.4980, 448.5744, 448.8237, 448.7016, 448.4528, 449.0646,
        448.3874, 448.7369, 448.6257, 448.7455, 448.6199, 448.6151, 448.5543,
        448.5118, 448.5001, 448.4872, 448.3869, 448.4128, 448.9805, 451.4908,
        448.3807, 448.4705, 449.0308, 448.5249, 448.5031, 448.4753, 448.5085,
        448.7198, 448.3899, 449.0614, 448.5716, 448.4839, 448.3853, 448.6092,
        448.6952, 448.9343, 448.6702, 448.6940, 448.6227, 448.4787, 448.4910,
        448.5440, 449.0804, 448.4467, 448.3956, 448.5046, 448.4635, 448.8837,
        448.6844, 448.8159, 448.5647, 448.5744, 448.3557, 448.7307, 448.4537,
        448.4680, 448.4144, 448.5135, 448.6152, 448.8958, 448.5361, 448.5679,
        449.0605, 448.4087, 448.6743, 449.0811, 448.5843, 448.4371, 449.0500,
        448.6865, 448.7556, 448.4687, 448.4999, 448.5369, 448.5223, 448.5172,
        448.3607, 448.5136, 448.3748, 448.3881, 448.4175, 448.3758, 448.5718,
        448.6338, 448.5611, 448.5640, 448.4355, 448.7198, 448.5159, 448.5187,
        448.7360, 448.5170, 448.6886, 448.8318, 448.9332, 448.5244, 448.5167,
        448.7164, 448.3988, 448.5171, 448.4119, 448.5674, 448.4973, 448.3908,
        448.8735, 449.0776, 448.7141, 448.4460, 448.4583, 448.4773, 448.7061,
        448.5343, 448.9691, 449.0748, 448.4244, 448.4558, 449.0810, 448.4955,
        448.9788, 448.5547, 448.4660, 448.5596, 448.3948, 448.5848, 448.4028,
        448.5013, 448.7106, 449.0809, 448.5273, 449.0498, 448.7146, 448.6756,
        448.6665, 448.7611, 448.6151, 448.4158, 448.6614, 448.4171, 448.3792,
        448.4766, 448.3806, 448.6128, 448.5179, 448.7077, 448.6569, 448.4918,
        448.5484, 448.6896, 448.5218, 448.6346, 449.0809, 448.4803, 448.3628,
        448.4167, 448.5007, 448.4973, 448.9647, 448.6830, 449.0786, 448.5061,
        448.4296, 448.6292, 449.0432, 449.0811, 449.0820, 448.5251, 448.3704,
        448.6677, 448.4252, 448.4134, 448.7338, 448.5081, 448.5952, 449.0659,
        448.4691, 448.4186, 449.0737, 448.4601, 448.9120, 448.8692, 448.5454,
        448.3563, 448.4582, 448.5244, 448.8094, 448.4133, 448.6512, 449.0719,
        448.5653, 449.0815, 448.6937, 448.7443, 449.0814, 448.6880, 448.4753,
        448.5402, 449.0814, 448.3705, 448.4438, 448.9485, 448.3975, 448.4008,
        448.5127, 448.4786, 448.5294, 449.0164, 448.6826, 448.5958, 448.4646,
        448.4419, 448.5123, 448.6508, 448.3991, 448.4058, 448.6987, 449.0197,
        448.4760, 448.5842, 448.8595, 448.5283, 448.4608, 448.4580, 448.7209,
        449.0134, 448.4916, 448.7593, 448.5538, 448.3698, 448.5083, 448.3786,
        448.4119, 448.5159, 448.5119, 448.6238, 448.5427, 448.8790, 449.0686,
        448.5267, 449.0476, 449.0807, 448.4957, 449.0516, 448.3553, 448.4448,
        448.5054, 448.4623, 448.4477, 448.5426, 448.4846, 448.7298, 448.5180,
        448.5473, 448.7014, 448.7859, 448.4907, 448.6564, 448.5557, 448.7383,
        448.5298, 448.5614, 449.0762, 448.5841, 448.7086, 448.5206, 448.6525,
        448.4958, 448.6078, 448.5027, 448.4120, 448.4192, 448.8401, 448.4665,
        451.2013, 448.6856, 448.3997, 448.4339, 448.5612, 448.7479, 448.6933,
        448.4804, 449.0464, 448.5375, 448.5151, 448.5038, 448.4137, 448.5359,
        448.5142, 448.4417, 448.6043, 448.9681, 448.4731, 448.5207, 448.7823,
        448.4055, 448.4680, 448.7338, 448.5530, 449.0812, 448.4885, 449.0811,
        448.4490, 449.0708, 448.3571, 448.7438, 449.0815, 448.4962, 449.0374,
        448.4348, 448.5275, 448.7567, 448.4127, 448.6354, 448.5144, 448.6155,
        448.7032, 448.5762, 448.5060, 448.3708, 448.8393, 448.4237, 448.6513,
        448.4269, 448.4094, 448.3572, 448.5903, 448.5776, 448.6998, 448.4417,
        448.5445, 448.5661, 448.4637, 448.7877, 448.5576, 448.7547, 448.5376,
        448.5491, 448.5217, 448.3584, 448.5150, 448.3870, 448.5363, 448.4521,
        448.3705, 448.5643, 448.4085, 448.5092, 449.0430, 448.4145, 448.3675,
        448.6273, 448.5452, 448.5604, 448.7368, 448.7549, 448.5836, 448.4612,
        448.5013, 448.4005, 448.9061, 448.3916, 448.6327, 448.5404, 448.8713,
        448.5332, 448.6885, 448.4752, 448.5425, 448.5086, 448.4068, 448.3846,
        448.5004, 448.5495, 448.6180, 448.6289, 448.6647, 448.6252, 448.5369,
        449.0663, 448.5466, 448.7566, 448.8849, 448.4093, 448.5874, 448.5637,
        448.4994, 448.4584, 448.3798, 449.0815, 448.4812, 448.5958, 448.6633,
        448.6027, 448.5599, 448.5627, 449.0228, 448.3980, 448.3886, 449.0327,
        448.8953, 448.4301, 448.3962, 448.5551, 448.7006, 448.4733, 448.4631,
        448.5351, 448.5532, 448.6315, 448.9141, 448.4463, 448.4343, 449.8427,
        449.0504, 448.6472, 448.6584, 448.5991, 448.5305, 448.6049, 449.0764,
        448.6237, 448.5791, 448.3929, 448.5276, 448.4937, 448.5843, 448.5030,
        448.4066, 448.9120, 449.0814, 448.6298, 448.5757, 448.4186, 448.6624,
        448.6178, 448.6503, 448.5862, 448.5787, 448.6780, 448.5579, 448.6713,
        448.4808, 448.9185, 448.5313, 448.4417, 448.4886, 448.5022, 448.5315,
        448.5079, 449.0593, 448.5176, 448.5021, 448.5473, 448.5414, 448.9314,
        448.6828, 448.6884, 448.5834, 448.4417, 449.0870, 448.9285, 449.0813,
        448.5214, 448.7148, 448.4114, 448.3991, 448.5835, 448.7109, 448.6227,
        448.5069, 448.3981, 448.5344, 448.6923, 448.3987, 448.5690, 449.0807,
        448.5147, 448.5164, 449.0745, 449.0805, 449.0766, 448.7181, 449.0815,
        448.4029, 448.5295, 448.7166, 448.6622, 448.5162, 448.3729, 448.5308,
        448.6294, 448.3530, 448.5725, 448.3676, 448.7422, 449.0672, 448.3728,
        448.6608, 448.8276], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([399.1957], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0932],
             [112.1189],
             [112.0904],
             [112.1691]],

            [[112.1058],
             [112.1058],
             [112.1158],
             [112.1158]],

            [[112.1134],
             [112.0933],
             [112.0914],
             [112.0914]],

            ...,

            [[112.0910],
             [112.1344],
             [112.0904],
             [112.1300]],

            [[112.0894],
             [112.0893],
             [112.1621],
             [112.1621]],

            [[112.0891],
             [112.1029],
             [112.1102],
             [112.1593]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4716, 448.4432, 448.3895,  ..., 448.4459, 448.5029, 448.4614],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4716, 448.4432, 448.3895,  ..., 448.4459, 448.5029, 448.4614],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1255],
             [112.1541],
             [112.0863],
             [112.1732]],

            [[112.1463],
             [112.1181],
             [112.1865],
             [112.0893]],

            [[112.1284],
             [112.1284],
             [112.1873],
             [112.1873]],

            ...,

            [[112.1260],
             [112.2456],
             [112.2459],
             [112.1244]],

            [[112.0869],
             [112.0869],
             [112.0904],
             [112.0904]],

            [[112.1767],
             [112.1792],
             [112.1792],
             [112.1826]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5391, 448.5402, 448.6313,  ..., 448.7419, 448.3546, 448.7177],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5391, 448.5402, 448.6313,  ..., 448.7419, 448.3546, 448.7177],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2660],
             [112.2660],
             [112.2660],
             [112.2660]],

            [[112.0976],
             [112.0976],
             [112.1020],
             [112.1020]],

            [[112.1244],
             [112.0871],
             [112.1134],
             [112.1854]],

            ...,

            [[112.1587],
             [112.0858],
             [112.1848],
             [112.0862]],

            [[112.1072],
             [112.1761],
             [112.0935],
             [112.1819]],

            [[112.2576],
             [112.2655],
             [112.2656],
             [112.2570]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0639, 448.3993, 448.5104,  ..., 448.5154, 448.5587, 449.0456],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0639, 448.3993, 448.5104,  ..., 448.5154, 448.5587, 449.0456],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2805],
             [112.2805],
             [112.2799],
             [112.2799]],

            [[112.2805],
             [112.2805],
             [112.2804],
             [112.2804]],

            [[112.2681],
             [112.1561],
             [112.2267],
             [112.2267]],

            ...,

            [[112.0892],
             [112.0892],
             [112.1489],
             [112.1489]],

            [[112.2310],
             [112.2348],
             [112.0977],
             [112.0977]],

            [[112.2785],
             [112.2736],
             [112.2797],
             [112.2632]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1208, 449.1218, 448.8776,  ..., 448.4763, 448.6613, 449.0949],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1208, 449.1218, 448.8776,  ..., 448.4763, 448.6613, 449.0949],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1859],
             [112.1859],
             [112.1859],
             [112.1859]],

            [[112.1709],
             [112.0851],
             [112.1649],
             [112.0852]],

            [[112.1737],
             [112.0853],
             [112.2059],
             [112.0873]],

            ...,

            [[112.1543],
             [112.1707],
             [112.1679],
             [112.1334]],

            [[112.0858],
             [112.1494],
             [112.0936],
             [112.0936]],

            [[112.1432],
             [112.0953],
             [112.1950],
             [112.1318]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7436, 448.5061, 448.5523,  ..., 448.6263, 448.4225, 448.5653],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7436, 448.5061, 448.5523,  ..., 448.6263, 448.4225, 448.5653],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1956],
             [112.0840],
             [112.1838],
             [112.0924]],

            [[112.0797],
             [112.0797],
             [112.0801],
             [112.0801]],

            [[112.1624],
             [112.2503],
             [112.1590],
             [112.2555]],

            ...,

            [[112.0931],
             [112.0931],
             [112.0970],
             [112.0970]],

            [[112.1109],
             [112.0821],
             [112.0826],
             [112.0826]],

            [[112.0801],
             [112.1273],
             [112.1627],
             [112.1091]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5557, 448.3196, 448.8272,  ..., 448.3802, 448.3582, 448.4791],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5557, 448.3196, 448.8272,  ..., 448.3802, 448.3582, 448.4791],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0695],
             [112.1562],
             [112.0706],
             [112.1388]],

            [[112.0695],
             [112.0695],
             [112.0699],
             [112.0699]],

            [[112.1037],
             [112.1612],
             [112.0685],
             [112.0685]],

            ...,

            [[112.1475],
             [112.1026],
             [112.1790],
             [112.1790]],

            [[112.1209],
             [112.1758],
             [112.1195],
             [112.1195]],

            [[112.2392],
             [112.2445],
             [112.2460],
             [112.2393]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4350, 448.2789, 448.4019,  ..., 448.6082, 448.5356, 448.9691],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4350, 448.2789, 448.4019,  ..., 448.6082, 448.5356, 448.9691],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1125],
             [112.2193],
             [112.2189],
             [112.1081]],

            [[112.0583],
             [112.1240],
             [112.0563],
             [112.1387]],

            [[112.2286],
             [112.1671],
             [112.1688],
             [112.2329]],

            ...,

            [[112.1071],
             [112.1578],
             [112.1131],
             [112.0516]],

            [[112.0573],
             [112.0574],
             [112.0820],
             [112.0742]],

            [[112.1132],
             [112.0614],
             [112.0892],
             [112.1624]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6588, 448.3774, 448.7974,  ..., 448.4297, 448.2709, 448.4261],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6588, 448.3774, 448.7974,  ..., 448.4297, 448.2709, 448.4261],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2135],
             [112.2151],
             [112.2151],
             [112.2137]],

            [[112.1231],
             [112.1231],
             [112.1486],
             [112.1486]],

            [[112.1386],
             [112.0835],
             [112.1430],
             [112.1430]],

            ...,

            [[112.0391],
             [112.0391],
             [112.0720],
             [112.0720]],

            [[112.0364],
             [112.0364],
             [112.1145],
             [112.1145]],

            [[112.0368],
             [112.0368],
             [112.1152],
             [112.1152]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8574, 448.5433, 448.5081,  ..., 448.2222, 448.3018, 448.3039],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8574, 448.5433, 448.5081,  ..., 448.2222, 448.3018, 448.3039],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0219],
             [112.0221],
             [112.0623],
             [112.1069]],

            [[112.1248],
             [112.1248],
             [112.1265],
             [112.1265]],

            [[112.1867],
             [112.1867],
             [112.0777],
             [112.0777]],

            ...,

            [[112.1348],
             [112.1066],
             [112.0961],
             [112.0867]],

            [[112.0836],
             [112.0249],
             [112.0971],
             [112.0218]],

            [[112.0317],
             [112.0513],
             [112.0235],
             [112.0633]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2132, 448.5027, 448.5289,  ..., 448.4242, 448.2274, 448.1699],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2132, 448.5027, 448.5289,  ..., 448.4242, 448.2274, 448.1699],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0538],
             [112.1054],
             [112.0132],
             [112.0115]],

            [[112.1907],
             [112.1907],
             [112.1907],
             [112.1907]],

            [[112.0124],
             [112.0163],
             [112.0130],
             [112.0200]],

            ...,

            [[112.0140],
             [112.0140],
             [112.1007],
             [112.1007]],

            [[112.0868],
             [112.0235],
             [112.1037],
             [112.0163]],

            [[112.0555],
             [112.0555],
             [112.1236],
             [112.0133]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1838, 448.7627, 448.0618,  ..., 448.2293, 448.2303, 448.2479],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1838, 448.7627, 448.0618,  ..., 448.2293, 448.2303, 448.2479],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1835],
             [112.1266],
             [112.1838],
             [112.1280]],

            [[112.0880],
             [112.0880],
             [112.1250],
             [112.1250]],

            [[112.0837],
             [112.0632],
             [112.1221],
             [112.1221]],

            ...,

            [[112.0980],
             [112.0980],
             [112.1054],
             [112.1054]],

            [[112.1819],
             [112.1085],
             [112.1479],
             [112.1479]],

            [[112.0720],
             [112.0214],
             [112.0824],
             [112.1237]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6218, 448.4259, 448.3911,  ..., 448.4067, 448.5863, 448.2996],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6218, 448.4259, 448.3911,  ..., 448.4067, 448.5863, 448.2996],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0186],
             [112.0186],
             [112.0610],
             [112.0537]],

            [[112.0238],
             [112.0543],
             [112.1087],
             [112.1087]],

            [[112.0759],
             [112.0154],
             [112.0146],
             [112.0635]],

            ...,

            [[112.8289],
             [112.8290],
             [112.8485],
             [112.8441]],

            [[112.0176],
             [112.0479],
             [112.0498],
             [112.0196]],

            [[112.1014],
             [112.1102],
             [112.1111],
             [112.1124]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1518, 448.2955, 448.1694,  ..., 451.3505, 448.1349, 448.4351],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1518, 448.2955, 448.1694,  ..., 451.3505, 448.1349, 448.4351],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0509],
             [112.1446],
             [112.1264],
             [112.0235]],

            [[112.0332],
             [112.0959],
             [112.1172],
             [112.0351]],

            [[112.0211],
             [112.0127],
             [112.0161],
             [112.0339]],

            ...,

            [[112.0609],
             [112.1174],
             [112.1041],
             [112.1041]],

            [[112.1124],
             [112.1124],
             [112.1185],
             [112.1185]],

            [[112.0332],
             [112.0971],
             [112.0149],
             [112.0186]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3454, 448.2814, 448.0837,  ..., 448.3865, 448.4620, 448.1637],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3454, 448.2814, 448.0837,  ..., 448.3865, 448.4620, 448.1637],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1670],
             [112.0905],
             [112.1486],
             [112.1486]],

            [[112.1159],
             [112.0058],
             [112.0153],
             [112.0153]],

            [[112.8272],
             [112.8272],
             [112.8272],
             [112.8272]],

            ...,

            [[112.0978],
             [112.0978],
             [112.1051],
             [112.1051]],

            [[112.0136],
             [112.0136],
             [112.0986],
             [112.0986]],

            [[112.0168],
             [112.0168],
             [112.0227],
             [112.0227]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5547, 448.1524, 451.3089,  ..., 448.4058, 448.2243, 448.0788],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5547, 448.1524, 451.3089,  ..., 448.4058, 448.2243, 448.0788],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9919],
             [112.0776],
             [112.0120],
             [112.0120]],

            [[112.0639],
             [112.0220],
             [112.0952],
             [112.0952]],

            [[111.9879],
             [112.0733],
             [111.9981],
             [112.0911]],

            ...,

            [[112.0520],
             [111.9892],
             [112.0125],
             [112.0003]],

            [[111.9893],
             [111.9986],
             [111.9884],
             [112.0068]],

            [[112.0348],
             [112.0963],
             [111.9881],
             [112.0024]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0934, 448.2762, 448.1505,  ..., 448.0541, 447.9833, 448.1216],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0934, 448.2762, 448.1505,  ..., 448.0541, 447.9833, 448.1216],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9843],
             [111.9867],
             [111.9744],
             [111.9744]],

            [[111.9784],
             [111.9784],
             [111.9838],
             [111.9838]],

            [[112.0688],
             [112.0688],
             [112.0832],
             [112.0832]],

            ...,

            [[111.9755],
             [111.9755],
             [112.0622],
             [112.0622]],

            [[111.9771],
             [112.0697],
             [111.9756],
             [112.0905]],

            [[112.0821],
             [112.0647],
             [112.0302],
             [111.9905]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9198, 447.9243, 448.3040,  ..., 448.0756, 448.1129, 448.1675],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9198, 447.9243, 448.3040,  ..., 448.0756, 448.1129, 448.1675],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9958],
             [111.9710],
             [111.9718],
             [111.9941]],

            [[112.1222],
             [112.1225],
             [112.0445],
             [112.0445]],

            [[111.9761],
             [111.9761],
             [111.9929],
             [111.9929]],

            ...,

            [[111.9685],
             [112.0417],
             [111.9701],
             [112.0262]],

            [[112.1230],
             [112.0593],
             [112.0594],
             [112.1276]],

            [[112.1273],
             [112.1273],
             [112.1273],
             [112.1276]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9328, 448.3337, 447.9379,  ..., 448.0065, 448.3693, 448.5095],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9328, 448.3337, 447.9379,  ..., 448.0065, 448.3693, 448.5095],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9947e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1135],
             [112.0314],
             [112.0315],
             [112.1208]],

            [[112.0708],
             [112.0708],
             [112.0533],
             [112.0533]],

            [[111.9699],
             [112.0015],
             [111.9680],
             [112.0374]],

            ...,

            [[112.0661],
             [111.9721],
             [112.0524],
             [111.9873]],

            [[112.0542],
             [111.9675],
             [111.9893],
             [111.9893]],

            [[112.0541],
             [112.1163],
             [112.1174],
             [112.0612]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2971, 448.2483, 447.9769,  ..., 448.0779, 448.0004, 448.3489],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2971, 448.2483, 447.9769,  ..., 448.0779, 448.0004, 448.3489],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9656],
             [112.0163],
             [112.0179],
             [112.0604]],

            [[111.9830],
             [112.0618],
             [111.9687],
             [112.0008]],

            [[112.0968],
             [111.9913],
             [112.0921],
             [112.0034]],

            ...,

            [[111.9672],
             [112.0392],
             [111.9671],
             [112.0372]],

            [[111.9685],
             [112.0541],
             [112.0312],
             [112.0645]],

            [[112.0073],
             [112.0073],
             [112.0227],
             [112.0227]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0601, 448.0143, 448.1837,  ..., 448.0107, 448.1183, 448.0599],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0601, 448.0143, 448.1837,  ..., 448.0107, 448.1183, 448.0599],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1205],
             [112.1205],
             [112.1190],
             [112.1190]],

            [[112.0425],
             [112.0425],
             [112.0675],
             [112.0675]],

            [[112.0616],
             [111.9690],
             [111.9705],
             [111.9705]],

            ...,

            [[112.1205],
             [112.1205],
             [112.1203],
             [112.1203]],

            [[112.0811],
             [112.0811],
             [112.0857],
             [112.0857]],

            [[112.0290],
             [112.0395],
             [112.0710],
             [112.0710]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4791, 448.2202, 447.9716, 447.9940, 448.2684, 448.0454, 448.1922,
            448.0205, 448.0409, 448.2509, 448.2199, 448.0200, 448.0869, 447.9033,
            448.1754, 448.0717, 448.0871, 448.0751, 450.9443, 448.0562, 448.2596,
            448.1175, 448.1104, 448.0836, 448.2285, 447.9162, 448.4831, 448.0479,
            448.0871, 448.1064, 448.0624, 447.8949, 447.9844, 447.9191, 447.9182,
            448.2214, 448.0933, 448.0688, 447.9082, 448.3092, 448.0587, 448.1191,
            447.9264, 448.0421, 448.2598, 448.1107, 448.1754, 448.0585, 448.1342,
            447.9030, 448.3170, 447.8994, 447.8980, 448.0321, 447.9250, 447.9902,
            448.0575, 448.0312, 448.4811, 447.9272, 448.0643, 448.2346, 448.1289,
            448.2093, 447.9841, 447.9753, 448.4770, 448.0574, 448.0800, 447.8867,
            448.0164, 448.2699, 447.9288, 447.9397, 448.2203, 448.1620, 448.0490,
            448.3255, 448.0818, 447.9367, 448.0004, 448.4031, 448.0215, 448.0562,
            448.0594, 447.9178, 447.8949, 447.9372, 448.4846, 447.9547, 448.0605,
            447.9668, 447.9097, 448.2277, 451.1146, 448.0595, 448.0111, 448.0322,
            448.2605, 447.9978, 448.0644, 448.1973, 448.0230, 448.2157, 448.0806,
            447.9885, 448.2173, 447.9089, 447.9077, 448.2605, 448.0111, 448.1896,
            448.1869, 447.8693, 448.4528, 447.9240, 447.9272, 447.9708, 447.9356,
            448.1767, 448.1390, 448.0942, 448.0342, 448.4805, 448.0391, 448.1030,
            448.3571, 448.1984, 448.1318, 448.0732, 448.4818, 447.8837, 448.1518,
            448.2412, 448.1346, 448.0054, 448.0850, 448.0586, 447.9528, 448.0631,
            448.0199, 447.9116, 448.0503, 448.4590, 448.1169, 447.9226, 447.9265,
            448.1945, 448.0746, 447.9222, 448.0462, 448.0868, 448.0575, 448.1344,
            447.9390, 448.0703, 448.0745, 448.4716, 448.0583, 448.0717, 448.1029,
            451.2040, 448.4682, 448.0044, 448.0347, 448.0132, 448.0810, 448.0974,
            447.9431, 447.9306, 448.4830, 447.8696, 448.2552, 448.1061, 448.0493,
            448.4818, 448.4031, 448.0258, 448.0764, 447.8723, 448.1916, 448.4584,
            448.0718, 448.1552, 447.9606, 448.3206, 448.3377, 447.9819, 447.9142,
            448.1059, 447.8729, 447.9955, 448.4639, 447.9138, 448.1980, 448.1935,
            448.1064, 448.3992, 448.2437, 448.4552, 448.1529, 448.2513, 448.3273,
            448.0001, 447.9168, 448.1729, 447.9066, 448.0279, 448.2697, 448.0304,
            447.8685, 448.4801, 448.1124, 447.9895, 447.9147, 447.9583, 447.8905,
            447.9875, 448.0421, 448.4804, 448.0663, 447.9742, 451.2052, 448.0418,
            448.0466, 448.0691, 447.9980, 448.4821, 448.4827, 448.0723, 448.0583,
            448.1683, 448.0544, 448.0797, 448.0203, 448.0023, 448.1715, 448.0000,
            448.2217, 447.9837, 448.5842, 447.9780, 448.1602, 448.1393, 448.0792,
            448.1538, 448.0916, 448.0033, 447.9163, 447.9582, 447.9225, 448.0257,
            447.9136, 447.9413, 448.0005, 448.0698, 448.0313, 448.0861, 448.2533,
            448.4286, 447.9871, 447.9686, 448.1166, 448.1694, 448.0434, 447.8662,
            448.4334, 448.0533, 448.0742, 448.0396, 447.9706, 448.2572, 448.1194,
            447.9692, 448.0264, 448.1516, 447.9303, 448.2176, 448.0951, 448.0287,
            448.4812, 448.0697, 448.1383, 448.0338, 448.0519, 448.3222, 448.4834,
            448.1263, 448.1528, 448.0800, 448.4829, 448.1838, 448.1763, 448.0637,
            448.2632, 448.0385, 448.0195, 448.1914, 448.3427, 448.0219, 448.0862,
            448.0210, 447.9741, 447.9989, 448.0138, 448.0406, 448.0593, 448.0706,
            447.9619, 448.2380, 448.2764, 448.1451, 448.0457, 448.0132, 448.0722,
            448.4826, 448.0732, 447.9534, 448.0277, 448.0095, 448.1422, 448.4782,
            447.9450, 447.9829, 448.0237, 447.9366, 448.4811, 448.0226, 448.0410,
            448.1473, 447.9005, 448.0593, 448.0131, 448.2272, 448.4830, 448.2010,
            447.8957, 448.0336, 447.9102, 448.1337, 448.0140, 448.2530, 448.0383,
            448.4766, 448.1057, 448.0904, 448.2248, 447.9158, 447.9490, 448.0329,
            448.1606, 448.0029, 447.9426, 448.2543, 448.0701, 448.0499, 448.0585,
            448.0511, 447.8987, 448.2668, 447.9115, 448.0710, 447.9009, 448.0378,
            448.4814, 448.0434, 448.2534, 448.0168, 448.2065, 448.1405, 448.1881,
            448.1233, 447.9481, 448.0389, 448.1563, 447.8754, 448.1697, 447.8858,
            448.4818, 448.0259, 447.9683, 448.0699, 447.9046, 448.2075, 448.3035,
            448.4741, 447.8711, 448.1732, 447.9172, 448.4814, 448.0527, 448.0984,
            448.1089, 448.4518, 448.1047, 447.9122, 448.1843, 448.1100, 448.1627,
            448.2218, 448.2184, 448.0443, 448.4028, 448.2584, 447.9711, 448.1566,
            448.2212, 447.9395, 448.0531, 447.9166, 448.1115, 448.0887, 448.3242,
            447.9261, 448.3764, 447.8850, 448.0797, 448.2414, 448.3982, 448.1112,
            448.0162, 448.0529, 447.9785, 447.9158, 447.9439, 448.0148, 448.1524,
            447.9323, 448.0252, 448.1490, 448.3669, 447.9073, 448.0143, 448.0846,
            448.0115, 448.4634, 448.0547, 447.9254, 448.2397, 447.9962, 448.1681,
            447.9778, 447.9453, 447.9268, 448.0495, 448.4252, 448.0481, 448.1074,
            447.8868, 448.0442, 448.0448, 447.9191, 448.1199, 448.0080, 448.0973,
            448.0554, 448.1383, 448.4827, 447.9218, 448.2398, 448.0901, 448.0369,
            448.1288, 447.9233, 448.4779, 448.0684, 448.2160, 447.9243, 448.0754,
            448.0155, 447.9084, 448.2296, 448.2239, 448.0150, 448.1623, 448.4743,
            448.2105, 448.1296, 447.9517, 447.8932, 448.1679, 448.1371, 447.9993,
            447.8949, 448.0764, 447.9148, 448.0710, 447.9561, 448.4830, 447.9938,
            448.1199, 448.4706, 448.4830, 447.9158, 448.0630, 448.0607, 448.4814,
            447.9742, 447.9480, 448.1172, 448.2393, 448.4822, 448.0295, 448.2459,
            448.1266, 447.9279, 447.8949, 447.9584, 448.2122, 448.1018, 448.0000,
            447.9796, 448.2015, 448.0991, 447.8926, 448.0103, 448.0257, 448.2538,
            448.4452, 448.0109, 448.0801, 447.9704, 448.4033, 448.0586, 448.0498,
            448.1079, 448.0185, 448.2083, 448.1244, 448.0391, 448.0554, 448.1009,
            448.0344, 448.4253, 448.0866, 448.1624, 447.9237, 448.4824, 447.9107,
            448.2111, 448.0586, 448.1649, 448.2062, 448.0468, 448.2236, 448.1093,
            447.8924, 448.4611, 447.8892, 448.2210, 448.0418, 448.3917, 448.2029,
            448.0949, 448.1356, 448.2330, 448.1077, 448.1438, 447.9260, 448.0208,
            447.8817, 448.1707, 448.1902, 448.0644, 448.2566, 448.0254, 447.9487,
            447.9317, 448.2554, 448.1429, 448.0492, 448.2068, 447.9886, 447.8970,
            448.1208, 447.9207, 447.9568, 450.9738, 447.9398, 448.0113, 447.9214,
            448.2514, 447.8778, 447.9741, 448.0791, 447.8734, 448.1444, 448.0059,
            448.1555, 447.9134, 448.1369, 447.9907, 448.1302, 448.0512, 448.0495,
            448.4280, 448.1154, 447.9039, 448.1755, 447.9283, 448.0198, 448.4238,
            448.2188, 448.4822, 448.1685, 448.0478, 448.0882, 448.1426, 448.2276,
            448.0563, 448.0403, 448.3806, 447.9381, 448.4668, 447.9545, 448.0583,
            448.3772, 448.0563, 448.0572, 448.0409, 448.1964, 448.0722, 447.9362,
            447.9697, 447.9070, 448.1432, 448.0674, 448.1733, 448.0791, 448.0939,
            448.2210, 447.9216, 448.1014, 448.2311, 448.0111, 448.1297, 448.2402,
            448.4649, 448.4822, 448.2088, 448.0495, 448.1105, 448.1429, 448.0132,
            448.0409, 447.8914, 448.0846, 448.0707, 448.0508, 448.2428, 448.1105,
            448.1497, 448.3247, 448.2188, 448.2386, 448.0464, 448.0780, 448.0207,
            448.4734, 448.3112, 448.1847, 447.9901, 448.1520, 448.0565, 447.8967,
            448.4765, 448.4326, 448.4812, 447.8948, 447.9531, 447.9947, 448.0856,
            447.9437, 448.2545, 448.0659, 448.2097, 448.3876, 448.0941, 448.1219,
            448.4812, 447.9134, 448.2383, 448.3336, 448.4830, 448.0517, 448.0604,
            448.0549, 447.9034, 448.0474, 448.1213, 447.8991, 448.1971, 448.4808,
            448.0464, 447.9611, 447.9691, 448.1209, 447.9597, 447.8946, 447.9201,
            447.9775, 448.4822, 447.9716, 447.9974, 448.1736, 448.4472, 448.3685,
            447.9089, 448.0685, 448.0079, 448.4826, 448.4509, 447.9043, 448.2126,
            448.0530, 448.0623, 448.1895, 447.9179, 448.4314, 448.3203, 448.0587,
            448.4252, 447.9034, 448.1787, 448.2007, 448.0534, 448.4826, 448.4797,
            448.0492, 448.0771, 448.0434, 447.9114, 447.9912, 447.9283, 448.2047,
            447.9777, 448.0434, 448.2073, 447.9734, 448.1625, 448.1513, 448.2434,
            447.9772, 448.4240, 447.9788, 448.0028, 448.2438, 448.2582, 448.0508,
            448.2206, 448.4394, 447.8914, 448.1539, 448.1787, 447.9855, 448.0442,
            448.0885, 451.2064, 448.0558, 448.1635, 448.0811, 448.0000, 448.2181,
            448.1965, 448.0523, 448.0719, 447.9121, 448.2616, 448.2690, 447.9746,
            448.2245, 447.9067, 448.0446, 448.4769, 448.1773, 448.0530, 448.0828,
            448.1990, 448.0558, 447.8894, 447.9257, 447.9962, 447.9796, 448.1451,
            448.1266, 447.9198, 448.4822, 448.2321, 448.0439, 447.9613, 448.1195,
            448.2461, 448.0376, 448.0566, 448.1053, 448.4830, 447.8855, 448.1229,
            447.9317, 448.0268, 447.9192, 448.0602, 447.9479, 448.0579, 448.1460,
            448.0936, 448.2006, 448.0583, 447.9285, 448.0261, 448.4213, 447.9095,
            448.0224, 448.0974, 448.1558, 448.0353, 448.0688, 448.0609, 448.0164,
            447.9213, 448.4382, 448.2309, 448.4823, 448.1651, 448.0527, 448.4813,
            448.0020, 447.9601, 448.0299, 447.9549, 447.9205, 447.8952, 448.0823,
            448.0840, 448.4238, 448.1044, 448.4806, 447.9605, 448.3678, 447.8842,
            447.9446, 448.0260, 447.9428, 447.9092, 448.0892, 448.0315, 448.2249,
            448.0699, 447.9963, 448.0344, 447.9914, 448.1212, 448.0204, 447.9612,
            448.2365, 448.0811, 448.0717, 448.2206, 448.0576, 447.8664, 447.8873,
            448.2505, 448.1485, 447.9705, 448.0105, 448.0268, 448.4543, 448.2536,
            448.1987, 447.9810, 447.9890, 448.0607, 448.0002, 447.9366, 448.1946,
            448.0053, 448.0198, 448.3640, 448.0866, 447.8690, 448.1791, 448.4824,
            447.8775, 447.9758, 448.2589, 448.0580, 447.9477, 448.4675, 448.1279,
            448.0368, 448.0698, 448.0657, 447.9218, 448.0958, 448.1147, 448.0360,
            447.9741, 447.8903, 447.9217, 448.4806, 448.2038, 448.1159, 448.0027,
            448.0784, 448.3790, 448.3536, 448.0305, 448.0019, 448.1538, 448.0565,
            448.0644, 448.4755, 448.4829, 448.1781, 448.1229, 447.9493, 448.1953,
            447.9898, 448.3291, 448.1697, 447.9952, 448.3961, 447.9218, 448.4817,
            448.3336, 448.2106], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4791, 448.2202, 447.9716, 447.9940, 448.2684, 448.0454, 448.1922,
        448.0205, 448.0409, 448.2509, 448.2199, 448.0200, 448.0869, 447.9033,
        448.1754, 448.0717, 448.0871, 448.0751, 450.9443, 448.0562, 448.2596,
        448.1175, 448.1104, 448.0836, 448.2285, 447.9162, 448.4831, 448.0479,
        448.0871, 448.1064, 448.0624, 447.8949, 447.9844, 447.9191, 447.9182,
        448.2214, 448.0933, 448.0688, 447.9082, 448.3092, 448.0587, 448.1191,
        447.9264, 448.0421, 448.2598, 448.1107, 448.1754, 448.0585, 448.1342,
        447.9030, 448.3170, 447.8994, 447.8980, 448.0321, 447.9250, 447.9902,
        448.0575, 448.0312, 448.4811, 447.9272, 448.0643, 448.2346, 448.1289,
        448.2093, 447.9841, 447.9753, 448.4770, 448.0574, 448.0800, 447.8867,
        448.0164, 448.2699, 447.9288, 447.9397, 448.2203, 448.1620, 448.0490,
        448.3255, 448.0818, 447.9367, 448.0004, 448.4031, 448.0215, 448.0562,
        448.0594, 447.9178, 447.8949, 447.9372, 448.4846, 447.9547, 448.0605,
        447.9668, 447.9097, 448.2277, 451.1146, 448.0595, 448.0111, 448.0322,
        448.2605, 447.9978, 448.0644, 448.1973, 448.0230, 448.2157, 448.0806,
        447.9885, 448.2173, 447.9089, 447.9077, 448.2605, 448.0111, 448.1896,
        448.1869, 447.8693, 448.4528, 447.9240, 447.9272, 447.9708, 447.9356,
        448.1767, 448.1390, 448.0942, 448.0342, 448.4805, 448.0391, 448.1030,
        448.3571, 448.1984, 448.1318, 448.0732, 448.4818, 447.8837, 448.1518,
        448.2412, 448.1346, 448.0054, 448.0850, 448.0586, 447.9528, 448.0631,
        448.0199, 447.9116, 448.0503, 448.4590, 448.1169, 447.9226, 447.9265,
        448.1945, 448.0746, 447.9222, 448.0462, 448.0868, 448.0575, 448.1344,
        447.9390, 448.0703, 448.0745, 448.4716, 448.0583, 448.0717, 448.1029,
        451.2040, 448.4682, 448.0044, 448.0347, 448.0132, 448.0810, 448.0974,
        447.9431, 447.9306, 448.4830, 447.8696, 448.2552, 448.1061, 448.0493,
        448.4818, 448.4031, 448.0258, 448.0764, 447.8723, 448.1916, 448.4584,
        448.0718, 448.1552, 447.9606, 448.3206, 448.3377, 447.9819, 447.9142,
        448.1059, 447.8729, 447.9955, 448.4639, 447.9138, 448.1980, 448.1935,
        448.1064, 448.3992, 448.2437, 448.4552, 448.1529, 448.2513, 448.3273,
        448.0001, 447.9168, 448.1729, 447.9066, 448.0279, 448.2697, 448.0304,
        447.8685, 448.4801, 448.1124, 447.9895, 447.9147, 447.9583, 447.8905,
        447.9875, 448.0421, 448.4804, 448.0663, 447.9742, 451.2052, 448.0418,
        448.0466, 448.0691, 447.9980, 448.4821, 448.4827, 448.0723, 448.0583,
        448.1683, 448.0544, 448.0797, 448.0203, 448.0023, 448.1715, 448.0000,
        448.2217, 447.9837, 448.5842, 447.9780, 448.1602, 448.1393, 448.0792,
        448.1538, 448.0916, 448.0033, 447.9163, 447.9582, 447.9225, 448.0257,
        447.9136, 447.9413, 448.0005, 448.0698, 448.0313, 448.0861, 448.2533,
        448.4286, 447.9871, 447.9686, 448.1166, 448.1694, 448.0434, 447.8662,
        448.4334, 448.0533, 448.0742, 448.0396, 447.9706, 448.2572, 448.1194,
        447.9692, 448.0264, 448.1516, 447.9303, 448.2176, 448.0951, 448.0287,
        448.4812, 448.0697, 448.1383, 448.0338, 448.0519, 448.3222, 448.4834,
        448.1263, 448.1528, 448.0800, 448.4829, 448.1838, 448.1763, 448.0637,
        448.2632, 448.0385, 448.0195, 448.1914, 448.3427, 448.0219, 448.0862,
        448.0210, 447.9741, 447.9989, 448.0138, 448.0406, 448.0593, 448.0706,
        447.9619, 448.2380, 448.2764, 448.1451, 448.0457, 448.0132, 448.0722,
        448.4826, 448.0732, 447.9534, 448.0277, 448.0095, 448.1422, 448.4782,
        447.9450, 447.9829, 448.0237, 447.9366, 448.4811, 448.0226, 448.0410,
        448.1473, 447.9005, 448.0593, 448.0131, 448.2272, 448.4830, 448.2010,
        447.8957, 448.0336, 447.9102, 448.1337, 448.0140, 448.2530, 448.0383,
        448.4766, 448.1057, 448.0904, 448.2248, 447.9158, 447.9490, 448.0329,
        448.1606, 448.0029, 447.9426, 448.2543, 448.0701, 448.0499, 448.0585,
        448.0511, 447.8987, 448.2668, 447.9115, 448.0710, 447.9009, 448.0378,
        448.4814, 448.0434, 448.2534, 448.0168, 448.2065, 448.1405, 448.1881,
        448.1233, 447.9481, 448.0389, 448.1563, 447.8754, 448.1697, 447.8858,
        448.4818, 448.0259, 447.9683, 448.0699, 447.9046, 448.2075, 448.3035,
        448.4741, 447.8711, 448.1732, 447.9172, 448.4814, 448.0527, 448.0984,
        448.1089, 448.4518, 448.1047, 447.9122, 448.1843, 448.1100, 448.1627,
        448.2218, 448.2184, 448.0443, 448.4028, 448.2584, 447.9711, 448.1566,
        448.2212, 447.9395, 448.0531, 447.9166, 448.1115, 448.0887, 448.3242,
        447.9261, 448.3764, 447.8850, 448.0797, 448.2414, 448.3982, 448.1112,
        448.0162, 448.0529, 447.9785, 447.9158, 447.9439, 448.0148, 448.1524,
        447.9323, 448.0252, 448.1490, 448.3669, 447.9073, 448.0143, 448.0846,
        448.0115, 448.4634, 448.0547, 447.9254, 448.2397, 447.9962, 448.1681,
        447.9778, 447.9453, 447.9268, 448.0495, 448.4252, 448.0481, 448.1074,
        447.8868, 448.0442, 448.0448, 447.9191, 448.1199, 448.0080, 448.0973,
        448.0554, 448.1383, 448.4827, 447.9218, 448.2398, 448.0901, 448.0369,
        448.1288, 447.9233, 448.4779, 448.0684, 448.2160, 447.9243, 448.0754,
        448.0155, 447.9084, 448.2296, 448.2239, 448.0150, 448.1623, 448.4743,
        448.2105, 448.1296, 447.9517, 447.8932, 448.1679, 448.1371, 447.9993,
        447.8949, 448.0764, 447.9148, 448.0710, 447.9561, 448.4830, 447.9938,
        448.1199, 448.4706, 448.4830, 447.9158, 448.0630, 448.0607, 448.4814,
        447.9742, 447.9480, 448.1172, 448.2393, 448.4822, 448.0295, 448.2459,
        448.1266, 447.9279, 447.8949, 447.9584, 448.2122, 448.1018, 448.0000,
        447.9796, 448.2015, 448.0991, 447.8926, 448.0103, 448.0257, 448.2538,
        448.4452, 448.0109, 448.0801, 447.9704, 448.4033, 448.0586, 448.0498,
        448.1079, 448.0185, 448.2083, 448.1244, 448.0391, 448.0554, 448.1009,
        448.0344, 448.4253, 448.0866, 448.1624, 447.9237, 448.4824, 447.9107,
        448.2111, 448.0586, 448.1649, 448.2062, 448.0468, 448.2236, 448.1093,
        447.8924, 448.4611, 447.8892, 448.2210, 448.0418, 448.3917, 448.2029,
        448.0949, 448.1356, 448.2330, 448.1077, 448.1438, 447.9260, 448.0208,
        447.8817, 448.1707, 448.1902, 448.0644, 448.2566, 448.0254, 447.9487,
        447.9317, 448.2554, 448.1429, 448.0492, 448.2068, 447.9886, 447.8970,
        448.1208, 447.9207, 447.9568, 450.9738, 447.9398, 448.0113, 447.9214,
        448.2514, 447.8778, 447.9741, 448.0791, 447.8734, 448.1444, 448.0059,
        448.1555, 447.9134, 448.1369, 447.9907, 448.1302, 448.0512, 448.0495,
        448.4280, 448.1154, 447.9039, 448.1755, 447.9283, 448.0198, 448.4238,
        448.2188, 448.4822, 448.1685, 448.0478, 448.0882, 448.1426, 448.2276,
        448.0563, 448.0403, 448.3806, 447.9381, 448.4668, 447.9545, 448.0583,
        448.3772, 448.0563, 448.0572, 448.0409, 448.1964, 448.0722, 447.9362,
        447.9697, 447.9070, 448.1432, 448.0674, 448.1733, 448.0791, 448.0939,
        448.2210, 447.9216, 448.1014, 448.2311, 448.0111, 448.1297, 448.2402,
        448.4649, 448.4822, 448.2088, 448.0495, 448.1105, 448.1429, 448.0132,
        448.0409, 447.8914, 448.0846, 448.0707, 448.0508, 448.2428, 448.1105,
        448.1497, 448.3247, 448.2188, 448.2386, 448.0464, 448.0780, 448.0207,
        448.4734, 448.3112, 448.1847, 447.9901, 448.1520, 448.0565, 447.8967,
        448.4765, 448.4326, 448.4812, 447.8948, 447.9531, 447.9947, 448.0856,
        447.9437, 448.2545, 448.0659, 448.2097, 448.3876, 448.0941, 448.1219,
        448.4812, 447.9134, 448.2383, 448.3336, 448.4830, 448.0517, 448.0604,
        448.0549, 447.9034, 448.0474, 448.1213, 447.8991, 448.1971, 448.4808,
        448.0464, 447.9611, 447.9691, 448.1209, 447.9597, 447.8946, 447.9201,
        447.9775, 448.4822, 447.9716, 447.9974, 448.1736, 448.4472, 448.3685,
        447.9089, 448.0685, 448.0079, 448.4826, 448.4509, 447.9043, 448.2126,
        448.0530, 448.0623, 448.1895, 447.9179, 448.4314, 448.3203, 448.0587,
        448.4252, 447.9034, 448.1787, 448.2007, 448.0534, 448.4826, 448.4797,
        448.0492, 448.0771, 448.0434, 447.9114, 447.9912, 447.9283, 448.2047,
        447.9777, 448.0434, 448.2073, 447.9734, 448.1625, 448.1513, 448.2434,
        447.9772, 448.4240, 447.9788, 448.0028, 448.2438, 448.2582, 448.0508,
        448.2206, 448.4394, 447.8914, 448.1539, 448.1787, 447.9855, 448.0442,
        448.0885, 451.2064, 448.0558, 448.1635, 448.0811, 448.0000, 448.2181,
        448.1965, 448.0523, 448.0719, 447.9121, 448.2616, 448.2690, 447.9746,
        448.2245, 447.9067, 448.0446, 448.4769, 448.1773, 448.0530, 448.0828,
        448.1990, 448.0558, 447.8894, 447.9257, 447.9962, 447.9796, 448.1451,
        448.1266, 447.9198, 448.4822, 448.2321, 448.0439, 447.9613, 448.1195,
        448.2461, 448.0376, 448.0566, 448.1053, 448.4830, 447.8855, 448.1229,
        447.9317, 448.0268, 447.9192, 448.0602, 447.9479, 448.0579, 448.1460,
        448.0936, 448.2006, 448.0583, 447.9285, 448.0261, 448.4213, 447.9095,
        448.0224, 448.0974, 448.1558, 448.0353, 448.0688, 448.0609, 448.0164,
        447.9213, 448.4382, 448.2309, 448.4823, 448.1651, 448.0527, 448.4813,
        448.0020, 447.9601, 448.0299, 447.9549, 447.9205, 447.8952, 448.0823,
        448.0840, 448.4238, 448.1044, 448.4806, 447.9605, 448.3678, 447.8842,
        447.9446, 448.0260, 447.9428, 447.9092, 448.0892, 448.0315, 448.2249,
        448.0699, 447.9963, 448.0344, 447.9914, 448.1212, 448.0204, 447.9612,
        448.2365, 448.0811, 448.0717, 448.2206, 448.0576, 447.8664, 447.8873,
        448.2505, 448.1485, 447.9705, 448.0105, 448.0268, 448.4543, 448.2536,
        448.1987, 447.9810, 447.9890, 448.0607, 448.0002, 447.9366, 448.1946,
        448.0053, 448.0198, 448.3640, 448.0866, 447.8690, 448.1791, 448.4824,
        447.8775, 447.9758, 448.2589, 448.0580, 447.9477, 448.4675, 448.1279,
        448.0368, 448.0698, 448.0657, 447.9218, 448.0958, 448.1147, 448.0360,
        447.9741, 447.8903, 447.9217, 448.4806, 448.2038, 448.1159, 448.0027,
        448.0784, 448.3790, 448.3536, 448.0305, 448.0019, 448.1538, 448.0565,
        448.0644, 448.4755, 448.4829, 448.1781, 448.1229, 447.9493, 448.1953,
        447.9898, 448.3291, 448.1697, 447.9952, 448.3961, 447.9218, 448.4817,
        448.3336, 448.2106], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([410.4463], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1106],
             [112.0165],
             [112.0166],
             [112.1208]],

            [[112.0287],
             [111.9669],
             [111.9685],
             [112.0431]],

            [[111.9727],
             [112.0662],
             [112.0022],
             [112.0022]],

            ...,

            [[112.0274],
             [111.9773],
             [112.0113],
             [112.0703]],

            [[112.0606],
             [111.9673],
             [112.0606],
             [111.9673]],

            [[112.1111],
             [112.0185],
             [112.0186],
             [112.1208]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2645, 448.0073, 448.0434,  ..., 448.0862, 448.0558, 448.2690],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2645, 448.0073, 448.0434,  ..., 448.0862, 448.0558, 448.2690],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0218],
             [111.9773],
             [112.0329],
             [112.0756]],

            [[112.0079],
             [112.0079],
             [112.0079],
             [112.0079]],

            [[112.1247],
             [112.1247],
             [112.1248],
             [112.1248]],

            ...,

            [[112.1246],
             [112.1247],
             [112.1247],
             [112.1248]],

            [[112.1248],
             [112.1248],
             [112.1248],
             [112.1248]],

            [[112.1230],
             [112.0884],
             [112.1039],
             [112.1039]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1076, 448.0314, 448.4990,  ..., 448.4988, 448.4993, 448.4192],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1076, 448.0314, 448.4990,  ..., 448.4988, 448.4993, 448.4192],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0220],
             [112.0772],
             [111.9805],
             [112.0176]],

            [[111.9895],
             [111.9792],
             [112.0491],
             [111.9777]],

            [[112.1207],
             [112.1198],
             [112.1239],
             [112.1143]],

            ...,

            [[112.0240],
             [111.9765],
             [112.0790],
             [111.9932]],

            [[112.0635],
             [112.0473],
             [112.0725],
             [112.0725]],

            [[112.0241],
             [112.0716],
             [112.0637],
             [111.9927]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0973, 447.9955, 448.4787,  ..., 448.0728, 448.2559, 448.1521],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0973, 447.9955, 448.4787,  ..., 448.0728, 448.2559, 448.1521],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0601],
             [111.9648],
             [111.9826],
             [111.9826]],

            [[112.0231],
             [112.0231],
             [112.0591],
             [112.0591]],

            [[112.0521],
             [112.0447],
             [112.0581],
             [112.0077]],

            ...,

            [[112.1127],
             [112.1132],
             [112.1132],
             [112.1134]],

            [[112.0478],
             [112.0478],
             [112.0576],
             [112.0576]],

            [[112.0108],
             [111.9737],
             [111.9934],
             [112.0641]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9902, 448.1644, 448.1626,  ..., 448.4525, 448.2110, 448.0419],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9902, 448.1644, 448.1626,  ..., 448.4525, 448.2110, 448.0419],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9855],
             [112.0428],
             [112.0480],
             [112.0057]],

            [[111.9565],
             [111.9560],
             [111.9996],
             [111.9996]],

            [[112.0476],
             [112.0053],
             [112.0152],
             [112.0443]],

            ...,

            [[111.9983],
             [111.9983],
             [111.9566],
             [111.9566]],

            [[112.1034],
             [112.1034],
             [112.1013],
             [112.1013]],

            [[111.9594],
             [111.9594],
             [111.9665],
             [111.9665]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0820, 447.9117, 448.1124,  ..., 447.9098, 448.4094, 447.8517],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0820, 447.9117, 448.1124,  ..., 447.9098, 448.4094, 447.8517],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9376],
             [112.0064],
             [111.9387],
             [112.0135]],

            [[111.9969],
             [111.9434],
             [112.0270],
             [111.9478]],

            [[112.0891],
             [112.0891],
             [112.0891],
             [112.0891]],

            ...,

            [[111.9402],
             [111.9402],
             [111.9425],
             [111.9425]],

            [[111.9391],
             [111.9980],
             [111.9445],
             [112.0282]],

            [[111.9373],
             [111.9979],
             [111.9892],
             [111.9374]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8962, 447.9150, 448.3565,  ..., 447.7655, 447.9098, 447.8618],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8962, 447.9150, 448.3565,  ..., 447.7655, 447.9098, 447.8618],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9179],
             [111.9179],
             [111.9207],
             [111.9207]],

            [[111.9258],
             [111.9239],
             [111.9140],
             [111.9532]],

            [[112.0637],
             [112.0637],
             [112.0637],
             [112.0637]],

            ...,

            [[111.9166],
             [111.9363],
             [111.9158],
             [111.9158]],

            [[111.9492],
             [111.9492],
             [111.9455],
             [111.9455]],

            [[111.9612],
             [112.0503],
             [112.0470],
             [111.9363]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6770, 447.7169, 448.2549,  ..., 447.6846, 447.7893, 447.9948],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6770, 447.7169, 448.2549,  ..., 447.6846, 447.7893, 447.9948],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9022],
             [111.9022],
             [111.9530],
             [111.9530]],

            [[111.9499],
             [111.9600],
             [111.9933],
             [111.9933]],

            [[111.9445],
             [111.9444],
             [111.9951],
             [111.9136]],

            ...,

            [[111.9218],
             [111.9218],
             [111.9797],
             [111.9797]],

            [[112.0206],
             [111.9169],
             [112.0116],
             [111.9056]],

            [[111.9024],
             [111.9024],
             [111.9857],
             [111.9453]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7104, 447.8964, 447.7975,  ..., 447.8029, 447.8546, 447.7357],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7104, 447.8964, 447.7975,  ..., 447.8029, 447.8546, 447.7357],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9724],
             [111.9724],
             [111.9833],
             [111.9833]],

            [[111.8996],
             [111.9622],
             [111.9256],
             [111.9256]],

            [[111.9666],
             [111.9766],
             [111.9731],
             [111.9776]],

            ...,

            [[111.9076],
             [111.9076],
             [111.9725],
             [111.9725]],

            [[111.9001],
             [111.8999],
             [111.9611],
             [111.9611]],

            [[111.9084],
             [111.9001],
             [111.9166],
             [111.9227]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9114, 447.7130, 447.8939,  ..., 447.7601, 447.7222, 447.6478],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9114, 447.7130, 447.8939,  ..., 447.7601, 447.7222, 447.6478],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9917],
             [111.9917],
             [111.9905],
             [111.9905]],

            [[111.9372],
             [111.9810],
             [111.9592],
             [111.9675]],

            [[111.9694],
             [111.9837],
             [112.0105],
             [111.9611]],

            ...,

            [[111.9500],
             [111.9500],
             [111.9861],
             [111.9861]],

            [[111.9771],
             [111.9556],
             [111.9829],
             [111.9829]],

            [[111.9314],
             [111.9727],
             [111.9015],
             [111.9015]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9645, 447.8450, 447.9247,  ..., 447.8721, 447.8984, 447.7069],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9645, 447.8450, 447.9247,  ..., 447.8721, 447.8984, 447.7069],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9037],
             [111.9222],
             [111.9022],
             [111.9022]],

            [[111.9160],
             [111.9286],
             [111.9655],
             [111.9655]],

            [[111.9102],
             [111.9021],
             [111.9069],
             [111.9069]],

            ...,

            [[111.9851],
             [111.9016],
             [111.9854],
             [111.9016]],

            [[111.9022],
             [111.9258],
             [111.9286],
             [111.9735]],

            [[111.9299],
             [111.9702],
             [111.9014],
             [111.9014]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6304, 447.7755, 447.6262,  ..., 447.7737, 447.7302, 447.7029],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6304, 447.7755, 447.6262,  ..., 447.7737, 447.7302, 447.7029],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9405],
             [111.9587],
             [111.9601],
             [111.9620]],

            [[111.9630],
             [111.8915],
             [111.9048],
             [111.9048]],

            [[111.9249],
             [111.9249],
             [111.9182],
             [111.9182]],

            ...,

            [[111.8977],
             [111.9001],
             [111.9022],
             [111.8972]],

            [[111.9151],
             [111.9405],
             [111.9397],
             [111.9693]],

            [[112.0235],
             [111.9461],
             [111.9282],
             [111.9282]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8214, 447.6641, 447.6862,  ..., 447.5972, 447.7646, 447.8259],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8214, 447.6641, 447.6862,  ..., 447.5972, 447.7646, 447.8259],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8984],
             [111.8984],
             [111.9389],
             [111.9389]],

            [[111.9244],
             [111.8770],
             [111.8853],
             [111.8853]],

            [[112.0088],
             [112.0088],
             [112.0095],
             [112.0095]],

            ...,

            [[111.8793],
             [111.8869],
             [111.8781],
             [111.9360]],

            [[111.9944],
             [112.0208],
             [111.9855],
             [112.0200]],

            [[111.9059],
             [111.9111],
             [111.8861],
             [111.9592]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6746, 447.5720, 448.0365,  ..., 447.5803, 448.0207, 447.6623],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6746, 447.5720, 448.0365,  ..., 447.5803, 448.0207, 447.6623],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9185],
             [111.9218],
             [111.9297],
             [111.9323]],

            [[112.0006],
             [111.9044],
             [111.9423],
             [111.9423]],

            [[111.9104],
             [111.9104],
             [111.9360],
             [111.9360]],

            ...,

            [[111.9128],
             [111.9394],
             [111.9268],
             [111.9363]],

            [[112.0111],
             [112.0111],
             [112.0111],
             [112.0112]],

            [[111.9158],
             [111.8865],
             [111.9139],
             [111.8813]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7023, 447.7896, 447.6927,  ..., 447.7153, 448.0445, 447.5975],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7023, 447.7896, 447.6927,  ..., 447.7153, 448.0445, 447.5975],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8516],
             [111.8516],
             [111.8902],
             [111.8902]],

            [[111.8890],
             [111.8890],
             [111.8977],
             [111.8977]],

            [[111.9979],
             [111.9750],
             [111.9977],
             [111.9777]],

            ...,

            [[111.8790],
             [111.9302],
             [111.8538],
             [111.8740]],

            [[111.9396],
             [111.9396],
             [111.9374],
             [111.9374]],

            [[111.8531],
             [111.8687],
             [111.8554],
             [111.8630]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4836, 447.5733, 447.9483,  ..., 447.5371, 447.7541, 447.4402],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4836, 447.5733, 447.9483,  ..., 447.5371, 447.7541, 447.4402],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8976],
             [111.8976],
             [111.9145],
             [111.9145]],

            [[111.9002],
             [111.8801],
             [111.9230],
             [111.8592]],

            [[111.8791],
             [111.9777],
             [111.9797],
             [111.8822]],

            ...,

            [[111.8466],
             [111.8466],
             [111.8466],
             [111.8466]],

            [[111.8572],
             [111.8791],
             [111.9192],
             [111.9192]],

            [[111.8470],
             [111.8811],
             [111.8607],
             [111.8607]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6243, 447.5625, 447.7187,  ..., 447.3863, 447.5746, 447.4495],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6243, 447.5625, 447.7187,  ..., 447.3863, 447.5746, 447.4495],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9303],
             [111.8531],
             [111.9347],
             [111.8492]],

            [[111.8680],
             [111.8744],
             [111.9173],
             [111.8610]],

            [[111.9205],
             [111.9205],
             [111.8466],
             [111.8466]],

            ...,

            [[111.9919],
             [111.9918],
             [111.9918],
             [111.9921]],

            [[111.8697],
             [111.8480],
             [111.8713],
             [111.8713]],

            [[111.8656],
             [111.9585],
             [111.9650],
             [111.8543]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5673, 447.5207, 447.5342,  ..., 447.9676, 447.4603, 447.6435],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5673, 447.5207, 447.5342,  ..., 447.9676, 447.4603, 447.6435],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8933],
             [111.8933],
             [111.9189],
             [111.9189]],

            [[111.8753],
             [111.8752],
             [111.9241],
             [111.8609]],

            [[111.8688],
             [111.8688],
             [111.8657],
             [111.8657]],

            ...,

            [[111.9568],
             [111.8534],
             [111.9695],
             [111.8601]],

            [[111.8742],
             [111.8564],
             [111.9239],
             [111.8672]],

            [[111.9168],
             [111.8463],
             [111.9259],
             [111.8465]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6245, 447.5355, 447.4690,  ..., 447.6398, 447.5217, 447.5354],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6245, 447.5355, 447.4690,  ..., 447.6398, 447.5217, 447.5354],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9992e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9133],
             [111.9133],
             [111.8474],
             [111.8474]],

            [[111.9845],
             [111.9845],
             [111.9109],
             [111.9109]],

            [[111.8481],
             [111.8475],
             [111.8614],
             [111.9204]],

            ...,

            [[111.8485],
             [111.8884],
             [111.8472],
             [111.8680]],

            [[111.8792],
             [111.8545],
             [111.8626],
             [111.9201]],

            [[111.9053],
             [111.8472],
             [111.8564],
             [111.8564]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5215, 447.7908, 447.4774,  ..., 447.4520, 447.5164, 447.4653],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5215, 447.7908, 447.4774,  ..., 447.4520, 447.5164, 447.4653],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8899],
             [111.8899],
             [111.9132],
             [111.9132]],

            [[111.8611],
             [111.9221],
             [111.8865],
             [111.8865]],

            [[111.8560],
             [111.9156],
             [111.8479],
             [111.8650]],

            ...,

            [[111.9904],
             [111.9904],
             [111.9879],
             [111.9879]],

            [[111.8766],
             [111.8565],
             [111.9243],
             [111.8663]],

            [[111.8999],
             [111.8999],
             [111.9209],
             [111.9209]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6062, 447.5562, 447.4846,  ..., 447.9565, 447.5237, 447.6415],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6062, 447.5562, 447.4846,  ..., 447.9565, 447.5237, 447.6415],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8922],
             [111.8555],
             [111.9173],
             [111.9173]],

            [[111.8617],
             [111.8617],
             [111.9685],
             [111.9685]],

            [[111.9060],
             [111.9060],
             [111.9196],
             [111.9196]],

            ...,

            [[111.8562],
             [111.9152],
             [111.8474],
             [111.8615]],

            [[111.8480],
             [111.8754],
             [111.8823],
             [111.9218]],

            [[111.8497],
             [111.9212],
             [111.9004],
             [111.9004]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5823, 447.6603, 447.6512, 447.4731, 447.4005, 447.4677, 447.6333,
            447.4207, 447.8389, 447.6137, 447.4434, 447.5134, 447.5179, 447.4551,
            447.4177, 447.5802, 447.4500, 447.4975, 447.4232, 447.4609, 447.4194,
            447.5142, 447.5991, 447.5720, 447.5345, 447.6844, 447.4086, 447.5011,
            447.9235, 447.6748, 447.6260, 447.5242, 447.5949, 447.4890, 447.4071,
            447.4191, 447.6841, 447.8916, 447.5022, 447.4873, 447.6163, 447.5702,
            447.5325, 447.4414, 447.5383, 447.4583, 447.6707, 447.3920, 447.6205,
            447.4901, 447.5150, 447.5123, 447.5226, 447.4056, 447.5833, 447.5543,
            447.5125, 447.9614, 447.5482, 447.5335, 447.6619, 447.4321, 447.4576,
            447.4502, 447.5819, 447.5364, 447.6391, 447.5212, 447.5558, 447.4423,
            447.5115, 447.5415, 447.5133, 447.8303, 447.5109, 447.5112, 447.4971,
            447.4691, 447.5276, 447.5932, 447.4151, 447.5956, 447.6409, 447.9602,
            447.4984, 447.5400, 447.5224, 447.4287, 447.4858, 447.4234, 447.6340,
            447.4279, 447.5942, 447.6374, 447.4269, 447.4287, 447.4740, 447.4084,
            447.6654, 447.6205, 447.4044, 447.4925, 447.4728, 447.4582, 447.9568,
            447.5557, 447.5949, 447.5579, 447.4169, 447.4917, 447.4450, 447.4767,
            447.5448, 447.4211, 447.5139, 447.4490, 447.5086, 447.4985, 447.4075,
            447.4062, 447.4799, 447.4556, 447.6849, 447.4214, 447.4041, 447.5348,
            447.4244, 447.5189, 447.5067, 447.9619, 447.5555, 447.4880, 447.5056,
            447.7953, 447.9613, 447.5245, 447.4456, 447.6518, 447.9565, 447.4498,
            447.5387, 447.3918, 447.5074, 447.5436, 447.7599, 447.4078, 447.4972,
            447.5120, 447.4932, 447.5233, 447.4517, 447.4175, 447.6388, 447.5954,
            447.5197, 447.8881, 447.8307, 447.9364, 447.4971, 447.4140, 447.5745,
            447.4117, 447.6298, 447.6573, 447.4971, 447.5138, 447.8666, 447.4022,
            447.4986, 447.5454, 447.5052, 447.9570, 447.4955, 447.6423, 447.5051,
            447.5121, 447.9615, 447.5522, 447.4092, 447.5310, 447.4108, 447.5546,
            447.5071, 447.4667, 447.5893, 447.5380, 447.5969, 447.5087, 447.4109,
            447.6495, 447.4104, 447.7441, 447.9597, 447.6388, 447.4177, 447.4735,
            447.5985, 447.4109, 447.6105, 447.4183, 447.4891, 447.4157, 447.5972,
            447.5648, 447.5430, 447.4348, 447.5007, 447.5643, 447.5200, 447.6042,
            447.5107, 447.9029, 447.5809, 447.5111, 447.5212, 447.5158, 447.5253,
            447.4948, 447.9616, 447.7950, 447.4785, 447.4799, 447.5132, 447.4858,
            447.3890, 447.5034, 447.6689, 447.6397, 447.4392, 447.5143, 447.4713,
            447.6440, 447.6076, 447.5526, 447.5609, 447.8637, 447.5145, 447.4163,
            447.5229, 447.5077, 447.9409, 447.5318, 447.5134, 447.9039, 447.5780,
            447.4117, 447.9595, 447.5116, 447.8565, 447.4133, 447.4200, 447.4845,
            447.3896, 447.4705, 447.5012, 447.4674, 447.8559, 447.5214, 447.8591,
            447.4130, 447.5109, 447.5883, 447.4872, 447.5433, 447.4891, 447.6207,
            447.5854, 447.8556, 447.6363, 447.4572, 447.8811, 447.4627, 447.6381,
            447.5134, 447.5099, 447.4330, 447.4161, 447.5803, 447.6214, 447.6399,
            447.4288, 447.9620, 447.4708, 447.5563, 447.4384, 447.4298, 447.4834,
            447.5189, 447.5244, 447.5076, 447.4182, 447.4373, 447.6632, 447.5142,
            447.6028, 447.4622, 447.4195, 447.5231, 447.8307, 447.4850, 447.5077,
            447.9410, 447.4602, 447.4481, 447.4202, 447.7892, 447.5154, 447.7923,
            447.6344, 447.7936, 447.5069, 447.5160, 447.5365, 447.3990, 447.6429,
            447.6497, 447.6224, 447.6029, 447.8149, 447.6483, 447.7103, 447.9615,
            447.4899, 447.5494, 447.5468, 447.6254, 447.5003, 447.4822, 447.6371,
            447.4472, 447.6178, 447.5012, 447.5234, 447.4230, 447.5370, 447.5087,
            447.6320, 447.4406, 447.9562, 447.5533, 447.6096, 447.4374, 448.0029,
            447.9401, 447.5048, 447.5617, 447.6590, 447.4153, 447.6255, 447.4822,
            447.6446, 447.5401, 447.9086, 447.5178, 447.5162, 447.5139, 447.6378,
            447.4695, 447.6025, 447.5615, 447.5062, 447.4919, 447.5298, 447.4691,
            447.5233, 447.5201, 447.6434, 447.5018, 447.3889, 447.4970, 447.5002,
            447.5198, 447.4537, 447.4417, 447.8755, 447.4412, 447.4761, 447.6573,
            447.8884, 447.4850, 447.9345, 447.4644, 447.6469, 447.4799, 447.6209,
            447.4174, 447.5595, 447.5029, 447.4215, 447.4661, 447.9616, 447.4920,
            447.5588, 447.4151, 447.6285, 447.4062, 447.5685, 447.4863, 447.6686,
            447.4467, 447.4105, 447.5052, 447.4769, 447.4964, 447.4346, 447.8307,
            447.4097, 447.4589, 447.6396, 447.5567, 447.6628, 447.4137, 447.5405,
            447.5824, 447.5211, 447.5202, 447.6479, 447.6031, 447.5144, 447.4665,
            447.6687, 447.4913, 447.6176, 447.5413, 447.5520, 447.8851, 447.4203,
            447.5145, 447.5147, 447.6523, 447.4222, 447.9619, 447.9326, 447.4781,
            447.7058, 447.5245, 447.5393, 447.5543, 447.6565, 447.6115, 447.5951,
            447.4934, 447.4814, 447.4763, 447.9492, 447.5468, 447.9613, 447.4783,
            447.5108, 447.5483, 447.5255, 447.9106, 447.4060, 447.5337, 447.4530,
            447.4861, 447.4197, 447.6010, 447.5340, 447.5037, 450.2711, 447.5357,
            447.6296, 447.9608, 447.7493, 447.5339, 447.5327, 447.5536, 447.5637,
            447.4264, 447.6086, 447.6824, 447.5706, 447.5475, 447.5352, 447.6634,
            447.4594, 447.9582, 447.5305, 447.4531, 447.5836, 447.4732, 447.6030,
            447.5157, 447.3912, 447.4373, 447.9490, 447.4201, 447.4070, 447.5405,
            447.5308, 447.5090, 447.4877, 447.4381, 447.4979, 447.5896, 447.4772,
            447.6498, 447.6906, 447.8600, 447.5096, 447.4981, 447.9606, 447.5555,
            447.4680, 447.5228, 447.7156, 447.6204, 447.4781, 447.4162, 447.9055,
            447.5492, 447.7144, 447.4164, 447.4243, 447.7287, 447.9606, 447.5794,
            447.6093, 447.4416, 447.5183, 447.9423, 447.5693, 447.4055, 447.5440,
            447.6268, 447.6273, 447.5942, 447.4924, 447.4109, 447.4846, 447.5781,
            447.9435, 447.5168, 447.4067, 447.5198, 447.9618, 447.5314, 447.9509,
            447.4407, 447.4363, 447.6575, 447.4169, 447.9097, 447.5806, 447.5069,
            447.4342, 447.4561, 447.5309, 447.4045, 447.9568, 447.4231, 447.4661,
            447.7999, 447.5482, 447.6409, 447.4805, 447.8285, 447.6221, 447.5084,
            447.4793, 447.5927, 447.9615, 447.5082, 447.4262, 447.6508, 447.6398,
            447.7410, 447.5165, 447.5372, 447.4080, 447.7403, 447.4041, 447.9620,
            447.5916, 447.6620, 447.9470, 447.4647, 447.4992, 447.5187, 447.9492,
            447.5354, 447.5935, 450.9485, 447.6337, 447.4236, 447.4326, 447.4841,
            447.5475, 447.4180, 447.6176, 447.5196, 447.5155, 447.5135, 447.4562,
            447.5119, 447.9534, 447.5890, 447.6342, 447.9611, 447.5214, 447.8936,
            447.4566, 447.4077, 447.6682, 447.9616, 447.5460, 447.4776, 447.9607,
            447.6534, 447.4775, 447.5560, 447.6366, 447.4904, 447.4776, 447.8723,
            450.7687, 447.4999, 447.5043, 447.4343, 447.5678, 447.3947, 447.6363,
            447.9543, 447.5005, 447.5901, 447.6509, 447.5475, 447.5447, 447.4403,
            447.7639, 447.5115, 447.4565, 447.5174, 447.7842, 447.9612, 447.6757,
            447.5553, 447.5468, 447.4064, 447.5124, 447.8192, 447.4189, 447.6156,
            447.5229, 447.5023, 447.9366, 447.5455, 447.6609, 447.5809, 447.4177,
            447.6635, 447.6157, 447.6320, 447.8731, 447.5210, 447.5300, 447.6363,
            447.9619, 447.8503, 447.4684, 447.5531, 447.4133, 447.9620, 447.5808,
            447.4732, 447.4349, 447.3895, 447.5140, 447.4283, 447.9128, 447.6005,
            447.5898, 447.5417, 447.6994, 447.5297, 447.4193, 447.4205, 447.4832,
            447.9492, 447.9597, 447.3959, 447.5115, 447.5227, 447.5091, 447.9397,
            447.5483, 447.4667, 447.6024, 449.0941, 447.7645, 447.6211, 447.3986,
            447.5159, 447.6613, 447.5007, 447.7537, 447.7446, 447.5311, 447.3922,
            447.5156, 447.5765, 447.5082, 447.8617, 447.4934, 447.7643, 447.5889,
            447.4994, 447.9620, 447.8075, 447.5617, 447.5267, 447.4050, 447.4774,
            447.5188, 447.5923, 447.6454, 447.7512, 447.4007, 447.9622, 447.6701,
            447.8162, 447.5052, 447.5601, 447.4860, 447.7667, 447.3885, 447.5430,
            447.5233, 447.4971, 447.5459, 447.5205, 447.4908, 447.5168, 447.6706,
            447.4113, 447.4576, 447.4321, 447.6129, 447.4416, 447.6087, 447.6765,
            447.6246, 447.4057, 447.3959, 447.3992, 447.8879, 447.5359, 447.4244,
            447.7321, 447.9562, 447.9553, 447.4994, 447.4601, 447.4720, 447.5183,
            447.4993, 447.4664, 447.4335, 447.4987, 447.5201, 447.9604, 447.4088,
            447.4834, 447.6040, 447.4983, 447.5581, 447.4264, 447.4193, 447.5586,
            447.5158, 447.4166, 447.4709, 447.4202, 447.9317, 447.4116, 447.5195,
            447.4373, 447.4970, 447.9619, 447.4392, 447.4796, 447.4758, 447.6185,
            447.5170, 447.9619, 447.3895, 447.6639, 447.3976, 447.7933, 447.5163,
            447.4331, 447.6370, 447.5475, 447.8181, 447.9619, 447.5085, 447.4463,
            447.9606, 447.5469, 447.4938, 447.3990, 447.3986, 447.9177, 447.8393,
            447.5311, 447.5331, 447.4686, 447.4745, 447.5107, 447.7910, 447.5405,
            447.4172, 447.6533, 447.5184, 447.7566, 447.5416, 447.5439, 447.4359,
            447.5069, 447.5073, 447.9009, 447.6096, 447.6699, 447.6822, 447.4426,
            447.5191, 447.5087, 447.7988, 447.4499, 447.5235, 447.5638, 447.4094,
            450.7093, 447.7665, 447.5809, 447.5109, 447.4603, 447.9366, 447.7935,
            447.4761, 447.4562, 447.4138, 447.4686, 447.5156, 447.5370, 447.5622,
            447.4177, 447.6190, 447.7506, 447.6370, 447.8831, 447.4826, 447.5173,
            447.4189, 447.4753, 447.5683, 447.9611, 447.5351, 447.5137, 447.8909,
            447.5153, 447.4208, 447.4959, 447.5146, 447.5089, 447.9074, 447.5302,
            447.6710, 447.6317, 447.4241, 447.6014, 447.4191, 447.5489, 447.9615,
            450.8009, 447.3966, 447.5129, 447.5193, 447.5196, 447.6140, 447.6303,
            447.9162, 447.5468, 447.6389, 447.4972, 447.9023, 447.5032, 447.4524,
            447.6264, 447.5038, 447.6140, 447.4511, 447.4802, 447.4695, 447.5172,
            447.8495, 447.5132, 447.4202, 447.4129, 447.3980, 447.6244, 447.4185,
            447.5119, 447.6667, 447.9650, 447.4124, 447.9434, 447.5978, 447.5063,
            447.4441, 447.4308, 447.4660, 447.8829, 447.9061, 447.4855, 447.5341,
            447.5380, 447.5151, 447.4131, 447.4326, 447.6632, 447.6259, 447.4803,
            447.5275, 447.5717], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5823, 447.6603, 447.6512, 447.4731, 447.4005, 447.4677, 447.6333,
        447.4207, 447.8389, 447.6137, 447.4434, 447.5134, 447.5179, 447.4551,
        447.4177, 447.5802, 447.4500, 447.4975, 447.4232, 447.4609, 447.4194,
        447.5142, 447.5991, 447.5720, 447.5345, 447.6844, 447.4086, 447.5011,
        447.9235, 447.6748, 447.6260, 447.5242, 447.5949, 447.4890, 447.4071,
        447.4191, 447.6841, 447.8916, 447.5022, 447.4873, 447.6163, 447.5702,
        447.5325, 447.4414, 447.5383, 447.4583, 447.6707, 447.3920, 447.6205,
        447.4901, 447.5150, 447.5123, 447.5226, 447.4056, 447.5833, 447.5543,
        447.5125, 447.9614, 447.5482, 447.5335, 447.6619, 447.4321, 447.4576,
        447.4502, 447.5819, 447.5364, 447.6391, 447.5212, 447.5558, 447.4423,
        447.5115, 447.5415, 447.5133, 447.8303, 447.5109, 447.5112, 447.4971,
        447.4691, 447.5276, 447.5932, 447.4151, 447.5956, 447.6409, 447.9602,
        447.4984, 447.5400, 447.5224, 447.4287, 447.4858, 447.4234, 447.6340,
        447.4279, 447.5942, 447.6374, 447.4269, 447.4287, 447.4740, 447.4084,
        447.6654, 447.6205, 447.4044, 447.4925, 447.4728, 447.4582, 447.9568,
        447.5557, 447.5949, 447.5579, 447.4169, 447.4917, 447.4450, 447.4767,
        447.5448, 447.4211, 447.5139, 447.4490, 447.5086, 447.4985, 447.4075,
        447.4062, 447.4799, 447.4556, 447.6849, 447.4214, 447.4041, 447.5348,
        447.4244, 447.5189, 447.5067, 447.9619, 447.5555, 447.4880, 447.5056,
        447.7953, 447.9613, 447.5245, 447.4456, 447.6518, 447.9565, 447.4498,
        447.5387, 447.3918, 447.5074, 447.5436, 447.7599, 447.4078, 447.4972,
        447.5120, 447.4932, 447.5233, 447.4517, 447.4175, 447.6388, 447.5954,
        447.5197, 447.8881, 447.8307, 447.9364, 447.4971, 447.4140, 447.5745,
        447.4117, 447.6298, 447.6573, 447.4971, 447.5138, 447.8666, 447.4022,
        447.4986, 447.5454, 447.5052, 447.9570, 447.4955, 447.6423, 447.5051,
        447.5121, 447.9615, 447.5522, 447.4092, 447.5310, 447.4108, 447.5546,
        447.5071, 447.4667, 447.5893, 447.5380, 447.5969, 447.5087, 447.4109,
        447.6495, 447.4104, 447.7441, 447.9597, 447.6388, 447.4177, 447.4735,
        447.5985, 447.4109, 447.6105, 447.4183, 447.4891, 447.4157, 447.5972,
        447.5648, 447.5430, 447.4348, 447.5007, 447.5643, 447.5200, 447.6042,
        447.5107, 447.9029, 447.5809, 447.5111, 447.5212, 447.5158, 447.5253,
        447.4948, 447.9616, 447.7950, 447.4785, 447.4799, 447.5132, 447.4858,
        447.3890, 447.5034, 447.6689, 447.6397, 447.4392, 447.5143, 447.4713,
        447.6440, 447.6076, 447.5526, 447.5609, 447.8637, 447.5145, 447.4163,
        447.5229, 447.5077, 447.9409, 447.5318, 447.5134, 447.9039, 447.5780,
        447.4117, 447.9595, 447.5116, 447.8565, 447.4133, 447.4200, 447.4845,
        447.3896, 447.4705, 447.5012, 447.4674, 447.8559, 447.5214, 447.8591,
        447.4130, 447.5109, 447.5883, 447.4872, 447.5433, 447.4891, 447.6207,
        447.5854, 447.8556, 447.6363, 447.4572, 447.8811, 447.4627, 447.6381,
        447.5134, 447.5099, 447.4330, 447.4161, 447.5803, 447.6214, 447.6399,
        447.4288, 447.9620, 447.4708, 447.5563, 447.4384, 447.4298, 447.4834,
        447.5189, 447.5244, 447.5076, 447.4182, 447.4373, 447.6632, 447.5142,
        447.6028, 447.4622, 447.4195, 447.5231, 447.8307, 447.4850, 447.5077,
        447.9410, 447.4602, 447.4481, 447.4202, 447.7892, 447.5154, 447.7923,
        447.6344, 447.7936, 447.5069, 447.5160, 447.5365, 447.3990, 447.6429,
        447.6497, 447.6224, 447.6029, 447.8149, 447.6483, 447.7103, 447.9615,
        447.4899, 447.5494, 447.5468, 447.6254, 447.5003, 447.4822, 447.6371,
        447.4472, 447.6178, 447.5012, 447.5234, 447.4230, 447.5370, 447.5087,
        447.6320, 447.4406, 447.9562, 447.5533, 447.6096, 447.4374, 448.0029,
        447.9401, 447.5048, 447.5617, 447.6590, 447.4153, 447.6255, 447.4822,
        447.6446, 447.5401, 447.9086, 447.5178, 447.5162, 447.5139, 447.6378,
        447.4695, 447.6025, 447.5615, 447.5062, 447.4919, 447.5298, 447.4691,
        447.5233, 447.5201, 447.6434, 447.5018, 447.3889, 447.4970, 447.5002,
        447.5198, 447.4537, 447.4417, 447.8755, 447.4412, 447.4761, 447.6573,
        447.8884, 447.4850, 447.9345, 447.4644, 447.6469, 447.4799, 447.6209,
        447.4174, 447.5595, 447.5029, 447.4215, 447.4661, 447.9616, 447.4920,
        447.5588, 447.4151, 447.6285, 447.4062, 447.5685, 447.4863, 447.6686,
        447.4467, 447.4105, 447.5052, 447.4769, 447.4964, 447.4346, 447.8307,
        447.4097, 447.4589, 447.6396, 447.5567, 447.6628, 447.4137, 447.5405,
        447.5824, 447.5211, 447.5202, 447.6479, 447.6031, 447.5144, 447.4665,
        447.6687, 447.4913, 447.6176, 447.5413, 447.5520, 447.8851, 447.4203,
        447.5145, 447.5147, 447.6523, 447.4222, 447.9619, 447.9326, 447.4781,
        447.7058, 447.5245, 447.5393, 447.5543, 447.6565, 447.6115, 447.5951,
        447.4934, 447.4814, 447.4763, 447.9492, 447.5468, 447.9613, 447.4783,
        447.5108, 447.5483, 447.5255, 447.9106, 447.4060, 447.5337, 447.4530,
        447.4861, 447.4197, 447.6010, 447.5340, 447.5037, 450.2711, 447.5357,
        447.6296, 447.9608, 447.7493, 447.5339, 447.5327, 447.5536, 447.5637,
        447.4264, 447.6086, 447.6824, 447.5706, 447.5475, 447.5352, 447.6634,
        447.4594, 447.9582, 447.5305, 447.4531, 447.5836, 447.4732, 447.6030,
        447.5157, 447.3912, 447.4373, 447.9490, 447.4201, 447.4070, 447.5405,
        447.5308, 447.5090, 447.4877, 447.4381, 447.4979, 447.5896, 447.4772,
        447.6498, 447.6906, 447.8600, 447.5096, 447.4981, 447.9606, 447.5555,
        447.4680, 447.5228, 447.7156, 447.6204, 447.4781, 447.4162, 447.9055,
        447.5492, 447.7144, 447.4164, 447.4243, 447.7287, 447.9606, 447.5794,
        447.6093, 447.4416, 447.5183, 447.9423, 447.5693, 447.4055, 447.5440,
        447.6268, 447.6273, 447.5942, 447.4924, 447.4109, 447.4846, 447.5781,
        447.9435, 447.5168, 447.4067, 447.5198, 447.9618, 447.5314, 447.9509,
        447.4407, 447.4363, 447.6575, 447.4169, 447.9097, 447.5806, 447.5069,
        447.4342, 447.4561, 447.5309, 447.4045, 447.9568, 447.4231, 447.4661,
        447.7999, 447.5482, 447.6409, 447.4805, 447.8285, 447.6221, 447.5084,
        447.4793, 447.5927, 447.9615, 447.5082, 447.4262, 447.6508, 447.6398,
        447.7410, 447.5165, 447.5372, 447.4080, 447.7403, 447.4041, 447.9620,
        447.5916, 447.6620, 447.9470, 447.4647, 447.4992, 447.5187, 447.9492,
        447.5354, 447.5935, 450.9485, 447.6337, 447.4236, 447.4326, 447.4841,
        447.5475, 447.4180, 447.6176, 447.5196, 447.5155, 447.5135, 447.4562,
        447.5119, 447.9534, 447.5890, 447.6342, 447.9611, 447.5214, 447.8936,
        447.4566, 447.4077, 447.6682, 447.9616, 447.5460, 447.4776, 447.9607,
        447.6534, 447.4775, 447.5560, 447.6366, 447.4904, 447.4776, 447.8723,
        450.7687, 447.4999, 447.5043, 447.4343, 447.5678, 447.3947, 447.6363,
        447.9543, 447.5005, 447.5901, 447.6509, 447.5475, 447.5447, 447.4403,
        447.7639, 447.5115, 447.4565, 447.5174, 447.7842, 447.9612, 447.6757,
        447.5553, 447.5468, 447.4064, 447.5124, 447.8192, 447.4189, 447.6156,
        447.5229, 447.5023, 447.9366, 447.5455, 447.6609, 447.5809, 447.4177,
        447.6635, 447.6157, 447.6320, 447.8731, 447.5210, 447.5300, 447.6363,
        447.9619, 447.8503, 447.4684, 447.5531, 447.4133, 447.9620, 447.5808,
        447.4732, 447.4349, 447.3895, 447.5140, 447.4283, 447.9128, 447.6005,
        447.5898, 447.5417, 447.6994, 447.5297, 447.4193, 447.4205, 447.4832,
        447.9492, 447.9597, 447.3959, 447.5115, 447.5227, 447.5091, 447.9397,
        447.5483, 447.4667, 447.6024, 449.0941, 447.7645, 447.6211, 447.3986,
        447.5159, 447.6613, 447.5007, 447.7537, 447.7446, 447.5311, 447.3922,
        447.5156, 447.5765, 447.5082, 447.8617, 447.4934, 447.7643, 447.5889,
        447.4994, 447.9620, 447.8075, 447.5617, 447.5267, 447.4050, 447.4774,
        447.5188, 447.5923, 447.6454, 447.7512, 447.4007, 447.9622, 447.6701,
        447.8162, 447.5052, 447.5601, 447.4860, 447.7667, 447.3885, 447.5430,
        447.5233, 447.4971, 447.5459, 447.5205, 447.4908, 447.5168, 447.6706,
        447.4113, 447.4576, 447.4321, 447.6129, 447.4416, 447.6087, 447.6765,
        447.6246, 447.4057, 447.3959, 447.3992, 447.8879, 447.5359, 447.4244,
        447.7321, 447.9562, 447.9553, 447.4994, 447.4601, 447.4720, 447.5183,
        447.4993, 447.4664, 447.4335, 447.4987, 447.5201, 447.9604, 447.4088,
        447.4834, 447.6040, 447.4983, 447.5581, 447.4264, 447.4193, 447.5586,
        447.5158, 447.4166, 447.4709, 447.4202, 447.9317, 447.4116, 447.5195,
        447.4373, 447.4970, 447.9619, 447.4392, 447.4796, 447.4758, 447.6185,
        447.5170, 447.9619, 447.3895, 447.6639, 447.3976, 447.7933, 447.5163,
        447.4331, 447.6370, 447.5475, 447.8181, 447.9619, 447.5085, 447.4463,
        447.9606, 447.5469, 447.4938, 447.3990, 447.3986, 447.9177, 447.8393,
        447.5311, 447.5331, 447.4686, 447.4745, 447.5107, 447.7910, 447.5405,
        447.4172, 447.6533, 447.5184, 447.7566, 447.5416, 447.5439, 447.4359,
        447.5069, 447.5073, 447.9009, 447.6096, 447.6699, 447.6822, 447.4426,
        447.5191, 447.5087, 447.7988, 447.4499, 447.5235, 447.5638, 447.4094,
        450.7093, 447.7665, 447.5809, 447.5109, 447.4603, 447.9366, 447.7935,
        447.4761, 447.4562, 447.4138, 447.4686, 447.5156, 447.5370, 447.5622,
        447.4177, 447.6190, 447.7506, 447.6370, 447.8831, 447.4826, 447.5173,
        447.4189, 447.4753, 447.5683, 447.9611, 447.5351, 447.5137, 447.8909,
        447.5153, 447.4208, 447.4959, 447.5146, 447.5089, 447.9074, 447.5302,
        447.6710, 447.6317, 447.4241, 447.6014, 447.4191, 447.5489, 447.9615,
        450.8009, 447.3966, 447.5129, 447.5193, 447.5196, 447.6140, 447.6303,
        447.9162, 447.5468, 447.6389, 447.4972, 447.9023, 447.5032, 447.4524,
        447.6264, 447.5038, 447.6140, 447.4511, 447.4802, 447.4695, 447.5172,
        447.8495, 447.5132, 447.4202, 447.4129, 447.3980, 447.6244, 447.4185,
        447.5119, 447.6667, 447.9650, 447.4124, 447.9434, 447.5978, 447.5063,
        447.4441, 447.4308, 447.4660, 447.8829, 447.9061, 447.4855, 447.5341,
        447.5380, 447.5151, 447.4131, 447.4326, 447.6632, 447.6259, 447.4803,
        447.5275, 447.5717], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([408.6111], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9691],
             [111.8793],
             [111.9615],
             [111.8647]],

            [[111.8493],
             [111.8473],
             [111.8751],
             [111.9193]],

            [[111.8622],
             [111.8984],
             [111.8481],
             [111.8477]],

            ...,

            [[111.8835],
             [111.8550],
             [111.9176],
             [111.8538]],

            [[111.8524],
             [111.9244],
             [111.8667],
             [111.8616]],

            [[111.9162],
             [111.9162],
             [111.9194],
             [111.9194]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6746, 447.4911, 447.4565,  ..., 447.5099, 447.5051, 447.6711],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6746, 447.4911, 447.4565,  ..., 447.5099, 447.5051, 447.6711],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8784],
             [111.8892],
             [111.8965],
             [111.9297]],

            [[111.9016],
             [111.9016],
             [111.9302],
             [111.9302]],

            [[111.9968],
             [111.9974],
             [111.9978],
             [111.9970]],

            ...,

            [[111.8550],
             [111.9023],
             [111.8635],
             [111.8635]],

            [[111.9981],
             [111.9981],
             [111.9981],
             [111.9981]],

            [[111.8581],
             [111.8997],
             [111.8617],
             [111.9259]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5938, 447.6637, 447.9890,  ..., 447.4844, 447.9924, 447.5453],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5938, 447.6637, 447.9890,  ..., 447.4844, 447.9924, 447.5453],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8511],
             [111.8638],
             [111.9140],
             [111.9140]],

            [[111.8506],
             [111.8506],
             [111.9120],
             [111.9120]],

            [[111.8813],
             [111.8499],
             [111.8848],
             [111.8498]],

            ...,

            [[111.9216],
             [111.8671],
             [111.8501],
             [111.8501]],

            [[111.8557],
             [111.8557],
             [111.8535],
             [111.8535]],

            [[111.8506],
             [111.9135],
             [111.8711],
             [111.8864]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5429, 447.5253, 447.4659,  ..., 447.4889, 447.4184, 447.5216],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5429, 447.5253, 447.4659,  ..., 447.4889, 447.4184, 447.5216],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8857],
             [111.8469],
             [111.8827],
             [111.8468]],

            [[111.8491],
             [111.8467],
             [111.8591],
             [111.9185]],

            [[111.8492],
             [111.8492],
             [111.8503],
             [111.8503]],

            ...,

            [[111.8795],
             [111.9166],
             [111.9104],
             [111.9104]],

            [[111.8491],
             [111.8652],
             [111.9143],
             [111.8693]],

            [[111.8467],
             [111.8577],
             [111.8467],
             [111.8816]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4621, 447.4734, 447.3990,  ..., 447.6169, 447.4978, 447.4326],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4621, 447.4734, 447.3990,  ..., 447.6169, 447.4978, 447.4326],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8639],
             [111.8219],
             [111.8260],
             [111.8260]],

            [[111.8343],
             [111.8726],
             [111.8555],
             [111.8978]],

            [[111.8789],
             [111.8789],
             [111.8626],
             [111.8626]],

            ...,

            [[111.8224],
             [111.8712],
             [111.8914],
             [111.8308]],

            [[111.8221],
             [111.8281],
             [111.8882],
             [111.8882]],

            [[111.8223],
             [111.8426],
             [111.8219],
             [111.8849]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3378, 447.4602, 447.4830,  ..., 447.4159, 447.4266, 447.3716],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3378, 447.4602, 447.4830,  ..., 447.4159, 447.4266, 447.3716],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8030],
             [111.8216],
             [111.8055],
             [111.8055]],

            [[111.8365],
             [111.8025],
             [111.8042],
             [111.8733]],

            [[111.8902],
             [111.8034],
             [111.8866],
             [111.8058]],

            ...,

            [[111.8449],
             [111.8124],
             [111.8793],
             [111.8029]],

            [[111.8044],
             [111.8840],
             [111.8300],
             [111.8295]],

            [[111.8139],
             [111.8328],
             [111.8835],
             [111.8131]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2356, 447.3165, 447.3860,  ..., 447.3394, 447.3480, 447.3434],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2356, 447.3165, 447.3860,  ..., 447.3394, 447.3480, 447.3434],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9490],
             [111.8632],
             [111.9172],
             [111.9172]],

            [[111.9439],
             [111.8708],
             [111.8347],
             [111.8347]],

            [[111.8024],
             [111.8477],
             [111.7963],
             [111.8572]],

            ...,

            [[111.8487],
             [111.8521],
             [111.8599],
             [111.8623]],

            [[111.8239],
             [111.8239],
             [111.8545],
             [111.8545]],

            [[111.7945],
             [111.8030],
             [111.7958],
             [111.8010]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6466, 447.4841, 447.3036,  ..., 447.4230, 447.3568, 447.1943],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6466, 447.4841, 447.3036,  ..., 447.4230, 447.3568, 447.1943],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7973],
             [111.8125],
             [111.8400],
             [111.8687]],

            [[111.8007],
             [111.7924],
             [111.8603],
             [111.8048]],

            [[111.8594],
             [111.8594],
             [111.8641],
             [111.8641]],

            ...,

            [[111.7952],
             [111.7952],
             [111.7957],
             [111.7957]],

            [[111.8607],
             [111.8607],
             [111.8719],
             [111.8719]],

            [[111.8263],
             [111.7987],
             [111.8722],
             [111.8330]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3185, 447.2582, 447.4468,  ..., 447.1819, 447.4651, 447.3301],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3185, 447.2582, 447.4468,  ..., 447.1819, 447.4651, 447.3301],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8746],
             [111.8227],
             [111.8279],
             [111.8279]],

            [[111.8674],
             [111.8111],
             [111.8713],
             [111.8598]],

            [[111.8044],
             [111.8044],
             [111.8057],
             [111.8057]],

            ...,

            [[111.8339],
             [111.8771],
             [111.8570],
             [111.8731]],

            [[111.8501],
             [111.8003],
             [111.8795],
             [111.8003]],

            [[111.8585],
             [111.8003],
             [111.8446],
             [111.8005]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3531, 447.4096, 447.2202,  ..., 447.4412, 447.3302, 447.3039],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3531, 447.4096, 447.2202,  ..., 447.4412, 447.3302, 447.3039],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8070],
             [111.8125],
             [111.8101],
             [111.8124]],

            [[111.8068],
             [111.8068],
             [111.8665],
             [111.8665]],

            [[111.9787],
             [111.9759],
             [111.9778],
             [111.9778]],

            ...,

            [[111.9296],
             [111.8254],
             [111.8070],
             [111.8062]],

            [[111.8077],
             [111.8754],
             [111.8276],
             [111.8444]],

            [[111.8807],
             [111.8177],
             [111.8252],
             [111.8252]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.2420, 447.3466, 447.9102,  ..., 447.3682, 447.3551, 447.3488],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.2420, 447.3466, 447.9102,  ..., 447.3682, 447.3551, 447.3488],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8351],
             [111.8351],
             [111.8399],
             [111.8399]],

            [[111.8098],
             [111.8360],
             [111.8319],
             [111.8099]],

            [[111.9800],
             [111.9190],
             [111.9233],
             [111.9233]],

            ...,

            [[111.9686],
             [111.8588],
             [111.9724],
             [111.8669]],

            [[111.8145],
             [111.8145],
             [111.8145],
             [111.8145]],

            [[111.8233],
             [111.8233],
             [111.8272],
             [111.8272]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3500, 447.2877, 447.7456,  ..., 447.6667, 447.2579, 447.3010],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3500, 447.2877, 447.7456,  ..., 447.6667, 447.2579, 447.3010],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8764],
             [111.8764],
             [111.9057],
             [111.9057]],

            [[111.9988],
             [111.9988],
             [111.9989],
             [111.9989]],

            [[111.8821],
             [111.8821],
             [111.9025],
             [111.9025]],

            ...,

            [[112.0005],
             [112.0005],
             [112.0005],
             [112.0005]],

            [[111.8289],
             [111.8567],
             [111.9002],
             [111.9002]],

            [[111.8296],
             [111.8296],
             [111.8791],
             [111.8791]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5641, 447.9955, 447.5692,  ..., 448.0020, 447.4860, 447.4174],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5641, 447.9955, 447.5692,  ..., 448.0020, 447.4860, 447.4174],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8892],
             [111.8442],
             [111.9126],
             [111.8442]],

            [[111.8461],
             [111.8830],
             [111.8482],
             [111.9187]],

            [[111.8437],
             [111.8437],
             [111.8689],
             [111.8689]],

            ...,

            [[111.8590],
             [111.9217],
             [111.8850],
             [111.8850]],

            [[111.9654],
             [111.8490],
             [111.8723],
             [111.8723]],

            [[111.8971],
             [111.8971],
             [111.9135],
             [111.9135]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4902, 447.4960, 447.4251,  ..., 447.5509, 447.5590, 447.6212],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4902, 447.4960, 447.4251,  ..., 447.5509, 447.5590, 447.6212],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8532],
             [111.8532],
             [111.8674],
             [111.8674]],

            [[112.0208],
             [112.0208],
             [112.0199],
             [112.0199]],

            [[111.8588],
             [111.8537],
             [111.8527],
             [111.8531]],

            ...,

            [[111.9327],
             [111.9124],
             [111.9373],
             [111.9016]],

            [[111.8974],
             [111.9227],
             [111.9250],
             [111.8823]],

            [[111.9974],
             [111.9011],
             [111.9936],
             [111.9936]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4412, 448.0812, 447.4182,  ..., 447.6841, 447.6274, 447.8855],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4412, 448.0812, 447.4182,  ..., 447.6841, 447.6274, 447.8855],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8566],
             [111.8668],
             [111.8560],
             [111.8624]],

            [[111.8752],
             [111.8540],
             [111.8752],
             [111.9259]],

            [[111.8957],
             [111.8760],
             [111.9249],
             [111.8554]],

            ...,

            [[111.8528],
             [111.8763],
             [111.8523],
             [111.8539]],

            [[111.8924],
             [111.8521],
             [111.8526],
             [111.9053]],

            [[111.8528],
             [111.8605],
             [111.8731],
             [111.9314]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4418, 447.5303, 447.5519,  ..., 447.4353, 447.5024, 447.5178],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4418, 447.5303, 447.5519,  ..., 447.4353, 447.5024, 447.5178],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9244],
             [111.8385],
             [111.8429],
             [111.8429]],

            [[111.8411],
             [111.8950],
             [111.8637],
             [111.8637]],

            [[111.8385],
             [111.8379],
             [111.8754],
             [111.9147]],

            ...,

            [[111.8844],
             [111.8673],
             [111.8384],
             [111.8383]],

            [[112.0179],
             [112.0179],
             [112.0178],
             [112.0178]],

            [[111.8407],
             [111.8971],
             [111.8418],
             [111.8418]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4487, 447.4634, 447.4664,  ..., 447.4284, 448.0714, 447.4214],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4487, 447.4634, 447.4664,  ..., 447.4284, 448.0714, 447.4214],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8925],
             [111.8925],
             [111.9155],
             [111.9155]],

            [[111.9397],
             [111.8375],
             [111.9397],
             [111.8375]],

            [[111.8383],
             [111.8538],
             [111.8385],
             [111.8385]],

            ...,

            [[112.0201],
             [112.0204],
             [112.0204],
             [112.0207]],

            [[111.9637],
             [111.8748],
             [111.9724],
             [111.8484]],

            [[111.8673],
             [111.8778],
             [111.8380],
             [111.9157]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6159, 447.5543, 447.3692,  ..., 448.0816, 447.6593, 447.4989],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6159, 447.5543, 447.3692,  ..., 448.0816, 447.6593, 447.4989],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9163],
             [111.9163],
             [111.9252],
             [111.9252]],

            [[111.8440],
             [111.8620],
             [111.8724],
             [111.9184]],

            [[112.0292],
             [112.0292],
             [112.0289],
             [112.0289]],

            ...,

            [[111.8927],
             [111.9312],
             [111.8814],
             [111.8814]],

            [[111.9206],
             [111.9240],
             [111.9230],
             [111.9230]],

            [[111.8791],
             [111.8569],
             [111.9246],
             [111.8524]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6830, 447.4968, 448.1162,  ..., 447.5866, 447.6906, 447.5131],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6830, 447.4968, 448.1162,  ..., 447.5866, 447.6906, 447.5131],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0265e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9313],
             [111.8795],
             [111.8903],
             [111.8589]],

            [[111.8629],
             [111.8890],
             [111.9257],
             [111.8713]],

            [[112.0377],
             [111.9461],
             [112.0029],
             [112.0029]],

            ...,

            [[111.9466],
             [111.8780],
             [111.9083],
             [111.9083]],

            [[112.0369],
             [112.0369],
             [112.0364],
             [112.0364]],

            [[111.8899],
             [111.8899],
             [111.9134],
             [111.9134]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5600, 447.5489, 447.9896,  ..., 447.6411, 448.1465, 447.6066],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5600, 447.5489, 447.9896,  ..., 447.6411, 448.1465, 447.6066],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9172],
             [111.9399],
             [111.9343],
             [111.9343]],

            [[111.8656],
             [111.8656],
             [111.8758],
             [111.8758]],

            [[111.8672],
             [111.9456],
             [111.8910],
             [111.8910]],

            ...,

            [[111.8576],
             [111.8901],
             [111.8589],
             [111.8828]],

            [[112.0463],
             [112.0463],
             [112.0463],
             [112.0463]],

            [[111.8629],
             [111.9383],
             [111.8820],
             [111.8820]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7256, 447.4827, 447.5949,  ..., 447.4895, 448.1852, 447.5653],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7256, 447.4827, 447.5949,  ..., 447.4895, 448.1852, 447.5653],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8882],
             [111.8776],
             [111.9178],
             [111.9485]],

            [[111.8650],
             [111.9496],
             [111.8889],
             [111.8875]],

            [[111.8631],
             [111.8631],
             [111.9258],
             [111.9258]],

            ...,

            [[111.8738],
             [111.8642],
             [111.8589],
             [111.8589]],

            [[111.9696],
             [111.9696],
             [111.8696],
             [111.8696]],

            [[112.0445],
             [112.0144],
             [112.0325],
             [112.0325]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6321, 447.5910, 447.5777, 447.7029, 447.5792, 447.4575, 447.4522,
            447.7045, 447.7708, 447.6613, 447.5698, 447.5815, 447.5942, 447.5453,
            447.5625, 447.4509, 447.6388, 447.5849, 448.0080, 447.4675, 447.6140,
            447.5387, 447.5493, 447.6595, 447.9302, 447.4581, 447.5363, 447.5885,
            447.5609, 447.6387, 447.8160, 447.5640, 447.6785, 447.6132, 447.4976,
            447.4501, 447.6236, 447.4758, 447.5146, 447.5807, 448.1376, 447.5154,
            447.5430, 447.5828, 447.7115, 447.5758, 447.4919, 448.1842, 447.4498,
            447.4628, 447.4818, 447.6339, 447.6064, 447.7031, 447.5690, 447.6339,
            448.3016, 448.1780, 447.6789, 447.6218, 447.6866, 447.7159, 447.5405,
            447.5354, 447.7522, 447.4788, 447.6364, 447.4407, 447.4472, 447.5656,
            447.6056, 447.5569, 447.4574, 447.6799, 447.4725, 447.9467, 447.5725,
            447.5900, 447.8190, 447.4522, 447.5463, 447.6249, 447.4645, 447.5347,
            448.1842, 448.1087, 447.5199, 447.4600, 447.6734, 447.8107, 447.7247,
            447.7144, 448.1849, 447.5937, 447.5847, 447.5864, 447.5262, 447.7674,
            448.0046, 448.1578, 447.7412, 447.4935, 447.5505, 448.1858, 447.5409,
            447.4622, 447.7269, 448.6957, 447.6687, 447.5502, 447.5402, 448.1824,
            447.5481, 447.9983, 448.1811, 447.8109, 447.5440, 447.6445, 447.5692,
            447.8021, 447.4657, 447.6019, 447.7424, 448.1036, 448.0531, 447.6201,
            447.5918, 447.5192, 447.6810, 447.4904, 447.7577, 447.4775, 447.7665,
            448.1678, 447.4354, 447.5757, 447.7114, 447.4703, 447.6201, 447.6016,
            448.1844, 448.0356, 448.1006, 447.6448, 448.1564, 447.5889, 447.5519,
            447.4666, 448.1732, 447.5544, 447.5490, 448.1842, 447.5359, 448.1776,
            447.4559, 447.4867, 447.5872, 447.7272, 448.1262, 447.5386, 448.1851,
            447.7072, 448.1748, 447.5210, 447.6879, 447.5511, 447.6177, 447.5671,
            447.5652, 448.1558, 447.5401, 447.5008, 447.4425, 447.8264, 448.1725,
            448.1830, 447.5856, 447.6549, 447.6067, 447.5648, 447.5230, 447.7593,
            447.6320, 447.5643, 447.8123, 447.6362, 447.7646, 447.6158, 447.6643,
            447.5563, 447.7140, 447.4786, 447.5593, 447.4800, 447.5752, 448.0373,
            447.4854, 447.6201, 447.7037, 447.5886, 447.5644, 448.1636, 447.6503,
            447.4752, 447.6316, 447.5081, 447.5203, 447.7618, 448.1744, 447.6850,
            447.5223, 447.6222, 448.1732, 447.5571, 448.1729, 447.5286, 447.9505,
            448.1652, 447.6847, 447.6239, 447.5706, 447.5410, 447.5981, 447.5246,
            447.6104, 448.0745, 447.7296, 447.5776, 447.7496, 447.7286, 447.4468,
            447.5097, 448.1444, 448.0405, 447.4933, 447.5470, 447.4620, 447.9767,
            448.1010, 447.7686, 447.6327, 447.6923, 447.7098, 448.0716, 447.5717,
            447.6353, 447.6024, 447.6293, 447.5125, 447.9721, 448.1446, 447.6362,
            447.5401, 447.6099, 447.4528, 447.5794, 447.5779, 447.6324, 447.6042,
            447.5390, 447.6044, 447.5828, 447.5823, 447.5658, 447.5654, 447.5591,
            447.5218, 447.7347, 447.6298, 447.6111, 447.7618, 447.5852, 447.7464,
            447.5019, 447.4661, 447.5590, 447.6916, 447.4549, 448.0269, 447.7690,
            447.5186, 447.5093, 447.7126, 447.5757, 447.5509, 447.6784, 447.5310,
            447.6445, 447.5263, 447.6331, 447.8830, 447.6583, 447.5248, 447.6986,
            447.6682, 447.7232, 447.6725, 447.7542, 447.7324, 447.6089, 447.6202,
            447.6125, 447.6599, 447.5469, 447.5808, 448.1853, 448.1657, 447.6766,
            448.1664, 447.4590, 447.6476, 447.5692, 447.4675, 448.1191, 448.1333,
            448.1844, 448.0670, 447.5123, 447.7541, 447.6139, 447.6969, 447.6263,
            448.1679, 447.5659, 447.9478, 447.5822, 447.7314, 447.5789, 447.7344,
            447.5278, 447.7249, 447.5773, 447.5868, 447.6318, 447.6511, 447.5995,
            447.7511, 447.5830, 447.6759, 447.7277, 447.5598, 447.5901, 448.1715,
            447.7471, 447.4957, 447.4696, 447.5952, 447.5767, 447.4612, 448.1494,
            447.6353, 447.4476, 447.6464, 447.5064, 447.6023, 447.5942, 447.4819,
            447.7615, 447.5766, 447.4861, 448.1230, 448.1309, 448.1871, 447.5493,
            447.6909, 447.5583, 447.5473, 447.5647, 447.5706, 447.5830, 447.5629,
            448.1263, 447.7080, 447.6781, 447.5804, 447.5441, 447.7335, 447.4893,
            447.7043, 447.5530, 447.4735, 447.6508, 447.5226, 447.5450, 447.5084,
            447.6529, 448.1848, 447.5985, 447.4775, 447.5634, 447.6574, 448.1798,
            447.6170, 447.4373, 447.5998, 447.5063, 448.1828, 447.6530, 447.8458,
            447.6173, 447.4626, 447.5685, 447.6102, 447.6649, 447.6237, 448.0411,
            448.1842, 447.7423, 447.5839, 448.1852, 447.4933, 447.5784, 447.5685,
            447.6531, 448.0771, 447.5707, 447.7427, 447.5440, 447.5229, 447.7251,
            447.8692, 447.8447, 447.6476, 451.1203, 447.6136, 447.4838, 447.9554,
            447.4921, 448.1834, 447.6251, 448.1846, 447.5552, 448.1019, 447.6007,
            447.5910, 447.5432, 447.9369, 447.6174, 447.5746, 447.6352, 447.5793,
            447.8005, 447.5147, 447.5919, 447.6119, 447.4485, 447.5909, 448.1836,
            448.0002, 447.5026, 447.6420, 447.5325, 447.5853, 447.7098, 447.5079,
            447.5555, 447.7474, 447.4603, 447.4673, 447.4616, 448.1751, 447.5383,
            447.4825, 447.4531, 447.4755, 447.5970, 447.7278, 447.5681, 447.4828,
            448.0412, 447.4727, 447.6740, 447.6211, 447.7324, 447.6392, 447.6164,
            447.6844, 447.4529, 447.6736, 447.5657, 447.5882, 448.1844, 448.1847,
            447.5909, 447.6878, 447.5410, 447.4602, 447.7188, 447.6525, 447.4489,
            447.9903, 447.5775, 447.4468, 447.5793, 451.2152, 447.4599, 447.4792,
            447.6078, 447.9368, 448.1850, 447.4574, 447.6441, 447.4596, 447.5726,
            447.5216, 447.4579, 448.1852, 447.5912, 447.5810, 447.5050, 448.1834,
            447.5606, 447.5440, 447.5842, 447.5844, 447.6233, 447.9200, 448.1264,
            447.4631, 448.1689, 448.1015, 447.6212, 448.1776, 447.6645, 447.5956,
            447.5645, 447.6673, 447.5582, 447.7562, 447.6275, 447.5787, 447.6470,
            447.5139, 447.6027, 447.8477, 447.5945, 447.9614, 447.9587, 448.1650,
            447.6899, 447.7672, 448.1192, 448.1845, 447.4857, 447.7574, 448.1803,
            447.5616, 447.5743, 448.1852, 447.7025, 447.4864, 448.0685, 447.6475,
            447.7313, 447.5406, 447.5248, 448.1842, 448.1839, 447.7560, 448.0020,
            447.7138, 447.5956, 450.9514, 447.4845, 447.8297, 448.0281, 447.6125,
            447.5258, 447.5978, 447.5972, 447.6489, 447.4779, 447.5210, 447.6063,
            448.0426, 447.5270, 447.7603, 447.8068, 447.6349, 447.5595, 447.5710,
            447.5730, 447.5847, 447.5981, 447.5310, 447.7141, 447.7559, 448.1594,
            447.5514, 447.4789, 447.6975, 447.6115, 447.4975, 447.4664, 447.5878,
            447.5221, 448.0040, 447.8241, 447.6163, 447.5385, 447.6164, 447.7263,
            448.1698, 447.7488, 447.6212, 447.9338, 447.7664, 447.4676, 447.6928,
            447.5775, 447.4366, 447.5880, 447.5180, 447.5801, 447.4684, 447.4666,
            447.6396, 447.6184, 447.5734, 447.7039, 447.6671, 447.6027, 447.5842,
            448.1674, 447.6507, 447.5645, 447.6248, 447.6001, 447.5640, 447.4832,
            448.1060, 447.5226, 447.6230, 447.9896, 447.6232, 447.6582, 447.4457,
            447.4958, 447.5305, 447.6525, 447.5483, 447.6138, 448.1852, 447.6539,
            447.7228, 447.6957, 447.5842, 447.8098, 447.4960, 447.7024, 448.1847,
            447.5833, 447.4648, 447.4647, 447.7303, 448.1844, 448.1657, 448.1662,
            448.1406, 447.5485, 447.7243, 447.6200, 447.6573, 447.4735, 447.7192,
            448.1962, 447.5030, 447.6199, 447.6081, 447.6025, 447.7609, 447.5211,
            447.4973, 447.5262, 448.0070, 447.6784, 447.5515, 447.4792, 447.4727,
            447.6062, 447.5245, 447.5768, 447.6459, 447.6953, 447.6600, 447.7611,
            447.6770, 447.9516, 447.5623, 447.4756, 447.5738, 447.5861, 447.5209,
            447.7429, 447.6086, 447.5930, 447.5445, 447.5978, 447.5869, 447.4612,
            448.1821, 447.5943, 447.5824, 448.1824, 447.9274, 448.1801, 447.7259,
            447.5930, 447.6725, 447.4635, 447.4588, 447.6966, 448.0877, 447.6349,
            447.4619, 448.0979, 447.5132, 447.5084, 447.5815, 447.5761, 447.6247,
            447.4564, 447.5841, 447.5792, 447.6319, 447.5356, 447.9523, 447.4677,
            447.7591, 447.5605, 447.6877, 448.1089, 447.7393, 447.7120, 447.7866,
            447.5019, 447.5991, 447.8619, 448.0721, 447.6102, 447.5721, 447.7343,
            447.6704, 447.5704, 447.5738, 447.4453, 447.7211, 447.9968, 447.6281,
            447.4587, 447.4767, 447.4721, 447.5486, 447.4656, 447.8786, 447.9801,
            448.1570, 447.5757, 447.5875, 448.1822, 447.5123, 447.5318, 447.5307,
            447.4953, 448.1816, 447.5401, 447.5992, 448.1111, 447.5233, 448.1846,
            448.1853, 447.5779, 447.5791, 447.6258, 448.1841, 447.4913, 447.4916,
            447.5500, 447.4382, 447.7492, 447.4513, 447.4665, 447.7448, 447.4762,
            447.6216, 448.1841, 447.5531, 447.5969, 447.6856, 447.7557, 447.4408,
            447.9988, 447.5652, 447.5470, 447.7122, 447.5662, 447.5998, 447.5812,
            447.6035, 447.6319, 447.4672, 447.4645, 447.4650, 447.6660, 447.5859,
            447.5412, 447.4858, 447.7162, 447.7622, 447.5465, 447.5881, 447.6477,
            448.1612, 447.5991, 447.7974, 447.5854, 447.6757, 447.5618, 447.4604,
            447.4685, 447.5387, 447.6588, 447.5543, 448.1803, 447.5303, 447.5580,
            447.6523, 447.5846, 447.4359, 447.5890, 447.7247, 447.5574, 447.4706,
            447.7226, 447.5924, 448.0349, 448.1805, 447.5193, 448.1857, 447.7480,
            447.5874, 447.5742, 447.8644, 447.6364, 447.5493, 447.7637, 447.5428,
            447.4731, 448.1526, 447.7429, 447.6437, 447.5714, 447.6012, 447.5108,
            447.4651, 447.5144, 447.7606, 447.5831, 447.4745, 447.5997, 447.5409,
            447.5500, 447.6497, 448.0837, 447.7991, 447.5465, 447.5895, 448.1838,
            448.1188, 447.6019, 447.6440, 447.5387, 447.5335, 447.5807, 447.7023,
            448.0177, 447.5871, 448.1659, 447.4530, 447.9670, 447.5206, 447.6042,
            447.7002, 447.5441, 447.5882, 447.6349, 447.5944, 448.1446, 447.9700,
            447.6711, 447.6503, 447.9001, 447.6982, 447.5627, 447.5858, 448.1840,
            447.6811, 447.6962, 448.1290, 447.5649, 447.6476, 447.5321, 447.5436,
            448.0891, 447.9636, 448.1015, 447.4641, 447.4808, 447.5875, 447.4671,
            448.0848, 447.6140, 447.7338, 447.5368, 447.6061, 447.6405, 447.4589,
            447.6207, 447.4664, 448.0192, 447.4512, 447.5702, 447.4716, 447.4559,
            447.6784, 448.1240], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6321, 447.5910, 447.5777, 447.7029, 447.5792, 447.4575, 447.4522,
        447.7045, 447.7708, 447.6613, 447.5698, 447.5815, 447.5942, 447.5453,
        447.5625, 447.4509, 447.6388, 447.5849, 448.0080, 447.4675, 447.6140,
        447.5387, 447.5493, 447.6595, 447.9302, 447.4581, 447.5363, 447.5885,
        447.5609, 447.6387, 447.8160, 447.5640, 447.6785, 447.6132, 447.4976,
        447.4501, 447.6236, 447.4758, 447.5146, 447.5807, 448.1376, 447.5154,
        447.5430, 447.5828, 447.7115, 447.5758, 447.4919, 448.1842, 447.4498,
        447.4628, 447.4818, 447.6339, 447.6064, 447.7031, 447.5690, 447.6339,
        448.3016, 448.1780, 447.6789, 447.6218, 447.6866, 447.7159, 447.5405,
        447.5354, 447.7522, 447.4788, 447.6364, 447.4407, 447.4472, 447.5656,
        447.6056, 447.5569, 447.4574, 447.6799, 447.4725, 447.9467, 447.5725,
        447.5900, 447.8190, 447.4522, 447.5463, 447.6249, 447.4645, 447.5347,
        448.1842, 448.1087, 447.5199, 447.4600, 447.6734, 447.8107, 447.7247,
        447.7144, 448.1849, 447.5937, 447.5847, 447.5864, 447.5262, 447.7674,
        448.0046, 448.1578, 447.7412, 447.4935, 447.5505, 448.1858, 447.5409,
        447.4622, 447.7269, 448.6957, 447.6687, 447.5502, 447.5402, 448.1824,
        447.5481, 447.9983, 448.1811, 447.8109, 447.5440, 447.6445, 447.5692,
        447.8021, 447.4657, 447.6019, 447.7424, 448.1036, 448.0531, 447.6201,
        447.5918, 447.5192, 447.6810, 447.4904, 447.7577, 447.4775, 447.7665,
        448.1678, 447.4354, 447.5757, 447.7114, 447.4703, 447.6201, 447.6016,
        448.1844, 448.0356, 448.1006, 447.6448, 448.1564, 447.5889, 447.5519,
        447.4666, 448.1732, 447.5544, 447.5490, 448.1842, 447.5359, 448.1776,
        447.4559, 447.4867, 447.5872, 447.7272, 448.1262, 447.5386, 448.1851,
        447.7072, 448.1748, 447.5210, 447.6879, 447.5511, 447.6177, 447.5671,
        447.5652, 448.1558, 447.5401, 447.5008, 447.4425, 447.8264, 448.1725,
        448.1830, 447.5856, 447.6549, 447.6067, 447.5648, 447.5230, 447.7593,
        447.6320, 447.5643, 447.8123, 447.6362, 447.7646, 447.6158, 447.6643,
        447.5563, 447.7140, 447.4786, 447.5593, 447.4800, 447.5752, 448.0373,
        447.4854, 447.6201, 447.7037, 447.5886, 447.5644, 448.1636, 447.6503,
        447.4752, 447.6316, 447.5081, 447.5203, 447.7618, 448.1744, 447.6850,
        447.5223, 447.6222, 448.1732, 447.5571, 448.1729, 447.5286, 447.9505,
        448.1652, 447.6847, 447.6239, 447.5706, 447.5410, 447.5981, 447.5246,
        447.6104, 448.0745, 447.7296, 447.5776, 447.7496, 447.7286, 447.4468,
        447.5097, 448.1444, 448.0405, 447.4933, 447.5470, 447.4620, 447.9767,
        448.1010, 447.7686, 447.6327, 447.6923, 447.7098, 448.0716, 447.5717,
        447.6353, 447.6024, 447.6293, 447.5125, 447.9721, 448.1446, 447.6362,
        447.5401, 447.6099, 447.4528, 447.5794, 447.5779, 447.6324, 447.6042,
        447.5390, 447.6044, 447.5828, 447.5823, 447.5658, 447.5654, 447.5591,
        447.5218, 447.7347, 447.6298, 447.6111, 447.7618, 447.5852, 447.7464,
        447.5019, 447.4661, 447.5590, 447.6916, 447.4549, 448.0269, 447.7690,
        447.5186, 447.5093, 447.7126, 447.5757, 447.5509, 447.6784, 447.5310,
        447.6445, 447.5263, 447.6331, 447.8830, 447.6583, 447.5248, 447.6986,
        447.6682, 447.7232, 447.6725, 447.7542, 447.7324, 447.6089, 447.6202,
        447.6125, 447.6599, 447.5469, 447.5808, 448.1853, 448.1657, 447.6766,
        448.1664, 447.4590, 447.6476, 447.5692, 447.4675, 448.1191, 448.1333,
        448.1844, 448.0670, 447.5123, 447.7541, 447.6139, 447.6969, 447.6263,
        448.1679, 447.5659, 447.9478, 447.5822, 447.7314, 447.5789, 447.7344,
        447.5278, 447.7249, 447.5773, 447.5868, 447.6318, 447.6511, 447.5995,
        447.7511, 447.5830, 447.6759, 447.7277, 447.5598, 447.5901, 448.1715,
        447.7471, 447.4957, 447.4696, 447.5952, 447.5767, 447.4612, 448.1494,
        447.6353, 447.4476, 447.6464, 447.5064, 447.6023, 447.5942, 447.4819,
        447.7615, 447.5766, 447.4861, 448.1230, 448.1309, 448.1871, 447.5493,
        447.6909, 447.5583, 447.5473, 447.5647, 447.5706, 447.5830, 447.5629,
        448.1263, 447.7080, 447.6781, 447.5804, 447.5441, 447.7335, 447.4893,
        447.7043, 447.5530, 447.4735, 447.6508, 447.5226, 447.5450, 447.5084,
        447.6529, 448.1848, 447.5985, 447.4775, 447.5634, 447.6574, 448.1798,
        447.6170, 447.4373, 447.5998, 447.5063, 448.1828, 447.6530, 447.8458,
        447.6173, 447.4626, 447.5685, 447.6102, 447.6649, 447.6237, 448.0411,
        448.1842, 447.7423, 447.5839, 448.1852, 447.4933, 447.5784, 447.5685,
        447.6531, 448.0771, 447.5707, 447.7427, 447.5440, 447.5229, 447.7251,
        447.8692, 447.8447, 447.6476, 451.1203, 447.6136, 447.4838, 447.9554,
        447.4921, 448.1834, 447.6251, 448.1846, 447.5552, 448.1019, 447.6007,
        447.5910, 447.5432, 447.9369, 447.6174, 447.5746, 447.6352, 447.5793,
        447.8005, 447.5147, 447.5919, 447.6119, 447.4485, 447.5909, 448.1836,
        448.0002, 447.5026, 447.6420, 447.5325, 447.5853, 447.7098, 447.5079,
        447.5555, 447.7474, 447.4603, 447.4673, 447.4616, 448.1751, 447.5383,
        447.4825, 447.4531, 447.4755, 447.5970, 447.7278, 447.5681, 447.4828,
        448.0412, 447.4727, 447.6740, 447.6211, 447.7324, 447.6392, 447.6164,
        447.6844, 447.4529, 447.6736, 447.5657, 447.5882, 448.1844, 448.1847,
        447.5909, 447.6878, 447.5410, 447.4602, 447.7188, 447.6525, 447.4489,
        447.9903, 447.5775, 447.4468, 447.5793, 451.2152, 447.4599, 447.4792,
        447.6078, 447.9368, 448.1850, 447.4574, 447.6441, 447.4596, 447.5726,
        447.5216, 447.4579, 448.1852, 447.5912, 447.5810, 447.5050, 448.1834,
        447.5606, 447.5440, 447.5842, 447.5844, 447.6233, 447.9200, 448.1264,
        447.4631, 448.1689, 448.1015, 447.6212, 448.1776, 447.6645, 447.5956,
        447.5645, 447.6673, 447.5582, 447.7562, 447.6275, 447.5787, 447.6470,
        447.5139, 447.6027, 447.8477, 447.5945, 447.9614, 447.9587, 448.1650,
        447.6899, 447.7672, 448.1192, 448.1845, 447.4857, 447.7574, 448.1803,
        447.5616, 447.5743, 448.1852, 447.7025, 447.4864, 448.0685, 447.6475,
        447.7313, 447.5406, 447.5248, 448.1842, 448.1839, 447.7560, 448.0020,
        447.7138, 447.5956, 450.9514, 447.4845, 447.8297, 448.0281, 447.6125,
        447.5258, 447.5978, 447.5972, 447.6489, 447.4779, 447.5210, 447.6063,
        448.0426, 447.5270, 447.7603, 447.8068, 447.6349, 447.5595, 447.5710,
        447.5730, 447.5847, 447.5981, 447.5310, 447.7141, 447.7559, 448.1594,
        447.5514, 447.4789, 447.6975, 447.6115, 447.4975, 447.4664, 447.5878,
        447.5221, 448.0040, 447.8241, 447.6163, 447.5385, 447.6164, 447.7263,
        448.1698, 447.7488, 447.6212, 447.9338, 447.7664, 447.4676, 447.6928,
        447.5775, 447.4366, 447.5880, 447.5180, 447.5801, 447.4684, 447.4666,
        447.6396, 447.6184, 447.5734, 447.7039, 447.6671, 447.6027, 447.5842,
        448.1674, 447.6507, 447.5645, 447.6248, 447.6001, 447.5640, 447.4832,
        448.1060, 447.5226, 447.6230, 447.9896, 447.6232, 447.6582, 447.4457,
        447.4958, 447.5305, 447.6525, 447.5483, 447.6138, 448.1852, 447.6539,
        447.7228, 447.6957, 447.5842, 447.8098, 447.4960, 447.7024, 448.1847,
        447.5833, 447.4648, 447.4647, 447.7303, 448.1844, 448.1657, 448.1662,
        448.1406, 447.5485, 447.7243, 447.6200, 447.6573, 447.4735, 447.7192,
        448.1962, 447.5030, 447.6199, 447.6081, 447.6025, 447.7609, 447.5211,
        447.4973, 447.5262, 448.0070, 447.6784, 447.5515, 447.4792, 447.4727,
        447.6062, 447.5245, 447.5768, 447.6459, 447.6953, 447.6600, 447.7611,
        447.6770, 447.9516, 447.5623, 447.4756, 447.5738, 447.5861, 447.5209,
        447.7429, 447.6086, 447.5930, 447.5445, 447.5978, 447.5869, 447.4612,
        448.1821, 447.5943, 447.5824, 448.1824, 447.9274, 448.1801, 447.7259,
        447.5930, 447.6725, 447.4635, 447.4588, 447.6966, 448.0877, 447.6349,
        447.4619, 448.0979, 447.5132, 447.5084, 447.5815, 447.5761, 447.6247,
        447.4564, 447.5841, 447.5792, 447.6319, 447.5356, 447.9523, 447.4677,
        447.7591, 447.5605, 447.6877, 448.1089, 447.7393, 447.7120, 447.7866,
        447.5019, 447.5991, 447.8619, 448.0721, 447.6102, 447.5721, 447.7343,
        447.6704, 447.5704, 447.5738, 447.4453, 447.7211, 447.9968, 447.6281,
        447.4587, 447.4767, 447.4721, 447.5486, 447.4656, 447.8786, 447.9801,
        448.1570, 447.5757, 447.5875, 448.1822, 447.5123, 447.5318, 447.5307,
        447.4953, 448.1816, 447.5401, 447.5992, 448.1111, 447.5233, 448.1846,
        448.1853, 447.5779, 447.5791, 447.6258, 448.1841, 447.4913, 447.4916,
        447.5500, 447.4382, 447.7492, 447.4513, 447.4665, 447.7448, 447.4762,
        447.6216, 448.1841, 447.5531, 447.5969, 447.6856, 447.7557, 447.4408,
        447.9988, 447.5652, 447.5470, 447.7122, 447.5662, 447.5998, 447.5812,
        447.6035, 447.6319, 447.4672, 447.4645, 447.4650, 447.6660, 447.5859,
        447.5412, 447.4858, 447.7162, 447.7622, 447.5465, 447.5881, 447.6477,
        448.1612, 447.5991, 447.7974, 447.5854, 447.6757, 447.5618, 447.4604,
        447.4685, 447.5387, 447.6588, 447.5543, 448.1803, 447.5303, 447.5580,
        447.6523, 447.5846, 447.4359, 447.5890, 447.7247, 447.5574, 447.4706,
        447.7226, 447.5924, 448.0349, 448.1805, 447.5193, 448.1857, 447.7480,
        447.5874, 447.5742, 447.8644, 447.6364, 447.5493, 447.7637, 447.5428,
        447.4731, 448.1526, 447.7429, 447.6437, 447.5714, 447.6012, 447.5108,
        447.4651, 447.5144, 447.7606, 447.5831, 447.4745, 447.5997, 447.5409,
        447.5500, 447.6497, 448.0837, 447.7991, 447.5465, 447.5895, 448.1838,
        448.1188, 447.6019, 447.6440, 447.5387, 447.5335, 447.5807, 447.7023,
        448.0177, 447.5871, 448.1659, 447.4530, 447.9670, 447.5206, 447.6042,
        447.7002, 447.5441, 447.5882, 447.6349, 447.5944, 448.1446, 447.9700,
        447.6711, 447.6503, 447.9001, 447.6982, 447.5627, 447.5858, 448.1840,
        447.6811, 447.6962, 448.1290, 447.5649, 447.6476, 447.5321, 447.5436,
        448.0891, 447.9636, 448.1015, 447.4641, 447.4808, 447.5875, 447.4671,
        448.0848, 447.6140, 447.7338, 447.5368, 447.6061, 447.6405, 447.4589,
        447.6207, 447.4664, 448.0192, 447.4512, 447.5702, 447.4716, 447.4559,
        447.6784, 448.1240], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([397.2014], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9940],
             [111.8664],
             [111.8986],
             [111.8986]],

            [[111.9046],
             [111.8666],
             [111.9068],
             [111.9468]],

            [[111.8590],
             [111.9355],
             [111.8595],
             [111.9306]],

            ...,

            [[111.8963],
             [111.9111],
             [111.8724],
             [111.9473]],

            [[111.9644],
             [111.8593],
             [111.9647],
             [111.8593]],

            [[111.8616],
             [111.8640],
             [111.8597],
             [111.8745]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6577, 447.6248, 447.5847,  ..., 447.6271, 447.6477, 447.4599],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6577, 447.6248, 447.5847,  ..., 447.6271, 447.6477, 447.4599],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8804],
             [111.8804],
             [111.8895],
             [111.8895]],

            [[112.0678],
             [112.0576],
             [112.0634],
             [112.0634]],

            [[111.9428],
             [111.9428],
             [111.9607],
             [111.9607]],

            ...,

            [[111.9003],
             [111.9543],
             [111.9562],
             [111.9652]],

            [[111.8805],
             [111.8805],
             [111.8804],
             [111.8804]],

            [[111.9019],
             [111.9295],
             [111.9673],
             [111.8947]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5398, 448.2521, 447.8069,  ..., 447.7759, 447.5217, 447.6935],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5398, 448.2521, 447.8069,  ..., 447.7759, 447.5217, 447.6935],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8912],
             [111.9682],
             [111.9412],
             [111.9729]],

            [[111.9733],
             [111.9749],
             [111.9736],
             [111.9735]],

            [[111.9600],
             [111.9725],
             [111.9831],
             [111.9831]],

            ...,

            [[111.9748],
             [111.9709],
             [111.9028],
             [111.9010]],

            [[111.9486],
             [111.8880],
             [111.8894],
             [111.9309]],

            [[111.8886],
             [111.8886],
             [111.9566],
             [111.9566]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7735, 447.8953, 447.8986,  ..., 447.7496, 447.6569, 447.6905],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7735, 447.8953, 447.8986,  ..., 447.7496, 447.6569, 447.6905],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0997],
             [112.0998],
             [112.0998],
             [112.0999]],

            [[111.9051],
             [111.9066],
             [111.9004],
             [111.9292]],

            [[111.9048],
             [111.9006],
             [112.0138],
             [112.0138]],

            ...,

            [[111.9387],
             [111.9951],
             [111.9817],
             [111.9817]],

            [[111.9394],
             [111.9394],
             [111.9472],
             [111.9472]],

            [[111.9818],
             [111.9818],
             [111.9812],
             [111.9812]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3992, 447.6412, 447.8331,  ..., 447.8972, 447.7733, 447.9261],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3992, 447.6412, 447.8331,  ..., 447.8972, 447.7733, 447.9261],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0376],
             [112.0376],
             [111.9221],
             [111.9221]],

            [[111.9431],
             [112.0295],
             [111.9470],
             [111.9213]],

            [[112.1432],
             [112.1454],
             [112.1458],
             [112.1418]],

            ...,

            [[112.1463],
             [112.1463],
             [112.1463],
             [112.1463]],

            [[112.1404],
             [112.0667],
             [112.0691],
             [112.1463]],

            [[111.9874],
             [111.9189],
             [111.9912],
             [111.9189]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9193, 447.8409, 448.5762,  ..., 448.5851, 448.4225, 447.8164],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9193, 447.8409, 448.5762,  ..., 448.5851, 448.4225, 447.8164],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1438],
             [112.1750],
             [112.1751],
             [112.1470]],

            [[111.9890],
             [111.9890],
             [112.0401],
             [112.0401]],

            [[111.9197],
             [111.9995],
             [111.9217],
             [112.0143]],

            ...,

            [[112.0927],
             [112.0927],
             [111.9474],
             [111.9474]],

            [[111.9205],
             [111.9205],
             [111.9208],
             [111.9208]],

            [[112.0332],
             [112.0332],
             [112.0341],
             [112.0341]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6409, 448.0582, 447.8552,  ..., 448.0801, 447.6824, 448.1346],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6409, 448.0582, 447.8552,  ..., 448.0801, 447.6824, 448.1346],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9803],
             [112.0433],
             [111.9449],
             [111.9449]],

            [[111.9644],
             [111.9606],
             [111.9309],
             [112.0586]],

            [[112.0163],
             [111.9231],
             [111.9241],
             [112.0343]],

            ...,

            [[112.0427],
             [112.0401],
             [112.0402],
             [112.0418]],

            [[111.9635],
             [111.9732],
             [111.9387],
             [112.0470]],

            [[112.0789],
             [112.1992],
             [112.2014],
             [112.0654]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9134, 447.9146, 447.8977,  ..., 448.1649, 447.9223, 448.5449],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9134, 447.9146, 447.8977,  ..., 448.1649, 447.9223, 448.5449],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2465],
             [112.2465],
             [112.2461],
             [112.2461]],

            [[112.0088],
             [112.0652],
             [112.0552],
             [112.0552]],

            [[112.0268],
             [112.0268],
             [112.0676],
             [112.0676]],

            ...,

            [[111.9277],
             [112.0314],
             [111.9302],
             [112.0397]],

            [[111.9286],
             [111.9719],
             [111.9288],
             [111.9808]],

            [[112.1923],
             [111.9676],
             [112.2084],
             [111.9791]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9852, 448.1843, 448.1887,  ..., 447.9291, 447.8101, 448.3474],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9852, 448.1843, 448.1887,  ..., 447.9291, 447.8101, 448.3474],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9569],
             [111.9569],
             [111.9476],
             [111.9476]],

            [[112.3123],
             [112.3123],
             [112.3121],
             [112.3121]],

            [[112.3120],
             [112.3119],
             [112.3119],
             [112.3123]],

            ...,

            [[112.4220],
             [112.4920],
             [112.0686],
             [112.1743]],

            [[111.9396],
             [112.0699],
             [111.9467],
             [112.0832]],

            [[111.9594],
             [112.0564],
             [111.9587],
             [112.0956]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8090, 449.2487, 449.2480,  ..., 449.1569, 448.0394, 448.0701],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8090, 449.2487, 449.2480,  ..., 449.1569, 448.0394, 448.0701],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0194],
             [112.0769],
             [112.1219],
             [111.9889]],

            [[111.9493],
             [111.9714],
             [112.0218],
             [111.9950]],

            [[111.9594],
             [112.0508],
             [111.9506],
             [111.9565]],

            ...,

            [[111.9498],
             [112.0641],
             [112.0033],
             [112.0033]],

            [[112.0574],
             [111.9504],
             [112.0470],
             [112.0470]],

            [[112.1030],
             [112.1030],
             [112.1269],
             [112.1269]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2072, 447.9375, 447.9173,  ..., 448.0206, 448.1018, 448.4598],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2072, 447.9375, 447.9173,  ..., 448.0206, 448.1018, 448.4598],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9642],
             [112.0307],
             [111.9639],
             [111.9639]],

            [[112.0852],
             [112.0847],
             [112.1549],
             [112.0123]],

            [[112.2847],
             [112.2847],
             [112.2813],
             [112.2813]],

            ...,

            [[111.9623],
             [112.0532],
             [111.9634],
             [112.0984]],

            [[112.1369],
             [112.1123],
             [112.1395],
             [112.1161]],

            [[111.9616],
             [112.1037],
             [111.9617],
             [111.9617]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9227, 448.3371, 449.1319,  ..., 448.0772, 448.5049, 447.9887],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9227, 448.3371, 449.1319,  ..., 448.0772, 448.5049, 447.9887],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1146],
             [112.0321],
             [112.1848],
             [111.9934]],

            [[112.4674],
             [112.2350],
             [112.2410],
             [112.4848]],

            [[111.9838],
             [111.9838],
             [112.0036],
             [112.0036]],

            ...,

            [[112.0070],
             [112.0149],
             [111.9928],
             [111.9928]],

            [[112.1644],
             [112.1719],
             [112.1675],
             [112.1675]],

            [[112.1592],
             [112.1592],
             [112.1643],
             [112.1643]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3248, 449.4282, 447.9747,  ..., 448.0076, 448.6713, 448.6469],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3248, 449.4282, 447.9747,  ..., 448.0076, 448.6713, 448.6469],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0080],
             [112.0007],
             [112.0953],
             [112.1758]],

            [[112.5302],
             [112.5302],
             [112.5301],
             [112.5301]],

            [[111.9970],
             [112.1927],
             [112.1857],
             [112.1757]],

            ...,

            [[112.9764],
             [113.0921],
             [113.1282],
             [113.1567]],

            [[111.9968],
             [111.9973],
             [112.1349],
             [112.1753]],

            [[112.0250],
             [112.1614],
             [112.0097],
             [112.1705]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2798, 450.1206, 448.5511,  ..., 452.3533, 448.3044, 448.3666],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2798, 450.1206, 448.5511,  ..., 452.3533, 448.3044, 448.3666],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0248],
             [112.0248],
             [112.0213],
             [112.0213]],

            [[112.1872],
             [112.1969],
             [112.1614],
             [112.2095]],

            [[112.1509],
             [112.0668],
             [112.2179],
             [112.0298]],

            ...,

            [[112.5719],
             [112.5101],
             [112.5568],
             [112.5568]],

            [[112.5180],
             [112.0791],
             [112.2384],
             [112.2384]],

            [[112.0536],
             [112.2220],
             [112.1373],
             [112.2180]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0922, 448.7550, 448.4654,  ..., 450.1955, 449.0740, 448.6309],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0922, 448.7550, 448.4654,  ..., 450.1955, 449.0740, 448.6309],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2915],
             [112.0613],
             [112.0451],
             [112.3207]],

            [[112.1577],
             [112.2479],
             [112.1831],
             [112.1831]],

            [[112.0114],
             [112.0135],
             [112.1830],
             [112.1830]],

            ...,

            [[112.0304],
             [112.1356],
             [112.1811],
             [112.2443]],

            [[112.5715],
             [112.1311],
             [112.3950],
             [112.3950]],

            [[112.0181],
             [112.0183],
             [112.0232],
             [112.0498]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7186, 448.7719, 448.3911,  ..., 448.5914, 449.4925, 448.1093],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7186, 448.7719, 448.3911,  ..., 448.5914, 449.4925, 448.1093],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0343],
             [112.0343],
             [112.0247],
             [112.0247]],

            [[112.0813],
             [112.4642],
             [112.3871],
             [112.0157]],

            [[112.3944],
             [112.0226],
             [112.2097],
             [112.0003]],

            ...,

            [[112.6340],
             [112.6343],
             [112.6343],
             [112.6346]],

            [[112.0239],
             [112.2047],
             [112.0010],
             [112.0573]],

            [[112.1795],
             [112.0029],
             [112.0014],
             [112.2058]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1180, 448.9483, 448.6270,  ..., 450.5372, 448.2868, 448.3896],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1180, 448.9483, 448.6270,  ..., 450.5372, 448.2868, 448.3896],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3733],
             [111.9953],
             [112.3797],
             [111.9953]],

            [[112.1243],
             [112.1277],
             [112.0876],
             [112.2667]],

            [[112.2319],
             [112.2315],
             [112.2480],
             [112.0152]],

            ...,

            [[112.6515],
             [112.6515],
             [112.6515],
             [112.6515]],

            [[112.1460],
             [112.1555],
             [112.1132],
             [112.2564]],

            [[112.4322],
             [111.9957],
             [112.0047],
             [112.0915]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7436, 448.6063, 448.7266,  ..., 450.6059, 448.6710, 448.5242],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7436, 448.6063, 448.7266,  ..., 450.6059, 448.6710, 448.5242],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0703],
             [112.2198],
             [111.9969],
             [112.2358]],

            [[112.5487],
             [112.6028],
             [112.6426],
             [112.4385]],

            [[112.2173],
             [112.2173],
             [112.2635],
             [112.2635]],

            ...,

            [[112.6551],
             [112.5759],
             [112.6220],
             [112.6220]],

            [[111.9840],
             [112.2172],
             [112.0151],
             [112.2453]],

            [[112.1546],
             [112.1295],
             [111.9839],
             [111.9840]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5229, 450.2326, 448.9617,  ..., 450.4750, 448.4615, 448.2520],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5229, 450.2326, 448.9617,  ..., 450.4750, 448.4615, 448.2520],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0355e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0456],
             [111.9936],
             [111.9886],
             [112.0966]],

            [[112.2657],
             [112.2585],
             [112.2561],
             [112.2664]],

            [[111.9918],
             [112.4479],
             [111.9825],
             [112.4170]],

            ...,

            [[112.5601],
             [111.9934],
             [112.2087],
             [112.0756]],

            [[112.1248],
             [112.1248],
             [111.9817],
             [111.9817]],

            [[112.2390],
             [112.2546],
             [112.2486],
             [112.2569]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1244, 449.0467, 448.8392,  ..., 448.8377, 448.2130, 448.9991],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1244, 449.0467, 448.8392,  ..., 448.8377, 448.2130, 448.9991],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2486],
             [112.2486],
             [112.2612],
             [112.2612]],

            [[112.0620],
             [112.2674],
             [111.9853],
             [112.1892]],

            [[112.1810],
             [112.2742],
             [111.9915],
             [112.1581]],

            ...,

            [[112.0105],
             [112.2318],
             [112.2237],
             [112.0652]],

            [[112.0914],
             [112.2580],
             [112.0909],
             [112.2580]],

            [[112.2104],
             [112.0973],
             [112.0059],
             [112.2706]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0196, 448.5039, 448.6048,  ..., 448.5311, 448.6983, 448.5843],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0196, 448.5039, 448.6048,  ..., 448.5311, 448.6983, 448.5843],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6279],
             [112.1084],
             [112.1085],
             [112.6652]],

            [[111.9824],
             [111.9824],
             [112.0026],
             [112.0026]],

            [[112.0614],
             [112.0614],
             [112.2494],
             [112.2494]],

            ...,

            [[112.6638],
             [112.6638],
             [112.6639],
             [112.6639]],

            [[112.5943],
             [112.5943],
             [112.6032],
             [112.6032]],

            [[112.2582],
             [112.2672],
             [112.2488],
             [112.2600]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.5099, 447.9700, 448.6215, 449.6639, 448.4739, 448.9947, 449.0231,
            448.6493, 448.1862, 447.9890, 450.5575, 448.3643, 448.8047, 448.8037,
            448.1017, 447.9353, 450.0700, 449.2971, 448.4785, 448.6915, 448.9976,
            450.4221, 448.8920, 448.5786, 448.9275, 448.1487, 448.8231, 448.6483,
            448.6506, 448.6730, 449.7058, 448.5727, 448.7977, 448.3964, 448.8962,
            448.6106, 448.9286, 448.5378, 447.9413, 448.4199, 448.9945, 450.1274,
            448.3730, 448.6722, 448.2506, 448.7369, 449.1650, 448.6183, 448.6182,
            447.9960, 448.5742, 448.9701, 448.8599, 450.1641, 448.6228, 449.4714,
            450.6078, 448.6765, 448.5658, 449.2878, 448.6293, 448.3772, 448.5595,
            449.0457, 448.9793, 448.9972, 448.4002, 448.2818, 448.0122, 449.3192,
            448.4805, 448.5116, 448.0685, 450.6011, 448.6333, 448.6299, 448.4627,
            448.9009, 448.4151, 448.1550, 448.6374, 448.4251, 448.4066, 448.6677,
            448.4326, 448.4719, 448.0510, 447.9873, 448.8074, 449.0125, 448.3126,
            448.6862, 448.4433, 448.4553, 448.5907, 449.3256, 449.0060, 448.9664,
            448.9471, 448.4148, 448.5790, 448.3559, 450.4037, 448.4664, 448.9958,
            448.0110, 448.5048, 448.4916, 448.9267, 448.6271, 448.1694, 448.3972,
            448.2430, 448.9904, 448.6576, 448.2556, 448.1620, 448.1731, 448.9182,
            448.4545, 448.6499, 450.1985, 448.5288, 448.8293, 448.2273, 449.4371,
            449.1291, 447.9428, 448.5786, 448.6990, 448.4630, 448.6876, 449.0468,
            448.9778, 448.4612, 449.0351, 448.4736, 449.5686, 448.6393, 448.1863,
            447.9310, 449.0027, 448.4953, 448.2107, 450.5946, 448.0762, 448.0814,
            448.3086, 448.9830, 448.4263, 448.5522, 448.4058, 450.6603, 449.4460,
            448.6834, 448.3365, 448.3513, 448.7729, 448.7634, 448.7996, 448.6185,
            448.0536, 448.4781, 448.4650, 449.6506, 448.9623, 448.7253, 448.5102,
            448.6053, 448.1344, 447.9310, 448.8093, 448.4349, 448.7792, 449.9146,
            448.3130, 448.9902, 447.9268, 448.2457, 448.0687, 450.6584, 450.5945,
            449.0089, 448.7866, 448.9353, 448.3081, 448.1296, 448.4416, 447.9447,
            448.5987, 448.6876, 448.8181, 448.3996, 448.4234, 448.5001, 448.7389,
            448.8913, 448.7099, 448.2392, 448.8661, 450.5299, 450.5156, 448.4597,
            448.5680, 448.0908, 448.1837, 448.6092, 448.6881, 448.7700, 448.3826,
            448.5500, 448.2458, 448.4393, 448.9920, 450.2651, 447.9647, 448.0792,
            448.7510, 449.4683, 450.6545, 448.8280, 448.5017, 448.0059, 448.7184,
            448.6556, 449.7130, 448.5687, 448.8494, 448.7041, 449.0411, 449.0297,
            448.2215, 450.5950, 448.5264, 448.0944, 448.0025, 448.3334, 448.4342,
            448.7085, 449.0264, 448.6387, 448.2696, 448.4604, 448.7914, 450.6488,
            448.3078, 449.0608, 448.0319, 448.0217, 449.2053, 448.5125, 447.9704,
            448.9318, 448.6767, 448.9675, 448.9982, 449.6594, 448.4453, 448.6288,
            448.8191, 448.4021, 448.5176, 448.2384, 448.5206, 448.3752, 448.9943,
            448.0476, 448.2479, 448.6159, 448.7453, 447.9899, 450.6148, 448.6357,
            448.1560, 448.6343, 448.1005, 448.0685, 450.5157, 449.0018, 448.6330,
            448.5523, 448.9609, 448.7227, 448.1730, 450.5707, 448.6388, 448.4280,
            448.6951, 448.4272, 448.7826, 448.1938, 450.6609, 448.2563, 448.6296,
            448.5345, 448.6506, 448.9858, 448.8443, 448.2546, 448.0734, 450.3447,
            448.6807, 448.5857, 448.0676, 448.0236, 450.5454, 448.6215, 448.5786,
            448.4708, 449.0165, 448.9317, 450.6428, 449.0585, 448.5038, 448.7797,
            448.4054, 448.0138, 448.7688, 449.2584, 448.5561, 448.7808, 449.9334,
            448.9425, 448.3437, 450.5667, 448.7029, 448.4091, 448.5766, 448.1035,
            448.0197, 448.0477, 448.0207, 448.4559, 450.6180, 448.7504, 448.5670,
            448.5410, 450.4802, 450.6216, 448.8984, 448.8391, 448.3861, 449.0348,
            448.8428, 449.2300, 448.3477, 448.6288, 448.1238, 450.6308, 448.7609,
            449.3112, 448.2358, 447.9453, 448.5211, 448.9249, 450.6105, 448.4357,
            449.4692, 450.2851, 448.6749, 448.0388, 448.8911, 448.8092, 448.4690,
            448.4999, 449.3966, 448.5004, 448.8304, 449.4565, 449.0392, 448.6694,
            448.3807, 449.0000, 448.2166, 448.7664, 449.4473, 448.6361, 448.5306,
            448.8285, 450.2770, 448.8512, 448.4785, 448.3888, 448.4500, 450.4691,
            448.5015, 448.5805, 448.6483, 448.7413, 448.0741, 448.0333, 448.4359,
            448.7974, 448.4493, 448.2066, 448.7959, 448.5062, 448.3410, 448.4694,
            448.6166, 450.5717, 448.7378, 448.2435, 448.7383, 448.9041, 450.6543,
            447.9638, 448.6344, 447.9544, 448.8347, 448.4744, 450.4596, 448.1552,
            448.0744, 448.0078, 450.6505, 448.1371, 448.7081, 450.5450, 448.5037,
            448.7277, 448.7569, 448.0273, 448.5321, 448.6866, 448.5129, 450.3000,
            448.4659, 448.3187, 448.9596, 450.1374, 448.6140, 448.9996, 448.3224,
            448.4410, 450.6526, 448.1989, 448.9054, 448.5524, 448.4213, 449.0613,
            448.4630, 448.4453, 450.5830, 448.6257, 448.3036, 448.5419, 449.2966,
            448.6712, 449.9385, 448.7407, 448.7462, 448.9370, 449.0648, 447.9416,
            448.9973, 448.8665, 450.1941, 448.3801, 448.4073, 448.4568, 449.0508,
            450.5111, 448.0187, 448.8383, 448.4514, 448.9805, 450.6190, 449.0034,
            450.6578, 449.7081, 448.4417, 448.7596, 448.3451, 448.7071, 449.3575,
            448.4344, 448.8830, 448.6912, 447.9249, 448.8354, 448.6418, 448.8439,
            448.7079, 448.3064, 447.9264, 448.7164, 448.9966, 448.1323, 449.5273,
            448.3954, 448.2881, 448.4222, 448.7258, 448.7766, 447.9264, 448.0753,
            449.6132, 448.3869, 449.0066, 450.2803, 448.3100, 448.9569, 449.3184,
            447.9950, 448.0333, 448.7021, 448.8104, 448.6367, 448.2603, 448.3962,
            448.4688, 448.9406, 448.5041, 449.0048, 448.2484, 448.7130, 448.8992,
            448.4674, 448.0898, 450.6342, 452.2310, 449.0019, 449.0387, 448.3699,
            448.5055, 448.7807, 448.4446, 448.6944, 450.0424, 448.6029, 448.9975,
            448.5990, 449.5990, 447.9395, 448.7474, 448.4735, 448.7985, 448.4306,
            447.9483, 450.1299, 448.8870, 448.3265, 452.8088, 448.0451, 448.7502,
            450.5885, 448.7943, 448.3378, 449.0386, 448.5858, 448.8419, 448.0923,
            448.6346, 448.4482, 448.3438, 449.6252, 450.6474, 448.4165, 448.7303,
            449.6446, 447.9370, 449.0173, 448.7193, 448.6352, 448.7284, 448.5764,
            450.6577, 448.4257, 448.3351, 448.6197, 448.7188, 448.9706, 448.6484,
            449.0016, 448.3082, 448.6835, 448.1291, 450.6559, 448.8665, 448.0783,
            448.6783, 448.4848, 448.0869, 449.7941, 452.8079, 448.5230, 448.8029,
            448.6544, 449.0046, 449.6973, 450.6540, 449.8834, 450.6489, 448.5162,
            448.6574, 450.0154, 448.1053, 448.4420, 448.8828, 450.4622, 448.6747,
            449.7271, 448.9600, 448.5502, 448.8962, 448.8466, 448.2825, 447.9741,
            449.3904, 448.2385, 449.9102, 448.0274, 448.8978, 449.0220, 448.4942,
            448.4249, 448.2078, 449.6991, 448.4420, 448.6904, 449.0773, 448.9822,
            448.7063, 448.8383, 448.5229, 448.1762, 448.4551, 448.9677, 448.4257,
            450.3633, 448.2587, 448.3233, 450.6338, 448.6584, 448.5165, 450.6596,
            450.6263, 448.9993, 448.4632, 450.6160, 448.5371, 448.2964, 448.4137,
            448.1957, 448.9254, 448.6503, 448.2447, 448.9385, 449.6212, 448.1509,
            449.1432, 448.9991, 448.7999, 448.4335, 448.3545, 448.6391, 448.1382,
            449.0166, 448.3151, 447.9576, 448.6163, 448.8678, 448.6991, 448.9899,
            448.9960, 448.4018, 450.4304, 448.9695, 448.6730, 448.7094, 448.5612,
            449.0409, 450.6185, 448.2913, 448.6792, 448.0220, 448.4825, 448.5871,
            448.9772, 448.1989, 448.3668, 448.0956, 447.9624, 448.5086, 450.1716,
            448.4628, 448.1460, 448.4534, 448.3253, 448.1437, 448.7127, 448.5157,
            448.8830, 448.8889, 448.5238, 448.2619, 448.1167, 449.0607, 448.4087,
            448.6196, 448.3668, 448.4318, 448.4938, 450.5055, 450.5742, 449.0030,
            448.9618, 448.7038, 448.2726, 448.7573, 448.9068, 448.3241, 448.7234,
            448.0684, 448.8501, 449.0446, 448.5522, 448.6082, 448.6111, 448.8110,
            448.5202, 448.7399, 448.7213, 450.6565, 448.0764, 448.7770, 448.5382,
            448.6561, 448.5560, 448.7207, 448.0484, 450.6546, 448.2072, 450.4202,
            448.6196, 448.4359, 448.7686, 450.6587, 449.0403, 448.9837, 448.8463,
            448.5873, 448.7581, 448.8805, 448.0676, 448.7118, 449.1794, 449.1033,
            448.1769, 448.6489, 449.4103, 448.1436, 448.4930, 449.2131, 449.0192,
            448.5244, 448.9163, 449.9958, 448.5154, 448.5527, 449.0295, 450.5183,
            448.6380, 448.4662, 449.0597, 449.0172, 450.5139, 449.0297, 448.6579,
            448.0010, 448.2144, 450.4631, 448.6020, 448.1891, 448.9055, 448.9837,
            448.9097, 449.0422, 448.6985, 449.9327, 448.8646, 448.4479, 449.0613,
            450.6603, 448.5793, 450.4069, 448.4256, 450.6557, 448.4407, 448.7867,
            448.6299, 448.2154, 449.0472, 448.7751, 448.3085, 448.4696, 448.7185,
            448.2016, 448.7590, 448.6410, 448.9277, 447.9952, 452.4781, 449.0908,
            448.1030, 449.4932, 448.4962, 448.9829, 448.0710, 448.2744, 449.1353,
            448.5377, 448.6543, 448.6231, 448.5142, 448.7629, 448.4784, 448.5122,
            448.6454, 448.3683, 448.6143, 448.3676, 450.5615, 448.9402, 448.4781,
            448.0707, 448.4306, 448.5353, 448.2026, 448.0044, 448.0335, 448.7613,
            448.8048, 448.9764, 448.1992, 449.1678, 449.9424, 449.0616, 448.6069,
            448.5962, 449.1377, 448.2547, 447.9959, 448.5234, 452.6123, 448.5210,
            450.6582, 448.9219, 448.9550, 448.6223, 448.7821, 449.0621, 448.8212,
            448.1839, 448.5710, 448.7153, 449.1412, 448.2418, 448.6629, 448.4717,
            448.9158, 448.2345, 448.9532, 448.6535, 448.4159, 450.5595, 448.3497,
            448.6797, 448.0435, 449.0297, 450.1041, 448.4717, 448.8575, 448.3504,
            448.4580, 449.7074, 450.4981, 449.6907, 448.4418, 448.4554, 450.6567,
            449.0071, 448.9834, 448.8835, 448.5496, 448.0990, 448.9759, 448.4120,
            449.0027, 448.0524, 448.3230, 450.6116, 448.8645, 448.9729, 447.9397,
            449.7384, 448.4833, 448.7626, 448.6069, 448.3353, 449.0502, 449.6348,
            448.8546, 449.0818, 450.5186, 450.6466, 448.9481, 448.0276, 448.4194,
            450.0426, 448.1414, 448.8572, 448.5522, 448.1727, 448.1771, 448.4606,
            448.7733, 448.2913, 449.0284, 450.5127, 450.4563, 448.4008, 450.6553,
            450.3950, 449.0343], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.5099, 447.9700, 448.6215, 449.6639, 448.4739, 448.9947, 449.0231,
        448.6493, 448.1862, 447.9890, 450.5575, 448.3643, 448.8047, 448.8037,
        448.1017, 447.9353, 450.0700, 449.2971, 448.4785, 448.6915, 448.9976,
        450.4221, 448.8920, 448.5786, 448.9275, 448.1487, 448.8231, 448.6483,
        448.6506, 448.6730, 449.7058, 448.5727, 448.7977, 448.3964, 448.8962,
        448.6106, 448.9286, 448.5378, 447.9413, 448.4199, 448.9945, 450.1274,
        448.3730, 448.6722, 448.2506, 448.7369, 449.1650, 448.6183, 448.6182,
        447.9960, 448.5742, 448.9701, 448.8599, 450.1641, 448.6228, 449.4714,
        450.6078, 448.6765, 448.5658, 449.2878, 448.6293, 448.3772, 448.5595,
        449.0457, 448.9793, 448.9972, 448.4002, 448.2818, 448.0122, 449.3192,
        448.4805, 448.5116, 448.0685, 450.6011, 448.6333, 448.6299, 448.4627,
        448.9009, 448.4151, 448.1550, 448.6374, 448.4251, 448.4066, 448.6677,
        448.4326, 448.4719, 448.0510, 447.9873, 448.8074, 449.0125, 448.3126,
        448.6862, 448.4433, 448.4553, 448.5907, 449.3256, 449.0060, 448.9664,
        448.9471, 448.4148, 448.5790, 448.3559, 450.4037, 448.4664, 448.9958,
        448.0110, 448.5048, 448.4916, 448.9267, 448.6271, 448.1694, 448.3972,
        448.2430, 448.9904, 448.6576, 448.2556, 448.1620, 448.1731, 448.9182,
        448.4545, 448.6499, 450.1985, 448.5288, 448.8293, 448.2273, 449.4371,
        449.1291, 447.9428, 448.5786, 448.6990, 448.4630, 448.6876, 449.0468,
        448.9778, 448.4612, 449.0351, 448.4736, 449.5686, 448.6393, 448.1863,
        447.9310, 449.0027, 448.4953, 448.2107, 450.5946, 448.0762, 448.0814,
        448.3086, 448.9830, 448.4263, 448.5522, 448.4058, 450.6603, 449.4460,
        448.6834, 448.3365, 448.3513, 448.7729, 448.7634, 448.7996, 448.6185,
        448.0536, 448.4781, 448.4650, 449.6506, 448.9623, 448.7253, 448.5102,
        448.6053, 448.1344, 447.9310, 448.8093, 448.4349, 448.7792, 449.9146,
        448.3130, 448.9902, 447.9268, 448.2457, 448.0687, 450.6584, 450.5945,
        449.0089, 448.7866, 448.9353, 448.3081, 448.1296, 448.4416, 447.9447,
        448.5987, 448.6876, 448.8181, 448.3996, 448.4234, 448.5001, 448.7389,
        448.8913, 448.7099, 448.2392, 448.8661, 450.5299, 450.5156, 448.4597,
        448.5680, 448.0908, 448.1837, 448.6092, 448.6881, 448.7700, 448.3826,
        448.5500, 448.2458, 448.4393, 448.9920, 450.2651, 447.9647, 448.0792,
        448.7510, 449.4683, 450.6545, 448.8280, 448.5017, 448.0059, 448.7184,
        448.6556, 449.7130, 448.5687, 448.8494, 448.7041, 449.0411, 449.0297,
        448.2215, 450.5950, 448.5264, 448.0944, 448.0025, 448.3334, 448.4342,
        448.7085, 449.0264, 448.6387, 448.2696, 448.4604, 448.7914, 450.6488,
        448.3078, 449.0608, 448.0319, 448.0217, 449.2053, 448.5125, 447.9704,
        448.9318, 448.6767, 448.9675, 448.9982, 449.6594, 448.4453, 448.6288,
        448.8191, 448.4021, 448.5176, 448.2384, 448.5206, 448.3752, 448.9943,
        448.0476, 448.2479, 448.6159, 448.7453, 447.9899, 450.6148, 448.6357,
        448.1560, 448.6343, 448.1005, 448.0685, 450.5157, 449.0018, 448.6330,
        448.5523, 448.9609, 448.7227, 448.1730, 450.5707, 448.6388, 448.4280,
        448.6951, 448.4272, 448.7826, 448.1938, 450.6609, 448.2563, 448.6296,
        448.5345, 448.6506, 448.9858, 448.8443, 448.2546, 448.0734, 450.3447,
        448.6807, 448.5857, 448.0676, 448.0236, 450.5454, 448.6215, 448.5786,
        448.4708, 449.0165, 448.9317, 450.6428, 449.0585, 448.5038, 448.7797,
        448.4054, 448.0138, 448.7688, 449.2584, 448.5561, 448.7808, 449.9334,
        448.9425, 448.3437, 450.5667, 448.7029, 448.4091, 448.5766, 448.1035,
        448.0197, 448.0477, 448.0207, 448.4559, 450.6180, 448.7504, 448.5670,
        448.5410, 450.4802, 450.6216, 448.8984, 448.8391, 448.3861, 449.0348,
        448.8428, 449.2300, 448.3477, 448.6288, 448.1238, 450.6308, 448.7609,
        449.3112, 448.2358, 447.9453, 448.5211, 448.9249, 450.6105, 448.4357,
        449.4692, 450.2851, 448.6749, 448.0388, 448.8911, 448.8092, 448.4690,
        448.4999, 449.3966, 448.5004, 448.8304, 449.4565, 449.0392, 448.6694,
        448.3807, 449.0000, 448.2166, 448.7664, 449.4473, 448.6361, 448.5306,
        448.8285, 450.2770, 448.8512, 448.4785, 448.3888, 448.4500, 450.4691,
        448.5015, 448.5805, 448.6483, 448.7413, 448.0741, 448.0333, 448.4359,
        448.7974, 448.4493, 448.2066, 448.7959, 448.5062, 448.3410, 448.4694,
        448.6166, 450.5717, 448.7378, 448.2435, 448.7383, 448.9041, 450.6543,
        447.9638, 448.6344, 447.9544, 448.8347, 448.4744, 450.4596, 448.1552,
        448.0744, 448.0078, 450.6505, 448.1371, 448.7081, 450.5450, 448.5037,
        448.7277, 448.7569, 448.0273, 448.5321, 448.6866, 448.5129, 450.3000,
        448.4659, 448.3187, 448.9596, 450.1374, 448.6140, 448.9996, 448.3224,
        448.4410, 450.6526, 448.1989, 448.9054, 448.5524, 448.4213, 449.0613,
        448.4630, 448.4453, 450.5830, 448.6257, 448.3036, 448.5419, 449.2966,
        448.6712, 449.9385, 448.7407, 448.7462, 448.9370, 449.0648, 447.9416,
        448.9973, 448.8665, 450.1941, 448.3801, 448.4073, 448.4568, 449.0508,
        450.5111, 448.0187, 448.8383, 448.4514, 448.9805, 450.6190, 449.0034,
        450.6578, 449.7081, 448.4417, 448.7596, 448.3451, 448.7071, 449.3575,
        448.4344, 448.8830, 448.6912, 447.9249, 448.8354, 448.6418, 448.8439,
        448.7079, 448.3064, 447.9264, 448.7164, 448.9966, 448.1323, 449.5273,
        448.3954, 448.2881, 448.4222, 448.7258, 448.7766, 447.9264, 448.0753,
        449.6132, 448.3869, 449.0066, 450.2803, 448.3100, 448.9569, 449.3184,
        447.9950, 448.0333, 448.7021, 448.8104, 448.6367, 448.2603, 448.3962,
        448.4688, 448.9406, 448.5041, 449.0048, 448.2484, 448.7130, 448.8992,
        448.4674, 448.0898, 450.6342, 452.2310, 449.0019, 449.0387, 448.3699,
        448.5055, 448.7807, 448.4446, 448.6944, 450.0424, 448.6029, 448.9975,
        448.5990, 449.5990, 447.9395, 448.7474, 448.4735, 448.7985, 448.4306,
        447.9483, 450.1299, 448.8870, 448.3265, 452.8088, 448.0451, 448.7502,
        450.5885, 448.7943, 448.3378, 449.0386, 448.5858, 448.8419, 448.0923,
        448.6346, 448.4482, 448.3438, 449.6252, 450.6474, 448.4165, 448.7303,
        449.6446, 447.9370, 449.0173, 448.7193, 448.6352, 448.7284, 448.5764,
        450.6577, 448.4257, 448.3351, 448.6197, 448.7188, 448.9706, 448.6484,
        449.0016, 448.3082, 448.6835, 448.1291, 450.6559, 448.8665, 448.0783,
        448.6783, 448.4848, 448.0869, 449.7941, 452.8079, 448.5230, 448.8029,
        448.6544, 449.0046, 449.6973, 450.6540, 449.8834, 450.6489, 448.5162,
        448.6574, 450.0154, 448.1053, 448.4420, 448.8828, 450.4622, 448.6747,
        449.7271, 448.9600, 448.5502, 448.8962, 448.8466, 448.2825, 447.9741,
        449.3904, 448.2385, 449.9102, 448.0274, 448.8978, 449.0220, 448.4942,
        448.4249, 448.2078, 449.6991, 448.4420, 448.6904, 449.0773, 448.9822,
        448.7063, 448.8383, 448.5229, 448.1762, 448.4551, 448.9677, 448.4257,
        450.3633, 448.2587, 448.3233, 450.6338, 448.6584, 448.5165, 450.6596,
        450.6263, 448.9993, 448.4632, 450.6160, 448.5371, 448.2964, 448.4137,
        448.1957, 448.9254, 448.6503, 448.2447, 448.9385, 449.6212, 448.1509,
        449.1432, 448.9991, 448.7999, 448.4335, 448.3545, 448.6391, 448.1382,
        449.0166, 448.3151, 447.9576, 448.6163, 448.8678, 448.6991, 448.9899,
        448.9960, 448.4018, 450.4304, 448.9695, 448.6730, 448.7094, 448.5612,
        449.0409, 450.6185, 448.2913, 448.6792, 448.0220, 448.4825, 448.5871,
        448.9772, 448.1989, 448.3668, 448.0956, 447.9624, 448.5086, 450.1716,
        448.4628, 448.1460, 448.4534, 448.3253, 448.1437, 448.7127, 448.5157,
        448.8830, 448.8889, 448.5238, 448.2619, 448.1167, 449.0607, 448.4087,
        448.6196, 448.3668, 448.4318, 448.4938, 450.5055, 450.5742, 449.0030,
        448.9618, 448.7038, 448.2726, 448.7573, 448.9068, 448.3241, 448.7234,
        448.0684, 448.8501, 449.0446, 448.5522, 448.6082, 448.6111, 448.8110,
        448.5202, 448.7399, 448.7213, 450.6565, 448.0764, 448.7770, 448.5382,
        448.6561, 448.5560, 448.7207, 448.0484, 450.6546, 448.2072, 450.4202,
        448.6196, 448.4359, 448.7686, 450.6587, 449.0403, 448.9837, 448.8463,
        448.5873, 448.7581, 448.8805, 448.0676, 448.7118, 449.1794, 449.1033,
        448.1769, 448.6489, 449.4103, 448.1436, 448.4930, 449.2131, 449.0192,
        448.5244, 448.9163, 449.9958, 448.5154, 448.5527, 449.0295, 450.5183,
        448.6380, 448.4662, 449.0597, 449.0172, 450.5139, 449.0297, 448.6579,
        448.0010, 448.2144, 450.4631, 448.6020, 448.1891, 448.9055, 448.9837,
        448.9097, 449.0422, 448.6985, 449.9327, 448.8646, 448.4479, 449.0613,
        450.6603, 448.5793, 450.4069, 448.4256, 450.6557, 448.4407, 448.7867,
        448.6299, 448.2154, 449.0472, 448.7751, 448.3085, 448.4696, 448.7185,
        448.2016, 448.7590, 448.6410, 448.9277, 447.9952, 452.4781, 449.0908,
        448.1030, 449.4932, 448.4962, 448.9829, 448.0710, 448.2744, 449.1353,
        448.5377, 448.6543, 448.6231, 448.5142, 448.7629, 448.4784, 448.5122,
        448.6454, 448.3683, 448.6143, 448.3676, 450.5615, 448.9402, 448.4781,
        448.0707, 448.4306, 448.5353, 448.2026, 448.0044, 448.0335, 448.7613,
        448.8048, 448.9764, 448.1992, 449.1678, 449.9424, 449.0616, 448.6069,
        448.5962, 449.1377, 448.2547, 447.9959, 448.5234, 452.6123, 448.5210,
        450.6582, 448.9219, 448.9550, 448.6223, 448.7821, 449.0621, 448.8212,
        448.1839, 448.5710, 448.7153, 449.1412, 448.2418, 448.6629, 448.4717,
        448.9158, 448.2345, 448.9532, 448.6535, 448.4159, 450.5595, 448.3497,
        448.6797, 448.0435, 449.0297, 450.1041, 448.4717, 448.8575, 448.3504,
        448.4580, 449.7074, 450.4981, 449.6907, 448.4418, 448.4554, 450.6567,
        449.0071, 448.9834, 448.8835, 448.5496, 448.0990, 448.9759, 448.4120,
        449.0027, 448.0524, 448.3230, 450.6116, 448.8645, 448.9729, 447.9397,
        449.7384, 448.4833, 448.7626, 448.6069, 448.3353, 449.0502, 449.6348,
        448.8546, 449.0818, 450.5186, 450.6466, 448.9481, 448.0276, 448.4194,
        450.0426, 448.1414, 448.8572, 448.5522, 448.1727, 448.1771, 448.4606,
        448.7733, 448.2913, 449.0284, 450.5127, 450.4563, 448.4008, 450.6553,
        450.3950, 449.0343], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([393.3639], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6649],
             [112.6649],
             [112.6652],
             [112.6652]],

            [[112.6648],
             [112.6534],
             [112.6614],
             [112.6614]],

            [[112.2397],
             [112.2397],
             [112.2726],
             [112.2726]],

            ...,

            [[112.2654],
             [112.2654],
             [112.2654],
             [112.2654]],

            [[111.9911],
             [111.9900],
             [112.2331],
             [112.2331]],

            [[112.6327],
             [112.5448],
             [112.1097],
             [112.1097]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.6602, 450.6411, 449.0247,  ..., 449.0616, 448.4473, 449.3969],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.6602, 450.6411, 449.0247,  ..., 449.0616, 448.4473, 449.3969],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6742],
             [112.6742],
             [112.6739],
             [112.6739]],

            [[111.9988],
             [111.9779],
             [111.9926],
             [112.0025]],

            [[112.0124],
             [112.2431],
             [112.2281],
             [111.9882]],

            ...,

            [[112.0064],
             [111.9789],
             [112.1043],
             [111.9875]],

            [[111.9909],
             [111.9781],
             [112.2294],
             [112.2481]],

            [[112.3143],
             [111.9792],
             [112.3142],
             [111.9792]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.6962, 447.9719, 448.4719,  ..., 448.0771, 448.4465, 448.5869],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.6962, 447.9719, 448.4719,  ..., 448.0771, 448.4465, 448.5869],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1493],
             [112.1493],
             [112.2784],
             [112.2784]],

            [[112.2779],
             [112.2824],
             [112.2746],
             [112.2746]],

            [[111.9724],
             [111.9834],
             [112.2091],
             [112.2592]],

            ...,

            [[112.7023],
             [112.7022],
             [112.7024],
             [112.7047]],

            [[111.9963],
             [112.2443],
             [112.2828],
             [111.9738]],

            [[112.2292],
             [112.0769],
             [112.2835],
             [112.0321]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8553, 449.1094, 448.4241,  ..., 450.8116, 448.4972, 448.6217],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8553, 449.1094, 448.4241,  ..., 450.8116, 448.4972, 448.6217],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0357],
             [112.2526],
             [112.2100],
             [112.2100]],

            [[112.0883],
             [112.2883],
             [111.9656],
             [112.2098]],

            [[112.0644],
             [112.2325],
             [112.0409],
             [112.2900]],

            ...,

            [[112.6414],
             [112.6414],
             [112.0057],
             [112.0057]],

            [[111.9954],
             [112.0158],
             [112.0271],
             [111.9839]],

            [[112.0091],
             [112.0309],
             [111.9793],
             [112.0469]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7083, 448.5520, 448.6278,  ..., 449.2942, 448.0222, 448.0662],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7083, 448.5520, 448.6278,  ..., 449.2942, 448.0222, 448.0662],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.7336],
             [112.7336],
             [112.7307],
             [112.7307]],

            [[112.2098],
             [112.1944],
             [112.1592],
             [112.2284]],

            [[111.9385],
             [112.1589],
             [112.0057],
             [112.0057]],

            ...,

            [[112.6769],
             [112.0007],
             [112.4100],
             [112.4100]],

            [[112.2587],
             [112.1189],
             [112.2562],
             [112.2397]],

            [[111.9428],
             [112.0039],
             [111.9742],
             [111.9375]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.9286, 448.7919, 448.1089,  ..., 449.4976, 448.8735, 447.8584],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.9286, 448.7919, 448.1089,  ..., 449.4976, 448.8735, 447.8584],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0498],
             [111.9387],
             [112.2468],
             [112.1848]],

            [[112.0440],
             [112.2444],
             [111.9283],
             [112.1720]],

            [[112.6462],
             [112.0215],
             [112.2482],
             [112.2482]],

            ...,

            [[112.2985],
             [112.5268],
             [112.6321],
             [112.1492]],

            [[112.2325],
             [112.2394],
             [112.2257],
             [112.2370]],

            [[112.1127],
             [112.1225],
             [112.1231],
             [112.2446]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4200, 448.3887, 449.1642,  ..., 449.6066, 448.9346, 448.6030],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4200, 448.3887, 449.1642,  ..., 449.6066, 448.9346, 448.6030],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0755],
             [112.1960],
             [112.0261],
             [112.2024]],

            [[112.0010],
             [112.1963],
             [112.1660],
             [112.1660]],

            [[112.0274],
             [111.9226],
             [112.0921],
             [111.9161]],

            ...,

            [[112.1671],
             [112.1671],
             [112.1929],
             [112.1929]],

            [[111.9437],
             [111.9346],
             [112.1549],
             [112.2010]],

            [[112.1863],
             [112.2090],
             [112.2126],
             [112.2155]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4999, 448.5293, 447.9582,  ..., 448.7200, 448.2342, 448.8234],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4999, 448.5293, 447.9582,  ..., 448.7200, 448.2342, 448.8234],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1598],
             [111.9568],
             [112.1439],
             [112.2368]],

            [[112.0831],
             [112.2288],
             [111.9346],
             [112.0402]],

            [[112.1950],
             [112.0407],
             [111.9946],
             [112.2315]],

            ...,

            [[111.9352],
             [111.9859],
             [112.1929],
             [112.1929]],

            [[111.9429],
             [111.9414],
             [112.1980],
             [112.1980]],

            [[111.9285],
             [111.9323],
             [112.0548],
             [111.9612]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4972, 448.2867, 448.4619,  ..., 448.3068, 448.2803, 447.8767],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4972, 448.2867, 448.4619,  ..., 448.3068, 448.2803, 447.8767],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1641],
             [112.0427],
             [111.9880],
             [112.0457]],

            [[112.0309],
             [112.1749],
             [112.1669],
             [112.2323]],

            [[112.1431],
             [112.2353],
             [112.1667],
             [112.1667]],

            ...,

            [[112.0487],
             [112.2313],
             [112.1698],
             [112.1698]],

            [[111.9536],
             [111.9536],
             [112.1581],
             [112.1581]],

            [[112.1605],
             [111.9410],
             [112.1529],
             [111.9413]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2406, 448.6049, 448.7118,  ..., 448.6197, 448.2233, 448.1957],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2406, 448.6049, 448.7118,  ..., 448.6197, 448.2233, 448.1957],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9436],
             [111.9967],
             [112.1603],
             [112.1987]],

            [[112.2095],
             [112.2169],
             [112.2046],
             [112.2117]],

            [[112.0308],
             [112.5471],
             [112.4726],
             [111.9941]],

            ...,

            [[111.9566],
             [112.1212],
             [112.1830],
             [112.2222]],

            [[111.9684],
             [111.9758],
             [111.9658],
             [111.9597]],

            [[111.9965],
             [111.9489],
             [111.9895],
             [111.9511]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2993, 448.8427, 449.0446,  ..., 448.4831, 447.8697, 447.8859],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2993, 448.8427, 449.0446,  ..., 448.4831, 447.8697, 447.8859],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0714],
             [112.0714],
             [111.9841],
             [112.1329]],

            [[112.0999],
             [112.1034],
             [112.1602],
             [112.2144]],

            [[112.1662],
             [111.9728],
             [112.0487],
             [112.2082]],

            ...,

            [[112.1235],
             [112.2092],
             [112.1129],
             [112.1744]],

            [[112.1986],
             [111.9168],
             [111.9375],
             [111.9375]],

            [[111.9636],
             [111.9551],
             [111.9189],
             [111.9189]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2598, 448.5779, 448.3960,  ..., 448.6199, 447.9904, 447.7565],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2598, 448.5779, 448.3960,  ..., 448.6199, 447.9904, 447.7565],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1537],
             [112.1537],
             [112.2151],
             [112.2151]],

            [[112.5404],
             [112.5404],
             [112.5398],
             [112.5398]],

            [[111.9652],
             [111.9652],
             [112.1966],
             [112.1966]],

            ...,

            [[112.1348],
             [111.9317],
             [111.9286],
             [111.9286]],

            [[112.0097],
             [111.9448],
             [112.0086],
             [111.9458]],

            [[112.0935],
             [112.2085],
             [112.0015],
             [112.0015]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7377, 450.1605, 448.3236,  ..., 447.9237, 447.9088, 448.3049],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7377, 450.1605, 448.3236,  ..., 447.9237, 447.9088, 448.3049],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1575],
             [112.1760],
             [112.2123],
             [112.2123]],

            [[112.1270],
             [112.1990],
             [112.2104],
             [112.1539]],

            [[111.9844],
             [112.2001],
             [111.9844],
             [112.2001]],

            ...,

            [[112.0897],
             [112.2143],
             [111.9699],
             [112.1360]],

            [[111.9345],
             [111.9345],
             [111.9416],
             [111.9416]],

            [[112.4140],
             [111.9390],
             [112.0089],
             [112.0089]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7582, 448.6903, 448.3690,  ..., 448.4099, 447.7521, 448.3707],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7582, 448.6903, 448.3690,  ..., 448.4099, 447.7521, 448.3707],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1997],
             [112.1657],
             [112.2123],
             [112.2123]],

            [[111.9516],
             [112.0340],
             [112.1654],
             [112.1980]],

            [[112.1811],
             [112.4978],
             [112.4979],
             [112.1677]],

            ...,

            [[112.1388],
             [112.1388],
             [112.1311],
             [112.1311]],

            [[112.1075],
             [112.1075],
             [112.1597],
             [112.1597]],

            [[113.1069],
             [113.1069],
             [113.0590],
             [113.0590]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7899, 448.3490, 449.3445,  ..., 448.5398, 448.5344, 452.3317],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7899, 448.3490, 449.3445,  ..., 448.5398, 448.5344, 452.3317],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.4844],
             [112.4673],
             [112.4882],
             [112.4583]],

            [[112.4921],
             [112.4921],
             [112.4474],
             [112.4474]],

            [[112.1433],
             [112.1734],
             [112.1954],
             [112.1954]],

            ...,

            [[112.1869],
             [111.9511],
             [112.1668],
             [111.9495]],

            [[112.4602],
             [111.9694],
             [112.4559],
             [111.9698]],

            [[111.9714],
             [112.2083],
             [112.1833],
             [112.1833]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.8982, 449.8791, 448.7076,  ..., 448.2543, 448.8553, 448.5462],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.8982, 449.8791, 448.7076,  ..., 448.2543, 448.8553, 448.5462],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5508],
             [112.5508],
             [112.5508],
             [112.5508]],

            [[112.0029],
             [112.2197],
             [112.2153],
             [112.2153]],

            [[112.1666],
             [112.1816],
             [112.1778],
             [112.2245]],

            ...,

            [[112.1186],
             [112.2245],
             [112.1811],
             [112.1811]],

            [[112.2173],
             [112.2173],
             [112.2173],
             [112.2173]],

            [[112.0635],
             [112.1551],
             [111.9424],
             [112.0034]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.2030, 448.6532, 448.7506,  ..., 448.7053, 448.8691, 448.1644],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.2030, 448.6532, 448.7506,  ..., 448.7053, 448.8691, 448.1644],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2212],
             [112.2064],
             [112.2279],
             [112.2279]],

            [[111.9598],
             [112.5328],
             [112.5360],
             [111.9538]],

            [[112.1988],
             [112.2025],
             [112.2326],
             [112.2326]],

            ...,

            [[112.4298],
             [111.9396],
             [111.9396],
             [112.5962]],

            [[112.3632],
             [112.3618],
             [111.9739],
             [111.9451]],

            [[112.2322],
             [112.0782],
             [112.1931],
             [112.1931]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8834, 448.9824, 448.8665,  ..., 448.9051, 448.6440, 448.6964],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8834, 448.9824, 448.8665,  ..., 448.9051, 448.6440, 448.6964],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2172],
             [112.2172],
             [112.2355],
             [112.2355]],

            [[112.2344],
             [112.2050],
             [112.2131],
             [112.2303]],

            [[112.1662],
             [112.3631],
             [112.4083],
             [112.0959]],

            ...,

            [[112.3559],
             [111.9371],
             [112.3182],
             [111.9367]],

            [[111.9988],
             [111.9988],
             [112.2046],
             [112.2046]],

            [[112.2179],
             [112.1672],
             [111.9384],
             [112.2317]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9055, 448.8828, 449.0334,  ..., 448.5479, 448.4068, 448.5552],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9055, 448.8828, 449.0334,  ..., 448.5479, 448.4068, 448.5552],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9987e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3545],
             [112.3545],
             [111.9218],
             [111.9218]],

            [[112.1439],
             [111.9241],
             [111.9247],
             [112.1709]],

            [[112.0010],
             [112.2114],
             [112.1602],
             [112.1707]],

            ...,

            [[112.4669],
             [112.4669],
             [112.4373],
             [112.4373]],

            [[112.1793],
             [112.0643],
             [112.1360],
             [112.2092]],

            [[112.0744],
             [112.0744],
             [112.2023],
             [112.2023]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5526, 448.1636, 448.5432,  ..., 449.8085, 448.5887, 448.5534],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5526, 448.1636, 448.5432,  ..., 449.8085, 448.5887, 448.5534],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1414],
             [112.1807],
             [112.2026],
             [112.0218]],

            [[112.0586],
             [111.9348],
             [111.9214],
             [111.9214]],

            [[112.2005],
             [112.2093],
             [112.1944],
             [112.2024]],

            ...,

            [[112.1965],
             [112.0082],
             [112.2063],
             [112.2063]],

            [[112.1681],
             [112.2097],
             [112.0674],
             [112.0674]],

            [[111.9333],
             [112.0100],
             [112.1994],
             [112.1994]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5464, 447.8363, 448.8066,  ..., 448.6174, 448.5125, 448.3420],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5464, 447.8363, 448.8066,  ..., 448.6174, 448.5125, 448.3420],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2115],
             [112.2113],
             [112.2021],
             [112.1685]],

            [[112.0721],
             [111.9225],
             [111.9229],
             [112.1521]],

            [[112.1772],
             [112.0933],
             [112.1677],
             [112.2115]],

            ...,

            [[111.9234],
             [111.9234],
             [111.9310],
             [111.9310]],

            [[112.2081],
             [112.2075],
             [112.2069],
             [112.2069]],

            [[111.9244],
             [111.9244],
             [112.1652],
             [112.1652]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7934, 448.0695, 448.6498, 448.4807, 448.1379, 448.6337, 448.6160,
            448.7792, 448.6956, 447.7944, 448.7931, 448.3374, 448.1123, 450.4947,
            448.7582, 448.4451, 448.2000, 449.4506, 448.7526, 448.4531, 448.7971,
            448.0074, 448.7723, 447.7739, 448.1478, 447.8658, 449.9614, 449.0810,
            448.4080, 448.8363, 448.3403, 447.9713, 448.4105, 449.2255, 448.7668,
            448.8052, 448.3643, 448.7230, 448.8275, 448.5885, 448.7963, 448.1700,
            448.7025, 450.2852, 448.7494, 448.8355, 448.2491, 447.8561, 448.6595,
            448.6249, 450.6054, 449.2700, 448.6169, 448.0417, 448.1513, 448.6328,
            447.8268, 448.5135, 448.5931, 448.4713, 452.9225, 448.1861, 448.1687,
            448.3252, 447.9890, 448.7422, 448.6105, 448.2630, 448.7205, 448.3615,
            448.1666, 449.1161, 448.4809, 448.4922, 448.3437, 448.7407, 447.9132,
            448.8177, 448.9584, 448.5312, 448.4857, 448.3613, 448.7914, 448.8271,
            448.3739, 448.4959, 448.8120, 448.4379, 447.7063, 448.7065, 448.4469,
            448.5923, 448.6313, 448.8250, 448.2638, 447.7448, 448.0691, 448.6605,
            448.0378, 448.5819, 448.3619, 448.7875, 447.9573, 448.4545, 448.4295,
            448.2205, 448.4432, 448.7717, 448.8193, 448.0327, 448.8250, 449.9022,
            448.0150, 449.9773, 448.2016, 447.9390, 448.2973, 448.8062, 448.7306,
            448.7967, 448.3393, 448.3426, 448.6322, 448.4415, 448.3867, 447.9518,
            448.2588, 448.6483, 448.5895, 448.2437, 448.5592, 450.6419, 447.7152,
            448.2695, 448.5349, 448.8036, 448.1328, 447.9725, 448.4145, 448.6566,
            448.1620, 448.6068, 447.8594, 448.7618, 448.7742, 448.7587, 448.2299,
            448.7745, 448.6678, 448.7341, 448.3376, 449.1232, 447.8892, 449.9761,
            448.6895, 447.8235, 448.8034, 448.1050, 448.5648, 448.2780, 448.3541,
            448.4466, 448.7777, 449.7587, 448.7360, 448.5594, 448.7529, 448.6443,
            448.5630, 447.9351, 447.7671, 448.4347, 448.3704, 448.1252, 448.9381,
            448.5438, 448.6525, 448.5044, 448.7624, 448.7806, 448.8178, 448.4334,
            448.3776, 450.5900, 447.8073, 448.6151, 448.8239, 448.7229, 448.7798,
            447.7717, 448.4738, 450.4268, 448.7745, 448.2255, 448.3244, 448.2113,
            448.6957, 448.7673, 448.0518, 449.5869, 448.2349, 448.3059, 450.1759,
            448.7621, 448.7582, 448.6693, 448.7169, 448.7661, 449.8792, 448.4033,
            448.1345, 448.7179, 447.7450, 448.3504, 447.7820, 448.2339, 447.6947,
            448.5234, 448.8306, 450.6220, 448.6703, 448.7746, 447.7200, 448.6105,
            447.6852, 448.5854, 448.3727, 448.2777, 448.4333, 449.0435, 448.2484,
            450.5924, 448.7661, 447.8082, 448.2419, 450.6519, 448.2563, 448.6852,
            448.8570, 448.6367, 448.3746, 448.7198, 447.9371, 448.7260, 447.8578,
            448.1996, 448.4388, 449.1176, 448.2036, 450.1343, 448.4119, 448.3911,
            448.6353, 448.8001, 447.8031, 448.4334, 448.6541, 448.8074, 448.7542,
            447.9595, 450.6584, 448.1135, 448.2567, 448.7975, 448.2180, 448.0303,
            448.2557, 448.1381, 448.5013, 448.4909, 448.5219, 448.2808, 447.9984,
            448.7775, 448.2530, 448.8080, 448.4266, 448.7106, 448.0821, 447.7263,
            449.0560, 448.3952, 448.7749, 448.7417, 447.9765, 448.5608, 450.5021,
            447.8222, 448.1225, 448.2990, 450.3254, 448.6936, 448.0710, 448.3470,
            448.7916, 448.4739, 448.2806, 450.6613, 447.6965, 447.7741, 448.8391,
            447.8549, 448.1643, 448.5030, 448.3137, 448.2233, 448.5072, 448.5691,
            448.6100, 448.4863, 448.2268, 448.7765, 448.5734, 448.8094, 449.8802,
            449.0892, 448.7361, 448.7354, 448.4870, 448.3715, 448.4315, 448.7196,
            447.8440, 447.7450, 448.8383, 448.7574, 447.8284, 448.5846, 447.6897,
            448.5178, 448.8218, 448.1254, 448.4202, 448.7059, 447.8711, 448.5345,
            448.3057, 448.8250, 448.2665, 450.6520, 448.7871, 448.4337, 448.5575,
            448.7831, 448.2698, 449.2234, 448.4041, 448.8280, 448.8309, 448.3755,
            448.1932, 448.2408, 448.8350, 448.4985, 448.7350, 448.3671, 448.5733,
            448.7869, 448.8192, 448.0823, 449.6609, 449.0264, 448.7198, 449.2632,
            448.3406, 447.6899, 448.0465, 448.7240, 448.4875, 450.6595, 448.2556,
            448.9289, 448.2974, 448.4162, 448.4370, 448.3673, 447.9224, 448.1209,
            448.5861, 448.7800, 450.5908, 448.0654, 448.5987, 448.6006, 448.6967,
            447.9026, 448.5032, 448.2261, 447.9920, 448.2759, 447.8401, 448.8051,
            450.3327, 447.6990, 450.5399, 448.1765, 448.4337, 447.8438, 448.4528,
            448.4967, 448.6432, 447.8861, 447.9318, 448.5073, 448.4141, 448.5905,
            448.7848, 448.1960, 448.4397, 449.9673, 448.6550, 449.1103, 448.0615,
            448.6933, 448.8859, 447.8585, 448.5011, 448.7927, 448.4360, 448.5768,
            448.7384, 448.8135, 447.9063, 448.6368, 448.3141, 448.6679, 447.9437,
            447.7185, 448.6821, 447.9016, 447.8613, 448.7976, 448.1636, 447.7274,
            450.6472, 448.3054, 448.4527, 448.8187, 447.8664, 448.3756, 448.6386,
            448.2762, 448.0696, 448.7849, 448.2385, 448.1892, 448.6302, 448.7289,
            448.8084, 448.2175, 448.8235, 448.0829, 450.3989, 449.0052, 448.4354,
            447.7320, 448.8290, 448.4395, 448.7649, 447.7657, 448.2955, 447.6895,
            450.3773, 448.0893, 448.1292, 448.7505, 448.4326, 448.8183, 448.3518,
            448.6204, 450.6191, 448.3159, 448.4249, 448.0866, 448.4559, 448.7818,
            450.5152, 448.6293, 448.4638, 447.9217, 448.1166, 448.1399, 448.7657,
            450.5655, 448.3255, 448.8359, 448.4598, 447.8633, 448.4587, 448.3515,
            447.9712, 447.7904, 448.8266, 448.2795, 448.4472, 447.9109, 448.4773,
            448.4325, 450.5606, 447.9915, 448.3523, 448.7716, 447.7502, 448.7731,
            448.5549, 448.6951, 448.5159, 447.7040, 447.9952, 448.7734, 448.4431,
            447.6857, 448.2174, 448.7116, 448.7549, 448.1523, 448.5099, 449.1433,
            448.7312, 448.8014, 448.2735, 450.3868, 447.7630, 448.0443, 448.2048,
            448.6946, 447.7323, 449.0828, 447.7787, 448.3991, 450.5444, 449.1327,
            448.7510, 447.9143, 448.6207, 448.3283, 449.0151, 447.8360, 448.3366,
            447.8192, 448.0839, 448.8909, 448.3354, 448.0745, 448.3274, 448.6393,
            448.4781, 447.8727, 447.6953, 448.7269, 448.0121, 448.7591, 448.4521,
            448.0389, 448.6351, 448.5082, 447.9632, 448.2098, 448.7971, 448.1780,
            448.5298, 448.6769, 448.4958, 447.8182, 448.5058, 448.2260, 448.7394,
            449.5511, 448.5020, 448.3306, 448.5687, 448.6729, 448.4450, 448.5295,
            448.1137, 447.8456, 447.8913, 448.8233, 448.4334, 447.8542, 448.7065,
            448.1683, 448.4869, 448.7463, 448.7603, 448.7450, 450.5268, 448.6371,
            448.3554, 448.0255, 448.6443, 448.8302, 448.6307, 448.8141, 449.9660,
            447.7776, 448.0318, 448.1692, 448.7853, 448.0124, 447.9957, 447.8776,
            448.7244, 448.0972, 448.2724, 448.4120, 448.5421, 448.2167, 448.8137,
            452.8219, 447.8879, 447.8882, 448.5038, 448.4417, 447.8971, 448.4928,
            448.6586, 448.5110, 448.7422, 448.1403, 448.3539, 448.0162, 448.3987,
            448.6541, 447.8586, 450.6523, 448.1159, 448.3591, 448.7859, 447.7701,
            448.6147, 447.7441, 448.4653, 448.5467, 450.6232, 448.4106, 448.6774,
            448.4946, 448.3521, 448.9632, 447.7811, 447.6895, 448.7239, 447.8355,
            448.5952, 449.5730, 448.5645, 450.0924, 449.6291, 448.0677, 448.6403,
            448.2153, 448.7334, 448.6375, 448.2521, 448.5655, 448.3135, 448.8054,
            448.5149, 448.8264, 447.7761, 448.5368, 448.4291, 448.7641, 450.4795,
            448.7287, 448.7369, 448.4501, 448.4884, 448.6715, 448.1060, 448.6051,
            448.5313, 447.9663, 448.3207, 448.5872, 448.6975, 448.1724, 449.0093,
            448.6654, 447.7101, 448.7750, 448.5979, 448.3864, 448.7159, 448.8153,
            447.7108, 448.1669, 447.9888, 448.7126, 448.5317, 447.7079, 448.3067,
            448.7954, 448.9344, 448.5677, 450.5664, 448.3555, 448.1266, 448.3540,
            448.6689, 448.5545, 448.7480, 450.5397, 447.7042, 448.8868, 448.4911,
            448.2996, 448.5455, 448.5000, 448.3474, 448.1057, 448.8236, 448.0041,
            448.6216, 448.3137, 448.2623, 448.8014, 448.6597, 448.7058, 447.9112,
            448.7262, 448.4466, 448.4061, 448.2922, 448.8232, 448.7620, 448.5516,
            448.4336, 448.3110, 448.7688, 447.7823, 447.9020, 448.7112, 448.5606,
            447.7223, 448.1872, 447.9901, 448.8379, 448.9727, 448.4255, 447.8098,
            448.2627, 447.8323, 448.8087, 448.7276, 448.6344, 449.3130, 448.0585,
            448.7323, 448.7009, 450.4301, 448.7633, 448.6964, 448.2690, 447.9894,
            447.8754, 448.6942, 447.7424, 448.4104, 450.3204, 448.0748, 448.7910,
            448.4061, 448.7769, 448.3443, 448.8237, 448.6014, 447.8269, 448.8105,
            448.8345, 448.4854, 448.2913, 448.6588, 450.1203, 448.6117, 449.0401,
            449.9022, 448.2087, 447.7845, 450.2104, 448.7465, 450.5302, 448.5125,
            448.2843, 447.6849, 448.8320, 448.4506, 449.0188, 448.2584, 448.2177,
            447.8999, 448.6125, 447.9374, 448.5027, 448.2382, 448.8190, 448.2782,
            450.3433, 447.7523, 448.1582, 448.3231, 448.5176, 448.6909, 450.6086,
            448.8024, 448.0497, 448.5234, 448.0952, 448.7122, 447.9498, 448.2688,
            448.3687, 448.5116, 448.3495, 450.2778, 447.9919, 448.5265, 448.4847,
            448.5383, 447.8717, 448.3106, 450.6023, 448.5158, 448.2116, 448.4807,
            448.1702, 448.5125, 448.2562, 448.3348, 447.9427, 448.0931, 450.6542,
            447.9696, 448.7977, 448.7518, 448.7884, 448.1934, 448.4998, 448.7884,
            448.7760, 448.8215, 448.3216, 448.7627, 447.8475, 447.8958, 448.6251,
            452.5983, 448.6801, 448.6405, 448.6303, 448.2508, 449.0659, 448.4962,
            448.5706, 448.8036, 448.4375, 448.9226, 448.7208, 448.7741, 448.5609,
            448.7131, 448.1225, 450.6591, 448.6223, 448.6028, 448.8082, 447.8243,
            450.3801, 449.2065, 452.9608, 448.7942, 448.8186, 448.0780, 447.9390,
            448.0112, 448.8380, 448.2194, 448.2905, 448.8323, 448.8159, 448.5274,
            448.2743, 448.2401, 448.1645, 448.7683, 447.6848, 449.0765, 447.7931,
            448.6196, 450.6558, 448.6608, 447.7967, 447.7157, 448.8230, 448.7309,
            448.4702, 448.4617, 448.4619, 448.6196, 449.2587, 447.7729, 447.8958,
            448.7033, 448.7906, 448.3111, 448.2526, 448.5803, 448.5118, 448.2677,
            448.1108, 450.5936, 448.6506, 448.7124, 448.3543, 448.1122, 447.7187,
            448.3312, 448.6685, 448.1522, 448.2255, 448.8363, 448.6751, 447.7088,
            448.8294, 448.1792], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7934, 448.0695, 448.6498, 448.4807, 448.1379, 448.6337, 448.6160,
        448.7792, 448.6956, 447.7944, 448.7931, 448.3374, 448.1123, 450.4947,
        448.7582, 448.4451, 448.2000, 449.4506, 448.7526, 448.4531, 448.7971,
        448.0074, 448.7723, 447.7739, 448.1478, 447.8658, 449.9614, 449.0810,
        448.4080, 448.8363, 448.3403, 447.9713, 448.4105, 449.2255, 448.7668,
        448.8052, 448.3643, 448.7230, 448.8275, 448.5885, 448.7963, 448.1700,
        448.7025, 450.2852, 448.7494, 448.8355, 448.2491, 447.8561, 448.6595,
        448.6249, 450.6054, 449.2700, 448.6169, 448.0417, 448.1513, 448.6328,
        447.8268, 448.5135, 448.5931, 448.4713, 452.9225, 448.1861, 448.1687,
        448.3252, 447.9890, 448.7422, 448.6105, 448.2630, 448.7205, 448.3615,
        448.1666, 449.1161, 448.4809, 448.4922, 448.3437, 448.7407, 447.9132,
        448.8177, 448.9584, 448.5312, 448.4857, 448.3613, 448.7914, 448.8271,
        448.3739, 448.4959, 448.8120, 448.4379, 447.7063, 448.7065, 448.4469,
        448.5923, 448.6313, 448.8250, 448.2638, 447.7448, 448.0691, 448.6605,
        448.0378, 448.5819, 448.3619, 448.7875, 447.9573, 448.4545, 448.4295,
        448.2205, 448.4432, 448.7717, 448.8193, 448.0327, 448.8250, 449.9022,
        448.0150, 449.9773, 448.2016, 447.9390, 448.2973, 448.8062, 448.7306,
        448.7967, 448.3393, 448.3426, 448.6322, 448.4415, 448.3867, 447.9518,
        448.2588, 448.6483, 448.5895, 448.2437, 448.5592, 450.6419, 447.7152,
        448.2695, 448.5349, 448.8036, 448.1328, 447.9725, 448.4145, 448.6566,
        448.1620, 448.6068, 447.8594, 448.7618, 448.7742, 448.7587, 448.2299,
        448.7745, 448.6678, 448.7341, 448.3376, 449.1232, 447.8892, 449.9761,
        448.6895, 447.8235, 448.8034, 448.1050, 448.5648, 448.2780, 448.3541,
        448.4466, 448.7777, 449.7587, 448.7360, 448.5594, 448.7529, 448.6443,
        448.5630, 447.9351, 447.7671, 448.4347, 448.3704, 448.1252, 448.9381,
        448.5438, 448.6525, 448.5044, 448.7624, 448.7806, 448.8178, 448.4334,
        448.3776, 450.5900, 447.8073, 448.6151, 448.8239, 448.7229, 448.7798,
        447.7717, 448.4738, 450.4268, 448.7745, 448.2255, 448.3244, 448.2113,
        448.6957, 448.7673, 448.0518, 449.5869, 448.2349, 448.3059, 450.1759,
        448.7621, 448.7582, 448.6693, 448.7169, 448.7661, 449.8792, 448.4033,
        448.1345, 448.7179, 447.7450, 448.3504, 447.7820, 448.2339, 447.6947,
        448.5234, 448.8306, 450.6220, 448.6703, 448.7746, 447.7200, 448.6105,
        447.6852, 448.5854, 448.3727, 448.2777, 448.4333, 449.0435, 448.2484,
        450.5924, 448.7661, 447.8082, 448.2419, 450.6519, 448.2563, 448.6852,
        448.8570, 448.6367, 448.3746, 448.7198, 447.9371, 448.7260, 447.8578,
        448.1996, 448.4388, 449.1176, 448.2036, 450.1343, 448.4119, 448.3911,
        448.6353, 448.8001, 447.8031, 448.4334, 448.6541, 448.8074, 448.7542,
        447.9595, 450.6584, 448.1135, 448.2567, 448.7975, 448.2180, 448.0303,
        448.2557, 448.1381, 448.5013, 448.4909, 448.5219, 448.2808, 447.9984,
        448.7775, 448.2530, 448.8080, 448.4266, 448.7106, 448.0821, 447.7263,
        449.0560, 448.3952, 448.7749, 448.7417, 447.9765, 448.5608, 450.5021,
        447.8222, 448.1225, 448.2990, 450.3254, 448.6936, 448.0710, 448.3470,
        448.7916, 448.4739, 448.2806, 450.6613, 447.6965, 447.7741, 448.8391,
        447.8549, 448.1643, 448.5030, 448.3137, 448.2233, 448.5072, 448.5691,
        448.6100, 448.4863, 448.2268, 448.7765, 448.5734, 448.8094, 449.8802,
        449.0892, 448.7361, 448.7354, 448.4870, 448.3715, 448.4315, 448.7196,
        447.8440, 447.7450, 448.8383, 448.7574, 447.8284, 448.5846, 447.6897,
        448.5178, 448.8218, 448.1254, 448.4202, 448.7059, 447.8711, 448.5345,
        448.3057, 448.8250, 448.2665, 450.6520, 448.7871, 448.4337, 448.5575,
        448.7831, 448.2698, 449.2234, 448.4041, 448.8280, 448.8309, 448.3755,
        448.1932, 448.2408, 448.8350, 448.4985, 448.7350, 448.3671, 448.5733,
        448.7869, 448.8192, 448.0823, 449.6609, 449.0264, 448.7198, 449.2632,
        448.3406, 447.6899, 448.0465, 448.7240, 448.4875, 450.6595, 448.2556,
        448.9289, 448.2974, 448.4162, 448.4370, 448.3673, 447.9224, 448.1209,
        448.5861, 448.7800, 450.5908, 448.0654, 448.5987, 448.6006, 448.6967,
        447.9026, 448.5032, 448.2261, 447.9920, 448.2759, 447.8401, 448.8051,
        450.3327, 447.6990, 450.5399, 448.1765, 448.4337, 447.8438, 448.4528,
        448.4967, 448.6432, 447.8861, 447.9318, 448.5073, 448.4141, 448.5905,
        448.7848, 448.1960, 448.4397, 449.9673, 448.6550, 449.1103, 448.0615,
        448.6933, 448.8859, 447.8585, 448.5011, 448.7927, 448.4360, 448.5768,
        448.7384, 448.8135, 447.9063, 448.6368, 448.3141, 448.6679, 447.9437,
        447.7185, 448.6821, 447.9016, 447.8613, 448.7976, 448.1636, 447.7274,
        450.6472, 448.3054, 448.4527, 448.8187, 447.8664, 448.3756, 448.6386,
        448.2762, 448.0696, 448.7849, 448.2385, 448.1892, 448.6302, 448.7289,
        448.8084, 448.2175, 448.8235, 448.0829, 450.3989, 449.0052, 448.4354,
        447.7320, 448.8290, 448.4395, 448.7649, 447.7657, 448.2955, 447.6895,
        450.3773, 448.0893, 448.1292, 448.7505, 448.4326, 448.8183, 448.3518,
        448.6204, 450.6191, 448.3159, 448.4249, 448.0866, 448.4559, 448.7818,
        450.5152, 448.6293, 448.4638, 447.9217, 448.1166, 448.1399, 448.7657,
        450.5655, 448.3255, 448.8359, 448.4598, 447.8633, 448.4587, 448.3515,
        447.9712, 447.7904, 448.8266, 448.2795, 448.4472, 447.9109, 448.4773,
        448.4325, 450.5606, 447.9915, 448.3523, 448.7716, 447.7502, 448.7731,
        448.5549, 448.6951, 448.5159, 447.7040, 447.9952, 448.7734, 448.4431,
        447.6857, 448.2174, 448.7116, 448.7549, 448.1523, 448.5099, 449.1433,
        448.7312, 448.8014, 448.2735, 450.3868, 447.7630, 448.0443, 448.2048,
        448.6946, 447.7323, 449.0828, 447.7787, 448.3991, 450.5444, 449.1327,
        448.7510, 447.9143, 448.6207, 448.3283, 449.0151, 447.8360, 448.3366,
        447.8192, 448.0839, 448.8909, 448.3354, 448.0745, 448.3274, 448.6393,
        448.4781, 447.8727, 447.6953, 448.7269, 448.0121, 448.7591, 448.4521,
        448.0389, 448.6351, 448.5082, 447.9632, 448.2098, 448.7971, 448.1780,
        448.5298, 448.6769, 448.4958, 447.8182, 448.5058, 448.2260, 448.7394,
        449.5511, 448.5020, 448.3306, 448.5687, 448.6729, 448.4450, 448.5295,
        448.1137, 447.8456, 447.8913, 448.8233, 448.4334, 447.8542, 448.7065,
        448.1683, 448.4869, 448.7463, 448.7603, 448.7450, 450.5268, 448.6371,
        448.3554, 448.0255, 448.6443, 448.8302, 448.6307, 448.8141, 449.9660,
        447.7776, 448.0318, 448.1692, 448.7853, 448.0124, 447.9957, 447.8776,
        448.7244, 448.0972, 448.2724, 448.4120, 448.5421, 448.2167, 448.8137,
        452.8219, 447.8879, 447.8882, 448.5038, 448.4417, 447.8971, 448.4928,
        448.6586, 448.5110, 448.7422, 448.1403, 448.3539, 448.0162, 448.3987,
        448.6541, 447.8586, 450.6523, 448.1159, 448.3591, 448.7859, 447.7701,
        448.6147, 447.7441, 448.4653, 448.5467, 450.6232, 448.4106, 448.6774,
        448.4946, 448.3521, 448.9632, 447.7811, 447.6895, 448.7239, 447.8355,
        448.5952, 449.5730, 448.5645, 450.0924, 449.6291, 448.0677, 448.6403,
        448.2153, 448.7334, 448.6375, 448.2521, 448.5655, 448.3135, 448.8054,
        448.5149, 448.8264, 447.7761, 448.5368, 448.4291, 448.7641, 450.4795,
        448.7287, 448.7369, 448.4501, 448.4884, 448.6715, 448.1060, 448.6051,
        448.5313, 447.9663, 448.3207, 448.5872, 448.6975, 448.1724, 449.0093,
        448.6654, 447.7101, 448.7750, 448.5979, 448.3864, 448.7159, 448.8153,
        447.7108, 448.1669, 447.9888, 448.7126, 448.5317, 447.7079, 448.3067,
        448.7954, 448.9344, 448.5677, 450.5664, 448.3555, 448.1266, 448.3540,
        448.6689, 448.5545, 448.7480, 450.5397, 447.7042, 448.8868, 448.4911,
        448.2996, 448.5455, 448.5000, 448.3474, 448.1057, 448.8236, 448.0041,
        448.6216, 448.3137, 448.2623, 448.8014, 448.6597, 448.7058, 447.9112,
        448.7262, 448.4466, 448.4061, 448.2922, 448.8232, 448.7620, 448.5516,
        448.4336, 448.3110, 448.7688, 447.7823, 447.9020, 448.7112, 448.5606,
        447.7223, 448.1872, 447.9901, 448.8379, 448.9727, 448.4255, 447.8098,
        448.2627, 447.8323, 448.8087, 448.7276, 448.6344, 449.3130, 448.0585,
        448.7323, 448.7009, 450.4301, 448.7633, 448.6964, 448.2690, 447.9894,
        447.8754, 448.6942, 447.7424, 448.4104, 450.3204, 448.0748, 448.7910,
        448.4061, 448.7769, 448.3443, 448.8237, 448.6014, 447.8269, 448.8105,
        448.8345, 448.4854, 448.2913, 448.6588, 450.1203, 448.6117, 449.0401,
        449.9022, 448.2087, 447.7845, 450.2104, 448.7465, 450.5302, 448.5125,
        448.2843, 447.6849, 448.8320, 448.4506, 449.0188, 448.2584, 448.2177,
        447.8999, 448.6125, 447.9374, 448.5027, 448.2382, 448.8190, 448.2782,
        450.3433, 447.7523, 448.1582, 448.3231, 448.5176, 448.6909, 450.6086,
        448.8024, 448.0497, 448.5234, 448.0952, 448.7122, 447.9498, 448.2688,
        448.3687, 448.5116, 448.3495, 450.2778, 447.9919, 448.5265, 448.4847,
        448.5383, 447.8717, 448.3106, 450.6023, 448.5158, 448.2116, 448.4807,
        448.1702, 448.5125, 448.2562, 448.3348, 447.9427, 448.0931, 450.6542,
        447.9696, 448.7977, 448.7518, 448.7884, 448.1934, 448.4998, 448.7884,
        448.7760, 448.8215, 448.3216, 448.7627, 447.8475, 447.8958, 448.6251,
        452.5983, 448.6801, 448.6405, 448.6303, 448.2508, 449.0659, 448.4962,
        448.5706, 448.8036, 448.4375, 448.9226, 448.7208, 448.7741, 448.5609,
        448.7131, 448.1225, 450.6591, 448.6223, 448.6028, 448.8082, 447.8243,
        450.3801, 449.2065, 452.9608, 448.7942, 448.8186, 448.0780, 447.9390,
        448.0112, 448.8380, 448.2194, 448.2905, 448.8323, 448.8159, 448.5274,
        448.2743, 448.2401, 448.1645, 448.7683, 447.6848, 449.0765, 447.7931,
        448.6196, 450.6558, 448.6608, 447.7967, 447.7157, 448.8230, 448.7309,
        448.4702, 448.4617, 448.4619, 448.6196, 449.2587, 447.7729, 447.8958,
        448.7033, 448.7906, 448.3111, 448.2526, 448.5803, 448.5118, 448.2677,
        448.1108, 450.5936, 448.6506, 448.7124, 448.3543, 448.1122, 447.7187,
        448.3312, 448.6685, 448.1522, 448.2255, 448.8363, 448.6751, 447.7088,
        448.8294, 448.1792], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([408.8206], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.5908],
             [111.9301],
             [111.9301],
             [112.6652]],

            [[112.1788],
             [112.1554],
             [112.1775],
             [112.2115]],

            [[112.1817],
             [112.1800],
             [112.2115],
             [112.0661]],

            ...,

            [[111.9214],
             [111.9214],
             [111.9209],
             [111.9209]],

            [[112.5843],
             [111.9316],
             [112.5716],
             [111.9303]],

            [[111.9465],
             [112.6072],
             [112.6180],
             [111.9571]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1162, 448.7232, 448.6393,  ..., 447.6847, 449.0178, 449.1288],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1162, 448.7232, 448.6393,  ..., 447.6847, 449.0178, 449.1288],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9958],
             [112.1638],
             [111.9092],
             [112.0415]],

            [[112.0686],
             [112.1789],
             [111.9248],
             [112.1901]],

            [[112.1602],
             [112.1602],
             [112.1653],
             [112.1653]],

            ...,

            [[112.1047],
             [112.1761],
             [112.1915],
             [112.1915]],

            [[112.7060],
             [112.7294],
             [112.2127],
             [112.2145]],

            [[111.9212],
             [112.1712],
             [112.1078],
             [112.1078]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1103, 448.3625, 448.6511,  ..., 448.6637, 449.8626, 448.3079],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1103, 448.3625, 448.6511,  ..., 448.6637, 449.8626, 448.3079],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9282],
             [111.9282],
             [112.1576],
             [112.1576]],

            [[112.0549],
             [111.9118],
             [111.9909],
             [111.8979]],

            [[112.7524],
             [112.7925],
             [112.7823],
             [112.7823]],

            ...,

            [[111.8919],
             [111.9555],
             [111.8909],
             [112.0091]],

            [[112.1428],
             [112.1428],
             [112.1507],
             [112.1507]],

            [[112.0496],
             [112.1691],
             [112.1330],
             [112.1330]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1717, 447.8555, 451.1096,  ..., 447.7473, 448.5872, 448.4848],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1717, 447.8555, 451.1096,  ..., 447.7473, 448.5872, 448.4848],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0225],
             [112.1458],
             [112.1226],
             [112.1325]],

            [[112.5069],
             [111.8752],
             [112.3760],
             [111.8753]],

            [[112.1099],
             [112.1099],
             [112.1199],
             [112.1199]],

            ...,

            [[112.4989],
             [112.4989],
             [112.4983],
             [112.4983]],

            [[112.1229],
             [112.1229],
             [112.1497],
             [112.1497]],

            [[112.1171],
             [112.1171],
             [112.1425],
             [112.1425]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4234, 448.6334, 448.4596,  ..., 449.9942, 448.5452, 448.5193],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4234, 448.6334, 448.4596,  ..., 449.9942, 448.5452, 448.5193],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8711],
             [111.8837],
             [112.0585],
             [112.0319]],

            [[111.9707],
             [112.1419],
             [111.9024],
             [112.1450]],

            [[112.0591],
             [112.1429],
             [112.1220],
             [112.1315]],

            ...,

            [[111.8785],
             [111.8976],
             [111.9466],
             [112.1066]],

            [[112.1367],
             [112.1367],
             [112.1471],
             [112.1471]],

            [[111.8727],
             [112.1254],
             [111.8794],
             [112.1284]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8452, 448.1601, 448.4554,  ..., 447.8293, 448.5676, 448.0059],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8452, 448.1601, 448.4554,  ..., 447.8293, 448.5676, 448.0059],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9398],
             [112.1301],
             [112.1329],
             [112.1329]],

            [[111.9255],
             [112.7389],
             [112.7390],
             [111.9255]],

            [[111.9026],
             [112.1364],
             [112.1570],
             [111.9864]],

            ...,

            [[112.2229],
             [112.2229],
             [111.9003],
             [111.9003]],

            [[112.0061],
             [112.1504],
             [112.1361],
             [112.1361]],

            [[112.1256],
             [112.1565],
             [112.1569],
             [112.1569]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3357, 449.3288, 448.1823,  ..., 448.2465, 448.4287, 448.5959],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3357, 449.3288, 448.1823,  ..., 448.2465, 448.4287, 448.5959],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9843],
             [111.9489],
             [111.9101],
             [111.9101]],

            [[112.1459],
             [112.1459],
             [112.1534],
             [112.1534]],

            [[112.1353],
             [111.9328],
             [112.0948],
             [112.0509]],

            ...,

            [[112.0908],
             [112.1561],
             [112.1356],
             [112.1356]],

            [[111.9097],
             [112.1381],
             [112.0616],
             [112.0616]],

            [[111.9302],
             [112.0738],
             [111.9133],
             [112.1184]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7533, 448.5985, 448.2139,  ..., 448.5181, 448.1711, 448.0358],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7533, 448.5985, 448.2139,  ..., 448.5181, 448.1711, 448.0358],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9191],
             [112.0855],
             [111.9157],
             [112.0826]],

            [[112.1528],
             [112.1528],
             [112.1528],
             [112.1528]],

            [[111.9140],
             [112.1293],
             [112.0214],
             [112.0214]],

            ...,

            [[112.0660],
             [112.1407],
             [112.0098],
             [112.1478]],

            [[111.9455],
             [111.9455],
             [112.1501],
             [112.1501]],

            [[112.1322],
             [112.1532],
             [111.9362],
             [111.9503]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0029, 448.6113, 448.0862,  ..., 448.3643, 448.1913, 448.1718],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0029, 448.6113, 448.0862,  ..., 448.3643, 448.1913, 448.1718],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1322],
             [112.1479],
             [112.0919],
             [112.0919]],

            [[111.9202],
             [112.0605],
             [112.0168],
             [111.9330]],

            [[111.9194],
             [111.9194],
             [112.1440],
             [112.1440]],

            ...,

            [[112.6258],
             [111.9140],
             [111.9140],
             [112.8671]],

            [[112.1378],
             [112.1485],
             [112.1467],
             [112.1467]],

            [[111.9291],
             [111.9291],
             [111.9291],
             [111.9291]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4641, 447.9305, 448.1267,  ..., 449.3209, 448.5797, 447.7165],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4641, 447.9305, 448.1267,  ..., 449.3209, 448.5797, 447.7165],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.6842],
             [112.6842],
             [112.4674],
             [112.4674]],

            [[112.0966],
             [112.1185],
             [112.1030],
             [112.1165]],

            [[112.1120],
             [112.1200],
             [112.1205],
             [112.1210]],

            ...,

            [[112.7817],
             [111.9080],
             [111.9081],
             [112.8801]],

            [[111.9812],
             [111.9812],
             [112.1152],
             [112.1152]],

            [[112.1106],
             [112.0708],
             [112.1220],
             [111.9798]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.3032, 448.4345, 448.4735,  ..., 449.4779, 448.1929, 448.2831],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.3032, 448.4345, 448.4735,  ..., 449.4779, 448.1929, 448.2831],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8972],
             [111.8972],
             [111.9062],
             [111.9062]],

            [[111.9707],
             [111.8911],
             [111.9816],
             [111.8887]],

            [[112.1000],
             [112.0941],
             [112.0858],
             [112.0833]],

            ...,

            [[112.0998],
             [112.0492],
             [112.0995],
             [112.0995]],

            [[112.0900],
             [112.0900],
             [112.1006],
             [112.1006]],

            [[112.9070],
             [112.3953],
             [112.6881],
             [112.6881]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6068, 447.7321, 448.3632,  ..., 448.3480, 448.3812, 450.6784],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6068, 447.7321, 448.3632,  ..., 448.3480, 448.3812, 450.6784],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0868],
             [112.0868],
             [112.0869],
             [112.0869]],

            [[111.9619],
             [111.9486],
             [112.0646],
             [112.0862]],

            [[111.8759],
             [111.8759],
             [111.8745],
             [111.8745]],

            ...,

            [[112.0770],
             [112.0770],
             [112.0870],
             [112.0870]],

            [[112.9166],
             [112.9413],
             [112.9444],
             [112.8925]],

            [[112.9456],
             [112.9456],
             [112.9444],
             [112.9444]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3475, 448.0613, 447.5009,  ..., 448.3281, 451.6948, 451.7800],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3475, 448.0613, 447.5009,  ..., 448.3281, 451.6948, 451.7800],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0772],
             [112.0011],
             [112.0694],
             [112.0694]],

            [[112.0547],
             [111.9349],
             [111.9687],
             [111.9271]],

            [[112.9416],
             [112.9416],
             [112.9387],
             [112.9387]],

            ...,

            [[112.0694],
             [112.0780],
             [112.0778],
             [112.0778]],

            [[112.0778],
             [112.0783],
             [112.0767],
             [112.0779]],

            [[112.9506],
             [112.0295],
             [112.8559],
             [112.3257]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2170, 447.8853, 451.7605,  ..., 448.3030, 448.3107, 450.1617],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2170, 447.8853, 451.7605,  ..., 448.3030, 448.3107, 450.1617],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9163],
             [112.0661],
             [112.0645],
             [112.0645]],

            [[112.0461],
             [112.0464],
             [112.0656],
             [111.8738]],

            [[111.8695],
             [112.0190],
             [112.0656],
             [112.0656]],

            ...,

            [[112.0301],
             [112.0624],
             [112.0301],
             [112.0624]],

            [[112.9888],
             [112.9888],
             [112.9888],
             [112.9888]],

            [[112.0354],
             [112.0483],
             [111.8809],
             [112.0655]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1115, 448.0319, 448.0198,  ..., 448.1851, 451.9551, 448.0301],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1115, 448.0319, 448.0198,  ..., 448.1851, 451.9551, 448.0301],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0534],
             [112.0534],
             [112.0550],
             [112.0550]],

            [[111.8724],
             [111.8724],
             [111.8764],
             [111.8764]],

            [[111.9540],
             [111.9540],
             [112.0336],
             [112.0336]],

            ...,

            [[112.7032],
             [112.7032],
             [112.6530],
             [112.6530]],

            [[112.0428],
             [112.0092],
             [112.0453],
             [112.0453]],

            [[112.0397],
             [112.0397],
             [111.9421],
             [111.9421]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2168, 447.4976, 447.9752,  ..., 450.7125, 448.1425, 447.9637],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2168, 447.4976, 447.9752,  ..., 450.7125, 448.1425, 447.9637],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9560],
             [112.0369],
             [112.0315],
             [112.0469]],

            [[111.9147],
             [111.9227],
             [111.8923],
             [111.9271]],

            [[112.0499],
             [112.0311],
             [112.0500],
             [112.0497]],

            ...,

            [[113.0075],
             [112.0179],
             [113.0120],
             [112.0852]],

            [[112.0367],
             [111.8665],
             [111.8962],
             [112.0500]],

            [[111.8628],
             [111.8627],
             [112.0412],
             [112.0494]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0713, 447.6569, 448.1806,  ..., 450.1227, 447.8494, 447.8161],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0713, 447.6569, 448.1806,  ..., 450.1227, 447.8494, 447.8161],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8828],
             [111.9244],
             [111.8696],
             [111.8696]],

            [[111.8686],
             [112.0434],
             [111.9336],
             [112.0412]],

            [[111.9729],
             [112.0434],
             [112.0421],
             [112.0246]],

            ...,

            [[112.1545],
             [112.1545],
             [112.1151],
             [112.1151]],

            [[111.8601],
             [111.8601],
             [111.8618],
             [111.8618]],

            [[111.8608],
             [111.8781],
             [112.0350],
             [112.0350]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5463, 447.8867, 448.0829,  ..., 448.5392, 447.4439, 447.8089],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5463, 447.8867, 448.0829,  ..., 448.5392, 447.4439, 447.8089],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0378],
             [112.0377],
             [112.0378],
             [112.0377]],

            [[112.0289],
             [112.0289],
             [112.0317],
             [112.0317]],

            [[112.0205],
             [112.0242],
             [111.9253],
             [112.0379]],

            ...,

            [[112.9780],
             [112.9780],
             [111.8731],
             [111.8731]],

            [[111.8643],
             [111.8643],
             [111.9827],
             [111.9827]],

            [[111.8572],
             [112.0284],
             [111.9675],
             [111.9675]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1511, 448.1211, 448.0079,  ..., 449.7020, 447.6941, 447.8205],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1511, 448.1211, 448.0079,  ..., 449.7020, 447.6941, 447.8205],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0231e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8663],
             [112.0909],
             [111.8802],
             [111.8692]],

            [[111.9572],
             [112.0368],
             [112.0421],
             [112.0381]],

            [[112.0254],
             [112.0351],
             [112.0347],
             [112.0255]],

            ...,

            [[111.9035],
             [111.9035],
             [111.8693],
             [111.8693]],

            [[113.0446],
             [113.0321],
             [113.0465],
             [113.0266]],

            [[111.9557],
             [111.9557],
             [111.9978],
             [111.9978]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7066, 448.0742, 448.1205,  ..., 447.5455, 452.1498, 447.9071],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7066, 448.0742, 448.1205,  ..., 447.5455, 452.1498, 447.9071],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0408],
             [111.9278],
             [112.0429],
             [111.8696]],

            [[111.9088],
             [111.9088],
             [112.0343],
             [112.0343]],

            [[112.0229],
             [112.0266],
             [112.0339],
             [112.0397]],

            ...,

            [[111.8720],
             [112.0407],
             [112.0425],
             [112.0425]],

            [[111.8834],
             [111.8834],
             [112.0406],
             [112.0406]],

            [[112.0275],
             [112.0275],
             [112.0318],
             [112.0318]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8812, 447.8863, 448.1231,  ..., 447.9978, 447.8480, 448.1186],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8812, 447.8863, 448.1231,  ..., 447.9978, 447.8480, 448.1186],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8626],
             [111.8626],
             [111.9644],
             [111.9644]],

            [[111.9937],
             [111.8666],
             [112.0286],
             [111.9016]],

            [[113.0333],
             [111.9232],
             [112.3348],
             [112.3348]],

            ...,

            [[111.8620],
             [112.0167],
             [111.9159],
             [111.9159]],

            [[111.8727],
             [111.8985],
             [111.8766],
             [111.9932]],

            [[111.8817],
             [112.0422],
             [112.0258],
             [112.0337]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6541, 447.7905, 449.6261, 447.6929, 449.8768, 448.1447, 448.0938,
            447.9940, 448.1360, 448.1187, 447.9258, 449.7516, 448.0204, 449.7180,
            452.1056, 448.0185, 447.6251, 447.9671, 447.9518, 447.5577, 447.8419,
            447.6295, 452.1676, 447.9446, 447.8165, 447.9335, 449.0922, 448.7568,
            448.1309, 447.6238, 447.8907, 447.9989, 447.9636, 452.0696, 447.8436,
            448.6061, 451.9932, 448.0544, 447.6733, 448.1686, 447.9835, 447.9133,
            447.7686, 448.2019, 447.5089, 450.9136, 448.8221, 452.1526, 447.9258,
            448.1536, 449.9167, 447.6450, 447.8786, 447.8179, 452.2031, 448.1707,
            448.0929, 448.1601, 449.6554, 447.7065, 447.8148, 447.7709, 448.4999,
            448.0291, 447.8658, 452.2356, 452.2041, 447.9598, 447.9413, 448.1564,
            447.7940, 448.1427, 449.2683, 448.0044, 447.6750, 447.8028, 447.5493,
            448.0616, 447.8780, 448.0923, 447.7757, 447.8392, 448.0364, 452.2003,
            448.1680, 452.2043, 448.1008, 448.1003, 447.4649, 447.6585, 447.6210,
            447.8932, 447.9915, 449.4134, 447.6677, 447.7159, 448.9350, 448.0767,
            447.5517, 448.0526, 448.1122, 448.1628, 452.1154, 447.6714, 447.9659,
            447.8627, 447.5888, 448.1560, 448.6744, 452.2035, 447.8856, 447.8461,
            447.8832, 447.8242, 448.1716, 448.0908, 447.8975, 448.1376, 448.8924,
            448.1608, 447.5322, 451.5319, 447.5237, 448.0204, 447.7703, 452.2043,
            447.8004, 448.0283, 448.0349, 448.8560, 448.0212, 447.6582, 448.1388,
            447.7250, 452.1583, 449.9931, 448.1109, 447.9536, 447.8137, 447.4869,
            448.1371, 448.1504, 452.1842, 448.1579, 448.1005, 447.5335, 448.0054,
            447.9962, 447.9327, 447.8169, 450.4197, 449.1126, 447.5037, 448.0446,
            447.5573, 447.9111, 448.1569, 452.1122, 447.5204, 447.9207, 447.5850,
            447.9150, 450.3297, 452.2003, 447.6314, 451.3629, 452.0451, 448.1556,
            447.9005, 447.7786, 448.0570, 448.0326, 447.7899, 448.0164, 451.8032,
            448.1094, 448.0001, 447.7983, 448.1709, 447.7253, 447.9931, 447.6565,
            448.1664, 447.7921, 447.9940, 448.0164, 447.7474, 448.0814, 447.7523,
            448.3337, 447.7813, 447.6570, 448.0905, 448.1319, 452.2039, 447.4647,
            447.9252, 448.1071, 452.1448, 447.8616, 447.7930, 452.2043, 452.2038,
            447.7350, 452.1111, 447.9395, 447.8948, 447.8690, 447.6684, 448.1528,
            447.9883, 449.3657, 447.6620, 447.9321, 448.1491, 448.1185, 447.7357,
            447.9136, 449.4958, 448.1022, 448.1139, 452.2042, 451.0907, 447.5935,
            448.0823, 447.8626, 447.8073, 448.1576, 447.8415, 448.0116, 448.1682,
            447.7832, 449.4760, 452.2043, 452.2043, 447.8510, 448.0293, 447.7472,
            448.0377, 447.9757, 447.4889, 448.1263, 447.8213, 448.0469, 450.8358,
            448.0144, 447.8056, 452.1048, 448.5620, 447.7759, 447.8137, 447.6095,
            447.9203, 447.5909, 448.1011, 448.1655, 450.0117, 448.3819, 447.9760,
            447.8190, 448.0296, 447.6351, 447.9629, 448.1205, 447.5698, 452.2043,
            448.1700, 447.5858, 447.8069, 447.9896, 447.8455, 449.9148, 447.4848,
            448.0954, 448.0025, 447.8226, 448.1138, 448.1499, 447.8794, 447.8520,
            448.1713, 448.1680, 448.1614, 447.6166, 450.3207, 448.1299, 447.9641,
            448.1460, 447.6924, 448.1693, 447.5438, 447.9641, 447.4550, 448.1447,
            447.9069, 447.5388, 447.8708, 448.3085, 447.9449, 452.1935, 452.2040,
            448.0463, 447.4766, 448.0090, 452.1994, 447.9407, 448.0065, 448.1711,
            452.2017, 449.3724, 448.1279, 448.1587, 450.8068, 448.1168, 452.2042,
            448.1613, 448.1690, 447.8351, 452.1348, 447.9181, 447.7766, 448.1494,
            447.9575, 447.9089, 447.6724, 448.1464, 448.1657, 447.9832, 448.0755,
            448.1718, 448.0042, 452.2043, 448.1517, 447.9957, 447.9782, 447.4569,
            448.0487, 447.8446, 448.0925, 448.1442, 447.9097, 451.9878, 451.3536,
            447.8820, 447.8566, 448.0043, 447.8510, 447.5089, 448.1651, 451.4630,
            448.3679, 449.1559, 452.2044, 448.1705, 448.0695, 448.0436, 448.0814,
            447.6329, 447.7461, 448.1517, 447.9651, 447.6967, 450.1279, 447.8617,
            448.0165, 450.1629, 452.1988, 448.6899, 449.5692, 452.2039, 448.2676,
            448.1644, 447.9534, 448.0389, 448.6826, 447.8410, 448.1484, 447.9723,
            447.8854, 449.4528, 448.1670, 448.1641, 447.6551, 447.8054, 447.5999,
            447.8515, 448.1694, 448.1711, 448.1154, 447.8353, 447.8336, 447.7888,
            448.0051, 447.9576, 448.0162, 448.1635, 448.1707, 447.5517, 447.7040,
            449.6862, 447.6830, 448.7904, 448.1701, 447.6807, 448.0082, 452.2015,
            447.9144, 447.9196, 448.1528, 447.7244, 447.6299, 447.8390, 448.1352,
            452.1534, 447.9212, 448.1289, 450.6141, 447.5497, 448.1549, 452.1650,
            447.8276, 447.5220, 447.9693, 447.9102, 447.9987, 448.0239, 447.5089,
            447.7627, 447.8773, 448.1646, 449.8561, 452.2044, 449.6124, 448.1707,
            448.1053, 449.9805, 447.7852, 447.5542, 447.7484, 448.0004, 449.1199,
            448.1086, 447.9530, 447.6218, 448.1478, 449.4988, 447.5711, 448.1168,
            447.6368, 448.9342, 448.0972, 447.9251, 447.5590, 452.1958, 447.8944,
            448.1561, 447.8212, 448.0789, 452.2042, 447.7420, 449.3572, 448.1525,
            447.7980, 447.8737, 450.0203, 450.8718, 452.2043, 447.6599, 447.6496,
            448.0986, 447.7558, 448.1705, 447.9487, 448.1717, 452.2040, 451.2339,
            447.8601, 448.1478, 448.0067, 452.2029, 447.8354, 447.8801, 447.6376,
            447.8016, 448.1499, 447.9695, 452.2041, 447.4561, 447.8488, 447.7575,
            449.9004, 447.5568, 452.2042, 449.8110, 449.2888, 447.5332, 447.8551,
            447.6301, 448.0473, 447.6307, 447.9111, 448.0654, 447.7684, 448.1716,
            447.6085, 447.8294, 449.0894, 448.3946, 448.1673, 448.1270, 447.8544,
            447.8488, 448.1466, 447.9544, 448.1580, 448.1541, 448.1657, 447.9764,
            447.8983, 447.5109, 447.9517, 447.6575, 448.1096, 450.5614, 448.0967,
            448.1718, 448.1316, 448.1684, 452.2040, 447.9861, 448.0120, 448.1536,
            452.1275, 452.2040, 448.1625, 447.5455, 448.1712, 450.5007, 447.9640,
            447.8778, 447.8862, 449.6553, 448.3375, 447.5721, 447.9213, 447.7939,
            447.7231, 447.7196, 447.9905, 448.0795, 448.1336, 448.1396, 452.1691,
            450.8434, 452.1587, 447.8292, 447.9757, 447.9971, 448.0767, 447.7217,
            448.0106, 448.8818, 448.1363, 448.1710, 447.7160, 451.0161, 447.7912,
            448.0735, 447.8906, 448.1625, 448.1117, 447.8690, 450.2477, 447.4961,
            447.6439, 447.8766, 447.8335, 448.2194, 448.1483, 447.5642, 447.9675,
            447.6328, 450.2171, 448.1219, 447.6420, 447.4640, 447.6676, 447.6720,
            447.4934, 447.7733, 449.1204, 448.1499, 451.9715, 447.7665, 451.7270,
            447.9309, 449.1907, 448.1707, 448.0755, 448.1544, 447.5266, 447.8665,
            447.9164, 448.1086, 447.5290, 447.8364, 447.6654, 447.8127, 448.0042,
            448.1614, 447.6877, 448.6526, 448.1221, 448.1570, 448.1614, 448.8490,
            447.8832, 448.1658, 447.8284, 448.1561, 448.1714, 447.7603, 447.6712,
            447.7237, 447.9806, 447.9576, 447.9903, 447.9937, 447.4741, 447.8538,
            447.5855, 447.8255, 449.7739, 448.1603, 447.8487, 448.1544, 448.0813,
            447.8661, 447.8081, 452.3584, 448.1533, 448.0378, 447.8062, 447.9449,
            452.1792, 448.1596, 448.0554, 448.1378, 450.9615, 448.1376, 447.7931,
            447.7812, 448.0732, 447.9241, 449.1407, 448.1180, 452.1337, 452.2043,
            447.8529, 447.4622, 447.5802, 448.0165, 448.1274, 449.7769, 450.8376,
            447.8581, 448.1517, 448.1570, 447.8685, 447.9760, 447.9396, 452.2044,
            447.9914, 448.0361, 450.1973, 448.3142, 452.0287, 448.1140, 447.7451,
            448.1392, 450.9986, 448.0132, 447.6052, 448.0892, 447.6929, 447.7170,
            448.1357, 447.8400, 448.1483, 447.6072, 447.8867, 448.1249, 447.6766,
            447.9362, 448.1362, 447.8227, 449.9731, 447.9636, 447.8228, 447.7908,
            452.1078, 447.9687, 452.2040, 447.4655, 448.1545, 448.1538, 447.6173,
            448.1711, 448.1436, 447.7291, 450.1524, 447.7852, 448.1713, 448.0497,
            448.1718, 447.9150, 448.1520, 448.0353, 452.2265, 447.9874, 451.8372,
            447.9973, 448.1273, 447.9807, 448.7337, 448.4818, 447.6998, 447.8282,
            447.6307, 447.7102, 447.5340, 447.6949, 448.0739, 450.1464, 448.0207,
            448.0586, 448.1660, 448.1698, 452.2035, 447.7299, 447.6474, 447.9198,
            447.9498, 452.2042, 452.2042, 448.1649, 447.9134, 449.3608, 447.9113,
            447.6261, 447.6428, 447.5859, 447.6228, 447.9650, 448.9095, 448.2935,
            447.7792, 447.8833, 447.9526, 447.8075, 447.6815, 447.7510, 447.9101,
            447.9702, 447.9781, 448.1216, 447.9154, 447.5733, 447.5758, 447.9138,
            447.6288, 448.0024, 447.9924, 447.6049, 448.1442, 447.7716, 448.1453,
            448.0226, 448.1313, 448.1707, 448.1440, 448.1714, 447.7430, 448.1472,
            448.1393, 448.1602, 452.2042, 449.2535, 447.8741, 452.3457, 449.8275,
            448.1715, 448.1052, 447.6277, 448.1645, 448.1578, 447.7834, 447.4835,
            448.0569, 448.0031, 447.5004, 447.7697, 448.1654, 448.1658, 447.9417,
            447.9860, 452.2039, 448.1557, 448.5349, 447.9536, 450.8622, 447.7653,
            447.9877, 447.8968, 447.9893, 447.8754, 448.1175, 448.0427, 448.1209,
            448.1717, 450.0251, 447.7880, 448.1410, 448.7096, 449.9058, 447.8871,
            448.1456, 448.1028, 448.1026, 450.1125, 447.5414, 447.7243, 447.9737,
            447.9281, 447.8215, 448.1670, 447.8464, 447.5966, 447.7651, 448.0034,
            447.9019, 448.1387, 447.9323, 448.0702, 449.3394, 447.9419, 448.1614,
            447.8577, 447.6363, 447.5271, 447.7127, 447.8564, 447.8359, 447.4893,
            451.9301, 447.7865, 447.9993, 449.0280, 448.0714, 449.5018, 447.9938,
            447.7554, 448.1544, 447.7701, 452.2042, 447.5518, 448.1712, 451.4229,
            448.0218, 447.7666, 447.8120, 448.1428, 447.9723, 451.4696, 448.0363,
            447.8527, 447.7929, 448.5347, 449.4508, 452.2042, 448.1500, 452.2040,
            448.0024, 448.0240, 447.9393, 447.9347, 447.9762, 448.0507, 448.1512,
            448.1583, 448.1025, 448.8708, 448.6925, 452.2042, 447.9722, 448.1098,
            452.2004, 452.2043, 447.8796, 447.5942, 447.6266, 448.1062, 452.1945,
            448.1153, 452.2043, 447.8585, 451.3948, 450.4395, 449.6201, 452.2643,
            448.7585, 447.9126, 448.1162, 447.8791, 447.8417, 447.8824, 449.7230,
            448.1715, 448.0349, 447.9506, 447.8176, 448.1040, 449.7257, 447.7105,
            447.6411, 447.9835], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6541, 447.7905, 449.6261, 447.6929, 449.8768, 448.1447, 448.0938,
        447.9940, 448.1360, 448.1187, 447.9258, 449.7516, 448.0204, 449.7180,
        452.1056, 448.0185, 447.6251, 447.9671, 447.9518, 447.5577, 447.8419,
        447.6295, 452.1676, 447.9446, 447.8165, 447.9335, 449.0922, 448.7568,
        448.1309, 447.6238, 447.8907, 447.9989, 447.9636, 452.0696, 447.8436,
        448.6061, 451.9932, 448.0544, 447.6733, 448.1686, 447.9835, 447.9133,
        447.7686, 448.2019, 447.5089, 450.9136, 448.8221, 452.1526, 447.9258,
        448.1536, 449.9167, 447.6450, 447.8786, 447.8179, 452.2031, 448.1707,
        448.0929, 448.1601, 449.6554, 447.7065, 447.8148, 447.7709, 448.4999,
        448.0291, 447.8658, 452.2356, 452.2041, 447.9598, 447.9413, 448.1564,
        447.7940, 448.1427, 449.2683, 448.0044, 447.6750, 447.8028, 447.5493,
        448.0616, 447.8780, 448.0923, 447.7757, 447.8392, 448.0364, 452.2003,
        448.1680, 452.2043, 448.1008, 448.1003, 447.4649, 447.6585, 447.6210,
        447.8932, 447.9915, 449.4134, 447.6677, 447.7159, 448.9350, 448.0767,
        447.5517, 448.0526, 448.1122, 448.1628, 452.1154, 447.6714, 447.9659,
        447.8627, 447.5888, 448.1560, 448.6744, 452.2035, 447.8856, 447.8461,
        447.8832, 447.8242, 448.1716, 448.0908, 447.8975, 448.1376, 448.8924,
        448.1608, 447.5322, 451.5319, 447.5237, 448.0204, 447.7703, 452.2043,
        447.8004, 448.0283, 448.0349, 448.8560, 448.0212, 447.6582, 448.1388,
        447.7250, 452.1583, 449.9931, 448.1109, 447.9536, 447.8137, 447.4869,
        448.1371, 448.1504, 452.1842, 448.1579, 448.1005, 447.5335, 448.0054,
        447.9962, 447.9327, 447.8169, 450.4197, 449.1126, 447.5037, 448.0446,
        447.5573, 447.9111, 448.1569, 452.1122, 447.5204, 447.9207, 447.5850,
        447.9150, 450.3297, 452.2003, 447.6314, 451.3629, 452.0451, 448.1556,
        447.9005, 447.7786, 448.0570, 448.0326, 447.7899, 448.0164, 451.8032,
        448.1094, 448.0001, 447.7983, 448.1709, 447.7253, 447.9931, 447.6565,
        448.1664, 447.7921, 447.9940, 448.0164, 447.7474, 448.0814, 447.7523,
        448.3337, 447.7813, 447.6570, 448.0905, 448.1319, 452.2039, 447.4647,
        447.9252, 448.1071, 452.1448, 447.8616, 447.7930, 452.2043, 452.2038,
        447.7350, 452.1111, 447.9395, 447.8948, 447.8690, 447.6684, 448.1528,
        447.9883, 449.3657, 447.6620, 447.9321, 448.1491, 448.1185, 447.7357,
        447.9136, 449.4958, 448.1022, 448.1139, 452.2042, 451.0907, 447.5935,
        448.0823, 447.8626, 447.8073, 448.1576, 447.8415, 448.0116, 448.1682,
        447.7832, 449.4760, 452.2043, 452.2043, 447.8510, 448.0293, 447.7472,
        448.0377, 447.9757, 447.4889, 448.1263, 447.8213, 448.0469, 450.8358,
        448.0144, 447.8056, 452.1048, 448.5620, 447.7759, 447.8137, 447.6095,
        447.9203, 447.5909, 448.1011, 448.1655, 450.0117, 448.3819, 447.9760,
        447.8190, 448.0296, 447.6351, 447.9629, 448.1205, 447.5698, 452.2043,
        448.1700, 447.5858, 447.8069, 447.9896, 447.8455, 449.9148, 447.4848,
        448.0954, 448.0025, 447.8226, 448.1138, 448.1499, 447.8794, 447.8520,
        448.1713, 448.1680, 448.1614, 447.6166, 450.3207, 448.1299, 447.9641,
        448.1460, 447.6924, 448.1693, 447.5438, 447.9641, 447.4550, 448.1447,
        447.9069, 447.5388, 447.8708, 448.3085, 447.9449, 452.1935, 452.2040,
        448.0463, 447.4766, 448.0090, 452.1994, 447.9407, 448.0065, 448.1711,
        452.2017, 449.3724, 448.1279, 448.1587, 450.8068, 448.1168, 452.2042,
        448.1613, 448.1690, 447.8351, 452.1348, 447.9181, 447.7766, 448.1494,
        447.9575, 447.9089, 447.6724, 448.1464, 448.1657, 447.9832, 448.0755,
        448.1718, 448.0042, 452.2043, 448.1517, 447.9957, 447.9782, 447.4569,
        448.0487, 447.8446, 448.0925, 448.1442, 447.9097, 451.9878, 451.3536,
        447.8820, 447.8566, 448.0043, 447.8510, 447.5089, 448.1651, 451.4630,
        448.3679, 449.1559, 452.2044, 448.1705, 448.0695, 448.0436, 448.0814,
        447.6329, 447.7461, 448.1517, 447.9651, 447.6967, 450.1279, 447.8617,
        448.0165, 450.1629, 452.1988, 448.6899, 449.5692, 452.2039, 448.2676,
        448.1644, 447.9534, 448.0389, 448.6826, 447.8410, 448.1484, 447.9723,
        447.8854, 449.4528, 448.1670, 448.1641, 447.6551, 447.8054, 447.5999,
        447.8515, 448.1694, 448.1711, 448.1154, 447.8353, 447.8336, 447.7888,
        448.0051, 447.9576, 448.0162, 448.1635, 448.1707, 447.5517, 447.7040,
        449.6862, 447.6830, 448.7904, 448.1701, 447.6807, 448.0082, 452.2015,
        447.9144, 447.9196, 448.1528, 447.7244, 447.6299, 447.8390, 448.1352,
        452.1534, 447.9212, 448.1289, 450.6141, 447.5497, 448.1549, 452.1650,
        447.8276, 447.5220, 447.9693, 447.9102, 447.9987, 448.0239, 447.5089,
        447.7627, 447.8773, 448.1646, 449.8561, 452.2044, 449.6124, 448.1707,
        448.1053, 449.9805, 447.7852, 447.5542, 447.7484, 448.0004, 449.1199,
        448.1086, 447.9530, 447.6218, 448.1478, 449.4988, 447.5711, 448.1168,
        447.6368, 448.9342, 448.0972, 447.9251, 447.5590, 452.1958, 447.8944,
        448.1561, 447.8212, 448.0789, 452.2042, 447.7420, 449.3572, 448.1525,
        447.7980, 447.8737, 450.0203, 450.8718, 452.2043, 447.6599, 447.6496,
        448.0986, 447.7558, 448.1705, 447.9487, 448.1717, 452.2040, 451.2339,
        447.8601, 448.1478, 448.0067, 452.2029, 447.8354, 447.8801, 447.6376,
        447.8016, 448.1499, 447.9695, 452.2041, 447.4561, 447.8488, 447.7575,
        449.9004, 447.5568, 452.2042, 449.8110, 449.2888, 447.5332, 447.8551,
        447.6301, 448.0473, 447.6307, 447.9111, 448.0654, 447.7684, 448.1716,
        447.6085, 447.8294, 449.0894, 448.3946, 448.1673, 448.1270, 447.8544,
        447.8488, 448.1466, 447.9544, 448.1580, 448.1541, 448.1657, 447.9764,
        447.8983, 447.5109, 447.9517, 447.6575, 448.1096, 450.5614, 448.0967,
        448.1718, 448.1316, 448.1684, 452.2040, 447.9861, 448.0120, 448.1536,
        452.1275, 452.2040, 448.1625, 447.5455, 448.1712, 450.5007, 447.9640,
        447.8778, 447.8862, 449.6553, 448.3375, 447.5721, 447.9213, 447.7939,
        447.7231, 447.7196, 447.9905, 448.0795, 448.1336, 448.1396, 452.1691,
        450.8434, 452.1587, 447.8292, 447.9757, 447.9971, 448.0767, 447.7217,
        448.0106, 448.8818, 448.1363, 448.1710, 447.7160, 451.0161, 447.7912,
        448.0735, 447.8906, 448.1625, 448.1117, 447.8690, 450.2477, 447.4961,
        447.6439, 447.8766, 447.8335, 448.2194, 448.1483, 447.5642, 447.9675,
        447.6328, 450.2171, 448.1219, 447.6420, 447.4640, 447.6676, 447.6720,
        447.4934, 447.7733, 449.1204, 448.1499, 451.9715, 447.7665, 451.7270,
        447.9309, 449.1907, 448.1707, 448.0755, 448.1544, 447.5266, 447.8665,
        447.9164, 448.1086, 447.5290, 447.8364, 447.6654, 447.8127, 448.0042,
        448.1614, 447.6877, 448.6526, 448.1221, 448.1570, 448.1614, 448.8490,
        447.8832, 448.1658, 447.8284, 448.1561, 448.1714, 447.7603, 447.6712,
        447.7237, 447.9806, 447.9576, 447.9903, 447.9937, 447.4741, 447.8538,
        447.5855, 447.8255, 449.7739, 448.1603, 447.8487, 448.1544, 448.0813,
        447.8661, 447.8081, 452.3584, 448.1533, 448.0378, 447.8062, 447.9449,
        452.1792, 448.1596, 448.0554, 448.1378, 450.9615, 448.1376, 447.7931,
        447.7812, 448.0732, 447.9241, 449.1407, 448.1180, 452.1337, 452.2043,
        447.8529, 447.4622, 447.5802, 448.0165, 448.1274, 449.7769, 450.8376,
        447.8581, 448.1517, 448.1570, 447.8685, 447.9760, 447.9396, 452.2044,
        447.9914, 448.0361, 450.1973, 448.3142, 452.0287, 448.1140, 447.7451,
        448.1392, 450.9986, 448.0132, 447.6052, 448.0892, 447.6929, 447.7170,
        448.1357, 447.8400, 448.1483, 447.6072, 447.8867, 448.1249, 447.6766,
        447.9362, 448.1362, 447.8227, 449.9731, 447.9636, 447.8228, 447.7908,
        452.1078, 447.9687, 452.2040, 447.4655, 448.1545, 448.1538, 447.6173,
        448.1711, 448.1436, 447.7291, 450.1524, 447.7852, 448.1713, 448.0497,
        448.1718, 447.9150, 448.1520, 448.0353, 452.2265, 447.9874, 451.8372,
        447.9973, 448.1273, 447.9807, 448.7337, 448.4818, 447.6998, 447.8282,
        447.6307, 447.7102, 447.5340, 447.6949, 448.0739, 450.1464, 448.0207,
        448.0586, 448.1660, 448.1698, 452.2035, 447.7299, 447.6474, 447.9198,
        447.9498, 452.2042, 452.2042, 448.1649, 447.9134, 449.3608, 447.9113,
        447.6261, 447.6428, 447.5859, 447.6228, 447.9650, 448.9095, 448.2935,
        447.7792, 447.8833, 447.9526, 447.8075, 447.6815, 447.7510, 447.9101,
        447.9702, 447.9781, 448.1216, 447.9154, 447.5733, 447.5758, 447.9138,
        447.6288, 448.0024, 447.9924, 447.6049, 448.1442, 447.7716, 448.1453,
        448.0226, 448.1313, 448.1707, 448.1440, 448.1714, 447.7430, 448.1472,
        448.1393, 448.1602, 452.2042, 449.2535, 447.8741, 452.3457, 449.8275,
        448.1715, 448.1052, 447.6277, 448.1645, 448.1578, 447.7834, 447.4835,
        448.0569, 448.0031, 447.5004, 447.7697, 448.1654, 448.1658, 447.9417,
        447.9860, 452.2039, 448.1557, 448.5349, 447.9536, 450.8622, 447.7653,
        447.9877, 447.8968, 447.9893, 447.8754, 448.1175, 448.0427, 448.1209,
        448.1717, 450.0251, 447.7880, 448.1410, 448.7096, 449.9058, 447.8871,
        448.1456, 448.1028, 448.1026, 450.1125, 447.5414, 447.7243, 447.9737,
        447.9281, 447.8215, 448.1670, 447.8464, 447.5966, 447.7651, 448.0034,
        447.9019, 448.1387, 447.9323, 448.0702, 449.3394, 447.9419, 448.1614,
        447.8577, 447.6363, 447.5271, 447.7127, 447.8564, 447.8359, 447.4893,
        451.9301, 447.7865, 447.9993, 449.0280, 448.0714, 449.5018, 447.9938,
        447.7554, 448.1544, 447.7701, 452.2042, 447.5518, 448.1712, 451.4229,
        448.0218, 447.7666, 447.8120, 448.1428, 447.9723, 451.4696, 448.0363,
        447.8527, 447.7929, 448.5347, 449.4508, 452.2042, 448.1500, 452.2040,
        448.0024, 448.0240, 447.9393, 447.9347, 447.9762, 448.0507, 448.1512,
        448.1583, 448.1025, 448.8708, 448.6925, 452.2042, 447.9722, 448.1098,
        452.2004, 452.2043, 447.8796, 447.5942, 447.6266, 448.1062, 452.1945,
        448.1153, 452.2043, 447.8585, 451.3948, 450.4395, 449.6201, 452.2643,
        448.7585, 447.9126, 448.1162, 447.8791, 447.8417, 447.8824, 449.7230,
        448.1715, 448.0349, 447.9506, 447.8176, 448.1040, 449.7257, 447.7105,
        447.6411, 447.9835], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([398.6316], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9734],
             [112.0428],
             [111.8685],
             [112.0291]],

            [[111.9312],
             [111.9312],
             [111.9620],
             [111.9620]],

            [[112.0088],
             [112.0373],
             [111.8650],
             [111.8688]],

            ...,

            [[112.1967],
             [111.8653],
             [111.8781],
             [111.8781]],

            [[111.8611],
             [112.0264],
             [111.8629],
             [112.0192]],

            [[111.8877],
             [111.8691],
             [111.8679],
             [111.8640]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9138, 447.7865, 447.7799,  ..., 447.8182, 447.7696, 447.4888],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9138, 447.7865, 447.7799,  ..., 447.8182, 447.7696, 447.4888],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0250],
             [112.0250],
             [112.0313],
             [112.0313]],

            [[112.0305],
             [112.0321],
             [112.0305],
             [112.0321]],

            [[111.8502],
             [111.8677],
             [112.0209],
             [112.0209]],

            ...,

            [[113.2119],
             [113.1073],
             [113.1279],
             [113.1279]],

            [[111.8698],
             [112.0242],
             [112.0320],
             [111.8577]],

            [[111.8914],
             [111.8713],
             [111.8777],
             [111.8777]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1125, 448.1252, 447.7596,  ..., 452.5751, 447.7838, 447.5181],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1125, 448.1252, 447.7596,  ..., 452.5751, 447.7838, 447.5181],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8475],
             [111.8475],
             [112.0216],
             [112.0216]],

            [[111.8572],
             [111.8464],
             [111.8959],
             [111.8463]],

            [[112.0262],
             [112.0264],
             [112.0264],
             [112.0264]],

            ...,

            [[111.9438],
             [111.9438],
             [111.8472],
             [112.0078]],

            [[113.0840],
             [112.1836],
             [112.8727],
             [112.8727]],

            [[112.0090],
             [111.9704],
             [111.9892],
             [112.0228]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7382, 447.4457, 448.1055,  ..., 447.7427, 451.0130, 447.9914],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7382, 447.4457, 448.1055,  ..., 447.7427, 451.0130, 447.9914],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9986],
             [112.0216],
             [111.9974],
             [111.9974]],

            [[111.9461],
             [111.9461],
             [112.0148],
             [112.0148]],

            [[113.0950],
             [113.0961],
             [113.0958],
             [113.0955]],

            ...,

            [[112.0066],
             [112.0108],
             [112.0129],
             [112.0199]],

            [[112.0234],
             [112.0234],
             [112.0234],
             [112.0234]],

            [[111.8363],
             [111.8587],
             [111.8733],
             [111.8733]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0151, 447.9217, 452.3824,  ..., 448.0502, 448.0937, 447.4416],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0151, 447.9217, 452.3824,  ..., 448.0502, 448.0937, 447.4416],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9739],
             [112.0151],
             [111.9873],
             [111.9819]],

            [[113.1068],
             [112.8491],
             [113.1019],
             [113.1019]],

            [[112.9257],
             [112.9257],
             [112.6442],
             [112.6442]],

            ...,

            [[112.9919],
             [113.0944],
             [113.1022],
             [112.9766]],

            [[113.1061],
             [113.1061],
             [113.0948],
             [113.0948]],

            [[112.0156],
             [111.9835],
             [112.0174],
             [112.0070]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9581, 452.1597, 451.1398,  ..., 452.1650, 452.4017, 448.0236],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9581, 452.1597, 451.1398,  ..., 452.1650, 452.4017, 448.0236],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8316],
             [111.8316],
             [111.8399],
             [111.8399]],

            [[112.0145],
             [111.8748],
             [111.9810],
             [112.0080]],

            [[112.0038],
             [112.0144],
             [112.0038],
             [112.0144]],

            ...,

            [[111.8380],
             [111.8264],
             [111.8320],
             [111.8882]],

            [[112.0111],
             [112.0111],
             [112.0132],
             [112.0132]],

            [[112.3249],
             [112.3249],
             [112.2106],
             [112.2106]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.3430, 447.8783, 448.0365,  ..., 447.3846, 448.0486, 449.0710],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.3430, 447.8783, 448.0365,  ..., 447.3846, 448.0486, 449.0710],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0082],
             [112.0087],
             [112.0079],
             [112.0088]],

            [[112.0003],
             [112.0013],
             [112.0089],
             [112.0089]],

            [[112.0087],
             [112.0014],
             [112.0089],
             [112.0089]],

            ...,

            [[111.8312],
             [111.8956],
             [111.8269],
             [111.8269]],

            [[111.8469],
             [112.0029],
             [111.9731],
             [111.9916]],

            [[111.8171],
             [111.8171],
             [111.9957],
             [111.9957]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0336, 448.0193, 448.0279,  ..., 447.3806, 447.8146, 447.6256],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0336, 448.0193, 448.0279,  ..., 447.3806, 447.8146, 447.6256],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9675],
             [113.1416],
             [113.1420],
             [111.9812]],

            [[111.8052],
             [112.8702],
             [112.9250],
             [111.8056]],

            [[111.9815],
             [111.8170],
             [111.9242],
             [111.8186]],

            ...,

            [[111.8031],
             [111.9489],
             [111.8120],
             [111.9356]],

            [[111.9041],
             [111.9464],
             [111.9862],
             [111.9984]],

            [[113.1432],
             [113.1432],
             [113.1433],
             [113.1433]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.2323, 449.4059, 447.5413,  ..., 447.4996, 447.8351, 452.5731],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.2323, 449.4059, 447.5413,  ..., 447.4996, 447.8351, 452.5731],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9920],
             [111.9794],
             [111.9929],
             [111.9929]],

            [[111.8255],
             [111.9256],
             [111.8465],
             [111.9825]],

            [[113.1858],
             [113.1413],
             [113.1870],
             [113.1870]],

            ...,

            [[111.7973],
             [111.8039],
             [111.9767],
             [111.9767]],

            [[111.9780],
             [111.9780],
             [111.9912],
             [111.9912]],

            [[111.9442],
             [111.9538],
             [111.8032],
             [111.8032]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9572, 447.5802, 452.7011,  ..., 447.5544, 447.9384, 447.5044],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9572, 447.5802, 452.7011,  ..., 447.5544, 447.9384, 447.5044],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9514],
             [111.9818],
             [111.7875],
             [111.7883]],

            [[111.9443],
             [111.7847],
             [111.7857],
             [111.9660]],

            [[111.7863],
             [111.7863],
             [111.8220],
             [111.8220]],

            ...,

            [[112.2798],
             [112.2798],
             [112.1244],
             [112.1243]],

            [[111.9797],
             [111.9797],
             [111.9887],
             [111.9887]],

            [[111.8046],
             [113.1176],
             [113.1887],
             [111.8117]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5089, 447.4807, 447.2164,  ..., 448.8083, 447.9367, 449.9225],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5089, 447.4807, 447.2164,  ..., 448.8083, 447.9367, 449.9225],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9640],
             [111.9181],
             [111.8023],
             [111.9949]],

            [[112.5306],
             [112.7644],
             [111.9595],
             [112.0872]],

            [[111.9637],
             [111.9695],
             [111.7938],
             [113.2459]],

            ...,

            [[111.9954],
             [111.8945],
             [111.9745],
             [111.9745]],

            [[111.7945],
             [111.7982],
             [111.9955],
             [111.9782]],

            [[111.9893],
             [111.9953],
             [111.9945],
             [111.9870]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6793, 449.3416, 448.9728,  ..., 447.8388, 447.5664, 447.9662],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6793, 449.3416, 448.9728,  ..., 447.8388, 447.5664, 447.9662],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0005],
             [112.0005],
             [112.0105],
             [112.0105]],

            [[111.8138],
             [111.9878],
             [111.8162],
             [111.9672]],

            [[111.9935],
             [111.9935],
             [112.0104],
             [112.0104]],

            ...,

            [[111.9743],
             [112.0105],
             [111.9900],
             [112.0065]],

            [[112.1855],
             [113.2634],
             [113.2643],
             [112.0839]],

            [[113.2599],
             [113.2598],
             [113.2598],
             [113.2597]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0220, 447.5850, 448.0078,  ..., 447.9812, 450.7971, 453.0392],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0220, 447.5850, 448.0078,  ..., 447.9812, 450.7971, 453.0392],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0279],
             [112.6875],
             [111.8394],
             [111.8294]],

            [[113.2450],
             [113.2728],
             [113.2729],
             [113.2504]],

            [[113.2722],
             [113.2716],
             [113.2715],
             [113.2724]],

            ...,

            [[111.9953],
             [111.8298],
             [111.9965],
             [111.8288]],

            [[111.8293],
             [111.8293],
             [111.9997],
             [111.9997]],

            [[113.2750],
             [112.8112],
             [112.8117],
             [113.2715]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3841, 453.0411, 453.0876,  ..., 447.6503, 447.6581, 452.1693],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3841, 453.0411, 453.0876,  ..., 447.6503, 447.6581, 452.1693],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9079],
             [111.8828],
             [111.8995],
             [111.8839]],

            [[112.9913],
             [112.5845],
             [112.8569],
             [113.1072]],

            [[111.8875],
             [112.0240],
             [112.0419],
             [112.0419]],

            ...,

            [[113.2766],
             [113.2766],
             [113.2765],
             [113.2765]],

            [[111.9527],
             [111.9714],
             [112.0193],
             [112.0443]],

            [[111.8661],
             [111.9208],
             [112.0320],
             [112.0320]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5740, 451.5400, 447.9953,  ..., 453.1062, 447.9877, 447.8509],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5740, 451.5400, 447.9953,  ..., 453.1062, 447.9877, 447.8509],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0559],
             [112.0559],
             [112.0600],
             [112.0600]],

            [[112.0094],
             [111.8965],
             [111.9530],
             [111.8989]],

            [[113.2762],
             [113.2792],
             [113.2772],
             [113.2772]],

            ...,

            [[112.0462],
             [111.8879],
             [112.0587],
             [112.0587]],

            [[111.9552],
             [111.9094],
             [111.8933],
             [111.9673]],

            [[111.8935],
             [111.8908],
             [112.0514],
             [112.0514]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2319, 447.7579, 453.1099,  ..., 448.0516, 447.7252, 447.8871],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2319, 447.7579, 453.1099,  ..., 448.0516, 447.7252, 447.8871],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9151],
             [112.0659],
             [112.0132],
             [112.0107]],

            [[113.1188],
             [113.1188],
             [113.2850],
             [113.2850]],

            [[113.3127],
             [113.2822],
             [113.2811],
             [113.2796]],

            ...,

            [[113.2735],
             [113.2735],
             [113.2735],
             [113.2735]],

            [[111.9911],
             [111.9854],
             [111.9292],
             [112.0781]],

            [[112.0679],
             [112.0679],
             [112.0790],
             [112.0790]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0049, 452.8076, 453.1556,  ..., 453.0939, 447.9838, 448.2939],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0049, 452.8076, 453.1556,  ..., 453.0939, 447.9838, 448.2939],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.2828],
             [113.2828],
             [113.2589],
             [113.2589]],

            [[111.9480],
             [111.9480],
             [111.9620],
             [111.9620]],

            [[112.0341],
             [112.0341],
             [112.0874],
             [112.0874]],

            ...,

            [[111.9482],
             [111.9947],
             [112.0529],
             [112.0894]],

            [[111.9502],
             [111.9420],
             [111.9336],
             [111.9575]],

            [[112.0004],
             [112.0361],
             [111.9908],
             [112.0887]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([453.0835, 447.8200, 448.2429,  ..., 448.0852, 447.7833, 448.1160],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([453.0835, 447.8200, 448.2429,  ..., 448.0852, 447.7833, 448.1160],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9431],
             [112.0317],
             [111.9561],
             [111.9988]],

            [[113.1977],
             [113.1977],
             [113.1975],
             [113.1975]],

            [[111.9429],
             [112.0645],
             [111.9521],
             [111.9521]],

            ...,

            [[111.9510],
             [112.0977],
             [112.0220],
             [112.0204]],

            [[112.1290],
             [112.1290],
             [112.0994],
             [112.0994]],

            [[112.3453],
             [111.9445],
             [112.2243],
             [111.9439]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9297, 452.7906, 447.9116,  ..., 448.0910, 448.4568, 448.4580],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9297, 452.7906, 447.9116,  ..., 448.0910, 448.4568, 448.4580],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0167e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1925],
             [111.9625],
             [112.0160],
             [112.0160]],

            [[113.1592],
             [113.0021],
             [113.0029],
             [113.1301]],

            [[113.1329],
             [113.1509],
             [113.1490],
             [113.1359]],

            ...,

            [[112.0952],
             [112.0057],
             [112.1021],
             [112.1021]],

            [[111.9605],
             [111.9600],
             [112.0685],
             [112.0685]],

            [[113.1791],
             [113.1781],
             [112.0369],
             [113.2122]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1868, 452.2943, 452.5688,  ..., 448.3051, 448.0576, 451.6063],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1868, 452.2943, 452.5688,  ..., 448.3051, 448.0576, 451.6063],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9598],
             [112.0669],
             [111.9639],
             [112.0581]],

            [[111.9841],
             [112.0405],
             [112.0986],
             [111.9865]],

            [[112.0684],
             [112.0233],
             [112.0269],
             [112.1008]],

            ...,

            [[111.9988],
             [111.9612],
             [111.9628],
             [112.0459]],

            [[113.2122],
             [113.1514],
             [113.1451],
             [113.2355]],

            [[112.0518],
             [112.0518],
             [112.0959],
             [112.0959]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0487, 448.1097, 448.2195,  ..., 447.9686, 452.7441, 448.2953],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0487, 448.1097, 448.2195,  ..., 447.9686, 452.7441, 448.2953],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.1124],
             [111.9924],
             [113.0572],
             [111.9900]],

            [[111.9740],
             [112.0989],
             [111.9633],
             [112.0323]],

            [[112.0004],
             [111.9820],
             [111.9914],
             [111.9647]],

            ...,

            [[112.0577],
             [111.9841],
             [112.1026],
             [111.9673]],

            [[111.9643],
             [112.0556],
             [112.0953],
             [111.9618]],

            [[111.9621],
             [111.9621],
             [112.0070],
             [112.0070]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.1520, 448.0686, 447.9385, 452.7236, 448.3030, 448.1846, 448.1750,
            452.4749, 452.5212, 448.0501, 448.0973, 447.9284, 448.1105, 448.0703,
            452.5497, 449.5540, 451.2989, 448.7390, 449.6647, 448.2149, 448.0991,
            448.6418, 452.7292, 448.1525, 447.9072, 448.2223, 447.9608, 448.2455,
            450.1997, 448.0447, 447.9295, 452.5204, 448.1561, 448.0689, 448.1497,
            452.5217, 448.2206, 452.5386, 448.2810, 447.9162, 448.2970, 448.0341,
            451.8716, 447.8826, 449.4113, 448.1064, 448.2112, 448.1142, 448.3314,
            447.9746, 447.9748, 449.6313, 448.0972, 449.6647, 452.7300, 447.9547,
            448.7625, 448.1127, 448.3085, 448.2726, 448.0826, 447.9276, 448.0792,
            448.3914, 448.1248, 448.0667, 448.1487, 448.2017, 452.6494, 452.5676,
            447.9231, 448.1428, 448.0966, 447.9208, 448.1466, 448.3897, 448.2315,
            448.2427, 448.1069, 452.3765, 448.8120, 452.5303, 447.9362, 452.4072,
            448.0930, 448.3458, 448.1290, 452.9045, 448.3341, 448.2867, 450.4503,
            452.8879, 448.3829, 447.9490, 448.0074, 448.0101, 452.5447, 450.9061,
            452.7269, 447.9688, 447.9232, 448.2080, 448.0834, 448.3300, 448.3318,
            448.2625, 448.6738, 448.1426, 448.1194, 448.1148, 448.1431, 448.0101,
            448.3333, 451.9710, 448.1061, 448.2556, 448.2988, 448.1317, 448.4202,
            448.3309, 448.1648, 452.6364, 448.0184, 448.2778, 447.9150, 447.9403,
            447.8536, 448.0267, 447.9499, 448.1071, 448.3727, 448.1949, 448.1117,
            448.2967, 448.1496, 448.3362, 449.3150, 447.9994, 448.0910, 448.1095,
            447.9487, 451.5043, 452.5264, 448.3127, 447.9411, 447.9962, 448.0078,
            447.9321, 448.2294, 448.0769, 450.2675, 452.5212, 447.9950, 447.8976,
            451.3082, 448.0241, 448.0779, 447.9664, 448.2925, 448.1487, 447.9686,
            448.1769, 448.0931, 448.0878, 447.9182, 448.3557, 448.1057, 448.1043,
            447.9576, 452.6061, 449.4848, 448.2209, 448.2140, 448.0802, 452.5305,
            448.0953, 448.1892, 450.9992, 448.0739, 452.6011, 447.8969, 448.2985,
            448.0700, 448.1617, 448.1337, 448.5417, 452.5204, 450.1997, 449.2375,
            452.7223, 447.8632, 449.5047, 452.8455, 448.1820, 452.9115, 449.6133,
            452.6714, 452.6916, 451.9681, 447.9839, 447.9055, 448.0061, 453.6060,
            448.0037, 452.8322, 452.5251, 447.9934, 451.0446, 448.0308, 452.6600,
            449.4208, 447.9659, 452.5202, 448.1342, 448.2413, 451.5714, 448.2067,
            448.2811, 452.7481, 451.7080, 449.0226, 447.9200, 448.0921, 447.9178,
            452.6409, 449.1796, 452.5284, 452.7052, 448.0118, 448.1819, 448.7358,
            447.9126, 448.0975, 447.9670, 452.8096, 448.0935, 448.0099, 448.3229,
            448.1475, 452.7219, 448.2293, 447.9480, 447.9678, 448.1333, 447.9197,
            448.3590, 452.5302, 452.5282, 448.0982, 448.1141, 447.9189, 447.8957,
            447.9377, 450.5963, 452.8792, 449.1646, 448.0867, 448.1590, 452.5862,
            447.9445, 448.3371, 452.5205, 448.0834, 448.0114, 451.9467, 452.5224,
            451.5848, 449.4580, 447.9553, 450.1998, 452.7467, 449.7025, 448.1954,
            450.1965, 450.9991, 448.1005, 448.2004, 448.0281, 452.8354, 448.4964,
            448.2479, 448.3522, 452.5303, 447.9622, 448.3520, 448.3201, 448.3279,
            448.0670, 448.0555, 448.0592, 448.1291, 452.5894, 452.5258, 448.0373,
            448.1088, 448.3405, 448.0269, 452.5282, 448.2124, 447.9144, 448.0302,
            448.1017, 448.2732, 448.1947, 448.1663, 448.3449, 448.0767, 448.1422,
            450.1894, 448.1191, 447.9312, 448.0277, 452.5243, 452.5746, 448.3908,
            447.9594, 447.9921, 452.5203, 447.8553, 452.5203, 448.0435, 448.0974,
            448.3903, 447.9426, 448.3607, 448.1800, 447.9279, 447.9297, 448.1058,
            450.0568, 448.1516, 452.5346, 452.5205, 448.3843, 448.1921, 447.9548,
            452.6024, 452.6909, 452.5423, 451.6714, 448.0261, 452.5556, 448.0475,
            448.0980, 449.6279, 450.2629, 448.1171, 448.0960, 448.2061, 448.0145,
            452.5202, 447.9127, 447.9246, 448.0612, 452.7263, 452.5464, 447.8932,
            452.3754, 448.0381, 448.1057, 452.5215, 448.0046, 448.0519, 450.6284,
            448.2363, 448.0959, 448.1033, 450.1312, 448.0918, 452.6385, 452.3018,
            448.1241, 448.0063, 452.5202, 448.2864, 448.2411, 452.6458, 448.2094,
            449.2258, 448.3089, 448.1386, 448.1060, 447.9613, 448.0120, 447.9520,
            448.0321, 448.0906, 448.1947, 451.3407, 447.9571, 448.3307, 448.3479,
            448.2388, 448.0551, 449.5067, 448.1027, 452.5227, 448.0826, 448.3317,
            452.7509, 448.0911, 448.5736, 447.9242, 447.9638, 447.9129, 447.9758,
            448.0860, 452.3540, 448.0911, 448.3025, 448.0439, 448.0763, 447.9008,
            447.9265, 452.6841, 452.5428, 452.1475, 447.9503, 448.2037, 448.1150,
            449.5656, 448.2278, 448.3610, 449.5229, 447.9276, 448.3205, 452.5551,
            448.0492, 452.5565, 448.2215, 448.3876, 450.9491, 448.4054, 448.2184,
            452.7397, 448.1064, 452.5205, 448.3408, 447.9201, 448.3910, 448.0132,
            450.7479, 447.9745, 447.9839, 448.0516, 452.3525, 452.5237, 448.2392,
            448.3221, 448.0679, 448.2479, 448.2332, 448.0637, 447.9315, 448.2469,
            452.9097, 447.9458, 452.3762, 452.5202, 447.9289, 448.1176, 447.9162,
            448.3820, 448.0890, 452.5215, 452.5675, 452.3763, 448.3563, 447.8857,
            447.9865, 448.0994, 448.0990, 452.6428, 448.1331, 451.0072, 448.0303,
            452.5784, 452.5421, 448.3818, 448.1418, 447.9306, 448.3588, 448.0428,
            448.0779, 449.4528, 448.7597, 452.6099, 448.0673, 448.3445, 448.3658,
            448.3828, 448.0565, 448.3577, 452.7512, 448.1025, 453.7242, 452.5771,
            452.5241, 448.3294, 450.1384, 449.0464, 448.3649, 448.2554, 447.9087,
            451.5757, 452.6516, 452.5839, 448.0290, 448.0795, 448.3828, 447.9690,
            449.0530, 448.0996, 448.1077, 448.2116, 450.5587, 451.6709, 449.8863,
            448.3571, 448.1075, 452.6218, 448.1083, 448.0858, 448.3230, 448.1992,
            448.2949, 447.9737, 448.2701, 448.0196, 452.5202, 448.2122, 452.6476,
            452.8499, 448.1578, 448.1500, 448.3607, 448.0755, 452.5482, 448.3130,
            448.3410, 448.1375, 451.1911, 450.4695, 448.0306, 448.2028, 447.9959,
            452.1581, 447.9952, 448.0252, 448.2851, 450.6835, 448.1559, 448.0278,
            447.9790, 448.1896, 448.1824, 450.4312, 448.2604, 447.9680, 452.7214,
            452.5205, 448.3244, 448.0593, 448.0583, 448.3426, 448.1165, 448.2090,
            448.3629, 452.7180, 448.0687, 448.1015, 448.3943, 448.0794, 448.0416,
            447.9227, 447.9905, 451.6350, 452.5203, 448.0992, 447.9460, 447.9734,
            452.9016, 447.8960, 448.3916, 448.1416, 448.0103, 448.0838, 448.1945,
            448.1382, 447.9557, 448.0229, 452.5204, 447.9240, 448.3713, 448.1053,
            448.8176, 452.5222, 450.3054, 448.0875, 448.0378, 448.0705, 452.6238,
            450.5358, 447.9062, 448.2248, 448.0591, 452.5442, 448.3572, 448.2270,
            452.5258, 448.1137, 448.4974, 452.2772, 448.0862, 448.2933, 448.1832,
            450.9619, 448.4768, 448.0615, 452.6228, 452.7477, 448.1144, 448.1212,
            448.1955, 452.7015, 448.1007, 448.3765, 448.9332, 452.5202, 452.5659,
            448.2590, 448.2532, 448.0591, 448.2412, 449.3487, 448.3707, 448.1664,
            448.4461, 448.3664, 448.2394, 448.0823, 452.7829, 448.1130, 452.5862,
            452.6791, 447.9577, 448.1777, 448.1129, 452.7932, 452.5965, 452.5202,
            448.1038, 452.3766, 448.1408, 452.7480, 448.3918, 448.3667, 447.9725,
            450.2251, 447.9932, 448.2289, 448.1401, 448.1223, 448.0753, 452.5369,
            448.1530, 448.0979, 452.5374, 448.0639, 448.1770, 452.9467, 450.1997,
            452.6040, 448.1161, 450.2266, 448.3298, 448.1034, 448.2302, 448.0950,
            448.1288, 448.3111, 448.1419, 448.1548, 447.9900, 452.8959, 448.0869,
            448.2676, 451.9927, 448.1262, 452.5641, 448.0445, 448.1385, 448.0432,
            447.9298, 447.9959, 448.1216, 452.5223, 448.3900, 448.2857, 448.1166,
            448.3033, 448.2686, 448.3210, 448.3134, 448.3646, 448.9814, 452.5202,
            452.9075, 447.9806, 447.9771, 448.0975, 448.0483, 447.9581, 448.2967,
            448.2406, 447.9880, 448.7670, 448.1462, 448.3216, 448.0194, 452.5882,
            448.3733, 450.2554, 448.1222, 452.7248, 448.3370, 448.0882, 452.5667,
            447.9097, 447.9514, 448.2022, 452.7265, 447.9641, 447.9289, 447.9211,
            448.0302, 447.9973, 452.7444, 448.3478, 448.1746, 448.3507, 448.1069,
            453.6155, 447.9745, 452.5533, 449.7662, 448.8932, 448.3260, 452.8499,
            452.5212, 448.3592, 452.7198, 448.2217, 448.3566, 448.0880, 448.1069,
            447.9789, 452.6097, 448.0933, 448.1315, 448.1065, 447.9829, 447.9136,
            448.2594, 448.2360, 448.0446, 448.1316, 447.8561, 448.5942, 448.1100,
            452.5803, 448.0986, 453.6350, 450.0061, 450.4286, 448.3620, 448.2245,
            452.5206, 447.9572, 447.9139, 448.0234, 452.7172, 450.4309, 448.1291,
            448.1702, 452.9500, 448.3258, 451.1000, 447.9598, 450.7834, 448.1085,
            448.0435, 447.9286, 452.5226, 451.1882, 448.1183, 448.0364, 452.5274,
            448.2720, 448.3248, 448.1924, 448.1037, 448.1434, 451.9319, 452.8121,
            448.2394, 448.2936, 452.5426, 448.1246, 452.5894, 452.5401, 452.5202,
            447.8994, 452.5244, 452.7548, 447.9437, 448.1209, 447.8433, 452.5203,
            448.9736, 448.3749, 448.0819, 448.1405, 448.0396, 448.1197, 450.1541,
            448.1666, 452.7394, 447.9789, 448.2419, 448.2591, 448.1365, 448.1073,
            452.5212, 447.8944, 448.0098, 448.0995, 450.7951, 448.0794, 448.3607,
            447.9336, 447.9873, 448.3663, 448.1252, 448.0617, 448.3521, 448.2636,
            447.9262, 448.1588, 448.0677, 449.4100, 447.8866, 447.9252, 450.1894,
            451.5287, 448.3731, 452.1202, 448.1280, 447.8653, 452.6984, 448.0182,
            450.5966, 448.0241, 452.5222, 448.0322, 452.5526, 448.2367, 449.2690,
            448.0887, 452.5207, 448.4011, 447.9240, 448.0529, 448.8954, 448.3431,
            448.0142, 448.1392, 447.9633, 448.1029, 447.9507, 448.1082, 448.2049,
            448.2922, 452.7219, 448.1683, 452.5221, 448.2462, 448.3009, 448.0587,
            448.0356, 448.2388, 452.5208, 448.0997, 448.2712, 448.3709, 448.9435,
            449.4998, 447.9866, 448.3261, 447.9363, 448.1167, 448.3484, 450.4088,
            448.1179, 452.5214, 448.0387, 448.3191, 452.5427, 451.3949, 448.0855,
            447.9476, 448.5537, 448.0015, 448.2535, 448.1142, 448.3974, 448.0490,
            448.4410, 447.9224, 448.1423, 448.0820, 452.6904, 448.1135, 448.1118,
            448.0771, 447.9383], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.1520, 448.0686, 447.9385, 452.7236, 448.3030, 448.1846, 448.1750,
        452.4749, 452.5212, 448.0501, 448.0973, 447.9284, 448.1105, 448.0703,
        452.5497, 449.5540, 451.2989, 448.7390, 449.6647, 448.2149, 448.0991,
        448.6418, 452.7292, 448.1525, 447.9072, 448.2223, 447.9608, 448.2455,
        450.1997, 448.0447, 447.9295, 452.5204, 448.1561, 448.0689, 448.1497,
        452.5217, 448.2206, 452.5386, 448.2810, 447.9162, 448.2970, 448.0341,
        451.8716, 447.8826, 449.4113, 448.1064, 448.2112, 448.1142, 448.3314,
        447.9746, 447.9748, 449.6313, 448.0972, 449.6647, 452.7300, 447.9547,
        448.7625, 448.1127, 448.3085, 448.2726, 448.0826, 447.9276, 448.0792,
        448.3914, 448.1248, 448.0667, 448.1487, 448.2017, 452.6494, 452.5676,
        447.9231, 448.1428, 448.0966, 447.9208, 448.1466, 448.3897, 448.2315,
        448.2427, 448.1069, 452.3765, 448.8120, 452.5303, 447.9362, 452.4072,
        448.0930, 448.3458, 448.1290, 452.9045, 448.3341, 448.2867, 450.4503,
        452.8879, 448.3829, 447.9490, 448.0074, 448.0101, 452.5447, 450.9061,
        452.7269, 447.9688, 447.9232, 448.2080, 448.0834, 448.3300, 448.3318,
        448.2625, 448.6738, 448.1426, 448.1194, 448.1148, 448.1431, 448.0101,
        448.3333, 451.9710, 448.1061, 448.2556, 448.2988, 448.1317, 448.4202,
        448.3309, 448.1648, 452.6364, 448.0184, 448.2778, 447.9150, 447.9403,
        447.8536, 448.0267, 447.9499, 448.1071, 448.3727, 448.1949, 448.1117,
        448.2967, 448.1496, 448.3362, 449.3150, 447.9994, 448.0910, 448.1095,
        447.9487, 451.5043, 452.5264, 448.3127, 447.9411, 447.9962, 448.0078,
        447.9321, 448.2294, 448.0769, 450.2675, 452.5212, 447.9950, 447.8976,
        451.3082, 448.0241, 448.0779, 447.9664, 448.2925, 448.1487, 447.9686,
        448.1769, 448.0931, 448.0878, 447.9182, 448.3557, 448.1057, 448.1043,
        447.9576, 452.6061, 449.4848, 448.2209, 448.2140, 448.0802, 452.5305,
        448.0953, 448.1892, 450.9992, 448.0739, 452.6011, 447.8969, 448.2985,
        448.0700, 448.1617, 448.1337, 448.5417, 452.5204, 450.1997, 449.2375,
        452.7223, 447.8632, 449.5047, 452.8455, 448.1820, 452.9115, 449.6133,
        452.6714, 452.6916, 451.9681, 447.9839, 447.9055, 448.0061, 453.6060,
        448.0037, 452.8322, 452.5251, 447.9934, 451.0446, 448.0308, 452.6600,
        449.4208, 447.9659, 452.5202, 448.1342, 448.2413, 451.5714, 448.2067,
        448.2811, 452.7481, 451.7080, 449.0226, 447.9200, 448.0921, 447.9178,
        452.6409, 449.1796, 452.5284, 452.7052, 448.0118, 448.1819, 448.7358,
        447.9126, 448.0975, 447.9670, 452.8096, 448.0935, 448.0099, 448.3229,
        448.1475, 452.7219, 448.2293, 447.9480, 447.9678, 448.1333, 447.9197,
        448.3590, 452.5302, 452.5282, 448.0982, 448.1141, 447.9189, 447.8957,
        447.9377, 450.5963, 452.8792, 449.1646, 448.0867, 448.1590, 452.5862,
        447.9445, 448.3371, 452.5205, 448.0834, 448.0114, 451.9467, 452.5224,
        451.5848, 449.4580, 447.9553, 450.1998, 452.7467, 449.7025, 448.1954,
        450.1965, 450.9991, 448.1005, 448.2004, 448.0281, 452.8354, 448.4964,
        448.2479, 448.3522, 452.5303, 447.9622, 448.3520, 448.3201, 448.3279,
        448.0670, 448.0555, 448.0592, 448.1291, 452.5894, 452.5258, 448.0373,
        448.1088, 448.3405, 448.0269, 452.5282, 448.2124, 447.9144, 448.0302,
        448.1017, 448.2732, 448.1947, 448.1663, 448.3449, 448.0767, 448.1422,
        450.1894, 448.1191, 447.9312, 448.0277, 452.5243, 452.5746, 448.3908,
        447.9594, 447.9921, 452.5203, 447.8553, 452.5203, 448.0435, 448.0974,
        448.3903, 447.9426, 448.3607, 448.1800, 447.9279, 447.9297, 448.1058,
        450.0568, 448.1516, 452.5346, 452.5205, 448.3843, 448.1921, 447.9548,
        452.6024, 452.6909, 452.5423, 451.6714, 448.0261, 452.5556, 448.0475,
        448.0980, 449.6279, 450.2629, 448.1171, 448.0960, 448.2061, 448.0145,
        452.5202, 447.9127, 447.9246, 448.0612, 452.7263, 452.5464, 447.8932,
        452.3754, 448.0381, 448.1057, 452.5215, 448.0046, 448.0519, 450.6284,
        448.2363, 448.0959, 448.1033, 450.1312, 448.0918, 452.6385, 452.3018,
        448.1241, 448.0063, 452.5202, 448.2864, 448.2411, 452.6458, 448.2094,
        449.2258, 448.3089, 448.1386, 448.1060, 447.9613, 448.0120, 447.9520,
        448.0321, 448.0906, 448.1947, 451.3407, 447.9571, 448.3307, 448.3479,
        448.2388, 448.0551, 449.5067, 448.1027, 452.5227, 448.0826, 448.3317,
        452.7509, 448.0911, 448.5736, 447.9242, 447.9638, 447.9129, 447.9758,
        448.0860, 452.3540, 448.0911, 448.3025, 448.0439, 448.0763, 447.9008,
        447.9265, 452.6841, 452.5428, 452.1475, 447.9503, 448.2037, 448.1150,
        449.5656, 448.2278, 448.3610, 449.5229, 447.9276, 448.3205, 452.5551,
        448.0492, 452.5565, 448.2215, 448.3876, 450.9491, 448.4054, 448.2184,
        452.7397, 448.1064, 452.5205, 448.3408, 447.9201, 448.3910, 448.0132,
        450.7479, 447.9745, 447.9839, 448.0516, 452.3525, 452.5237, 448.2392,
        448.3221, 448.0679, 448.2479, 448.2332, 448.0637, 447.9315, 448.2469,
        452.9097, 447.9458, 452.3762, 452.5202, 447.9289, 448.1176, 447.9162,
        448.3820, 448.0890, 452.5215, 452.5675, 452.3763, 448.3563, 447.8857,
        447.9865, 448.0994, 448.0990, 452.6428, 448.1331, 451.0072, 448.0303,
        452.5784, 452.5421, 448.3818, 448.1418, 447.9306, 448.3588, 448.0428,
        448.0779, 449.4528, 448.7597, 452.6099, 448.0673, 448.3445, 448.3658,
        448.3828, 448.0565, 448.3577, 452.7512, 448.1025, 453.7242, 452.5771,
        452.5241, 448.3294, 450.1384, 449.0464, 448.3649, 448.2554, 447.9087,
        451.5757, 452.6516, 452.5839, 448.0290, 448.0795, 448.3828, 447.9690,
        449.0530, 448.0996, 448.1077, 448.2116, 450.5587, 451.6709, 449.8863,
        448.3571, 448.1075, 452.6218, 448.1083, 448.0858, 448.3230, 448.1992,
        448.2949, 447.9737, 448.2701, 448.0196, 452.5202, 448.2122, 452.6476,
        452.8499, 448.1578, 448.1500, 448.3607, 448.0755, 452.5482, 448.3130,
        448.3410, 448.1375, 451.1911, 450.4695, 448.0306, 448.2028, 447.9959,
        452.1581, 447.9952, 448.0252, 448.2851, 450.6835, 448.1559, 448.0278,
        447.9790, 448.1896, 448.1824, 450.4312, 448.2604, 447.9680, 452.7214,
        452.5205, 448.3244, 448.0593, 448.0583, 448.3426, 448.1165, 448.2090,
        448.3629, 452.7180, 448.0687, 448.1015, 448.3943, 448.0794, 448.0416,
        447.9227, 447.9905, 451.6350, 452.5203, 448.0992, 447.9460, 447.9734,
        452.9016, 447.8960, 448.3916, 448.1416, 448.0103, 448.0838, 448.1945,
        448.1382, 447.9557, 448.0229, 452.5204, 447.9240, 448.3713, 448.1053,
        448.8176, 452.5222, 450.3054, 448.0875, 448.0378, 448.0705, 452.6238,
        450.5358, 447.9062, 448.2248, 448.0591, 452.5442, 448.3572, 448.2270,
        452.5258, 448.1137, 448.4974, 452.2772, 448.0862, 448.2933, 448.1832,
        450.9619, 448.4768, 448.0615, 452.6228, 452.7477, 448.1144, 448.1212,
        448.1955, 452.7015, 448.1007, 448.3765, 448.9332, 452.5202, 452.5659,
        448.2590, 448.2532, 448.0591, 448.2412, 449.3487, 448.3707, 448.1664,
        448.4461, 448.3664, 448.2394, 448.0823, 452.7829, 448.1130, 452.5862,
        452.6791, 447.9577, 448.1777, 448.1129, 452.7932, 452.5965, 452.5202,
        448.1038, 452.3766, 448.1408, 452.7480, 448.3918, 448.3667, 447.9725,
        450.2251, 447.9932, 448.2289, 448.1401, 448.1223, 448.0753, 452.5369,
        448.1530, 448.0979, 452.5374, 448.0639, 448.1770, 452.9467, 450.1997,
        452.6040, 448.1161, 450.2266, 448.3298, 448.1034, 448.2302, 448.0950,
        448.1288, 448.3111, 448.1419, 448.1548, 447.9900, 452.8959, 448.0869,
        448.2676, 451.9927, 448.1262, 452.5641, 448.0445, 448.1385, 448.0432,
        447.9298, 447.9959, 448.1216, 452.5223, 448.3900, 448.2857, 448.1166,
        448.3033, 448.2686, 448.3210, 448.3134, 448.3646, 448.9814, 452.5202,
        452.9075, 447.9806, 447.9771, 448.0975, 448.0483, 447.9581, 448.2967,
        448.2406, 447.9880, 448.7670, 448.1462, 448.3216, 448.0194, 452.5882,
        448.3733, 450.2554, 448.1222, 452.7248, 448.3370, 448.0882, 452.5667,
        447.9097, 447.9514, 448.2022, 452.7265, 447.9641, 447.9289, 447.9211,
        448.0302, 447.9973, 452.7444, 448.3478, 448.1746, 448.3507, 448.1069,
        453.6155, 447.9745, 452.5533, 449.7662, 448.8932, 448.3260, 452.8499,
        452.5212, 448.3592, 452.7198, 448.2217, 448.3566, 448.0880, 448.1069,
        447.9789, 452.6097, 448.0933, 448.1315, 448.1065, 447.9829, 447.9136,
        448.2594, 448.2360, 448.0446, 448.1316, 447.8561, 448.5942, 448.1100,
        452.5803, 448.0986, 453.6350, 450.0061, 450.4286, 448.3620, 448.2245,
        452.5206, 447.9572, 447.9139, 448.0234, 452.7172, 450.4309, 448.1291,
        448.1702, 452.9500, 448.3258, 451.1000, 447.9598, 450.7834, 448.1085,
        448.0435, 447.9286, 452.5226, 451.1882, 448.1183, 448.0364, 452.5274,
        448.2720, 448.3248, 448.1924, 448.1037, 448.1434, 451.9319, 452.8121,
        448.2394, 448.2936, 452.5426, 448.1246, 452.5894, 452.5401, 452.5202,
        447.8994, 452.5244, 452.7548, 447.9437, 448.1209, 447.8433, 452.5203,
        448.9736, 448.3749, 448.0819, 448.1405, 448.0396, 448.1197, 450.1541,
        448.1666, 452.7394, 447.9789, 448.2419, 448.2591, 448.1365, 448.1073,
        452.5212, 447.8944, 448.0098, 448.0995, 450.7951, 448.0794, 448.3607,
        447.9336, 447.9873, 448.3663, 448.1252, 448.0617, 448.3521, 448.2636,
        447.9262, 448.1588, 448.0677, 449.4100, 447.8866, 447.9252, 450.1894,
        451.5287, 448.3731, 452.1202, 448.1280, 447.8653, 452.6984, 448.0182,
        450.5966, 448.0241, 452.5222, 448.0322, 452.5526, 448.2367, 449.2690,
        448.0887, 452.5207, 448.4011, 447.9240, 448.0529, 448.8954, 448.3431,
        448.0142, 448.1392, 447.9633, 448.1029, 447.9507, 448.1082, 448.2049,
        448.2922, 452.7219, 448.1683, 452.5221, 448.2462, 448.3009, 448.0587,
        448.0356, 448.2388, 452.5208, 448.0997, 448.2712, 448.3709, 448.9435,
        449.4998, 447.9866, 448.3261, 447.9363, 448.1167, 448.3484, 450.4088,
        448.1179, 452.5214, 448.0387, 448.3191, 452.5427, 451.3949, 448.0855,
        447.9476, 448.5537, 448.0015, 448.2535, 448.1142, 448.3974, 448.0490,
        448.4410, 447.9224, 448.1423, 448.0820, 452.6904, 448.1135, 448.1118,
        448.0771, 447.9383], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([401.3763], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0303],
             [112.1040],
             [112.0671],
             [112.0671]],

            [[113.1487],
             [113.1487],
             [113.2016],
             [113.2016]],

            [[112.0637],
             [112.0637],
             [112.1065],
             [112.1065]],

            ...,

            [[112.0938],
             [112.0999],
             [112.0936],
             [112.0942]],

            [[113.2369],
             [113.2369],
             [113.2359],
             [113.2359]],

            [[112.2443],
             [111.9943],
             [111.9625],
             [111.9625]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2685, 452.7007, 448.3405,  ..., 448.3814, 452.9456, 448.1636],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2685, 452.7007, 448.3405,  ..., 448.3814, 452.9456, 448.1636],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9995],
             [111.9874],
             [111.9921],
             [112.0059]],

            [[112.0949],
             [112.0949],
             [112.1165],
             [112.1165]],

            [[113.0773],
             [113.0773],
             [113.0769],
             [113.0769]],

            ...,

            [[112.1042],
             [112.1042],
             [112.1210],
             [112.1210]],

            [[112.0042],
             [112.0042],
             [112.0257],
             [112.0257]],

            [[112.0271],
             [112.0271],
             [111.9871],
             [111.9871]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9849, 448.4227, 452.3084,  ..., 448.4505, 448.0598, 448.0283],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9849, 448.4227, 452.3084,  ..., 448.4505, 448.0598, 448.0283],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0916],
             [112.0873],
             [112.1341],
             [112.0441]],

            [[112.0588],
             [112.0648],
             [112.0595],
             [112.0657]],

            [[112.0331],
             [112.1311],
             [112.0805],
             [112.0805]],

            ...,

            [[112.2823],
             [112.2823],
             [112.0098],
             [112.0098]],

            [[113.1591],
             [113.0299],
             [113.0325],
             [113.1518]],

            [[112.0123],
             [112.0899],
             [112.0755],
             [112.1345]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3572, 448.2488, 448.3252,  ..., 448.5841, 452.3733, 448.3121],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3572, 448.2488, 448.3252,  ..., 448.5841, 452.3733, 448.3121],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[113.0401],
             [112.2676],
             [112.8179],
             [112.8180]],

            [[113.0243],
             [112.3284],
             [112.5527],
             [112.5527]],

            [[112.0518],
             [112.0762],
             [112.0948],
             [112.1514]],

            ...,

            [[112.0462],
             [112.0820],
             [112.1427],
             [112.1427]],

            [[112.0507],
             [112.0674],
             [112.0734],
             [112.0734]],

            [[112.0474],
             [112.0474],
             [112.0832],
             [112.0832]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.9436, 450.4581, 448.3741,  ..., 448.4136, 448.2648, 448.2612],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.9436, 450.4581, 448.3741,  ..., 448.4136, 448.2648, 448.2612],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0627],
             [112.1074],
             [112.0610],
             [112.1531]],

            [[112.0476],
             [112.0474],
             [112.1343],
             [112.1343]],

            [[112.1564],
             [112.1564],
             [112.0495],
             [112.0495]],

            ...,

            [[113.0415],
             [112.9744],
             [112.9722],
             [113.0553]],

            [[112.0534],
             [112.1316],
             [112.1608],
             [112.1608]],

            [[112.9377],
             [112.9377],
             [112.9377],
             [112.9377]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3842, 448.3635, 448.4117,  ..., 452.0434, 448.5066, 451.7509],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3842, 448.3635, 448.4117,  ..., 452.0434, 448.5066, 451.7509],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.9179],
             [112.9179],
             [112.9179],
             [112.9179]],

            [[112.1195],
             [112.1195],
             [112.1682],
             [112.1682]],

            [[112.1028],
             [112.1028],
             [112.1667],
             [112.1667]],

            ...,

            [[112.0598],
             [112.0904],
             [112.0624],
             [112.1574]],

            [[112.5748],
             [112.0776],
             [112.2077],
             [112.2077]],

            [[112.1001],
             [112.0925],
             [112.0658],
             [112.1727]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([451.6715, 448.5754, 448.5390,  ..., 448.3700, 449.0678, 448.4310],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([451.6715, 448.5754, 448.5390,  ..., 448.3700, 449.0678, 448.4310],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.7427],
             [112.7427],
             [112.7530],
             [112.7530]],

            [[112.0843],
             [112.1268],
             [112.0993],
             [112.0993]],

            [[112.0836],
             [112.0846],
             [112.0978],
             [112.1792]],

            ...,

            [[112.0896],
             [112.0798],
             [112.1690],
             [112.1168]],

            [[112.0790],
             [112.0796],
             [112.1073],
             [112.1073]],

            [[112.7415],
             [112.7415],
             [112.7415],
             [112.7415]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([450.9915, 448.4096, 448.4452,  ..., 448.4551, 448.3731, 450.9661],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([450.9915, 448.4096, 448.4452,  ..., 448.4551, 448.3731, 450.9661],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1032],
             [112.1732],
             [112.1025],
             [112.1491]],

            [[112.1684],
             [112.1578],
             [112.1134],
             [112.1380]],

            [[112.1298],
             [112.6256],
             [112.6249],
             [112.1297]],

            ...,

            [[112.1010],
             [112.1010],
             [112.1444],
             [112.1444]],

            [[112.1128],
             [112.1128],
             [112.1794],
             [112.1794]],

            [[112.1044],
             [112.1258],
             [112.1017],
             [112.1209]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5280, 448.5776, 449.5100,  ..., 448.4908, 448.5845, 448.4528],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5280, 448.5776, 449.5100,  ..., 448.4908, 448.5845, 448.4528],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1276],
             [112.1276],
             [112.1592],
             [112.1301]],

            [[112.2635],
             [112.1640],
             [112.3575],
             [112.1357]],

            [[112.1306],
             [112.1306],
             [112.1682],
             [112.1682]],

            ...,

            [[112.1713],
             [112.1559],
             [112.1340],
             [112.1340]],

            [[112.4414],
             [112.4414],
             [112.4414],
             [112.4414]],

            [[112.1341],
             [112.1341],
             [112.1853],
             [112.1853]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5445, 448.9207, 448.5975,  ..., 448.5952, 449.7656, 448.6389],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5445, 448.9207, 448.5975,  ..., 448.5952, 449.7656, 448.6389],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1548],
             [112.1552],
             [112.1944],
             [112.1944]],

            [[112.1498],
             [112.2018],
             [112.1495],
             [112.1468]],

            [[112.3823],
             [112.4035],
             [112.3845],
             [112.6304]],

            ...,

            [[112.1488],
             [112.1637],
             [112.1656],
             [112.2025]],

            [[112.3552],
             [112.3565],
             [112.3555],
             [112.3555]],

            [[112.1515],
             [112.1468],
             [112.1481],
             [112.1784]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6989, 448.6477, 449.8007,  ..., 448.6806, 449.4228, 448.6248],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6989, 448.6477, 449.8007,  ..., 448.6806, 449.4228, 448.6248],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3970],
             [112.4653],
             [112.4197],
             [112.3985]],

            [[112.2970],
             [112.2970],
             [112.2971],
             [112.2971]],

            [[112.2970],
             [112.2972],
             [112.2970],
             [112.2970]],

            ...,

            [[112.1599],
             [112.1599],
             [112.1948],
             [112.1948]],

            [[112.1587],
             [112.1616],
             [112.1747],
             [112.1609]],

            [[112.3739],
             [112.5664],
             [112.3368],
             [112.4725]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.6805, 449.1881, 449.1882,  ..., 448.7093, 448.6559, 449.7496],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.6805, 449.1881, 449.1882,  ..., 448.7093, 448.6559, 449.7496],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.4398],
             [112.4398],
             [112.1751],
             [112.1751]],

            [[112.1602],
             [112.1631],
             [112.1596],
             [112.1636]],

            [[112.1617],
             [112.1709],
             [112.1752],
             [112.2026]],

            ...,

            [[112.2316],
             [112.2316],
             [112.2316],
             [112.2316]],

            [[112.1658],
             [112.1619],
             [112.1616],
             [112.1808]],

            [[112.7643],
             [112.7643],
             [112.7643],
             [112.7643]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2298, 448.6464, 448.7104,  ..., 448.9264, 448.6701, 451.0573],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2298, 448.6464, 448.7104,  ..., 448.9264, 448.6701, 451.0573],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1782],
             [112.1739],
             [112.1769],
             [112.1703]],

            [[112.1698],
             [112.1816],
             [112.1700],
             [112.1907]],

            [[112.1971],
             [112.1971],
             [112.1976],
             [112.1976]],

            ...,

            [[112.1745],
             [112.1943],
             [112.1766],
             [112.1766]],

            [[112.1694],
             [112.1987],
             [112.1967],
             [112.1967]],

            [[112.1689],
             [112.1716],
             [112.1803],
             [112.1803]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6992, 448.7121, 448.7892,  ..., 448.7220, 448.7614, 448.7010],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6992, 448.7121, 448.7892,  ..., 448.7220, 448.7614, 448.7010],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1827],
             [112.2069],
             [112.1785],
             [112.1785]],

            [[112.2045],
             [112.1986],
             [112.1765],
             [112.1765]],

            [[112.1599],
             [112.1599],
             [112.1599],
             [112.1599]],

            ...,

            [[112.3318],
             [112.1799],
             [112.3195],
             [112.3195]],

            [[112.2860],
             [112.1786],
             [112.2745],
             [112.1842]],

            [[112.1598],
             [112.1598],
             [112.1598],
             [112.1598]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7465, 448.7561, 448.6395,  ..., 449.1506, 448.9233, 448.6393],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7465, 448.7561, 448.6395,  ..., 449.1506, 448.9233, 448.6393],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1957],
             [112.2117],
             [112.2029],
             [112.2093]],

            [[112.2044],
             [112.2087],
             [112.1894],
             [112.2115]],

            [[112.1902],
             [112.2087],
             [112.1896],
             [112.1899]],

            ...,

            [[112.2085],
             [112.2085],
             [112.2142],
             [112.2142]],

            [[112.1306],
             [112.1306],
             [112.1309],
             [112.1306]],

            [[112.1896],
             [112.2038],
             [112.1892],
             [112.2048]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8196, 448.8140, 448.7785,  ..., 448.8454, 448.5228, 448.7873],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8196, 448.8140, 448.7785,  ..., 448.8454, 448.5228, 448.7873],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1003],
             [112.1003],
             [112.1003],
             [112.1003]],

            [[112.1002],
             [112.1003],
             [112.1003],
             [112.1002]],

            [[112.2092],
             [112.2092],
             [112.2089],
             [112.2089]],

            ...,

            [[112.2096],
             [112.2110],
             [112.2268],
             [112.2133]],

            [[112.2103],
             [112.2103],
             [112.2229],
             [112.2126]],

            [[112.1002],
             [112.1002],
             [112.1002],
             [112.1002]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4010, 448.4010, 448.8362,  ..., 448.8607, 448.8561, 448.4010],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4010, 448.4010, 448.8362,  ..., 448.8607, 448.8561, 448.4010],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2402],
             [112.2402],
             [112.2397],
             [112.2397]],

            [[112.2261],
             [112.2411],
             [112.2264],
             [112.2392]],

            [[112.0756],
             [112.0756],
             [112.0895],
             [112.0895]],

            ...,

            [[112.0759],
             [112.0808],
             [112.1007],
             [112.1007]],

            [[112.2269],
             [112.2296],
             [112.2412],
             [112.2266]],

            [[112.2259],
             [112.2413],
             [112.2435],
             [112.2435]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9598, 448.9329, 448.3302,  ..., 448.3581, 448.9242, 448.9542],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9598, 448.9329, 448.3302,  ..., 448.3581, 448.9242, 448.9542],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0528],
             [112.0544],
             [112.3308],
             [112.3308]],

            [[112.0485],
             [112.0485],
             [112.0485],
             [112.0485]],

            [[112.2478],
             [112.2506],
             [112.2554],
             [112.2639]],

            ...,

            [[112.2503],
             [112.2503],
             [112.2552],
             [112.2552]],

            [[112.2493],
             [112.2530],
             [112.2544],
             [112.2619]],

            [[112.2674],
             [112.2481],
             [112.2566],
             [112.2484]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7687, 448.1941, 449.0177,  ..., 449.0111, 449.0186, 449.0205],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7687, 448.1941, 449.0177,  ..., 449.0111, 449.0186, 449.0205],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0290e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0521],
             [112.2719],
             [112.3237],
             [112.3237]],

            [[112.2728],
             [112.2806],
             [112.2713],
             [112.2663]],

            [[112.0244],
             [112.0244],
             [112.0245],
             [112.0245]],

            ...,

            [[112.2879],
             [112.2879],
             [112.2781],
             [112.2781]],

            [[112.2696],
             [112.2674],
             [112.2734],
             [112.2717]],

            [[112.2700],
             [112.2825],
             [112.2666],
             [112.2707]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9714, 449.0909, 448.0978,  ..., 449.1320, 449.0821, 449.0898],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9714, 449.0909, 448.0978,  ..., 449.1320, 449.0821, 449.0898],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0361],
             [112.0361],
             [112.3032],
             [112.3032]],

            [[112.0254],
             [112.0612],
             [112.0252],
             [112.0586]],

            [[112.2673],
             [112.2721],
             [112.2738],
             [112.2815]],

            ...,

            [[112.2667],
             [112.2667],
             [112.2666],
             [112.2666]],

            [[112.2700],
             [112.2747],
             [112.2826],
             [112.2826]],

            [[112.2672],
             [112.2735],
             [112.2669],
             [112.2669]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6786, 448.1704, 449.0948,  ..., 449.0665, 449.1099, 449.0745],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6786, 448.1704, 449.0948,  ..., 449.0665, 449.1099, 449.0745],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2692],
             [112.2672],
             [112.2700],
             [112.2684]],

            [[112.2666],
             [112.2708],
             [112.2672],
             [112.2818]],

            [[112.2667],
             [112.2667],
             [112.2667],
             [112.2667]],

            ...,

            [[112.0240],
             [112.0240],
             [112.0240],
             [112.0240]],

            [[112.2767],
             [112.0529],
             [112.2717],
             [112.0478]],

            [[112.2754],
             [112.2754],
             [112.2806],
             [112.2806]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0748, 449.0864, 449.0668, 449.0704, 449.0889, 448.0962, 449.0868,
            449.0849, 448.0965, 449.0976, 448.4397, 448.1053, 449.1510, 449.0690,
            449.0760, 449.1094, 449.1068, 449.1051, 449.1164, 449.0965, 449.0800,
            449.0876, 449.0722, 448.6405, 449.0945, 449.1099, 449.1077, 448.6581,
            448.4584, 449.0863, 448.2051, 449.0816, 449.0896, 448.7156, 449.0890,
            449.0862, 449.0838, 448.0962, 449.0799, 449.0896, 449.0727, 449.0854,
            449.0897, 449.0128, 449.0841, 449.0841, 449.0703, 449.0893, 449.0864,
            449.1267, 448.1135, 449.0873, 448.6974, 449.0674, 448.4795, 449.0992,
            449.6334, 449.0803, 449.0888, 449.0988, 449.0667, 449.0762, 448.1126,
            449.0820, 448.9078, 449.1187, 448.1215, 449.0822, 448.0988, 449.0852,
            449.0739, 449.0913, 449.0779, 448.1002, 449.1555, 449.0329, 449.0667,
            449.1189, 449.0823, 449.1013, 449.0796, 449.0751, 449.0882, 449.0873,
            448.1295, 449.0906, 448.1237, 449.0929, 449.0998, 449.0795, 448.9138,
            449.0869, 448.2356, 448.0961, 448.9730, 449.0882, 449.0780, 449.0880,
            448.7391, 449.0842, 449.0974, 448.7042, 449.0835, 448.1147, 449.0875,
            448.0962, 449.0818, 449.0930, 448.6342, 449.1092, 448.7311, 448.0962,
            449.0920, 449.0885, 449.0882, 449.0947, 448.1184, 449.0857, 449.0778,
            448.9576, 449.1110, 449.0852, 448.7552, 449.0948, 449.1050, 449.0849,
            449.1165, 449.0723, 449.0927, 448.1167, 449.0815, 449.0864, 449.0669,
            449.0937, 449.0819, 449.0900, 448.1324, 449.0955, 449.0075, 449.0974,
            448.7341, 449.0849, 449.0898, 449.0989, 449.1057, 449.1118, 449.0842,
            448.1350, 449.0834, 449.0898, 449.0812, 449.1352, 449.0848, 449.0704,
            448.6458, 448.9644, 448.1907, 449.0844, 448.1470, 449.0803, 448.0963,
            449.1055, 449.0903, 449.0951, 448.1302, 449.0831, 449.1756, 448.1242,
            449.0921, 449.1118, 448.8387, 449.1099, 449.0833, 448.1736, 449.1039,
            449.0830, 449.0792, 449.0767, 448.1110, 449.0781, 449.0894, 449.0671,
            448.6347, 448.2354, 448.1031, 449.0823, 449.0723, 448.0961, 449.0902,
            449.0869, 449.0847, 448.6499, 449.0944, 449.0801, 449.0869, 449.0745,
            449.1007, 448.0962, 449.1058, 449.0889, 449.1110, 448.4911, 449.0943,
            449.0938, 449.0757, 449.1004, 449.1997, 449.1060, 448.8610, 449.0877,
            449.0881, 449.0958, 448.7015, 449.0460, 449.0879, 448.1035, 449.0886,
            448.1056, 448.6783, 448.6342, 448.6314, 449.1342, 449.0701, 449.0891,
            449.0816, 448.9099, 449.0663, 449.0860, 449.0772, 449.0812, 449.0806,
            449.1584, 449.0914, 449.0851, 449.0997, 449.1124, 449.0863, 449.0874,
            448.6085, 449.0864, 449.0865, 448.1154, 449.0869, 449.0804, 449.2903,
            448.8194, 449.0839, 449.0778, 448.0982, 449.1689, 449.0950, 449.0731,
            449.0939, 449.0693, 449.0896, 449.0993, 449.0897, 448.1016, 449.1193,
            448.6387, 449.1127, 449.0871, 449.0912, 448.5510, 449.0901, 448.8930,
            448.0963, 449.1013, 448.2267, 449.0880, 448.1339, 449.0821, 449.1003,
            448.0961, 449.0834, 449.0568, 449.0861, 449.0860, 448.0985, 449.0914,
            449.0840, 449.1808, 449.0876, 449.1022, 449.0808, 448.0963, 448.1637,
            448.1795, 449.0923, 449.0966, 449.0770, 449.0840, 448.0995, 449.0848,
            449.2251, 448.1003, 449.0732, 449.0749, 448.0966, 449.0810, 448.1450,
            449.1196, 448.1528, 449.0875, 449.0943, 448.9090, 449.1003, 448.0969,
            449.3889, 449.0780, 449.0793, 449.1186, 449.0740, 449.0884, 449.6401,
            449.1048, 449.0970, 449.0819, 449.0907, 449.0815, 449.0721, 448.0971,
            449.0717, 449.0678, 449.1337, 449.0686, 449.0876, 449.0996, 448.1031,
            449.0839, 448.7026, 449.0900, 448.6931, 449.6324, 449.1060, 449.0812,
            449.1154, 448.6450, 449.0884, 449.0671, 449.0854, 449.0685, 449.3509,
            448.0962, 449.1171, 449.0951, 448.0963, 449.1012, 449.0905, 449.0854,
            448.1149, 449.0939, 448.0961, 448.1457, 449.2023, 449.0914, 448.9371,
            449.0941, 449.0989, 449.0941, 449.0933, 448.3386, 449.0848, 449.0940,
            449.0884, 449.0841, 449.0685, 449.0987, 448.0975, 449.0840, 449.1689,
            449.0706, 448.0964, 449.0872, 449.0803, 449.1976, 449.0909, 449.0870,
            449.0936, 449.0858, 449.0875, 449.1115, 449.1112, 448.0988, 448.8772,
            449.0941, 449.0815, 449.0875, 449.0759, 449.1069, 449.1049, 449.0854,
            449.0681, 449.0778, 449.0773, 449.0895, 449.1550, 448.1055, 449.1113,
            449.3537, 449.0935, 448.0964, 449.1122, 449.0703, 449.0770, 449.1142,
            449.1436, 449.0823, 448.1486, 449.1052, 449.0955, 449.0789, 449.1054,
            449.0941, 449.1335, 448.1008, 449.0822, 449.0960, 449.1081, 449.1077,
            448.0963, 449.1116, 449.0836, 449.0841, 449.0877, 449.0470, 448.1262,
            449.0944, 448.0970, 449.0801, 448.0961, 449.0938, 449.1080, 448.0963,
            448.1019, 449.0955, 449.0916, 449.1077, 449.0898, 449.2073, 449.1113,
            449.1047, 449.1028, 448.0961, 449.0869, 448.2454, 449.0898, 449.2026,
            449.1867, 449.1532, 448.1460, 448.1132, 449.0872, 449.0908, 448.7571,
            449.0887, 449.0739, 448.2651, 448.1188, 448.0976, 449.0948, 449.0984,
            448.1584, 448.5451, 449.0890, 448.7342, 448.7275, 448.0963, 449.0894,
            448.6406, 449.0886, 449.0804, 448.9048, 449.0852, 448.0966, 449.1047,
            449.0835, 449.0791, 449.0776, 449.0718, 449.0900, 449.0849, 449.0919,
            449.0952, 449.0714, 448.1449, 449.0817, 448.4395, 449.0870, 449.0774,
            448.0981, 449.0825, 449.0768, 449.0812, 449.0787, 449.1080, 449.0793,
            449.0964, 449.1013, 449.1035, 449.1349, 449.0904, 449.0704, 449.0920,
            449.0870, 449.0675, 449.0891, 448.9996, 449.0815, 448.1042, 449.0772,
            449.0780, 448.1588, 449.0973, 449.0977, 449.0867, 449.0787, 449.0912,
            448.6616, 449.0798, 449.0809, 449.0920, 449.0943, 449.0762, 449.0872,
            449.0843, 449.0976, 449.0795, 448.0980, 449.0811, 449.1044, 448.6381,
            449.0720, 448.1797, 448.0987, 449.0975, 449.0978, 448.0966, 449.0930,
            449.0827, 449.0808, 448.1058, 448.0962, 448.9425, 449.3432, 448.1259,
            449.0815, 449.0895, 449.0866, 449.0972, 448.2118, 448.2620, 448.0978,
            449.1018, 448.1185, 449.0897, 449.0880, 448.0963, 449.0891, 449.1191,
            449.0742, 449.0826, 448.1121, 448.7519, 448.1354, 448.1074, 449.1042,
            449.0911, 449.1119, 449.0915, 449.0738, 449.0861, 449.1027, 449.0938,
            448.0961, 449.0896, 448.8106, 449.0864, 449.0838, 448.2179, 449.0853,
            449.0761, 448.1313, 449.0895, 449.0724, 448.6568, 449.0893, 448.9520,
            448.7092, 448.6449, 449.0667, 449.1086, 449.1094, 449.0915, 449.0853,
            449.0930, 448.4300, 448.6468, 449.0780, 449.0886, 449.0732, 449.0803,
            448.6231, 449.0888, 449.1186, 449.0840, 448.6407, 449.0887, 449.0721,
            449.0864, 448.0967, 448.8148, 448.0962, 449.0685, 449.1143, 449.0741,
            449.0872, 449.0784, 449.1096, 449.0804, 449.0868, 449.0834, 449.0724,
            449.0890, 449.0892, 449.0731, 449.0694, 449.0995, 449.0954, 449.0786,
            449.1093, 449.0697, 448.9526, 449.1347, 449.0890, 449.1080, 449.1110,
            449.1004, 449.1096, 448.0986, 448.7510, 449.1477, 448.1944, 448.4828,
            448.9124, 449.0842, 449.0833, 449.0828, 448.2498, 448.2827, 448.0979,
            448.9193, 448.1591, 449.1055, 449.0907, 449.1493, 449.0757, 449.0851,
            448.1435, 448.1001, 449.0747, 449.6349, 448.0977, 448.1107, 449.0723,
            448.9347, 449.0840, 449.0866, 449.0858, 448.0987, 449.0747, 448.3639,
            449.1030, 448.0961, 449.1021, 448.1020, 449.1356, 449.0862, 448.1329,
            449.0892, 449.0997, 449.0823, 449.0844, 449.0909, 448.6315, 449.0852,
            449.0867, 449.0728, 449.0934, 448.7075, 448.0967, 449.0822, 449.0890,
            449.0837, 448.2155, 449.0872, 449.0966, 449.0716, 449.0877, 448.0962,
            449.1099, 449.0751, 449.0889, 449.0898, 448.1342, 449.0674, 449.0663,
            448.0963, 449.0811, 449.0931, 449.1037, 449.0684, 448.1010, 448.1496,
            448.4614, 448.0965, 448.5118, 449.0983, 449.1088, 449.0885, 449.0889,
            449.0887, 449.0663, 449.1012, 449.0915, 449.1055, 448.9486, 449.0918,
            448.6754, 449.0966, 449.0966, 449.0821, 449.0862, 449.0977, 449.0835,
            449.6312, 448.0964, 449.0804, 448.2062, 449.0801, 449.0746, 449.0737,
            448.6898, 448.9459, 449.0865, 449.1055, 449.0849, 449.0900, 449.0850,
            449.0963, 449.1029, 449.1095, 449.0673, 448.0972, 448.1056, 448.0962,
            449.0929, 449.0875, 448.0961, 449.0874, 449.1582, 448.1082, 449.0847,
            449.0872, 449.1139, 449.0783, 448.6763, 448.3391, 449.0843, 449.1124,
            449.0867, 448.0962, 449.0756, 448.1593, 449.1082, 448.9754, 449.0782,
            449.0800, 448.6579, 449.1736, 449.0759, 449.1052, 449.0781, 449.0790,
            449.0931, 448.6395, 449.0844, 449.0819, 449.0905, 449.0743, 449.1102,
            449.0829, 449.1061, 448.6387, 449.0972, 448.3087, 449.1177, 449.0937,
            449.1227, 449.0873, 449.0882, 449.0778, 449.0861, 449.0822, 449.1122,
            448.1162, 449.0713, 448.1021, 449.0782, 448.0962, 449.0742, 449.6317,
            448.8336, 448.2551, 449.0952, 448.5084, 448.1035, 449.1121, 448.7485,
            449.0839, 448.1183, 449.0840, 448.0963, 449.0939, 449.0843, 449.1144,
            449.0842, 449.1038, 449.0791, 449.0788, 449.0823, 449.0721, 448.2250,
            449.0823, 448.6930, 449.0952, 448.6331, 449.1137, 448.0973, 448.2119,
            449.1101, 448.6362, 448.1017, 448.2809, 449.0887, 448.0961, 449.0762,
            449.1541, 449.1097, 449.0884, 448.0962, 449.0199, 449.1185, 449.1132,
            448.9755, 449.0872, 449.0975, 449.0712, 449.0813, 449.1089, 448.1121,
            449.0852, 449.0991, 449.0761, 448.0965, 448.1020, 449.0741, 449.0988,
            449.0884, 449.0686, 449.0705, 449.0839, 449.1187, 448.8596, 448.8315,
            449.0781, 448.0962, 448.8764, 449.0959, 449.0959, 449.1099, 449.0859,
            449.0875, 449.1038, 449.0800, 449.0802, 449.2180, 448.1719, 448.0962,
            449.1089, 449.0861, 449.0844, 449.0982, 449.0847, 448.1290, 448.4273,
            449.0676, 449.1859, 448.5013, 449.0795, 449.1096, 448.0962, 449.0964,
            448.0961, 449.0769, 449.0839, 448.1086, 448.1267, 449.1098, 449.0790,
            449.0931, 449.1034, 448.0962, 449.0685, 448.0969, 449.0867, 449.0844,
            448.0984, 449.0877, 448.1053, 448.1004, 449.0803, 449.0743, 448.0961,
            448.6490, 449.1119], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0748, 449.0864, 449.0668, 449.0704, 449.0889, 448.0962, 449.0868,
        449.0849, 448.0965, 449.0976, 448.4397, 448.1053, 449.1510, 449.0690,
        449.0760, 449.1094, 449.1068, 449.1051, 449.1164, 449.0965, 449.0800,
        449.0876, 449.0722, 448.6405, 449.0945, 449.1099, 449.1077, 448.6581,
        448.4584, 449.0863, 448.2051, 449.0816, 449.0896, 448.7156, 449.0890,
        449.0862, 449.0838, 448.0962, 449.0799, 449.0896, 449.0727, 449.0854,
        449.0897, 449.0128, 449.0841, 449.0841, 449.0703, 449.0893, 449.0864,
        449.1267, 448.1135, 449.0873, 448.6974, 449.0674, 448.4795, 449.0992,
        449.6334, 449.0803, 449.0888, 449.0988, 449.0667, 449.0762, 448.1126,
        449.0820, 448.9078, 449.1187, 448.1215, 449.0822, 448.0988, 449.0852,
        449.0739, 449.0913, 449.0779, 448.1002, 449.1555, 449.0329, 449.0667,
        449.1189, 449.0823, 449.1013, 449.0796, 449.0751, 449.0882, 449.0873,
        448.1295, 449.0906, 448.1237, 449.0929, 449.0998, 449.0795, 448.9138,
        449.0869, 448.2356, 448.0961, 448.9730, 449.0882, 449.0780, 449.0880,
        448.7391, 449.0842, 449.0974, 448.7042, 449.0835, 448.1147, 449.0875,
        448.0962, 449.0818, 449.0930, 448.6342, 449.1092, 448.7311, 448.0962,
        449.0920, 449.0885, 449.0882, 449.0947, 448.1184, 449.0857, 449.0778,
        448.9576, 449.1110, 449.0852, 448.7552, 449.0948, 449.1050, 449.0849,
        449.1165, 449.0723, 449.0927, 448.1167, 449.0815, 449.0864, 449.0669,
        449.0937, 449.0819, 449.0900, 448.1324, 449.0955, 449.0075, 449.0974,
        448.7341, 449.0849, 449.0898, 449.0989, 449.1057, 449.1118, 449.0842,
        448.1350, 449.0834, 449.0898, 449.0812, 449.1352, 449.0848, 449.0704,
        448.6458, 448.9644, 448.1907, 449.0844, 448.1470, 449.0803, 448.0963,
        449.1055, 449.0903, 449.0951, 448.1302, 449.0831, 449.1756, 448.1242,
        449.0921, 449.1118, 448.8387, 449.1099, 449.0833, 448.1736, 449.1039,
        449.0830, 449.0792, 449.0767, 448.1110, 449.0781, 449.0894, 449.0671,
        448.6347, 448.2354, 448.1031, 449.0823, 449.0723, 448.0961, 449.0902,
        449.0869, 449.0847, 448.6499, 449.0944, 449.0801, 449.0869, 449.0745,
        449.1007, 448.0962, 449.1058, 449.0889, 449.1110, 448.4911, 449.0943,
        449.0938, 449.0757, 449.1004, 449.1997, 449.1060, 448.8610, 449.0877,
        449.0881, 449.0958, 448.7015, 449.0460, 449.0879, 448.1035, 449.0886,
        448.1056, 448.6783, 448.6342, 448.6314, 449.1342, 449.0701, 449.0891,
        449.0816, 448.9099, 449.0663, 449.0860, 449.0772, 449.0812, 449.0806,
        449.1584, 449.0914, 449.0851, 449.0997, 449.1124, 449.0863, 449.0874,
        448.6085, 449.0864, 449.0865, 448.1154, 449.0869, 449.0804, 449.2903,
        448.8194, 449.0839, 449.0778, 448.0982, 449.1689, 449.0950, 449.0731,
        449.0939, 449.0693, 449.0896, 449.0993, 449.0897, 448.1016, 449.1193,
        448.6387, 449.1127, 449.0871, 449.0912, 448.5510, 449.0901, 448.8930,
        448.0963, 449.1013, 448.2267, 449.0880, 448.1339, 449.0821, 449.1003,
        448.0961, 449.0834, 449.0568, 449.0861, 449.0860, 448.0985, 449.0914,
        449.0840, 449.1808, 449.0876, 449.1022, 449.0808, 448.0963, 448.1637,
        448.1795, 449.0923, 449.0966, 449.0770, 449.0840, 448.0995, 449.0848,
        449.2251, 448.1003, 449.0732, 449.0749, 448.0966, 449.0810, 448.1450,
        449.1196, 448.1528, 449.0875, 449.0943, 448.9090, 449.1003, 448.0969,
        449.3889, 449.0780, 449.0793, 449.1186, 449.0740, 449.0884, 449.6401,
        449.1048, 449.0970, 449.0819, 449.0907, 449.0815, 449.0721, 448.0971,
        449.0717, 449.0678, 449.1337, 449.0686, 449.0876, 449.0996, 448.1031,
        449.0839, 448.7026, 449.0900, 448.6931, 449.6324, 449.1060, 449.0812,
        449.1154, 448.6450, 449.0884, 449.0671, 449.0854, 449.0685, 449.3509,
        448.0962, 449.1171, 449.0951, 448.0963, 449.1012, 449.0905, 449.0854,
        448.1149, 449.0939, 448.0961, 448.1457, 449.2023, 449.0914, 448.9371,
        449.0941, 449.0989, 449.0941, 449.0933, 448.3386, 449.0848, 449.0940,
        449.0884, 449.0841, 449.0685, 449.0987, 448.0975, 449.0840, 449.1689,
        449.0706, 448.0964, 449.0872, 449.0803, 449.1976, 449.0909, 449.0870,
        449.0936, 449.0858, 449.0875, 449.1115, 449.1112, 448.0988, 448.8772,
        449.0941, 449.0815, 449.0875, 449.0759, 449.1069, 449.1049, 449.0854,
        449.0681, 449.0778, 449.0773, 449.0895, 449.1550, 448.1055, 449.1113,
        449.3537, 449.0935, 448.0964, 449.1122, 449.0703, 449.0770, 449.1142,
        449.1436, 449.0823, 448.1486, 449.1052, 449.0955, 449.0789, 449.1054,
        449.0941, 449.1335, 448.1008, 449.0822, 449.0960, 449.1081, 449.1077,
        448.0963, 449.1116, 449.0836, 449.0841, 449.0877, 449.0470, 448.1262,
        449.0944, 448.0970, 449.0801, 448.0961, 449.0938, 449.1080, 448.0963,
        448.1019, 449.0955, 449.0916, 449.1077, 449.0898, 449.2073, 449.1113,
        449.1047, 449.1028, 448.0961, 449.0869, 448.2454, 449.0898, 449.2026,
        449.1867, 449.1532, 448.1460, 448.1132, 449.0872, 449.0908, 448.7571,
        449.0887, 449.0739, 448.2651, 448.1188, 448.0976, 449.0948, 449.0984,
        448.1584, 448.5451, 449.0890, 448.7342, 448.7275, 448.0963, 449.0894,
        448.6406, 449.0886, 449.0804, 448.9048, 449.0852, 448.0966, 449.1047,
        449.0835, 449.0791, 449.0776, 449.0718, 449.0900, 449.0849, 449.0919,
        449.0952, 449.0714, 448.1449, 449.0817, 448.4395, 449.0870, 449.0774,
        448.0981, 449.0825, 449.0768, 449.0812, 449.0787, 449.1080, 449.0793,
        449.0964, 449.1013, 449.1035, 449.1349, 449.0904, 449.0704, 449.0920,
        449.0870, 449.0675, 449.0891, 448.9996, 449.0815, 448.1042, 449.0772,
        449.0780, 448.1588, 449.0973, 449.0977, 449.0867, 449.0787, 449.0912,
        448.6616, 449.0798, 449.0809, 449.0920, 449.0943, 449.0762, 449.0872,
        449.0843, 449.0976, 449.0795, 448.0980, 449.0811, 449.1044, 448.6381,
        449.0720, 448.1797, 448.0987, 449.0975, 449.0978, 448.0966, 449.0930,
        449.0827, 449.0808, 448.1058, 448.0962, 448.9425, 449.3432, 448.1259,
        449.0815, 449.0895, 449.0866, 449.0972, 448.2118, 448.2620, 448.0978,
        449.1018, 448.1185, 449.0897, 449.0880, 448.0963, 449.0891, 449.1191,
        449.0742, 449.0826, 448.1121, 448.7519, 448.1354, 448.1074, 449.1042,
        449.0911, 449.1119, 449.0915, 449.0738, 449.0861, 449.1027, 449.0938,
        448.0961, 449.0896, 448.8106, 449.0864, 449.0838, 448.2179, 449.0853,
        449.0761, 448.1313, 449.0895, 449.0724, 448.6568, 449.0893, 448.9520,
        448.7092, 448.6449, 449.0667, 449.1086, 449.1094, 449.0915, 449.0853,
        449.0930, 448.4300, 448.6468, 449.0780, 449.0886, 449.0732, 449.0803,
        448.6231, 449.0888, 449.1186, 449.0840, 448.6407, 449.0887, 449.0721,
        449.0864, 448.0967, 448.8148, 448.0962, 449.0685, 449.1143, 449.0741,
        449.0872, 449.0784, 449.1096, 449.0804, 449.0868, 449.0834, 449.0724,
        449.0890, 449.0892, 449.0731, 449.0694, 449.0995, 449.0954, 449.0786,
        449.1093, 449.0697, 448.9526, 449.1347, 449.0890, 449.1080, 449.1110,
        449.1004, 449.1096, 448.0986, 448.7510, 449.1477, 448.1944, 448.4828,
        448.9124, 449.0842, 449.0833, 449.0828, 448.2498, 448.2827, 448.0979,
        448.9193, 448.1591, 449.1055, 449.0907, 449.1493, 449.0757, 449.0851,
        448.1435, 448.1001, 449.0747, 449.6349, 448.0977, 448.1107, 449.0723,
        448.9347, 449.0840, 449.0866, 449.0858, 448.0987, 449.0747, 448.3639,
        449.1030, 448.0961, 449.1021, 448.1020, 449.1356, 449.0862, 448.1329,
        449.0892, 449.0997, 449.0823, 449.0844, 449.0909, 448.6315, 449.0852,
        449.0867, 449.0728, 449.0934, 448.7075, 448.0967, 449.0822, 449.0890,
        449.0837, 448.2155, 449.0872, 449.0966, 449.0716, 449.0877, 448.0962,
        449.1099, 449.0751, 449.0889, 449.0898, 448.1342, 449.0674, 449.0663,
        448.0963, 449.0811, 449.0931, 449.1037, 449.0684, 448.1010, 448.1496,
        448.4614, 448.0965, 448.5118, 449.0983, 449.1088, 449.0885, 449.0889,
        449.0887, 449.0663, 449.1012, 449.0915, 449.1055, 448.9486, 449.0918,
        448.6754, 449.0966, 449.0966, 449.0821, 449.0862, 449.0977, 449.0835,
        449.6312, 448.0964, 449.0804, 448.2062, 449.0801, 449.0746, 449.0737,
        448.6898, 448.9459, 449.0865, 449.1055, 449.0849, 449.0900, 449.0850,
        449.0963, 449.1029, 449.1095, 449.0673, 448.0972, 448.1056, 448.0962,
        449.0929, 449.0875, 448.0961, 449.0874, 449.1582, 448.1082, 449.0847,
        449.0872, 449.1139, 449.0783, 448.6763, 448.3391, 449.0843, 449.1124,
        449.0867, 448.0962, 449.0756, 448.1593, 449.1082, 448.9754, 449.0782,
        449.0800, 448.6579, 449.1736, 449.0759, 449.1052, 449.0781, 449.0790,
        449.0931, 448.6395, 449.0844, 449.0819, 449.0905, 449.0743, 449.1102,
        449.0829, 449.1061, 448.6387, 449.0972, 448.3087, 449.1177, 449.0937,
        449.1227, 449.0873, 449.0882, 449.0778, 449.0861, 449.0822, 449.1122,
        448.1162, 449.0713, 448.1021, 449.0782, 448.0962, 449.0742, 449.6317,
        448.8336, 448.2551, 449.0952, 448.5084, 448.1035, 449.1121, 448.7485,
        449.0839, 448.1183, 449.0840, 448.0963, 449.0939, 449.0843, 449.1144,
        449.0842, 449.1038, 449.0791, 449.0788, 449.0823, 449.0721, 448.2250,
        449.0823, 448.6930, 449.0952, 448.6331, 449.1137, 448.0973, 448.2119,
        449.1101, 448.6362, 448.1017, 448.2809, 449.0887, 448.0961, 449.0762,
        449.1541, 449.1097, 449.0884, 448.0962, 449.0199, 449.1185, 449.1132,
        448.9755, 449.0872, 449.0975, 449.0712, 449.0813, 449.1089, 448.1121,
        449.0852, 449.0991, 449.0761, 448.0965, 448.1020, 449.0741, 449.0988,
        449.0884, 449.0686, 449.0705, 449.0839, 449.1187, 448.8596, 448.8315,
        449.0781, 448.0962, 448.8764, 449.0959, 449.0959, 449.1099, 449.0859,
        449.0875, 449.1038, 449.0800, 449.0802, 449.2180, 448.1719, 448.0962,
        449.1089, 449.0861, 449.0844, 449.0982, 449.0847, 448.1290, 448.4273,
        449.0676, 449.1859, 448.5013, 449.0795, 449.1096, 448.0962, 449.0964,
        448.0961, 449.0769, 449.0839, 448.1086, 448.1267, 449.1098, 449.0790,
        449.0931, 449.1034, 448.0962, 449.0685, 448.0969, 449.0867, 449.0844,
        448.0984, 449.0877, 448.1053, 448.1004, 449.0803, 449.0743, 448.0961,
        448.6490, 449.1119], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([396.1927], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0295],
             [112.3083],
             [112.0664],
             [112.0664]],

            [[112.2722],
             [112.2682],
             [112.2700],
             [112.2685]],

            [[112.2726],
             [112.2666],
             [112.2797],
             [112.2672]],

            ...,

            [[112.2692],
             [112.2716],
             [112.2691],
             [112.2798]],

            [[112.2728],
             [112.2824],
             [112.2673],
             [112.2673]],

            [[112.0258],
             [112.1079],
             [112.0394],
             [112.0394]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4705, 449.0789, 449.0861,  ..., 449.0897, 449.0900, 448.2124],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4705, 449.0789, 449.0861,  ..., 449.0897, 449.0900, 448.2124],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0315],
             [112.2872],
             [112.3168],
             [112.3168]],

            [[112.2839],
             [112.2838],
             [112.2924],
             [112.2835]],

            [[112.2893],
             [112.2905],
             [112.2902],
             [112.2904]],

            ...,

            [[112.0040],
             [112.0134],
             [112.0131],
             [112.0131]],

            [[112.2835],
             [112.2833],
             [112.2918],
             [112.2918]],

            [[112.2897],
             [112.2850],
             [112.2928],
             [112.2843]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9524, 449.1436, 449.1604,  ..., 448.0436, 449.1505, 449.1518],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9524, 449.1436, 449.1604,  ..., 448.0436, 449.1505, 449.1518],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2994],
             [112.2994],
             [112.3007],
             [112.3007]],

            [[112.2982],
             [112.2998],
             [112.2975],
             [112.2975]],

            [[112.2992],
             [112.3012],
             [112.3048],
             [112.2970]],

            ...,

            [[111.9861],
             [111.9861],
             [111.9861],
             [111.9861]],

            [[112.3610],
             [112.2973],
             [112.3046],
             [112.3046]],

            [[111.9961],
             [111.9961],
             [112.0108],
             [112.0108]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2001, 449.1931, 449.2022,  ..., 447.9445, 449.2674, 448.0139],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2001, 449.1931, 449.2022,  ..., 447.9445, 449.2674, 448.0139],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3091],
             [112.3094],
             [112.3079],
             [112.3099]],

            [[112.3083],
             [112.3081],
             [112.3089],
             [112.3089]],

            [[111.9778],
             [111.9778],
             [112.3416],
             [112.3416]],

            ...,

            [[111.9728],
             [111.9728],
             [111.9728],
             [111.9727]],

            [[112.3096],
             [112.3083],
             [112.3197],
             [112.3071]],

            [[111.9742],
             [112.0293],
             [112.0291],
             [111.9727]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2364, 449.2342, 448.6388,  ..., 447.8911, 449.2446, 448.0054],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2364, 449.2342, 448.6388,  ..., 447.8911, 449.2446, 448.0054],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9634],
             [111.9673],
             [111.9647],
             [111.9647]],

            [[112.3211],
             [112.3198],
             [112.3216],
             [112.3216]],

            [[112.3159],
             [112.3159],
             [112.3196],
             [112.3196]],

            ...,

            [[112.3521],
             [112.3126],
             [112.3149],
             [112.3149]],

            [[112.3143],
             [112.3132],
             [112.3144],
             [112.3170]],

            [[112.3134],
             [112.3134],
             [112.3163],
             [112.3163]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8602, 449.2841, 449.2710,  ..., 449.2945, 449.2588, 449.2592],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8602, 449.2841, 449.2710,  ..., 449.2945, 449.2588, 449.2592],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3218],
             [112.3212],
             [112.3224],
             [112.3224]],

            [[111.9665],
             [111.9665],
             [112.3256],
             [112.3256]],

            [[112.3280],
             [111.9655],
             [112.3253],
             [112.3242]],

            ...,

            [[112.3209],
             [112.3210],
             [112.3212],
             [112.3316]],

            [[112.3220],
             [112.3223],
             [112.3238],
             [112.3238]],

            [[112.3218],
             [112.3218],
             [112.3212],
             [112.3212]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2877, 448.5843, 448.9429,  ..., 449.2947, 449.2919, 449.2859],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2877, 448.5843, 448.9429,  ..., 449.2947, 449.2919, 449.2859],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3271],
             [112.2401],
             [112.3278],
             [112.3278]],

            [[112.3340],
             [112.3340],
             [112.3344],
             [112.3344]],

            [[111.9465],
             [112.3263],
             [111.9412],
             [112.3568]],

            ...,

            [[111.9381],
             [111.9388],
             [111.9383],
             [111.9383]],

            [[112.3272],
             [112.3362],
             [112.3270],
             [112.3268]],

            [[112.3335],
             [112.3310],
             [112.3345],
             [112.3345]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2227, 449.3367, 448.5709,  ..., 447.7535, 449.3172, 449.3335],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2227, 449.3367, 448.5709,  ..., 447.7535, 449.3172, 449.3335],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3411],
             [112.3411],
             [112.3358],
             [112.3358]],

            [[112.3350],
             [112.3354],
             [112.3336],
             [112.3412]],

            [[111.9273],
             [111.9302],
             [111.9275],
             [111.9275]],

            ...,

            [[111.9271],
             [111.9271],
             [111.9271],
             [111.9271]],

            [[112.3343],
             [112.3359],
             [112.3395],
             [112.3337]],

            [[112.3402],
             [112.3391],
             [112.3410],
             [112.3410]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3538, 449.3452, 447.7124,  ..., 447.7084, 449.3435, 449.3613],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3538, 449.3452, 447.7124,  ..., 447.7084, 449.3435, 449.3613],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3315],
             [112.3315],
             [112.3315],
             [112.3315]],

            [[112.3314],
             [112.3316],
             [112.3314],
             [112.3401]],

            [[112.3331],
             [112.3331],
             [112.3355],
             [112.3355]],

            ...,

            [[112.3319],
             [112.3375],
             [112.3321],
             [112.3316]],

            [[111.9353],
             [112.3417],
             [111.9353],
             [112.3417]],

            [[112.3327],
             [112.3339],
             [112.3320],
             [112.3389]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3259, 449.3345, 449.3372,  ..., 449.3332, 448.5540, 449.3376],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3259, 449.3345, 449.3372,  ..., 449.3332, 448.5540, 449.3376],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9218],
             [111.9218],
             [111.9207],
             [111.9262]],

            [[111.9472],
             [112.3342],
             [111.9472],
             [112.3342]],

            [[112.3571],
             [111.9255],
             [111.9258],
             [112.3563]],

            ...,

            [[112.3327],
             [112.3312],
             [112.3320],
             [112.3309]],

            [[112.3316],
             [112.3316],
             [112.3311],
             [112.3392]],

            [[112.3319],
             [112.3319],
             [112.3313],
             [112.3313]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6905, 448.5627, 448.5646,  ..., 449.3269, 449.3335, 449.3264],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6905, 448.5627, 448.5646,  ..., 449.3269, 449.3335, 449.3264],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3369],
             [112.3416],
             [112.3378],
             [112.3387]],

            [[112.3369],
             [112.3347],
             [112.3395],
             [112.3395]],

            [[112.3387],
             [112.3385],
             [112.3392],
             [112.3391]],

            ...,

            [[111.9291],
             [112.3654],
             [112.3445],
             [112.3394]],

            [[112.3402],
             [112.3371],
             [112.3348],
             [112.3348]],

            [[112.3367],
             [112.3367],
             [112.3383],
             [112.3383]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3549, 449.3507, 449.3556,  ..., 448.9783, 449.3469, 449.3499],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3549, 449.3507, 449.3556,  ..., 448.9783, 449.3469, 449.3499],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3817],
             [111.9054],
             [111.9045],
             [112.3641]],

            [[111.9006],
             [111.9006],
             [111.9006],
             [111.9006]],

            [[112.1891],
             [112.1891],
             [112.3438],
             [112.3438]],

            ...,

            [[112.3368],
             [112.3368],
             [112.3369],
             [112.3369]],

            [[112.3379],
             [112.3406],
             [112.3368],
             [112.3368]],

            [[112.3408],
             [112.3408],
             [112.3404],
             [112.3404]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5558, 447.6023, 449.0658,  ..., 449.3474, 449.3521, 449.3624],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5558, 447.6023, 449.0658,  ..., 449.3474, 449.3521, 449.3624],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9775],
             [112.3440],
             [112.3430],
             [111.9136]],

            [[111.9018],
             [112.3510],
             [112.3702],
             [112.3702]],

            [[111.8963],
             [111.8956],
             [111.8937],
             [111.9015]],

            ...,

            [[112.3393],
             [112.3411],
             [112.3390],
             [112.3392]],

            [[112.3412],
             [112.3403],
             [112.3387],
             [112.3387]],

            [[111.8933],
             [111.8959],
             [111.8940],
             [111.8940]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5782, 448.9932, 447.5871,  ..., 449.3586, 449.3589, 447.5773],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5782, 448.9932, 447.5871,  ..., 449.3586, 449.3589, 447.5773],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3406],
             [112.3406],
             [112.3478],
             [112.3478]],

            [[112.3445],
             [112.3415],
             [112.3423],
             [112.3438]],

            [[111.8923],
             [111.8923],
             [111.8907],
             [111.8907]],

            ...,

            [[112.3546],
             [112.3463],
             [111.9570],
             [112.3429]],

            [[112.3515],
             [112.3515],
             [112.3421],
             [112.3421]],

            [[112.3428],
             [112.3403],
             [112.3400],
             [112.3469]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3768, 449.3721, 447.5659,  ..., 449.0009, 449.3873, 449.3700],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3768, 449.3721, 447.5659,  ..., 449.0009, 449.3873, 449.3700],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8808],
             [111.8808],
             [111.8807],
             [111.8807]],

            [[111.8800],
             [111.8800],
             [111.9348],
             [111.9348]],

            [[111.9051],
             [111.9051],
             [112.1294],
             [112.1294]],

            ...,

            [[112.3860],
             [112.3573],
             [112.3452],
             [112.3452]],

            [[111.8790],
             [111.8790],
             [111.8790],
             [111.8790]],

            [[111.9043],
             [111.9545],
             [111.9151],
             [111.8982]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5229, 447.6297, 448.0691,  ..., 449.4336, 447.5161, 447.6722],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5229, 447.6297, 448.0691,  ..., 449.4336, 447.5161, 447.6722],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3510],
             [112.3510],
             [112.3510],
             [112.3510]],

            [[112.3431],
             [112.3397],
             [112.3408],
             [112.3408]],

            [[112.3392],
             [112.3393],
             [112.3449],
             [112.3411]],

            ...,

            [[112.3410],
             [112.3395],
             [112.3410],
             [112.3395]],

            [[111.9174],
             [112.3440],
             [112.3459],
             [112.3459]],

            [[112.3527],
             [112.3527],
             [112.3512],
             [112.3512]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.4039, 449.3644, 449.3646,  ..., 449.3611, 448.9532, 449.4078],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.4039, 449.3644, 449.3646,  ..., 449.3611, 448.9532, 449.4078],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8871],
             [111.8871],
             [111.8871],
             [111.8871]],

            [[112.3384],
             [112.3382],
             [112.3329],
             [112.3329]],

            [[112.3352],
             [112.3329],
             [112.3353],
             [112.3383]],

            ...,

            [[112.3361],
             [112.3360],
             [112.3328],
             [112.3328]],

            [[112.3328],
             [112.3390],
             [112.3365],
             [112.3328]],

            [[112.3353],
             [112.3353],
             [112.3343],
             [112.3343]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5485, 449.3424, 449.3416,  ..., 449.3377, 449.3412, 449.3394],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5485, 449.3424, 449.3416,  ..., 449.3377, 449.3412, 449.3394],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3279],
             [112.3279],
             [112.3309],
             [112.3309]],

            [[112.3444],
             [112.3313],
             [112.3457],
             [112.3313]],

            [[112.3312],
             [112.3488],
             [112.3590],
             [112.3315]],

            ...,

            [[112.3329],
             [112.3349],
             [112.3295],
             [112.3285]],

            [[112.3335],
             [112.3312],
             [112.3297],
             [112.3293]],

            [[112.3278],
             [112.3278],
             [112.3321],
             [112.3321]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3176, 449.3527, 449.3706,  ..., 449.3258, 449.3237, 449.3198],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3176, 449.3527, 449.3706,  ..., 449.3258, 449.3237, 449.3198],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9876e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3374],
             [112.3374],
             [112.3304],
             [112.3304]],

            [[111.9360],
             [112.3386],
             [112.3398],
             [111.9152]],

            [[112.3371],
             [112.3309],
             [112.3303],
             [112.3303]],

            ...,

            [[112.3304],
             [112.3304],
             [112.3347],
             [112.3347]],

            [[111.8890],
             [112.1597],
             [111.8994],
             [111.8994]],

            [[112.3326],
             [112.3329],
             [112.3365],
             [112.3312]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3357, 448.5296, 449.3286,  ..., 449.3304, 447.8475, 449.3333],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3357, 448.5296, 449.3286,  ..., 449.3304, 447.8475, 449.3333],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3327],
             [112.3327],
             [112.3334],
             [112.3334]],

            [[111.8596],
             [111.8200],
             [111.8624],
             [111.8144]],

            [[112.3366],
             [112.3345],
             [112.3315],
             [112.3315]],

            ...,

            [[112.3347],
             [112.3343],
             [112.3312],
             [112.3312]],

            [[112.3346],
             [112.3325],
             [112.3346],
             [112.3325]],

            [[112.3319],
             [112.3345],
             [112.3306],
             [112.3306]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3323, 447.3564, 449.3341,  ..., 449.3314, 449.3341, 449.3274],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3323, 447.3564, 449.3341,  ..., 449.3314, 449.3341, 449.3274],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3379],
             [112.3338],
             [112.3303],
             [112.3303]],

            [[112.3308],
             [112.3326],
             [112.3360],
             [112.3360]],

            [[112.3345],
             [112.3378],
             [112.3309],
             [112.3363]],

            ...,

            [[111.9637],
             [112.3375],
             [112.3460],
             [112.3460]],

            [[112.3364],
             [112.3597],
             [112.3766],
             [112.3363]],

            [[112.3306],
             [112.3306],
             [112.3351],
             [112.3342]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3324, 449.3355, 449.3394, 447.5504, 449.3339, 449.3359, 449.3293,
            449.3277, 449.3275, 449.3342, 448.9998, 447.5504, 449.3341, 448.9855,
            449.3387, 449.3288, 449.3311, 448.5601, 449.3307, 449.3296, 449.3291,
            449.3911, 449.3301, 447.5531, 448.5286, 449.3317, 449.3297, 449.3447,
            449.3322, 448.4827, 449.3229, 447.5505, 449.3240, 447.6725, 449.3277,
            447.5977, 447.5542, 447.5696, 448.4960, 449.3302, 449.3445, 449.3403,
            449.3260, 447.5622, 447.5494, 449.3282, 449.3416, 447.5520, 448.2003,
            447.5698, 448.7137, 447.5495, 447.5622, 447.5494, 447.5939, 448.1952,
            449.3316, 448.2294, 449.3313, 449.3311, 449.3339, 449.3466, 449.3407,
            449.3271, 448.5017, 449.3267, 449.3280, 449.3600, 449.3364, 449.3286,
            449.3239, 449.3272, 449.3299, 449.3307, 449.3301, 447.5582, 449.3353,
            448.9285, 449.3283, 447.5533, 447.6072, 449.4265, 449.3359, 447.5602,
            449.3376, 449.3338, 447.5495, 449.3390, 447.7425, 447.5496, 449.3359,
            447.5640, 449.3394, 448.5396, 449.3268, 449.3273, 449.3568, 449.3391,
            449.3241, 447.5496, 449.3322, 449.3379, 449.3330, 449.3370, 449.3289,
            449.3297, 449.3307, 449.3317, 447.5518, 448.5082, 449.3226, 449.3326,
            449.3331, 449.3279, 448.5119, 449.3256, 448.9951, 449.3351, 449.3259,
            448.5361, 449.3307, 449.3364, 448.0808, 448.9871, 449.3350, 447.5508,
            449.3292, 449.3335, 449.3300, 449.3286, 449.3284, 449.3315, 447.5898,
            449.3368, 447.5495, 449.3316, 447.5495, 447.6945, 447.5494, 449.3355,
            448.5345, 448.4912, 449.3662, 449.3338, 449.3364, 449.3273, 449.3289,
            449.2434, 449.3294, 449.3323, 449.3295, 449.3353, 448.5325, 449.3286,
            449.3289, 449.3284, 449.3340, 449.3292, 448.5307, 447.5618, 449.3370,
            447.6432, 449.3292, 447.5528, 449.3254, 449.3264, 449.3336, 448.2470,
            449.3352, 448.5286, 449.3321, 449.3292, 449.3348, 448.4844, 449.3954,
            449.3312, 449.3290, 449.3250, 449.3475, 447.5501, 449.3273, 449.3331,
            448.0842, 449.3925, 449.3311, 449.3356, 448.5173, 449.3288, 449.3291,
            448.4634, 449.3293, 449.3299, 449.3363, 449.3234, 449.3336, 449.3308,
            449.3214, 449.3336, 449.3337, 449.3946, 449.3753, 449.3222, 447.5748,
            449.3333, 449.3309, 449.3331, 449.3307, 449.3256, 449.4333, 449.3338,
            449.3323, 449.3339, 449.3344, 449.3288, 449.3300, 449.3576, 449.3368,
            449.3296, 449.3364, 449.3972, 449.3281, 448.5015, 449.3304, 449.3367,
            447.5770, 448.8327, 448.5242, 448.2848, 449.3315, 449.3279, 449.3275,
            449.3343, 449.3515, 449.3261, 449.3267, 449.3310, 447.5496, 447.5543,
            449.3250, 449.3361, 449.3297, 449.3308, 447.5649, 447.5619, 449.3323,
            449.3320, 449.3254, 448.3236, 449.3299, 449.3313, 449.3394, 449.3314,
            449.3360, 448.9813, 449.3384, 447.6001, 449.3342, 449.3370, 449.3381,
            448.0668, 449.4432, 447.6036, 447.5494, 447.5494, 449.4336, 449.3323,
            449.3341, 447.5532, 449.3346, 449.3281, 449.4302, 449.3438, 447.5602,
            448.5311, 449.3333, 449.4008, 449.3344, 449.3286, 449.3293, 447.5515,
            447.5500, 449.3691, 447.5598, 449.3290, 449.3304, 449.3356, 449.0829,
            447.5495, 449.4057, 449.3319, 449.3296, 449.3318, 449.3243, 448.4862,
            448.9558, 449.3273, 449.3430, 448.9382, 447.5502, 449.3312, 449.3298,
            447.5494, 449.3309, 447.5496, 449.3283, 449.3287, 449.3304, 449.3684,
            447.5494, 449.3361, 449.3270, 449.3345, 447.5512, 449.3855, 449.3380,
            449.3271, 449.3221, 448.4996, 449.3361, 447.5532, 449.3297, 449.3269,
            449.3275, 449.1042, 449.3427, 449.3348, 449.3257, 449.3517, 447.6285,
            449.3314, 447.5495, 447.5494, 449.3312, 449.3322, 449.3275, 449.3356,
            447.5483, 449.3324, 449.3997, 449.3314, 447.5845, 449.3312, 447.5575,
            448.9594, 449.3349, 449.3321, 449.3253, 449.3315, 447.6258, 449.3292,
            449.3332, 449.3343, 449.3348, 449.3299, 448.0686, 449.3969, 447.5494,
            447.6235, 449.3374, 449.3293, 447.5729, 447.3097, 449.3283, 449.3285,
            447.6875, 449.3286, 449.3365, 449.3317, 448.9866, 449.3254, 449.3546,
            449.3256, 449.3351, 449.3298, 449.3409, 447.6927, 449.3298, 449.3895,
            449.3337, 449.3318, 449.3318, 449.3294, 447.5494, 449.3231, 449.3300,
            449.3379, 448.0646, 449.3279, 448.9628, 449.0317, 449.3333, 448.5259,
            449.3246, 449.3376, 447.6100, 449.3274, 449.3315, 449.3480, 449.3331,
            447.5491, 449.3309, 449.3337, 449.3542, 447.5494, 448.5699, 449.3391,
            448.9178, 449.3268, 449.3366, 449.3351, 449.3370, 449.3357, 449.3307,
            449.3292, 449.3297, 449.3272, 449.3314, 449.3286, 449.3218, 449.3358,
            448.0215, 449.3588, 449.3311, 447.5494, 449.3326, 449.4123, 449.3343,
            449.3267, 449.3256, 449.3407, 448.5475, 449.3327, 449.3220, 449.3299,
            449.3298, 448.5217, 448.9936, 449.3247, 449.3384, 449.3407, 447.5616,
            449.3386, 448.6163, 449.3442, 449.3353, 449.3334, 449.3365, 449.3329,
            449.3334, 449.3335, 449.3397, 449.4627, 449.3759, 449.3336, 449.3521,
            448.4945, 449.3447, 449.3283, 449.3376, 449.3283, 449.3300, 449.3288,
            447.5508, 447.5680, 449.4139, 449.3260, 449.3330, 449.3891, 449.3331,
            449.3257, 448.5216, 447.5508, 447.5527, 449.3329, 449.3319, 447.5579,
            447.5517, 449.3276, 449.3334, 449.4304, 449.3816, 447.7067, 449.3308,
            449.3268, 449.3262, 449.3270, 449.3358, 449.3400, 449.3335, 449.3339,
            448.6407, 449.3353, 449.2021, 448.0607, 448.1119, 449.3514, 449.3438,
            449.3249, 448.9687, 449.3281, 447.5497, 449.3336, 449.3321, 449.3302,
            449.3338, 449.3366, 449.3817, 448.9969, 448.9639, 449.3358, 449.3311,
            449.3289, 449.3263, 449.3286, 449.3301, 449.3326, 447.3089, 447.5494,
            447.5534, 448.9559, 449.3299, 449.3364, 449.3283, 449.3293, 449.3338,
            449.3307, 449.3315, 449.3299, 448.7864, 449.3704, 449.3297, 447.5496,
            449.3287, 449.3295, 449.3363, 449.3261, 449.3257, 449.3344, 449.3334,
            449.3323, 449.3858, 449.3272, 447.5523, 448.9797, 449.3316, 447.5540,
            449.3445, 449.3326, 447.5631, 449.3306, 449.3268, 449.3374, 449.3221,
            449.3579, 447.8099, 449.3343, 447.4476, 449.3336, 449.3328, 449.3359,
            449.3324, 449.3300, 449.3319, 449.3339, 449.3257, 448.0627, 447.5494,
            449.3242, 448.0617, 447.5494, 449.3316, 449.3416, 448.4903, 449.3303,
            449.3321, 449.3470, 447.5509, 449.3321, 449.3378, 449.3242, 449.3223,
            449.3349, 449.2489, 449.3397, 449.3317, 449.3281, 449.3376, 449.3398,
            449.3281, 449.3376, 449.3357, 449.3358, 449.3262, 449.3797, 449.3457,
            447.5533, 447.5500, 449.3577, 449.3463, 449.3305, 447.5534, 448.5684,
            449.3257, 447.6102, 449.3321, 448.7109, 449.3325, 449.3323, 449.3240,
            449.3513, 449.3288, 447.6221, 449.3288, 449.3294, 449.3235, 449.3391,
            449.3307, 449.3366, 449.3322, 449.3360, 449.4221, 449.3329, 448.9140,
            447.7484, 449.3248, 447.5504, 449.3438, 449.3276, 447.6850, 449.3343,
            449.3239, 449.3303, 449.3349, 449.3295, 449.2748, 449.3356, 449.3289,
            447.7906, 449.3349, 449.3319, 449.4462, 447.3089, 449.3474, 449.3299,
            448.5087, 449.3228, 447.6354, 449.3361, 449.3267, 449.3338, 449.3273,
            449.4193, 449.3378, 449.3361, 449.0695, 449.3315, 449.3307, 448.4819,
            449.3253, 447.5494, 449.3336, 449.3340, 447.5497, 449.3303, 449.3401,
            449.3297, 449.3366, 447.5491, 448.3517, 447.7549, 449.3273, 448.5096,
            449.3243, 447.5659, 447.5628, 449.3295, 449.3672, 447.5551, 447.5551,
            449.3315, 449.3540, 447.5524, 449.3253, 447.5502, 449.3324, 448.2280,
            447.5535, 449.3358, 449.3258, 449.3649, 448.0785, 447.5495, 449.3235,
            449.3265, 449.3320, 449.3290, 449.3535, 449.3363, 449.3335, 449.3356,
            449.3407, 449.3276, 449.3591, 449.3288, 449.3283, 448.5554, 447.5784,
            447.5915, 449.3333, 449.3328, 448.9578, 449.3294, 447.5494, 449.3282,
            447.5500, 449.4298, 449.3634, 449.3324, 447.5510, 449.3333, 449.3866,
            449.3305, 449.3900, 449.3361, 449.3287, 449.3357, 448.4917, 447.5496,
            447.5768, 448.5203, 449.3344, 449.3310, 449.3998, 449.3423, 448.3165,
            449.3571, 449.3245, 449.3289, 447.5497, 449.3336, 447.3089, 449.3438,
            449.3495, 447.5495, 449.3320, 449.3303, 449.3378, 448.9500, 449.3354,
            449.3315, 449.3345, 449.3282, 449.3307, 449.3268, 447.5521, 448.4948,
            449.4013, 449.0320, 449.3339, 448.4886, 449.3257, 449.3285, 449.3982,
            447.6521, 449.3278, 447.5953, 449.3338, 449.3381, 449.3360, 449.3699,
            448.5211, 449.3260, 449.3446, 449.3344, 449.3283, 449.3363, 449.3492,
            448.8374, 449.3363, 448.9408, 449.4263, 449.3336, 449.3342, 449.3506,
            449.3344, 449.3510, 448.8088, 449.3350, 449.3274, 449.3546, 447.5012,
            449.3447, 449.3536, 449.3271, 447.5515, 447.5520, 449.3268, 449.3243,
            449.3390, 447.7336, 449.3321, 449.4396, 447.6197, 449.3303, 449.3300,
            449.3269, 449.3324, 449.3311, 447.5502, 449.3323, 448.5211, 448.5691,
            448.9646, 449.3883, 449.3359, 448.9503, 449.3348, 449.3300, 449.3347,
            449.3318, 449.0323, 449.3761, 449.3352, 449.3296, 449.3294, 447.7021,
            449.3290, 449.3634, 449.3276, 447.5500, 448.4940, 448.9298, 449.3342,
            449.3425, 449.3268, 447.5521, 449.3665, 449.3421, 449.3344, 448.1224,
            449.3269, 449.3245, 449.3294, 449.3328, 449.3347, 449.3344, 449.3327,
            449.3308, 449.3301, 449.3292, 449.3283, 449.4210, 449.3271, 447.5654,
            449.3386, 447.5494, 447.5514, 448.5115, 449.3530, 449.3303, 449.3363,
            448.5118, 447.5494, 449.3312, 449.3262, 448.9540, 449.4099, 447.5494,
            447.5860, 449.3330, 449.3304, 449.3255, 448.5559, 449.3438, 449.3297,
            447.5495, 448.9409, 448.1760, 449.3254, 449.3445, 448.3747, 447.5495,
            448.9236, 447.5494, 447.7501, 449.3283, 449.3437, 449.3273, 448.4930,
            447.3207, 449.3346, 449.3307, 449.3252, 448.5096, 449.3280, 447.5558,
            449.3307, 449.3256, 449.3311, 447.5494, 449.3353, 449.3656, 447.7284,
            447.5498, 449.3362, 449.3271, 449.3666, 449.3330, 448.5638, 449.3356,
            449.3301, 449.3291, 449.3412, 449.3336, 449.3334, 449.3273, 448.5342,
            449.3270, 449.3371, 447.5494, 449.3347, 447.5505, 449.3323, 448.9932,
            449.4090, 449.3305], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3324, 449.3355, 449.3394, 447.5504, 449.3339, 449.3359, 449.3293,
        449.3277, 449.3275, 449.3342, 448.9998, 447.5504, 449.3341, 448.9855,
        449.3387, 449.3288, 449.3311, 448.5601, 449.3307, 449.3296, 449.3291,
        449.3911, 449.3301, 447.5531, 448.5286, 449.3317, 449.3297, 449.3447,
        449.3322, 448.4827, 449.3229, 447.5505, 449.3240, 447.6725, 449.3277,
        447.5977, 447.5542, 447.5696, 448.4960, 449.3302, 449.3445, 449.3403,
        449.3260, 447.5622, 447.5494, 449.3282, 449.3416, 447.5520, 448.2003,
        447.5698, 448.7137, 447.5495, 447.5622, 447.5494, 447.5939, 448.1952,
        449.3316, 448.2294, 449.3313, 449.3311, 449.3339, 449.3466, 449.3407,
        449.3271, 448.5017, 449.3267, 449.3280, 449.3600, 449.3364, 449.3286,
        449.3239, 449.3272, 449.3299, 449.3307, 449.3301, 447.5582, 449.3353,
        448.9285, 449.3283, 447.5533, 447.6072, 449.4265, 449.3359, 447.5602,
        449.3376, 449.3338, 447.5495, 449.3390, 447.7425, 447.5496, 449.3359,
        447.5640, 449.3394, 448.5396, 449.3268, 449.3273, 449.3568, 449.3391,
        449.3241, 447.5496, 449.3322, 449.3379, 449.3330, 449.3370, 449.3289,
        449.3297, 449.3307, 449.3317, 447.5518, 448.5082, 449.3226, 449.3326,
        449.3331, 449.3279, 448.5119, 449.3256, 448.9951, 449.3351, 449.3259,
        448.5361, 449.3307, 449.3364, 448.0808, 448.9871, 449.3350, 447.5508,
        449.3292, 449.3335, 449.3300, 449.3286, 449.3284, 449.3315, 447.5898,
        449.3368, 447.5495, 449.3316, 447.5495, 447.6945, 447.5494, 449.3355,
        448.5345, 448.4912, 449.3662, 449.3338, 449.3364, 449.3273, 449.3289,
        449.2434, 449.3294, 449.3323, 449.3295, 449.3353, 448.5325, 449.3286,
        449.3289, 449.3284, 449.3340, 449.3292, 448.5307, 447.5618, 449.3370,
        447.6432, 449.3292, 447.5528, 449.3254, 449.3264, 449.3336, 448.2470,
        449.3352, 448.5286, 449.3321, 449.3292, 449.3348, 448.4844, 449.3954,
        449.3312, 449.3290, 449.3250, 449.3475, 447.5501, 449.3273, 449.3331,
        448.0842, 449.3925, 449.3311, 449.3356, 448.5173, 449.3288, 449.3291,
        448.4634, 449.3293, 449.3299, 449.3363, 449.3234, 449.3336, 449.3308,
        449.3214, 449.3336, 449.3337, 449.3946, 449.3753, 449.3222, 447.5748,
        449.3333, 449.3309, 449.3331, 449.3307, 449.3256, 449.4333, 449.3338,
        449.3323, 449.3339, 449.3344, 449.3288, 449.3300, 449.3576, 449.3368,
        449.3296, 449.3364, 449.3972, 449.3281, 448.5015, 449.3304, 449.3367,
        447.5770, 448.8327, 448.5242, 448.2848, 449.3315, 449.3279, 449.3275,
        449.3343, 449.3515, 449.3261, 449.3267, 449.3310, 447.5496, 447.5543,
        449.3250, 449.3361, 449.3297, 449.3308, 447.5649, 447.5619, 449.3323,
        449.3320, 449.3254, 448.3236, 449.3299, 449.3313, 449.3394, 449.3314,
        449.3360, 448.9813, 449.3384, 447.6001, 449.3342, 449.3370, 449.3381,
        448.0668, 449.4432, 447.6036, 447.5494, 447.5494, 449.4336, 449.3323,
        449.3341, 447.5532, 449.3346, 449.3281, 449.4302, 449.3438, 447.5602,
        448.5311, 449.3333, 449.4008, 449.3344, 449.3286, 449.3293, 447.5515,
        447.5500, 449.3691, 447.5598, 449.3290, 449.3304, 449.3356, 449.0829,
        447.5495, 449.4057, 449.3319, 449.3296, 449.3318, 449.3243, 448.4862,
        448.9558, 449.3273, 449.3430, 448.9382, 447.5502, 449.3312, 449.3298,
        447.5494, 449.3309, 447.5496, 449.3283, 449.3287, 449.3304, 449.3684,
        447.5494, 449.3361, 449.3270, 449.3345, 447.5512, 449.3855, 449.3380,
        449.3271, 449.3221, 448.4996, 449.3361, 447.5532, 449.3297, 449.3269,
        449.3275, 449.1042, 449.3427, 449.3348, 449.3257, 449.3517, 447.6285,
        449.3314, 447.5495, 447.5494, 449.3312, 449.3322, 449.3275, 449.3356,
        447.5483, 449.3324, 449.3997, 449.3314, 447.5845, 449.3312, 447.5575,
        448.9594, 449.3349, 449.3321, 449.3253, 449.3315, 447.6258, 449.3292,
        449.3332, 449.3343, 449.3348, 449.3299, 448.0686, 449.3969, 447.5494,
        447.6235, 449.3374, 449.3293, 447.5729, 447.3097, 449.3283, 449.3285,
        447.6875, 449.3286, 449.3365, 449.3317, 448.9866, 449.3254, 449.3546,
        449.3256, 449.3351, 449.3298, 449.3409, 447.6927, 449.3298, 449.3895,
        449.3337, 449.3318, 449.3318, 449.3294, 447.5494, 449.3231, 449.3300,
        449.3379, 448.0646, 449.3279, 448.9628, 449.0317, 449.3333, 448.5259,
        449.3246, 449.3376, 447.6100, 449.3274, 449.3315, 449.3480, 449.3331,
        447.5491, 449.3309, 449.3337, 449.3542, 447.5494, 448.5699, 449.3391,
        448.9178, 449.3268, 449.3366, 449.3351, 449.3370, 449.3357, 449.3307,
        449.3292, 449.3297, 449.3272, 449.3314, 449.3286, 449.3218, 449.3358,
        448.0215, 449.3588, 449.3311, 447.5494, 449.3326, 449.4123, 449.3343,
        449.3267, 449.3256, 449.3407, 448.5475, 449.3327, 449.3220, 449.3299,
        449.3298, 448.5217, 448.9936, 449.3247, 449.3384, 449.3407, 447.5616,
        449.3386, 448.6163, 449.3442, 449.3353, 449.3334, 449.3365, 449.3329,
        449.3334, 449.3335, 449.3397, 449.4627, 449.3759, 449.3336, 449.3521,
        448.4945, 449.3447, 449.3283, 449.3376, 449.3283, 449.3300, 449.3288,
        447.5508, 447.5680, 449.4139, 449.3260, 449.3330, 449.3891, 449.3331,
        449.3257, 448.5216, 447.5508, 447.5527, 449.3329, 449.3319, 447.5579,
        447.5517, 449.3276, 449.3334, 449.4304, 449.3816, 447.7067, 449.3308,
        449.3268, 449.3262, 449.3270, 449.3358, 449.3400, 449.3335, 449.3339,
        448.6407, 449.3353, 449.2021, 448.0607, 448.1119, 449.3514, 449.3438,
        449.3249, 448.9687, 449.3281, 447.5497, 449.3336, 449.3321, 449.3302,
        449.3338, 449.3366, 449.3817, 448.9969, 448.9639, 449.3358, 449.3311,
        449.3289, 449.3263, 449.3286, 449.3301, 449.3326, 447.3089, 447.5494,
        447.5534, 448.9559, 449.3299, 449.3364, 449.3283, 449.3293, 449.3338,
        449.3307, 449.3315, 449.3299, 448.7864, 449.3704, 449.3297, 447.5496,
        449.3287, 449.3295, 449.3363, 449.3261, 449.3257, 449.3344, 449.3334,
        449.3323, 449.3858, 449.3272, 447.5523, 448.9797, 449.3316, 447.5540,
        449.3445, 449.3326, 447.5631, 449.3306, 449.3268, 449.3374, 449.3221,
        449.3579, 447.8099, 449.3343, 447.4476, 449.3336, 449.3328, 449.3359,
        449.3324, 449.3300, 449.3319, 449.3339, 449.3257, 448.0627, 447.5494,
        449.3242, 448.0617, 447.5494, 449.3316, 449.3416, 448.4903, 449.3303,
        449.3321, 449.3470, 447.5509, 449.3321, 449.3378, 449.3242, 449.3223,
        449.3349, 449.2489, 449.3397, 449.3317, 449.3281, 449.3376, 449.3398,
        449.3281, 449.3376, 449.3357, 449.3358, 449.3262, 449.3797, 449.3457,
        447.5533, 447.5500, 449.3577, 449.3463, 449.3305, 447.5534, 448.5684,
        449.3257, 447.6102, 449.3321, 448.7109, 449.3325, 449.3323, 449.3240,
        449.3513, 449.3288, 447.6221, 449.3288, 449.3294, 449.3235, 449.3391,
        449.3307, 449.3366, 449.3322, 449.3360, 449.4221, 449.3329, 448.9140,
        447.7484, 449.3248, 447.5504, 449.3438, 449.3276, 447.6850, 449.3343,
        449.3239, 449.3303, 449.3349, 449.3295, 449.2748, 449.3356, 449.3289,
        447.7906, 449.3349, 449.3319, 449.4462, 447.3089, 449.3474, 449.3299,
        448.5087, 449.3228, 447.6354, 449.3361, 449.3267, 449.3338, 449.3273,
        449.4193, 449.3378, 449.3361, 449.0695, 449.3315, 449.3307, 448.4819,
        449.3253, 447.5494, 449.3336, 449.3340, 447.5497, 449.3303, 449.3401,
        449.3297, 449.3366, 447.5491, 448.3517, 447.7549, 449.3273, 448.5096,
        449.3243, 447.5659, 447.5628, 449.3295, 449.3672, 447.5551, 447.5551,
        449.3315, 449.3540, 447.5524, 449.3253, 447.5502, 449.3324, 448.2280,
        447.5535, 449.3358, 449.3258, 449.3649, 448.0785, 447.5495, 449.3235,
        449.3265, 449.3320, 449.3290, 449.3535, 449.3363, 449.3335, 449.3356,
        449.3407, 449.3276, 449.3591, 449.3288, 449.3283, 448.5554, 447.5784,
        447.5915, 449.3333, 449.3328, 448.9578, 449.3294, 447.5494, 449.3282,
        447.5500, 449.4298, 449.3634, 449.3324, 447.5510, 449.3333, 449.3866,
        449.3305, 449.3900, 449.3361, 449.3287, 449.3357, 448.4917, 447.5496,
        447.5768, 448.5203, 449.3344, 449.3310, 449.3998, 449.3423, 448.3165,
        449.3571, 449.3245, 449.3289, 447.5497, 449.3336, 447.3089, 449.3438,
        449.3495, 447.5495, 449.3320, 449.3303, 449.3378, 448.9500, 449.3354,
        449.3315, 449.3345, 449.3282, 449.3307, 449.3268, 447.5521, 448.4948,
        449.4013, 449.0320, 449.3339, 448.4886, 449.3257, 449.3285, 449.3982,
        447.6521, 449.3278, 447.5953, 449.3338, 449.3381, 449.3360, 449.3699,
        448.5211, 449.3260, 449.3446, 449.3344, 449.3283, 449.3363, 449.3492,
        448.8374, 449.3363, 448.9408, 449.4263, 449.3336, 449.3342, 449.3506,
        449.3344, 449.3510, 448.8088, 449.3350, 449.3274, 449.3546, 447.5012,
        449.3447, 449.3536, 449.3271, 447.5515, 447.5520, 449.3268, 449.3243,
        449.3390, 447.7336, 449.3321, 449.4396, 447.6197, 449.3303, 449.3300,
        449.3269, 449.3324, 449.3311, 447.5502, 449.3323, 448.5211, 448.5691,
        448.9646, 449.3883, 449.3359, 448.9503, 449.3348, 449.3300, 449.3347,
        449.3318, 449.0323, 449.3761, 449.3352, 449.3296, 449.3294, 447.7021,
        449.3290, 449.3634, 449.3276, 447.5500, 448.4940, 448.9298, 449.3342,
        449.3425, 449.3268, 447.5521, 449.3665, 449.3421, 449.3344, 448.1224,
        449.3269, 449.3245, 449.3294, 449.3328, 449.3347, 449.3344, 449.3327,
        449.3308, 449.3301, 449.3292, 449.3283, 449.4210, 449.3271, 447.5654,
        449.3386, 447.5494, 447.5514, 448.5115, 449.3530, 449.3303, 449.3363,
        448.5118, 447.5494, 449.3312, 449.3262, 448.9540, 449.4099, 447.5494,
        447.5860, 449.3330, 449.3304, 449.3255, 448.5559, 449.3438, 449.3297,
        447.5495, 448.9409, 448.1760, 449.3254, 449.3445, 448.3747, 447.5495,
        448.9236, 447.5494, 447.7501, 449.3283, 449.3437, 449.3273, 448.4930,
        447.3207, 449.3346, 449.3307, 449.3252, 448.5096, 449.3280, 447.5558,
        449.3307, 449.3256, 449.3311, 447.5494, 449.3353, 449.3656, 447.7284,
        447.5498, 449.3362, 449.3271, 449.3666, 449.3330, 448.5638, 449.3356,
        449.3301, 449.3291, 449.3412, 449.3336, 449.3334, 449.3273, 448.5342,
        449.3270, 449.3371, 447.5494, 449.3347, 447.5505, 449.3323, 448.9932,
        449.4090, 449.3305], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([413.3389], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3622],
             [112.3347],
             [112.3654],
             [112.3350]],

            [[112.3371],
             [112.3331],
             [112.3305],
             [112.3305]],

            [[112.3303],
             [112.3303],
             [112.3323],
             [112.3323]],

            ...,

            [[112.3357],
             [112.3357],
             [112.3304],
             [112.3304]],

            [[111.8886],
             [111.9466],
             [111.9419],
             [111.8873]],

            [[112.0938],
             [112.1768],
             [111.9168],
             [112.3667]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3973, 449.3312, 449.3252,  ..., 449.3324, 447.6644, 448.5542],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3973, 449.3312, 449.3252,  ..., 449.3324, 447.6644, 448.5542],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3416],
             [112.3387],
             [112.3370],
             [112.3365]],

            [[112.3406],
             [112.3407],
             [112.3366],
             [112.3393]],

            [[112.3398],
             [112.3526],
             [112.3525],
             [112.3398]],

            ...,

            [[112.3364],
             [112.3401],
             [112.3424],
             [112.3373]],

            [[112.3445],
             [112.3445],
             [112.3364],
             [112.3364]],

            [[111.8820],
             [111.8820],
             [111.8820],
             [111.8820]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3539, 449.3572, 449.3846,  ..., 449.3561, 449.3617, 447.5280],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3539, 449.3572, 449.3846,  ..., 449.3561, 449.3617, 447.5280],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3460],
             [112.3458],
             [112.3469],
             [112.3487]],

            [[112.3446],
             [112.3446],
             [112.3444],
             [112.3460]],

            [[111.8896],
             [111.8754],
             [111.8970],
             [111.8755]],

            ...,

            [[112.3487],
             [112.3451],
             [112.3452],
             [112.3484]],

            [[112.3509],
             [112.3453],
             [112.3508],
             [112.3442]],

            [[111.8748],
             [111.8748],
             [111.8748],
             [111.8747]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3874, 449.3797, 447.5375,  ..., 449.3873, 449.3912, 447.4992],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3874, 449.3797, 447.5375,  ..., 449.3873, 449.3912, 447.4992],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3608],
             [112.3657],
             [112.3617],
             [112.3672]],

            [[112.3668],
             [112.3629],
             [112.3683],
             [112.3600]],

            [[112.4096],
             [112.3680],
             [112.3693],
             [112.3693]],

            ...,

            [[112.3603],
             [112.3610],
             [112.3628],
             [112.3638]],

            [[112.3600],
             [112.3600],
             [112.3638],
             [112.3638]],

            [[112.3602],
             [112.3621],
             [112.3678],
             [112.3678]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.4554, 449.4580, 449.5161,  ..., 449.4479, 449.4476, 449.4578],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.4554, 449.4580, 449.5161,  ..., 449.4479, 449.4476, 449.4578],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3821],
             [112.3755],
             [112.3736],
             [112.3736]],

            [[112.3766],
             [112.3779],
             [112.3732],
             [112.3732]],

            [[112.3745],
             [112.3744],
             [112.3742],
             [112.3743]],

            ...,

            [[112.3751],
             [112.3751],
             [112.3751],
             [112.3751]],

            [[112.3745],
             [112.3847],
             [112.3835],
             [112.3785]],

            [[112.3802],
             [112.3746],
             [112.3740],
             [112.3740]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.5047, 449.5010, 449.4974,  ..., 449.5004, 449.5212, 449.5028],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.5047, 449.5010, 449.4974,  ..., 449.5004, 449.5212, 449.5028],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8531],
             [111.9088],
             [111.9044],
             [111.8519]],

            [[111.8528],
             [111.8851],
             [111.8579],
             [111.8579]],

            [[112.3710],
             [112.3733],
             [112.3788],
             [112.3788]],

            ...,

            [[112.3725],
             [112.3723],
             [112.3727],
             [112.3727]],

            [[112.4049],
             [112.3786],
             [112.3812],
             [112.3812]],

            [[112.3814],
             [111.9576],
             [112.3960],
             [112.3866]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.5182, 447.4537, 449.5021,  ..., 449.4902, 449.5459, 449.1216],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.5182, 447.4537, 449.5021,  ..., 449.4902, 449.5459, 449.1216],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3698],
             [112.3698],
             [112.3702],
             [112.3702]],

            [[112.3695],
             [112.3772],
             [112.3705],
             [112.3705]],

            [[112.3774],
             [112.3685],
             [112.3712],
             [112.3727]],

            ...,

            [[112.3685],
             [112.3703],
             [112.3683],
             [112.3686]],

            [[112.3788],
             [112.3808],
             [112.3698],
             [112.3697]],

            [[111.8549],
             [111.8550],
             [111.8550],
             [111.8549]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.4800, 449.4877, 449.4899,  ..., 449.4757, 449.4991, 447.4199],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.4800, 449.4877, 449.4899,  ..., 449.4757, 449.4991, 447.4199],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3852],
             [112.3719],
             [112.3768],
             [112.3768]],

            [[112.3750],
             [112.3750],
             [112.3653],
             [112.3653]],

            [[112.4259],
             [112.3765],
             [111.9210],
             [112.3779]],

            ...,

            [[112.3785],
             [112.3660],
             [112.3782],
             [112.3668]],

            [[111.8576],
             [111.8576],
             [111.8583],
             [111.8583]],

            [[112.3761],
             [112.3790],
             [112.3676],
             [112.3671]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.5107, 449.4807, 449.1014,  ..., 449.4895, 447.4319, 449.4897],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.5107, 449.4807, 449.1014,  ..., 449.4895, 447.4319, 449.4897],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3624],
             [112.3624],
             [112.3602],
             [112.3602]],

            [[111.9467],
             [111.9467],
             [111.9697],
             [111.9697]],

            [[112.3638],
             [112.3527],
             [112.3623],
             [112.3531]],

            ...,

            [[112.3617],
             [112.3599],
             [112.3532],
             [112.3555]],

            [[112.0554],
             [112.3644],
             [112.3729],
             [112.3729]],

            [[112.3954],
             [112.3954],
             [112.3872],
             [112.3872]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.4451, 447.8328, 449.4318,  ..., 449.4303, 449.1655, 449.5652],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.4451, 447.8328, 449.4318,  ..., 449.4303, 449.1655, 449.5652],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3424],
             [112.3334],
             [112.3368],
             [112.3346]],

            [[112.3430],
             [112.3323],
             [112.3399],
             [112.3399]],

            [[112.3412],
             [112.3412],
             [112.3381],
             [112.3381]],

            ...,

            [[111.8875],
             [111.8864],
             [111.8862],
             [111.8889]],

            [[112.3488],
             [112.3438],
             [112.3414],
             [112.3364]],

            [[111.8856],
             [111.8856],
             [111.8857],
             [111.8857]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.3473, 449.3552, 449.3588,  ..., 447.5490, 449.3705, 447.5425],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.3473, 449.3552, 449.3588,  ..., 447.5490, 449.3705, 447.5425],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3271],
             [112.3179],
             [112.3199],
             [112.3199]],

            [[111.9006],
             [111.9006],
             [111.9009],
             [111.9009]],

            [[111.8982],
             [111.9020],
             [111.8990],
             [111.8990]],

            ...,

            [[112.3360],
             [112.3348],
             [112.3268],
             [112.3243]],

            [[112.3188],
             [112.3187],
             [112.3186],
             [112.3191]],

            [[112.3181],
             [112.3181],
             [112.3178],
             [112.3178]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2848, 447.6031, 447.5983,  ..., 449.3220, 449.2752, 449.2718],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2848, 447.6031, 447.5983,  ..., 449.3220, 449.2752, 449.2718],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3151],
             [112.3116],
             [112.3231],
             [112.3231]],

            [[112.3053],
             [112.3124],
             [112.3042],
             [112.3057]],

            [[112.3169],
             [112.3169],
             [112.3125],
             [112.3125]],

            ...,

            [[112.3058],
             [112.3113],
             [112.3047],
             [112.3047]],

            [[112.3043],
             [112.3141],
             [112.3046],
             [112.3142]],

            [[112.3673],
             [112.3673],
             [112.3149],
             [112.3149]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2730, 449.2277, 449.2589,  ..., 449.2265, 449.2371, 449.3644],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2730, 449.2277, 449.2589,  ..., 449.2265, 449.2371, 449.3644],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3003],
             [112.2998],
             [112.3004],
             [112.3013]],

            [[112.3058],
             [112.3005],
             [112.3112],
             [112.3029]],

            [[111.9153],
             [112.0239],
             [111.9156],
             [112.0544]],

            ...,

            [[111.7579],
             [111.7621],
             [111.7630],
             [111.7608]],

            [[111.9147],
             [111.9147],
             [111.9146],
             [111.9146]],

            [[112.2998],
             [112.2998],
             [112.3003],
             [112.3003]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2018, 449.2204, 447.9092,  ..., 447.0438, 447.6585, 449.2001],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2018, 449.2204, 447.9092,  ..., 447.0438, 447.6585, 449.2001],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2996],
             [112.2915],
             [112.2927],
             [112.2927]],

            [[112.2973],
             [112.2924],
             [112.2919],
             [112.2919]],

            [[111.9235],
             [112.3209],
             [111.9240],
             [112.3463]],

            ...,

            [[112.3073],
             [112.2961],
             [112.3025],
             [112.3020]],

            [[112.2907],
             [112.2907],
             [112.2904],
             [112.2904]],

            [[111.9229],
             [111.9816],
             [111.9816],
             [111.9217]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1765, 449.1735, 448.5146,  ..., 449.2080, 449.1621, 447.8077],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1765, 449.1735, 448.5146,  ..., 449.2080, 449.1621, 447.8077],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3339],
             [112.3257],
             [111.9522],
             [112.2968]],

            [[112.2820],
             [112.2825],
             [112.2812],
             [112.2812]],

            [[112.2844],
             [112.2837],
             [112.2828],
             [112.2915]],

            ...,

            [[112.2814],
             [112.2892],
             [112.2827],
             [112.2827]],

            [[111.9301],
             [111.9300],
             [112.0252],
             [112.0252]],

            [[111.9318],
             [112.3306],
             [111.9702],
             [111.9702]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9085, 449.1270, 449.1424,  ..., 449.1359, 447.9106, 448.2028],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9085, 449.1270, 449.1424,  ..., 449.1359, 447.9106, 448.2028],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2747],
             [112.2747],
             [112.2738],
             [112.2738]],

            [[111.9550],
             [112.2894],
             [111.9575],
             [112.2892]],

            [[112.2845],
             [112.2780],
             [112.2830],
             [112.2798]],

            ...,

            [[112.2728],
             [112.2728],
             [112.2741],
             [112.2741]],

            [[112.2750],
             [112.2784],
             [112.2849],
             [112.2732]],

            [[112.2736],
             [112.2733],
             [112.2727],
             [112.2734]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0970, 448.4911, 449.1252,  ..., 449.0939, 449.1115, 449.0931],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0970, 448.4911, 449.1252,  ..., 449.0939, 449.1115, 449.0931],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9377],
             [111.9428],
             [111.9391],
             [111.9391]],

            [[112.2839],
             [112.2847],
             [112.2852],
             [112.2854]],

            [[112.2852],
             [112.2836],
             [112.2727],
             [112.2714]],

            ...,

            [[112.2766],
             [112.2760],
             [112.2739],
             [112.2720]],

            [[112.2710],
             [112.2719],
             [112.2714],
             [112.2712]],

            [[112.2722],
             [112.2827],
             [112.2832],
             [112.2712]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7588, 449.1391, 449.1129,  ..., 449.0985, 449.0854, 449.1093],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7588, 449.1391, 449.1129,  ..., 449.0985, 449.0854, 449.1093],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.7518],
             [111.7529],
             [111.7514],
             [111.7529]],

            [[111.7653],
             [111.7393],
             [111.9671],
             [111.7319]],

            [[112.2731],
             [112.2680],
             [112.2697],
             [112.2697]],

            ...,

            [[112.2691],
             [112.2688],
             [112.2682],
             [112.2681]],

            [[112.2758],
             [112.2866],
             [112.2765],
             [112.2927]],

            [[112.0161],
             [112.2822],
             [112.2920],
             [112.2920]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.0090, 447.2036, 449.0806,  ..., 449.0742, 449.1317, 448.8823],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.0090, 447.2036, 449.0806,  ..., 449.0742, 449.1317, 448.8823],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0111e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2833],
             [112.2811],
             [112.2721],
             [112.2721]],

            [[112.2800],
             [112.2669],
             [112.2658],
             [112.2664]],

            [[112.2737],
             [112.3049],
             [112.2732],
             [112.2732]],

            ...,

            [[112.2773],
             [112.2678],
             [112.2788],
             [112.2662]],

            [[111.9566],
             [111.9566],
             [111.9651],
             [111.9651]],

            [[112.2753],
             [112.2754],
             [112.2771],
             [112.2734]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1085, 449.0790, 449.1249,  ..., 449.0902, 447.8433, 449.1012],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1085, 449.0790, 449.1249,  ..., 449.0902, 447.8433, 449.1012],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2868],
             [112.2752],
             [112.2663],
             [112.2806]],

            [[112.2670],
             [112.2811],
             [112.2663],
             [112.2804]],

            [[112.2948],
             [111.9476],
             [111.9499],
             [112.2920]],

            ...,

            [[112.2679],
             [112.2803],
             [112.2770],
             [112.2660]],

            [[112.2746],
             [112.2667],
             [112.2801],
             [112.2686]],

            [[112.3059],
             [112.3059],
             [112.2834],
             [112.2834]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1089, 449.0949, 448.4843,  ..., 449.0912, 449.0899, 449.1787],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1089, 449.0949, 448.4843,  ..., 449.0912, 449.0899, 449.1787],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2728],
             [112.2677],
             [112.2765],
             [112.2665]],

            [[112.2789],
             [112.2660],
             [112.2754],
             [112.2673]],

            [[112.3092],
             [112.3092],
             [112.2898],
             [112.2898]],

            ...,

            [[111.9669],
             [111.9669],
             [111.9690],
             [111.9690]],

            [[112.2762],
             [112.2762],
             [112.2758],
             [112.2758]],

            [[111.9454],
             [112.3178],
             [111.9446],
             [112.3267]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0835, 449.0876, 449.1981, 449.1306, 449.0778, 449.0874, 449.0795,
            447.7705, 449.0779, 447.7740, 448.8568, 449.0856, 449.0659, 447.8439,
            449.2158, 447.7780, 449.0666, 448.0897, 449.0983, 449.0844, 449.0817,
            449.0775, 449.1494, 449.1652, 449.0701, 447.7730, 448.5163, 449.1388,
            449.0919, 449.1234, 449.0939, 449.0881, 448.5092, 448.5245, 448.1855,
            449.0845, 449.1086, 449.0845, 448.5008, 449.0640, 449.0727, 449.0894,
            449.1160, 449.0865, 449.0688, 449.0970, 448.8783, 447.7701, 448.5488,
            447.7712, 447.8828, 448.4948, 448.0946, 449.0929, 449.0667, 448.5106,
            449.1608, 449.0964, 449.1124, 448.5159, 449.0812, 449.1303, 449.0887,
            449.0636, 448.6449, 449.0844, 449.1288, 449.0788, 449.0912, 449.0893,
            449.0991, 449.0961, 449.1151, 449.0789, 447.7728, 449.0800, 447.7831,
            449.0860, 449.0687, 449.1393, 449.0949, 447.7715, 449.0916, 449.0808,
            448.6230, 449.1192, 448.3881, 449.0693, 447.7700, 447.7721, 447.7947,
            449.0687, 449.0734, 449.0646, 447.8051, 449.0640, 449.0952, 449.0995,
            449.0682, 449.0647, 449.0912, 447.7698, 448.3963, 449.1302, 449.0837,
            447.7817, 448.8485, 449.1183, 447.8358, 449.0990, 449.0843, 449.0897,
            448.8769, 449.0753, 449.1120, 449.1167, 449.0628, 447.7703, 449.0814,
            449.1093, 449.0786, 447.7698, 447.7697, 447.7710, 449.0632, 449.1264,
            449.1224, 449.0926, 448.8254, 447.7700, 449.0914, 447.8279, 449.0774,
            449.1266, 449.0864, 449.1269, 448.0901, 448.1131, 449.1966, 449.0876,
            449.2362, 448.6370, 449.0847, 449.0660, 449.1379, 449.2877, 449.0844,
            449.0906, 447.7765, 449.0765, 449.2024, 449.0846, 448.5188, 448.5355,
            447.7908, 448.8436, 448.5128, 449.0966, 449.0964, 449.0708, 449.1469,
            447.8431, 448.1644, 449.0858, 447.7844, 449.0780, 449.1482, 448.2437,
            448.9020, 449.1133, 448.7415, 449.0689, 449.0951, 447.7794, 449.0646,
            449.0791, 449.0951, 449.1069, 449.0768, 447.7701, 449.0739, 449.0970,
            449.0850, 449.1061, 449.2241, 449.1231, 449.0958, 449.0972, 449.1871,
            449.0956, 449.0880, 449.0865, 448.4855, 447.7734, 449.1044, 448.2053,
            449.0927, 447.7949, 449.0928, 447.7700, 449.0695, 448.2305, 447.7980,
            448.4876, 449.1481, 449.0998, 447.7698, 449.0714, 449.0920, 447.8453,
            449.1146, 448.4809, 449.1357, 449.0959, 448.8708, 449.1497, 449.1445,
            447.7700, 449.1152, 449.0804, 449.0886, 449.1013, 447.7844, 447.8525,
            449.1168, 449.1525, 449.0677, 449.0930, 447.7712, 449.0998, 449.0787,
            449.1338, 449.0775, 449.0809, 449.1628, 449.0688, 449.0850, 448.8981,
            449.0645, 449.0933, 449.1332, 447.7886, 448.4829, 449.0874, 449.0941,
            449.0822, 447.7743, 449.0922, 449.0953, 448.1737, 449.0695, 449.0626,
            449.2986, 449.1242, 449.2619, 449.0661, 449.0831, 449.0677, 449.1332,
            449.0717, 449.0915, 449.0920, 449.0692, 449.1253, 447.7734, 449.0641,
            449.0781, 448.2135, 449.0761, 448.8765, 449.0654, 448.6544, 449.1597,
            448.5198, 448.5940, 449.1207, 449.0623, 449.0922, 449.1125, 449.0930,
            448.8172, 449.0919, 449.0640, 449.2287, 447.7844, 447.7849, 447.7723,
            449.0903, 449.0768, 449.0884, 448.8539, 447.7764, 449.0673, 447.7697,
            449.0925, 448.4808, 449.1014, 449.0650, 449.0916, 449.0929, 449.0649,
            449.0706, 447.7698, 449.0659, 447.8212, 449.0770, 449.0922, 449.0742,
            449.0817, 447.7701, 449.0901, 447.8977, 449.0766, 449.0648, 449.0726,
            449.1475, 447.7865, 447.7701, 447.7702, 449.1409, 449.0788, 449.0796,
            449.0698, 447.8081, 449.0659, 449.0696, 449.1119, 447.7723, 448.1653,
            449.0712, 449.0662, 449.0705, 449.0639, 449.0727, 449.0903, 447.9106,
            449.0779, 449.0643, 447.7713, 449.1232, 449.1001, 449.0651, 449.0875,
            449.0976, 447.7769, 447.8317, 449.0675, 447.7745, 449.0651, 447.7751,
            449.0929, 449.0713, 448.3375, 449.0647, 449.0974, 449.0890, 449.0817,
            449.0694, 449.0845, 448.5604, 449.0633, 447.7947, 449.0664, 447.7699,
            447.7698, 448.2354, 449.0874, 449.1260, 449.1081, 448.1586, 449.1003,
            449.0845, 449.1046, 449.0682, 449.0876, 449.0887, 449.0660, 449.0926,
            449.0655, 449.1115, 449.1057, 449.0660, 449.0706, 449.0989, 449.1449,
            447.7699, 447.7712, 449.0650, 449.0769, 449.1186, 448.8766, 447.7694,
            449.0777, 449.0859, 447.7698, 449.0780, 449.1321, 449.0959, 447.7697,
            447.7697, 449.0706, 449.0840, 449.0794, 447.8243, 449.0934, 449.0742,
            449.0758, 447.6220, 447.9510, 449.1066, 447.7697, 449.0920, 448.5312,
            449.0807, 449.1608, 449.0823, 449.1461, 449.1312, 449.1555, 449.0638,
            447.8339, 449.1736, 449.0618, 449.2137, 449.1105, 449.0852, 449.0933,
            449.0658, 449.0648, 449.0826, 449.0923, 449.0828, 449.0781, 449.0881,
            449.0666, 449.1199, 447.7698, 449.0729, 448.8048, 447.8813, 449.0694,
            449.1145, 449.0958, 448.4482, 449.0853, 449.0911, 447.7697, 449.0966,
            449.0804, 449.0834, 449.0654, 449.0715, 448.8646, 447.8319, 449.0787,
            449.0988, 448.9091, 449.0854, 449.1861, 449.0771, 449.0941, 449.0639,
            449.0996, 449.0634, 447.8351, 447.7697, 449.0945, 449.0659, 448.4979,
            449.0661, 449.0785, 449.0917, 447.7698, 449.0760, 449.0367, 449.0768,
            447.7699, 447.7874, 449.1592, 449.0903, 449.1404, 447.7701, 449.1055,
            448.5150, 449.0646, 449.0942, 449.1191, 448.5521, 449.1025, 447.9639,
            448.8905, 449.0819, 448.5265, 447.7805, 449.0855, 449.0914, 449.0851,
            449.0967, 448.8840, 449.0787, 449.1261, 449.0913, 447.7691, 449.0842,
            449.0957, 449.0663, 448.2299, 449.0664, 449.1203, 449.0886, 449.0870,
            447.7690, 447.7636, 449.1017, 449.1248, 449.0960, 449.0706, 448.8718,
            449.0765, 449.0733, 449.0718, 449.1493, 449.0864, 449.0999, 449.0759,
            447.7738, 449.0646, 449.0897, 449.0902, 449.0656, 448.0410, 449.1014,
            448.6089, 449.0834, 449.0817, 449.0916, 449.0740, 449.0651, 448.5115,
            448.5244, 449.0679, 447.8430, 449.0903, 449.0783, 448.8133, 447.7853,
            448.5521, 448.8636, 449.0648, 449.0641, 449.0830, 449.0784, 449.2156,
            447.8197, 447.7725, 449.1021, 447.7721, 447.7699, 449.0844, 449.0874,
            449.2277, 449.0644, 449.0673, 447.7699, 449.1096, 447.7706, 448.4820,
            449.0889, 449.0767, 449.0641, 449.0736, 448.2148, 449.0807, 449.0864,
            448.3085, 447.7870, 449.0938, 448.4986, 447.7701, 449.0905, 449.0804,
            447.7988, 447.7699, 449.0787, 449.0686, 448.9936, 449.0811, 447.7885,
            449.0881, 449.0992, 449.0798, 449.0768, 447.7847, 449.0860, 449.1272,
            448.9855, 449.0923, 448.8683, 448.4886, 447.7852, 449.1061, 449.0847,
            449.0747, 449.0999, 448.0293, 448.9819, 449.0786, 449.2210, 449.0658,
            449.0645, 449.0816, 448.8242, 449.1144, 449.1415, 449.0898, 449.0814,
            447.7699, 449.0737, 449.0861, 448.5855, 449.0963, 448.6707, 449.1013,
            449.0921, 449.0807, 449.0933, 449.0893, 449.0656, 448.9032, 449.1177,
            449.0906, 449.0792, 449.0853, 448.6062, 449.1119, 449.0810, 448.6555,
            447.7706, 449.0656, 449.0856, 447.7697, 449.0634, 448.1732, 447.7875,
            449.1099, 449.0758, 449.1006, 449.0781, 449.1165, 449.1201, 449.0848,
            449.0957, 449.1342, 449.0663, 449.1098, 449.0886, 449.1242, 447.7697,
            449.1533, 448.5609, 449.0681, 449.2194, 448.5240, 448.4941, 449.1299,
            447.9407, 447.7841, 449.0640, 447.7891, 449.0789, 449.0798, 449.1476,
            449.0887, 449.0721, 448.8585, 449.0908, 449.0898, 449.0736, 447.7701,
            449.0708, 449.1251, 448.0260, 449.0927, 449.0806, 449.0898, 449.0756,
            449.0727, 448.2505, 449.0906, 447.7763, 449.0793, 449.1512, 449.0677,
            448.7673, 449.1937, 447.8074, 449.0937, 449.1591, 449.1636, 449.1613,
            447.7957, 447.7934, 447.7841, 449.0645, 447.7911, 447.7676, 448.5135,
            447.7698, 448.9219, 448.5135, 447.7697, 449.0790, 449.0930, 448.4884,
            449.1130, 449.0700, 447.7700, 449.0979, 447.8196, 449.0918, 449.0950,
            449.0753, 449.1124, 448.5991, 449.0786, 447.7948, 449.0637, 448.4857,
            447.6412, 449.0766, 449.0736, 447.7697, 449.1091, 449.0895, 449.0636,
            447.7699, 449.0874, 449.1017, 448.8688, 449.0789, 448.4867, 449.0833,
            449.1066, 447.7693, 449.0677, 449.0912, 448.4879, 449.0629, 449.0699,
            448.1770, 448.4821, 449.0717, 449.0978, 449.0975, 447.7699, 447.8734,
            449.0999, 449.0914, 449.0802, 449.1597, 448.4852, 449.0759, 448.4896,
            449.0804, 449.0977, 449.0752, 447.8126, 449.0916, 447.7697, 449.0906,
            447.7700, 449.0648, 449.0656, 448.2442, 449.0848, 447.7744, 449.0826,
            449.0907, 447.9757, 449.0897, 449.0801, 449.1299, 449.1084, 448.5107,
            447.7925, 449.0788, 449.1073, 449.0931, 449.0918, 449.0676, 447.7723,
            449.0975, 448.4825, 449.0990, 449.0154, 449.0998, 447.7922, 449.0722,
            449.0850, 449.1547, 449.1166, 449.0849, 449.1176, 449.1107, 449.0779,
            449.0837, 449.0786, 449.0904, 449.1078, 449.0646, 449.0969, 449.0919,
            448.5237, 449.1398, 449.0898, 449.0901, 449.0666, 449.1069, 449.0917,
            449.0857, 448.1680, 449.0782, 449.0850, 449.1152, 449.0648, 449.1066,
            448.2951, 449.0964, 449.0881, 448.4799, 449.1265, 449.0633, 448.1715,
            448.7985, 449.1637, 449.0811, 449.0689, 449.0947, 449.0664, 449.0814,
            449.0991, 449.1135, 449.1348, 449.0842, 449.0632, 449.1228, 449.0712,
            449.0676, 449.0657, 449.0855, 448.6921, 449.0806, 449.0890, 449.0681,
            449.0962, 449.1324, 448.4590, 449.0859, 447.7772, 449.0865, 447.7783,
            449.0794, 447.7707, 449.0687, 449.0878, 449.0716, 449.1051, 449.0880,
            447.7899, 449.1238, 449.0995, 448.2340, 447.7698, 449.0763, 449.1230,
            449.0697, 449.0869, 449.1827, 449.0727, 448.8383, 448.5135, 449.0803,
            449.0654, 449.0641, 449.0948, 448.6016, 449.0781, 447.8218, 449.0785,
            449.0829, 449.0770, 449.0644, 449.0659, 449.0764, 447.7720, 448.4813,
            449.0776, 449.0810, 448.8784, 447.7691, 449.1151, 449.0964, 449.0925,
            449.1231, 449.0673, 448.5422, 449.0815, 449.0643, 449.2119, 447.7723,
            448.5163, 447.7821, 449.1288, 448.4906, 449.0913, 449.0971, 449.2515,
            449.0963, 449.0872, 449.1215, 449.0980, 449.1607, 448.8640, 447.8719,
            449.1040, 448.5346], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0835, 449.0876, 449.1981, 449.1306, 449.0778, 449.0874, 449.0795,
        447.7705, 449.0779, 447.7740, 448.8568, 449.0856, 449.0659, 447.8439,
        449.2158, 447.7780, 449.0666, 448.0897, 449.0983, 449.0844, 449.0817,
        449.0775, 449.1494, 449.1652, 449.0701, 447.7730, 448.5163, 449.1388,
        449.0919, 449.1234, 449.0939, 449.0881, 448.5092, 448.5245, 448.1855,
        449.0845, 449.1086, 449.0845, 448.5008, 449.0640, 449.0727, 449.0894,
        449.1160, 449.0865, 449.0688, 449.0970, 448.8783, 447.7701, 448.5488,
        447.7712, 447.8828, 448.4948, 448.0946, 449.0929, 449.0667, 448.5106,
        449.1608, 449.0964, 449.1124, 448.5159, 449.0812, 449.1303, 449.0887,
        449.0636, 448.6449, 449.0844, 449.1288, 449.0788, 449.0912, 449.0893,
        449.0991, 449.0961, 449.1151, 449.0789, 447.7728, 449.0800, 447.7831,
        449.0860, 449.0687, 449.1393, 449.0949, 447.7715, 449.0916, 449.0808,
        448.6230, 449.1192, 448.3881, 449.0693, 447.7700, 447.7721, 447.7947,
        449.0687, 449.0734, 449.0646, 447.8051, 449.0640, 449.0952, 449.0995,
        449.0682, 449.0647, 449.0912, 447.7698, 448.3963, 449.1302, 449.0837,
        447.7817, 448.8485, 449.1183, 447.8358, 449.0990, 449.0843, 449.0897,
        448.8769, 449.0753, 449.1120, 449.1167, 449.0628, 447.7703, 449.0814,
        449.1093, 449.0786, 447.7698, 447.7697, 447.7710, 449.0632, 449.1264,
        449.1224, 449.0926, 448.8254, 447.7700, 449.0914, 447.8279, 449.0774,
        449.1266, 449.0864, 449.1269, 448.0901, 448.1131, 449.1966, 449.0876,
        449.2362, 448.6370, 449.0847, 449.0660, 449.1379, 449.2877, 449.0844,
        449.0906, 447.7765, 449.0765, 449.2024, 449.0846, 448.5188, 448.5355,
        447.7908, 448.8436, 448.5128, 449.0966, 449.0964, 449.0708, 449.1469,
        447.8431, 448.1644, 449.0858, 447.7844, 449.0780, 449.1482, 448.2437,
        448.9020, 449.1133, 448.7415, 449.0689, 449.0951, 447.7794, 449.0646,
        449.0791, 449.0951, 449.1069, 449.0768, 447.7701, 449.0739, 449.0970,
        449.0850, 449.1061, 449.2241, 449.1231, 449.0958, 449.0972, 449.1871,
        449.0956, 449.0880, 449.0865, 448.4855, 447.7734, 449.1044, 448.2053,
        449.0927, 447.7949, 449.0928, 447.7700, 449.0695, 448.2305, 447.7980,
        448.4876, 449.1481, 449.0998, 447.7698, 449.0714, 449.0920, 447.8453,
        449.1146, 448.4809, 449.1357, 449.0959, 448.8708, 449.1497, 449.1445,
        447.7700, 449.1152, 449.0804, 449.0886, 449.1013, 447.7844, 447.8525,
        449.1168, 449.1525, 449.0677, 449.0930, 447.7712, 449.0998, 449.0787,
        449.1338, 449.0775, 449.0809, 449.1628, 449.0688, 449.0850, 448.8981,
        449.0645, 449.0933, 449.1332, 447.7886, 448.4829, 449.0874, 449.0941,
        449.0822, 447.7743, 449.0922, 449.0953, 448.1737, 449.0695, 449.0626,
        449.2986, 449.1242, 449.2619, 449.0661, 449.0831, 449.0677, 449.1332,
        449.0717, 449.0915, 449.0920, 449.0692, 449.1253, 447.7734, 449.0641,
        449.0781, 448.2135, 449.0761, 448.8765, 449.0654, 448.6544, 449.1597,
        448.5198, 448.5940, 449.1207, 449.0623, 449.0922, 449.1125, 449.0930,
        448.8172, 449.0919, 449.0640, 449.2287, 447.7844, 447.7849, 447.7723,
        449.0903, 449.0768, 449.0884, 448.8539, 447.7764, 449.0673, 447.7697,
        449.0925, 448.4808, 449.1014, 449.0650, 449.0916, 449.0929, 449.0649,
        449.0706, 447.7698, 449.0659, 447.8212, 449.0770, 449.0922, 449.0742,
        449.0817, 447.7701, 449.0901, 447.8977, 449.0766, 449.0648, 449.0726,
        449.1475, 447.7865, 447.7701, 447.7702, 449.1409, 449.0788, 449.0796,
        449.0698, 447.8081, 449.0659, 449.0696, 449.1119, 447.7723, 448.1653,
        449.0712, 449.0662, 449.0705, 449.0639, 449.0727, 449.0903, 447.9106,
        449.0779, 449.0643, 447.7713, 449.1232, 449.1001, 449.0651, 449.0875,
        449.0976, 447.7769, 447.8317, 449.0675, 447.7745, 449.0651, 447.7751,
        449.0929, 449.0713, 448.3375, 449.0647, 449.0974, 449.0890, 449.0817,
        449.0694, 449.0845, 448.5604, 449.0633, 447.7947, 449.0664, 447.7699,
        447.7698, 448.2354, 449.0874, 449.1260, 449.1081, 448.1586, 449.1003,
        449.0845, 449.1046, 449.0682, 449.0876, 449.0887, 449.0660, 449.0926,
        449.0655, 449.1115, 449.1057, 449.0660, 449.0706, 449.0989, 449.1449,
        447.7699, 447.7712, 449.0650, 449.0769, 449.1186, 448.8766, 447.7694,
        449.0777, 449.0859, 447.7698, 449.0780, 449.1321, 449.0959, 447.7697,
        447.7697, 449.0706, 449.0840, 449.0794, 447.8243, 449.0934, 449.0742,
        449.0758, 447.6220, 447.9510, 449.1066, 447.7697, 449.0920, 448.5312,
        449.0807, 449.1608, 449.0823, 449.1461, 449.1312, 449.1555, 449.0638,
        447.8339, 449.1736, 449.0618, 449.2137, 449.1105, 449.0852, 449.0933,
        449.0658, 449.0648, 449.0826, 449.0923, 449.0828, 449.0781, 449.0881,
        449.0666, 449.1199, 447.7698, 449.0729, 448.8048, 447.8813, 449.0694,
        449.1145, 449.0958, 448.4482, 449.0853, 449.0911, 447.7697, 449.0966,
        449.0804, 449.0834, 449.0654, 449.0715, 448.8646, 447.8319, 449.0787,
        449.0988, 448.9091, 449.0854, 449.1861, 449.0771, 449.0941, 449.0639,
        449.0996, 449.0634, 447.8351, 447.7697, 449.0945, 449.0659, 448.4979,
        449.0661, 449.0785, 449.0917, 447.7698, 449.0760, 449.0367, 449.0768,
        447.7699, 447.7874, 449.1592, 449.0903, 449.1404, 447.7701, 449.1055,
        448.5150, 449.0646, 449.0942, 449.1191, 448.5521, 449.1025, 447.9639,
        448.8905, 449.0819, 448.5265, 447.7805, 449.0855, 449.0914, 449.0851,
        449.0967, 448.8840, 449.0787, 449.1261, 449.0913, 447.7691, 449.0842,
        449.0957, 449.0663, 448.2299, 449.0664, 449.1203, 449.0886, 449.0870,
        447.7690, 447.7636, 449.1017, 449.1248, 449.0960, 449.0706, 448.8718,
        449.0765, 449.0733, 449.0718, 449.1493, 449.0864, 449.0999, 449.0759,
        447.7738, 449.0646, 449.0897, 449.0902, 449.0656, 448.0410, 449.1014,
        448.6089, 449.0834, 449.0817, 449.0916, 449.0740, 449.0651, 448.5115,
        448.5244, 449.0679, 447.8430, 449.0903, 449.0783, 448.8133, 447.7853,
        448.5521, 448.8636, 449.0648, 449.0641, 449.0830, 449.0784, 449.2156,
        447.8197, 447.7725, 449.1021, 447.7721, 447.7699, 449.0844, 449.0874,
        449.2277, 449.0644, 449.0673, 447.7699, 449.1096, 447.7706, 448.4820,
        449.0889, 449.0767, 449.0641, 449.0736, 448.2148, 449.0807, 449.0864,
        448.3085, 447.7870, 449.0938, 448.4986, 447.7701, 449.0905, 449.0804,
        447.7988, 447.7699, 449.0787, 449.0686, 448.9936, 449.0811, 447.7885,
        449.0881, 449.0992, 449.0798, 449.0768, 447.7847, 449.0860, 449.1272,
        448.9855, 449.0923, 448.8683, 448.4886, 447.7852, 449.1061, 449.0847,
        449.0747, 449.0999, 448.0293, 448.9819, 449.0786, 449.2210, 449.0658,
        449.0645, 449.0816, 448.8242, 449.1144, 449.1415, 449.0898, 449.0814,
        447.7699, 449.0737, 449.0861, 448.5855, 449.0963, 448.6707, 449.1013,
        449.0921, 449.0807, 449.0933, 449.0893, 449.0656, 448.9032, 449.1177,
        449.0906, 449.0792, 449.0853, 448.6062, 449.1119, 449.0810, 448.6555,
        447.7706, 449.0656, 449.0856, 447.7697, 449.0634, 448.1732, 447.7875,
        449.1099, 449.0758, 449.1006, 449.0781, 449.1165, 449.1201, 449.0848,
        449.0957, 449.1342, 449.0663, 449.1098, 449.0886, 449.1242, 447.7697,
        449.1533, 448.5609, 449.0681, 449.2194, 448.5240, 448.4941, 449.1299,
        447.9407, 447.7841, 449.0640, 447.7891, 449.0789, 449.0798, 449.1476,
        449.0887, 449.0721, 448.8585, 449.0908, 449.0898, 449.0736, 447.7701,
        449.0708, 449.1251, 448.0260, 449.0927, 449.0806, 449.0898, 449.0756,
        449.0727, 448.2505, 449.0906, 447.7763, 449.0793, 449.1512, 449.0677,
        448.7673, 449.1937, 447.8074, 449.0937, 449.1591, 449.1636, 449.1613,
        447.7957, 447.7934, 447.7841, 449.0645, 447.7911, 447.7676, 448.5135,
        447.7698, 448.9219, 448.5135, 447.7697, 449.0790, 449.0930, 448.4884,
        449.1130, 449.0700, 447.7700, 449.0979, 447.8196, 449.0918, 449.0950,
        449.0753, 449.1124, 448.5991, 449.0786, 447.7948, 449.0637, 448.4857,
        447.6412, 449.0766, 449.0736, 447.7697, 449.1091, 449.0895, 449.0636,
        447.7699, 449.0874, 449.1017, 448.8688, 449.0789, 448.4867, 449.0833,
        449.1066, 447.7693, 449.0677, 449.0912, 448.4879, 449.0629, 449.0699,
        448.1770, 448.4821, 449.0717, 449.0978, 449.0975, 447.7699, 447.8734,
        449.0999, 449.0914, 449.0802, 449.1597, 448.4852, 449.0759, 448.4896,
        449.0804, 449.0977, 449.0752, 447.8126, 449.0916, 447.7697, 449.0906,
        447.7700, 449.0648, 449.0656, 448.2442, 449.0848, 447.7744, 449.0826,
        449.0907, 447.9757, 449.0897, 449.0801, 449.1299, 449.1084, 448.5107,
        447.7925, 449.0788, 449.1073, 449.0931, 449.0918, 449.0676, 447.7723,
        449.0975, 448.4825, 449.0990, 449.0154, 449.0998, 447.7922, 449.0722,
        449.0850, 449.1547, 449.1166, 449.0849, 449.1176, 449.1107, 449.0779,
        449.0837, 449.0786, 449.0904, 449.1078, 449.0646, 449.0969, 449.0919,
        448.5237, 449.1398, 449.0898, 449.0901, 449.0666, 449.1069, 449.0917,
        449.0857, 448.1680, 449.0782, 449.0850, 449.1152, 449.0648, 449.1066,
        448.2951, 449.0964, 449.0881, 448.4799, 449.1265, 449.0633, 448.1715,
        448.7985, 449.1637, 449.0811, 449.0689, 449.0947, 449.0664, 449.0814,
        449.0991, 449.1135, 449.1348, 449.0842, 449.0632, 449.1228, 449.0712,
        449.0676, 449.0657, 449.0855, 448.6921, 449.0806, 449.0890, 449.0681,
        449.0962, 449.1324, 448.4590, 449.0859, 447.7772, 449.0865, 447.7783,
        449.0794, 447.7707, 449.0687, 449.0878, 449.0716, 449.1051, 449.0880,
        447.7899, 449.1238, 449.0995, 448.2340, 447.7698, 449.0763, 449.1230,
        449.0697, 449.0869, 449.1827, 449.0727, 448.8383, 448.5135, 449.0803,
        449.0654, 449.0641, 449.0948, 448.6016, 449.0781, 447.8218, 449.0785,
        449.0829, 449.0770, 449.0644, 449.0659, 449.0764, 447.7720, 448.4813,
        449.0776, 449.0810, 448.8784, 447.7691, 449.1151, 449.0964, 449.0925,
        449.1231, 449.0673, 448.5422, 449.0815, 449.0643, 449.2119, 447.7723,
        448.5163, 447.7821, 449.1288, 448.4906, 449.0913, 449.0971, 449.2515,
        449.0963, 449.0872, 449.1215, 449.0980, 449.1607, 448.8640, 447.8719,
        449.1040, 448.5346], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([403.6857], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9425],
             [111.9425],
             [111.9425],
             [111.9425]],

            [[112.2677],
             [112.2677],
             [112.2673],
             [112.2673]],

            [[112.2805],
             [112.2670],
             [112.2658],
             [112.2662]],

            ...,

            [[111.9425],
             [111.9425],
             [111.9425],
             [111.9424]],

            [[112.2808],
             [112.2662],
             [112.2750],
             [112.2750]],

            [[112.2721],
             [112.2694],
             [112.2664],
             [112.2795]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7699, 449.0700, 449.0795,  ..., 447.7698, 449.0971, 449.0874],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7699, 449.0700, 449.0795,  ..., 447.7698, 449.0971, 449.0874],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2774],
             [112.2785],
             [112.2657],
             [112.2617]],

            [[112.2614],
             [112.2738],
             [112.2746],
             [112.2613]],

            [[112.2675],
             [112.2640],
             [112.2611],
             [112.2611]],

            ...,

            [[112.2742],
             [112.2608],
             [112.2621],
             [112.2621]],

            [[112.2783],
             [112.2783],
             [112.2646],
             [112.2646]],

            [[111.9481],
             [111.9480],
             [111.9480],
             [111.9480]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0833, 449.0710, 449.0537,  ..., 449.0591, 449.0858, 447.7921],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0833, 449.0710, 449.0537,  ..., 449.0591, 449.0858, 447.7921],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2516],
             [112.2516],
             [112.2470],
             [112.2470]],

            [[111.9784],
             [111.9613],
             [111.9612],
             [111.9762]],

            [[112.2635],
             [112.2594],
             [112.2472],
             [112.2472]],

            ...,

            [[112.2480],
             [112.2568],
             [112.2477],
             [112.2477]],

            [[112.2486],
             [112.2570],
             [112.2482],
             [112.2482]],

            [[112.2484],
             [112.2602],
             [112.2480],
             [112.2480]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9972, 447.8771, 449.0174,  ..., 449.0002, 449.0020, 449.0047],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9972, 447.8771, 449.0174,  ..., 449.0002, 449.0020, 449.0047],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2357],
             [112.2357],
             [112.2318],
             [112.2318]],

            [[112.0505],
             [112.0505],
             [112.0314],
             [112.0314]],

            [[112.2504],
             [112.2504],
             [112.2343],
             [112.2343]],

            ...,

            [[112.2375],
             [112.2327],
             [112.2332],
             [112.2332]],

            [[112.2342],
             [112.2409],
             [112.2327],
             [112.2455]],

            [[112.2409],
             [112.2409],
             [112.2398],
             [112.2398]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9351, 448.1639, 448.9694,  ..., 448.9367, 448.9533, 448.9613],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9351, 448.1639, 448.9694,  ..., 448.9367, 448.9533, 448.9613],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2196],
             [112.2200],
             [112.2198],
             [112.2198]],

            [[111.9852],
             [111.9852],
             [111.9852],
             [111.9851]],

            [[112.2383],
             [112.2242],
             [112.2205],
             [112.2384]],

            ...,

            [[112.2198],
             [112.2198],
             [112.2206],
             [112.2206]],

            [[111.9865],
             [111.9865],
             [111.9862],
             [111.9862]],

            [[112.2196],
             [112.2196],
             [112.2205],
             [112.2205]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8793, 447.9407, 448.9214,  ..., 448.8807, 447.9455, 448.8802],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8793, 447.9407, 448.9214,  ..., 448.8807, 447.9455, 448.8802],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2066],
             [112.2066],
             [112.2071],
             [112.2071]],

            [[112.2239],
             [112.2485],
             [112.2206],
             [112.2206]],

            [[112.0212],
             [112.0189],
             [112.2272],
             [112.2272]],

            ...,

            [[112.2268],
             [112.2202],
             [112.2098],
             [112.2098]],

            [[111.9994],
             [112.2638],
             [112.2580],
             [112.2580]],

            [[112.2110],
             [112.2071],
             [112.2106],
             [112.2075]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8274, 448.9136, 448.4946,  ..., 448.8666, 448.7792, 448.8362],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8274, 448.9136, 448.4946,  ..., 448.8666, 448.7792, 448.8362],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2204],
             [112.2195],
             [112.2032],
             [112.2032]],

            [[112.2154],
             [112.2154],
             [112.2264],
             [112.2264]],

            [[112.0034],
             [112.0034],
             [112.0034],
             [112.0034]],

            ...,

            [[112.2153],
             [112.2184],
             [112.2008],
             [112.2046]],

            [[112.0100],
             [112.0100],
             [112.0150],
             [112.0150]],

            [[112.0133],
             [112.2323],
             [112.0593],
             [112.2231]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8463, 448.8838, 448.0137,  ..., 448.8391, 448.0501, 448.5280],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8463, 448.8838, 448.0137,  ..., 448.8391, 448.0501, 448.5280],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0063],
             [112.0119],
             [112.0080],
             [112.0080]],

            [[112.2124],
             [112.2012],
             [112.1986],
             [112.2135]],

            [[112.0131],
             [112.2425],
             [112.0098],
             [112.2274]],

            ...,

            [[112.2178],
             [112.1986],
             [112.2169],
             [112.1992]],

            [[112.2097],
             [112.1985],
             [112.2178],
             [112.2078]],

            [[112.0367],
             [112.2187],
             [112.0353],
             [112.2187]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0342, 448.8258, 448.4928,  ..., 448.8325, 448.8338, 448.5094],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0342, 448.8258, 448.4928,  ..., 448.8325, 448.8338, 448.5094],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1991],
             [112.1991],
             [112.1992],
             [112.1992]],

            [[112.2149],
             [112.2364],
             [112.2251],
             [112.2127]],

            [[112.2168],
             [112.2388],
             [112.2170],
             [112.2385]],

            ...,

            [[112.2177],
             [112.2177],
             [112.2148],
             [112.2148]],

            [[112.2058],
             [112.2040],
             [112.2034],
             [112.2000]],

            [[112.2169],
             [112.2292],
             [112.2211],
             [112.2125]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7966, 448.8892, 448.9111,  ..., 448.8650, 448.8131, 448.8798],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7966, 448.8892, 448.9111,  ..., 448.8650, 448.8131, 448.8798],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2166],
             [112.2313],
             [112.2305],
             [112.2130]],

            [[112.2317],
             [112.2316],
             [112.2161],
             [112.2111]],

            [[112.2252],
             [112.2271],
             [112.0277],
             [112.2130]],

            ...,

            [[112.2108],
             [112.2262],
             [112.2212],
             [112.2212]],

            [[112.2108],
             [112.2158],
             [112.2153],
             [112.2153]],

            [[112.2144],
             [112.2268],
             [112.2166],
             [112.2115]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8914, 448.8905, 448.6929,  ..., 448.8793, 448.8572, 448.8693],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8914, 448.8905, 448.6929,  ..., 448.8793, 448.8572, 448.8693],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9945],
             [112.2492],
             [112.2662],
             [112.2662]],

            [[112.2453],
             [112.2453],
             [112.2409],
             [112.2409]],

            [[112.2377],
             [112.2306],
             [112.2284],
             [112.2356]],

            ...,

            [[112.2442],
             [112.2716],
             [112.2444],
             [112.2773]],

            [[112.2433],
             [112.2373],
             [112.2305],
             [112.2300]],

            [[112.3068],
             [112.2448],
             [112.0692],
             [112.2457]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7760, 448.9724, 448.9324,  ..., 449.0375, 448.9412, 448.8666],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7760, 448.9724, 448.9324,  ..., 449.0375, 448.9412, 448.8666],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2561],
             [112.2424],
             [112.2534],
             [112.2428]],

            [[112.2598],
             [112.2568],
             [112.2818],
             [112.2818]],

            [[112.3067],
             [112.2593],
             [112.2950],
             [112.2591]],

            ...,

            [[112.2451],
             [112.2432],
             [112.2422],
             [112.2422]],

            [[112.2785],
             [112.2641],
             [112.2739],
             [112.2591]],

            [[112.2578],
             [112.2451],
             [112.2587],
             [112.2439]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9948, 449.0801, 449.1201,  ..., 448.9727, 449.0756, 449.0054],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9948, 449.0801, 449.1201,  ..., 448.9727, 449.0756, 449.0054],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2594],
             [112.2592],
             [112.2749],
             [112.2592]],

            [[111.9960],
             [112.1779],
             [112.0203],
             [111.9844]],

            [[112.2742],
             [112.2742],
             [112.2699],
             [112.2699]],

            ...,

            [[112.2680],
             [112.2680],
             [112.2592],
             [112.2592]],

            [[112.2607],
             [112.2747],
             [112.2591],
             [112.2776]],

            [[112.2772],
             [112.2617],
             [112.2731],
             [112.2591]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0528, 448.1786, 449.0880,  ..., 449.0545, 449.0721, 449.0710],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0528, 448.1786, 449.0880,  ..., 449.0545, 449.0721, 449.0710],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1329],
             [112.3143],
             [112.2967],
             [112.2934]],

            [[112.2790],
             [112.2775],
             [112.2801],
             [112.2779]],

            [[112.2776],
             [112.2825],
             [112.2812],
             [112.2812]],

            ...,

            [[112.2785],
             [112.2785],
             [112.2790],
             [112.2790]],

            [[111.9469],
             [112.3109],
             [112.3591],
             [112.3591]],

            [[111.9422],
             [111.9422],
             [111.9444],
             [111.9444]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0372, 449.1145, 449.1226,  ..., 449.1149, 448.9759, 447.7731],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0372, 449.1145, 449.1226,  ..., 449.1149, 448.9759, 447.7731],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3047],
             [112.2939],
             [112.3073],
             [112.3073]],

            [[112.2928],
             [112.2928],
             [112.2922],
             [112.2922]],

            [[112.3659],
             [112.3645],
             [112.3158],
             [111.9352]],

            ...,

            [[112.2949],
             [112.2925],
             [112.3055],
             [112.2986]],

            [[112.2996],
             [112.2963],
             [112.3030],
             [112.2917]],

            [[111.9689],
             [112.3090],
             [112.3166],
             [112.3166]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2133, 449.1700, 448.9813,  ..., 449.1916, 449.1906, 448.9111],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2133, 449.1700, 448.9813,  ..., 449.1916, 449.1906, 448.9111],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3272],
             [112.3106],
             [112.3103],
             [112.3358]],

            [[112.3068],
             [112.2976],
             [112.3121],
             [112.3000]],

            [[112.2957],
             [112.2976],
             [112.3027],
             [112.2974]],

            ...,

            [[112.3173],
             [112.2986],
             [112.3019],
             [112.2971]],

            [[112.3474],
             [112.3115],
             [112.3308],
             [112.3123]],

            [[112.2976],
             [112.2995],
             [112.2981],
             [112.3088]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2840, 449.2166, 449.1934,  ..., 449.2148, 449.3021, 449.2040],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2840, 449.2166, 449.1934,  ..., 449.2148, 449.3021, 449.2040],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2991],
             [112.2991],
             [112.2956],
             [112.2956]],

            [[112.3045],
             [112.3045],
             [112.3028],
             [112.3028]],

            [[112.3077],
             [112.2974],
             [112.2966],
             [112.2974]],

            ...,

            [[112.3095],
             [112.2985],
             [112.3095],
             [112.2985]],

            [[112.3006],
             [112.3006],
             [112.2958],
             [112.3083]],

            [[111.9275],
             [112.0089],
             [111.9426],
             [111.9426]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1895, 449.2146, 449.1991,  ..., 449.2160, 449.2053, 447.8215],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1895, 449.2146, 449.1991,  ..., 449.2160, 449.2053, 447.8215],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3004],
             [112.3022],
             [112.3053],
             [112.2987]],

            [[112.2980],
             [112.3135],
             [112.2980],
             [112.3144]],

            [[112.3118],
             [112.3140],
             [112.3032],
             [112.2984]],

            ...,

            [[112.2988],
             [112.3129],
             [112.2987],
             [112.3132]],

            [[111.9675],
             [111.9255],
             [111.9255],
             [111.9905]],

            [[111.9253],
             [111.9596],
             [111.9576],
             [111.9241]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2066, 449.2238, 449.2274,  ..., 449.2236, 447.8090, 447.7665],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2066, 449.2238, 449.2274,  ..., 449.2236, 447.8090, 447.7665],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9936e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2881],
             [112.2909],
             [112.2884],
             [112.2884]],

            [[112.3219],
             [112.2993],
             [112.3028],
             [112.3028]],

            [[112.3088],
             [112.2999],
             [112.2964],
             [112.2964]],

            ...,

            [[112.2978],
             [112.2979],
             [112.2992],
             [112.2962]],

            [[111.9320],
             [111.9320],
             [111.9320],
             [111.9320]],

            [[112.2957],
             [112.2957],
             [112.2961],
             [112.2961]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1558, 449.2268, 449.2016,  ..., 449.1912, 447.7281, 449.1837],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1558, 449.2268, 449.2016,  ..., 449.1912, 447.7281, 449.1837],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2873],
             [112.2874],
             [112.2895],
             [112.2881]],

            [[111.9320],
             [111.9320],
             [111.9320],
             [111.9320]],

            [[112.3009],
             [112.3009],
             [112.2976],
             [112.2976]],

            ...,

            [[112.3012],
             [112.2876],
             [112.3001],
             [112.2993]],

            [[112.2877],
             [112.2877],
             [112.2882],
             [112.2882]],

            [[112.3019],
             [112.2934],
             [112.2877],
             [112.2877]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1523, 447.7281, 449.1970,  ..., 449.1881, 449.1519, 449.1708],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1523, 447.7281, 449.1970,  ..., 449.1881, 449.1519, 449.1708],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3026],
             [112.3026],
             [112.2898],
             [112.2898]],

            [[111.9811],
             [111.9811],
             [111.9970],
             [111.9970]],

            [[112.3013],
             [112.2910],
             [112.3018],
             [112.2876]],

            ...,

            [[111.9593],
             [112.3036],
             [111.9590],
             [112.3036]],

            [[112.3121],
             [112.2986],
             [112.3387],
             [112.3001]],

            [[112.3059],
             [112.3059],
             [112.2979],
             [112.2979]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1848, 447.9562, 449.1817, 449.2232, 449.1655, 449.1678, 449.1695,
            449.1754, 449.1699, 447.7281, 447.7422, 449.1535, 449.1603, 448.9057,
            449.1761, 447.7427, 449.1629, 449.1732, 449.1555, 449.2166, 449.1765,
            449.1855, 447.7561, 449.1826, 449.1651, 449.1655, 449.1507, 448.9592,
            449.1485, 449.1795, 449.1643, 449.2661, 447.7289, 449.1606, 449.1579,
            449.1497, 448.1186, 447.7465, 449.1748, 448.5172, 449.1628, 447.7281,
            447.7475, 449.1582, 448.5090, 449.1569, 448.5092, 449.1508, 448.5553,
            449.1602, 449.1034, 449.1701, 449.1629, 449.2071, 448.9216, 448.5302,
            449.0702, 449.1715, 449.1782, 449.1723, 448.5237, 449.1786, 449.1035,
            449.2320, 447.7335, 449.1652, 449.4091, 447.8216, 449.1599, 449.1832,
            447.7368, 447.7317, 448.2039, 447.7304, 448.5507, 447.7281, 449.1764,
            447.7965, 447.7655, 449.1794, 449.1788, 447.7416, 447.7596, 449.1635,
            449.1916, 449.1774, 449.1720, 447.7287, 449.1769, 449.1719, 449.2090,
            449.1685, 449.1955, 449.1544, 449.2064, 449.1791, 449.1485, 448.5160,
            449.1781, 449.1714, 449.1925, 447.7338, 449.1561, 449.1707, 449.1527,
            449.2022, 449.1583, 449.1644, 449.1777, 449.1719, 449.1529, 449.1622,
            449.1945, 447.7281, 448.5364, 449.1644, 449.1827, 449.2055, 449.2639,
            448.5137, 447.7493, 449.1593, 449.1734, 449.1570, 449.1663, 449.0106,
            449.1432, 447.8301, 449.2554, 449.1898, 448.9148, 449.1736, 449.1686,
            449.1751, 447.7513, 449.1860, 449.1764, 449.1526, 447.7283, 449.1759,
            449.2764, 448.9423, 447.7411, 449.1988, 449.1550, 449.1546, 447.7286,
            449.1882, 447.7284, 449.1773, 449.1651, 449.1547, 449.1886, 449.1796,
            449.1517, 449.1985, 448.5104, 449.1656, 449.2079, 449.1567, 449.1784,
            449.1628, 449.1720, 447.7319, 449.1693, 449.1666, 447.7910, 449.1516,
            449.1544, 448.5646, 449.1553, 449.1650, 447.7606, 449.1695, 448.7994,
            449.1025, 449.1785, 449.1696, 449.1584, 449.1798, 449.1663, 449.1758,
            449.1500, 447.7862, 447.7299, 449.1740, 449.2053, 449.1495, 449.1776,
            447.7308, 449.1538, 449.1807, 449.1880, 447.8080, 449.2098, 449.1587,
            447.7281, 449.1757, 449.2068, 449.1738, 449.1630, 448.9232, 449.1548,
            449.1492, 449.2307, 449.1995, 449.1485, 449.2231, 447.7473, 449.1601,
            449.1666, 449.1649, 447.7281, 449.2050, 449.1704, 449.1986, 449.1798,
            448.5912, 449.2206, 447.8889, 449.1799, 447.7284, 449.1557, 449.1631,
            447.7297, 449.1595, 449.1855, 447.7325, 449.1555, 448.5217, 449.1505,
            449.1620, 447.7368, 449.1611, 449.2314, 449.2014, 448.5245, 447.7578,
            449.2078, 449.1527, 449.2563, 449.1524, 449.1995, 447.8802, 449.1655,
            449.1798, 449.1765, 449.2637, 449.1921, 449.1566, 449.1989, 449.1866,
            447.7289, 449.1559, 448.5966, 449.1784, 447.7281, 448.1949, 449.1519,
            447.7286, 449.1779, 449.1514, 447.7281, 449.1580, 449.2192, 449.1822,
            449.1620, 449.1513, 449.1507, 449.1777, 449.2097, 449.1559, 448.9108,
            448.5341, 449.1847, 449.1649, 449.1555, 449.1544, 447.7594, 449.1772,
            448.2766, 449.1544, 449.2168, 449.1935, 448.6304, 449.2448, 449.2047,
            449.1485, 449.2210, 447.7307, 447.7281, 449.2138, 449.1583, 449.1835,
            449.1565, 449.1586, 449.1775, 449.1828, 449.1643, 449.1547, 448.5586,
            449.1837, 449.1957, 449.1981, 449.1819, 449.1521, 449.1717, 448.6239,
            449.1750, 447.7283, 448.4735, 447.7296, 449.1771, 449.1703, 447.7307,
            448.5189, 447.7291, 448.5405, 447.7281, 449.1891, 447.7281, 449.0068,
            449.1573, 449.1977, 449.1551, 449.1567, 449.1751, 447.7734, 447.7862,
            449.1797, 448.5112, 449.2700, 448.5305, 449.1702, 449.1866, 449.1963,
            449.1723, 449.1671, 449.1869, 449.1572, 449.1737, 447.7296, 449.1541,
            449.1838, 449.1854, 447.7441, 448.6181, 447.7373, 447.9624, 447.8487,
            449.1649, 449.1966, 449.1707, 449.1783, 449.1804, 448.1402, 449.1703,
            449.1785, 449.1570, 448.9915, 447.7767, 447.7296, 449.2035, 449.2133,
            449.1857, 448.5286, 449.3264, 449.1599, 449.1198, 449.3157, 449.1141,
            449.1792, 449.1845, 449.1731, 449.1827, 449.1835, 449.1597, 449.1744,
            449.2006, 449.1807, 449.2054, 449.1807, 447.7297, 449.1571, 447.7292,
            448.5282, 449.1597, 449.1884, 447.9068, 449.1500, 449.1592, 449.2256,
            449.1794, 449.1624, 447.7325, 449.1796, 449.1801, 447.8105, 449.2221,
            449.1772, 448.9010, 449.1700, 449.1489, 449.0996, 449.1747, 449.1783,
            447.7466, 449.2224, 449.1540, 447.7645, 449.2101, 449.1701, 448.5873,
            449.1743, 448.5134, 449.3109, 449.2167, 449.1942, 449.1621, 447.7311,
            448.9049, 449.2172, 449.2278, 449.1777, 449.2424, 449.2809, 447.8007,
            447.7281, 449.1508, 449.1512, 449.1975, 449.0544, 448.8625, 449.1672,
            449.2420, 449.1911, 449.2247, 449.1677, 447.7950, 447.7288, 449.0828,
            449.2456, 447.7281, 447.7314, 449.1656, 449.1493, 449.1752, 449.2659,
            449.1571, 449.1730, 449.1833, 449.1512, 449.1490, 449.1697, 449.1726,
            449.1643, 447.7281, 449.1689, 449.1573, 449.1522, 447.7285, 448.5115,
            449.1880, 449.2557, 449.2549, 449.1788, 449.1500, 449.1728, 449.1848,
            448.8703, 449.1519, 449.1814, 449.2635, 449.1008, 449.1606, 449.2037,
            449.1503, 449.1566, 449.1998, 449.1743, 449.2310, 447.7393, 449.1654,
            449.1716, 449.1818, 449.1905, 449.1859, 449.1689, 449.2057, 448.5495,
            447.7288, 448.9479, 449.1768, 449.2268, 449.1870, 447.7371, 449.2016,
            449.2760, 449.1652, 448.6014, 449.2115, 449.1646, 449.1926, 448.6580,
            449.2004, 449.1764, 449.2047, 447.7352, 449.1812, 449.1718, 449.1703,
            449.1752, 449.1588, 447.7281, 449.1540, 449.1699, 447.7362, 449.1666,
            449.1738, 449.1764, 449.1540, 449.1678, 449.1613, 449.1630, 447.7321,
            449.2715, 447.7627, 449.1599, 449.1912, 449.1686, 449.1957, 449.1946,
            449.1790, 449.1754, 449.1749, 449.1850, 447.7283, 448.5752, 449.1687,
            448.7173, 448.4447, 448.1886, 449.1664, 449.2350, 447.7563, 448.5193,
            449.1514, 449.1783, 449.1786, 447.7281, 449.1682, 449.1501, 449.1532,
            449.1673, 449.1649, 449.1616, 449.1523, 449.1687, 447.7299, 447.7850,
            448.5438, 449.2131, 447.7290, 449.1550, 449.1522, 449.1737, 449.1516,
            449.1954, 449.1970, 447.7282, 448.2400, 449.2014, 449.1628, 449.1682,
            449.1685, 447.7308, 449.1786, 448.7020, 447.7281, 449.1775, 449.0711,
            447.7300, 449.1850, 449.1758, 449.1606, 449.2500, 447.7298, 449.1522,
            449.1761, 449.1770, 449.2221, 449.1026, 449.2623, 448.2269, 449.2377,
            449.1986, 449.1508, 449.1759, 447.7281, 449.1972, 449.1701, 448.9456,
            449.2029, 449.1691, 449.1783, 449.1784, 448.1782, 447.7397, 449.1771,
            449.1667, 449.1959, 449.2064, 449.1499, 448.6443, 449.1545, 448.5104,
            447.7586, 449.1553, 449.2057, 449.1672, 449.1542, 447.7970, 447.8431,
            447.7421, 448.5338, 449.1966, 447.7773, 449.1585, 449.1533, 448.6934,
            449.1652, 449.1612, 449.3274, 449.1767, 449.2003, 447.7281, 448.5247,
            449.1931, 449.1727, 449.2240, 449.1740, 448.5255, 447.7294, 449.2159,
            448.6136, 447.8489, 449.1674, 449.1537, 449.1593, 447.7993, 449.1675,
            449.1594, 449.1575, 449.1646, 449.1549, 449.2425, 448.9687, 449.1938,
            449.2658, 447.7291, 449.2142, 449.1690, 449.1544, 449.1729, 448.5450,
            449.2484, 449.1895, 449.1507, 449.1624, 449.2337, 449.1633, 449.1504,
            448.9081, 447.7293, 449.4089, 449.1535, 449.1576, 449.1728, 449.1761,
            449.1731, 449.1986, 449.1651, 449.1746, 447.7559, 447.7541, 449.1534,
            449.2521, 448.5570, 449.1580, 447.7845, 449.2661, 449.1666, 448.1894,
            449.1778, 449.1931, 449.2097, 447.7299, 449.1585, 449.1540, 449.1695,
            449.1652, 449.1622, 449.1851, 448.8820, 449.1578, 448.5143, 448.9777,
            448.7799, 449.1791, 447.7352, 449.1787, 449.2392, 449.1536, 448.2217,
            449.1750, 448.5284, 449.1758, 448.5245, 447.7510, 449.1808, 449.1771,
            449.1929, 449.1638, 449.2510, 449.1513, 449.1763, 449.1681, 448.5389,
            449.1613, 449.2073, 447.7423, 449.1689, 449.1739, 448.5715, 447.7288,
            449.2555, 449.2096, 449.3000, 447.7300, 449.1937, 449.1540, 449.1575,
            449.1923, 449.1755, 449.1603, 449.1633, 449.1651, 447.7706, 449.1786,
            449.1529, 449.1750, 448.4406, 448.5255, 449.1979, 449.2562, 449.2037,
            449.1800, 447.7285, 449.1514, 449.1750, 448.9534, 449.1772, 449.1838,
            449.1827, 449.1778, 449.1887, 449.1492, 449.1665, 449.1777, 449.1745,
            449.1580, 449.1749, 449.1590, 448.5159, 449.2623, 449.1871, 449.1566,
            449.1696, 449.1495, 449.1770, 449.2248, 449.1803, 447.9679, 448.5127,
            449.1942, 449.2214, 449.2123, 449.1656, 448.6484, 449.1732, 449.1892,
            447.7431, 449.1737, 448.5250, 449.2448, 449.1535, 447.7446, 449.1689,
            449.1939, 449.1523, 449.1510, 449.1605, 449.1491, 449.1757, 448.9453,
            449.1863, 449.1797, 448.8991, 449.1849, 447.8120, 447.7795, 449.1970,
            447.7284, 449.2024, 449.2081, 449.2435, 447.7883, 449.2236, 449.1569,
            449.1582, 447.7522, 448.6470, 449.1869, 449.1719, 449.2230, 449.1495,
            449.1605, 449.1530, 449.1954, 449.1576, 449.2621, 447.8131, 449.1512,
            449.1917, 449.1701, 449.2303, 447.7281, 449.1843, 449.1658, 449.1738,
            449.1506, 449.1791, 447.7709, 447.7684, 449.1691, 449.1505, 449.1616,
            449.2216, 449.1776, 449.2047, 449.1685, 449.1646, 449.1924, 449.1776,
            449.1655, 449.1578, 447.7300, 448.5237, 449.1768, 449.1945, 449.1799,
            449.1771, 447.7465, 447.8070, 447.9221, 449.1658, 449.1508, 449.1537,
            449.1571, 449.1501, 449.1767, 449.1577, 449.1699, 449.1530, 447.7281,
            449.1485, 449.2383, 447.7292, 448.1940, 447.7281, 449.1045, 449.1716,
            447.7519, 448.1475, 447.7681, 449.2286, 449.1544, 449.1768, 449.1835,
            449.1869, 447.7349, 449.1884, 449.1677, 447.7283, 449.1852, 449.1492,
            449.1520, 449.1525, 449.1807, 449.1866, 449.2283, 449.2330, 447.7538,
            449.1860, 447.7281, 449.1751, 449.1718, 448.5349, 449.1737, 447.7288,
            449.1749, 449.1568, 448.5238, 449.1753, 449.1824, 449.1023, 449.1890,
            447.7284, 449.1611, 449.1514, 447.8081, 448.5156, 447.8200, 448.5255,
            449.2496, 449.2077], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1848, 447.9562, 449.1817, 449.2232, 449.1655, 449.1678, 449.1695,
        449.1754, 449.1699, 447.7281, 447.7422, 449.1535, 449.1603, 448.9057,
        449.1761, 447.7427, 449.1629, 449.1732, 449.1555, 449.2166, 449.1765,
        449.1855, 447.7561, 449.1826, 449.1651, 449.1655, 449.1507, 448.9592,
        449.1485, 449.1795, 449.1643, 449.2661, 447.7289, 449.1606, 449.1579,
        449.1497, 448.1186, 447.7465, 449.1748, 448.5172, 449.1628, 447.7281,
        447.7475, 449.1582, 448.5090, 449.1569, 448.5092, 449.1508, 448.5553,
        449.1602, 449.1034, 449.1701, 449.1629, 449.2071, 448.9216, 448.5302,
        449.0702, 449.1715, 449.1782, 449.1723, 448.5237, 449.1786, 449.1035,
        449.2320, 447.7335, 449.1652, 449.4091, 447.8216, 449.1599, 449.1832,
        447.7368, 447.7317, 448.2039, 447.7304, 448.5507, 447.7281, 449.1764,
        447.7965, 447.7655, 449.1794, 449.1788, 447.7416, 447.7596, 449.1635,
        449.1916, 449.1774, 449.1720, 447.7287, 449.1769, 449.1719, 449.2090,
        449.1685, 449.1955, 449.1544, 449.2064, 449.1791, 449.1485, 448.5160,
        449.1781, 449.1714, 449.1925, 447.7338, 449.1561, 449.1707, 449.1527,
        449.2022, 449.1583, 449.1644, 449.1777, 449.1719, 449.1529, 449.1622,
        449.1945, 447.7281, 448.5364, 449.1644, 449.1827, 449.2055, 449.2639,
        448.5137, 447.7493, 449.1593, 449.1734, 449.1570, 449.1663, 449.0106,
        449.1432, 447.8301, 449.2554, 449.1898, 448.9148, 449.1736, 449.1686,
        449.1751, 447.7513, 449.1860, 449.1764, 449.1526, 447.7283, 449.1759,
        449.2764, 448.9423, 447.7411, 449.1988, 449.1550, 449.1546, 447.7286,
        449.1882, 447.7284, 449.1773, 449.1651, 449.1547, 449.1886, 449.1796,
        449.1517, 449.1985, 448.5104, 449.1656, 449.2079, 449.1567, 449.1784,
        449.1628, 449.1720, 447.7319, 449.1693, 449.1666, 447.7910, 449.1516,
        449.1544, 448.5646, 449.1553, 449.1650, 447.7606, 449.1695, 448.7994,
        449.1025, 449.1785, 449.1696, 449.1584, 449.1798, 449.1663, 449.1758,
        449.1500, 447.7862, 447.7299, 449.1740, 449.2053, 449.1495, 449.1776,
        447.7308, 449.1538, 449.1807, 449.1880, 447.8080, 449.2098, 449.1587,
        447.7281, 449.1757, 449.2068, 449.1738, 449.1630, 448.9232, 449.1548,
        449.1492, 449.2307, 449.1995, 449.1485, 449.2231, 447.7473, 449.1601,
        449.1666, 449.1649, 447.7281, 449.2050, 449.1704, 449.1986, 449.1798,
        448.5912, 449.2206, 447.8889, 449.1799, 447.7284, 449.1557, 449.1631,
        447.7297, 449.1595, 449.1855, 447.7325, 449.1555, 448.5217, 449.1505,
        449.1620, 447.7368, 449.1611, 449.2314, 449.2014, 448.5245, 447.7578,
        449.2078, 449.1527, 449.2563, 449.1524, 449.1995, 447.8802, 449.1655,
        449.1798, 449.1765, 449.2637, 449.1921, 449.1566, 449.1989, 449.1866,
        447.7289, 449.1559, 448.5966, 449.1784, 447.7281, 448.1949, 449.1519,
        447.7286, 449.1779, 449.1514, 447.7281, 449.1580, 449.2192, 449.1822,
        449.1620, 449.1513, 449.1507, 449.1777, 449.2097, 449.1559, 448.9108,
        448.5341, 449.1847, 449.1649, 449.1555, 449.1544, 447.7594, 449.1772,
        448.2766, 449.1544, 449.2168, 449.1935, 448.6304, 449.2448, 449.2047,
        449.1485, 449.2210, 447.7307, 447.7281, 449.2138, 449.1583, 449.1835,
        449.1565, 449.1586, 449.1775, 449.1828, 449.1643, 449.1547, 448.5586,
        449.1837, 449.1957, 449.1981, 449.1819, 449.1521, 449.1717, 448.6239,
        449.1750, 447.7283, 448.4735, 447.7296, 449.1771, 449.1703, 447.7307,
        448.5189, 447.7291, 448.5405, 447.7281, 449.1891, 447.7281, 449.0068,
        449.1573, 449.1977, 449.1551, 449.1567, 449.1751, 447.7734, 447.7862,
        449.1797, 448.5112, 449.2700, 448.5305, 449.1702, 449.1866, 449.1963,
        449.1723, 449.1671, 449.1869, 449.1572, 449.1737, 447.7296, 449.1541,
        449.1838, 449.1854, 447.7441, 448.6181, 447.7373, 447.9624, 447.8487,
        449.1649, 449.1966, 449.1707, 449.1783, 449.1804, 448.1402, 449.1703,
        449.1785, 449.1570, 448.9915, 447.7767, 447.7296, 449.2035, 449.2133,
        449.1857, 448.5286, 449.3264, 449.1599, 449.1198, 449.3157, 449.1141,
        449.1792, 449.1845, 449.1731, 449.1827, 449.1835, 449.1597, 449.1744,
        449.2006, 449.1807, 449.2054, 449.1807, 447.7297, 449.1571, 447.7292,
        448.5282, 449.1597, 449.1884, 447.9068, 449.1500, 449.1592, 449.2256,
        449.1794, 449.1624, 447.7325, 449.1796, 449.1801, 447.8105, 449.2221,
        449.1772, 448.9010, 449.1700, 449.1489, 449.0996, 449.1747, 449.1783,
        447.7466, 449.2224, 449.1540, 447.7645, 449.2101, 449.1701, 448.5873,
        449.1743, 448.5134, 449.3109, 449.2167, 449.1942, 449.1621, 447.7311,
        448.9049, 449.2172, 449.2278, 449.1777, 449.2424, 449.2809, 447.8007,
        447.7281, 449.1508, 449.1512, 449.1975, 449.0544, 448.8625, 449.1672,
        449.2420, 449.1911, 449.2247, 449.1677, 447.7950, 447.7288, 449.0828,
        449.2456, 447.7281, 447.7314, 449.1656, 449.1493, 449.1752, 449.2659,
        449.1571, 449.1730, 449.1833, 449.1512, 449.1490, 449.1697, 449.1726,
        449.1643, 447.7281, 449.1689, 449.1573, 449.1522, 447.7285, 448.5115,
        449.1880, 449.2557, 449.2549, 449.1788, 449.1500, 449.1728, 449.1848,
        448.8703, 449.1519, 449.1814, 449.2635, 449.1008, 449.1606, 449.2037,
        449.1503, 449.1566, 449.1998, 449.1743, 449.2310, 447.7393, 449.1654,
        449.1716, 449.1818, 449.1905, 449.1859, 449.1689, 449.2057, 448.5495,
        447.7288, 448.9479, 449.1768, 449.2268, 449.1870, 447.7371, 449.2016,
        449.2760, 449.1652, 448.6014, 449.2115, 449.1646, 449.1926, 448.6580,
        449.2004, 449.1764, 449.2047, 447.7352, 449.1812, 449.1718, 449.1703,
        449.1752, 449.1588, 447.7281, 449.1540, 449.1699, 447.7362, 449.1666,
        449.1738, 449.1764, 449.1540, 449.1678, 449.1613, 449.1630, 447.7321,
        449.2715, 447.7627, 449.1599, 449.1912, 449.1686, 449.1957, 449.1946,
        449.1790, 449.1754, 449.1749, 449.1850, 447.7283, 448.5752, 449.1687,
        448.7173, 448.4447, 448.1886, 449.1664, 449.2350, 447.7563, 448.5193,
        449.1514, 449.1783, 449.1786, 447.7281, 449.1682, 449.1501, 449.1532,
        449.1673, 449.1649, 449.1616, 449.1523, 449.1687, 447.7299, 447.7850,
        448.5438, 449.2131, 447.7290, 449.1550, 449.1522, 449.1737, 449.1516,
        449.1954, 449.1970, 447.7282, 448.2400, 449.2014, 449.1628, 449.1682,
        449.1685, 447.7308, 449.1786, 448.7020, 447.7281, 449.1775, 449.0711,
        447.7300, 449.1850, 449.1758, 449.1606, 449.2500, 447.7298, 449.1522,
        449.1761, 449.1770, 449.2221, 449.1026, 449.2623, 448.2269, 449.2377,
        449.1986, 449.1508, 449.1759, 447.7281, 449.1972, 449.1701, 448.9456,
        449.2029, 449.1691, 449.1783, 449.1784, 448.1782, 447.7397, 449.1771,
        449.1667, 449.1959, 449.2064, 449.1499, 448.6443, 449.1545, 448.5104,
        447.7586, 449.1553, 449.2057, 449.1672, 449.1542, 447.7970, 447.8431,
        447.7421, 448.5338, 449.1966, 447.7773, 449.1585, 449.1533, 448.6934,
        449.1652, 449.1612, 449.3274, 449.1767, 449.2003, 447.7281, 448.5247,
        449.1931, 449.1727, 449.2240, 449.1740, 448.5255, 447.7294, 449.2159,
        448.6136, 447.8489, 449.1674, 449.1537, 449.1593, 447.7993, 449.1675,
        449.1594, 449.1575, 449.1646, 449.1549, 449.2425, 448.9687, 449.1938,
        449.2658, 447.7291, 449.2142, 449.1690, 449.1544, 449.1729, 448.5450,
        449.2484, 449.1895, 449.1507, 449.1624, 449.2337, 449.1633, 449.1504,
        448.9081, 447.7293, 449.4089, 449.1535, 449.1576, 449.1728, 449.1761,
        449.1731, 449.1986, 449.1651, 449.1746, 447.7559, 447.7541, 449.1534,
        449.2521, 448.5570, 449.1580, 447.7845, 449.2661, 449.1666, 448.1894,
        449.1778, 449.1931, 449.2097, 447.7299, 449.1585, 449.1540, 449.1695,
        449.1652, 449.1622, 449.1851, 448.8820, 449.1578, 448.5143, 448.9777,
        448.7799, 449.1791, 447.7352, 449.1787, 449.2392, 449.1536, 448.2217,
        449.1750, 448.5284, 449.1758, 448.5245, 447.7510, 449.1808, 449.1771,
        449.1929, 449.1638, 449.2510, 449.1513, 449.1763, 449.1681, 448.5389,
        449.1613, 449.2073, 447.7423, 449.1689, 449.1739, 448.5715, 447.7288,
        449.2555, 449.2096, 449.3000, 447.7300, 449.1937, 449.1540, 449.1575,
        449.1923, 449.1755, 449.1603, 449.1633, 449.1651, 447.7706, 449.1786,
        449.1529, 449.1750, 448.4406, 448.5255, 449.1979, 449.2562, 449.2037,
        449.1800, 447.7285, 449.1514, 449.1750, 448.9534, 449.1772, 449.1838,
        449.1827, 449.1778, 449.1887, 449.1492, 449.1665, 449.1777, 449.1745,
        449.1580, 449.1749, 449.1590, 448.5159, 449.2623, 449.1871, 449.1566,
        449.1696, 449.1495, 449.1770, 449.2248, 449.1803, 447.9679, 448.5127,
        449.1942, 449.2214, 449.2123, 449.1656, 448.6484, 449.1732, 449.1892,
        447.7431, 449.1737, 448.5250, 449.2448, 449.1535, 447.7446, 449.1689,
        449.1939, 449.1523, 449.1510, 449.1605, 449.1491, 449.1757, 448.9453,
        449.1863, 449.1797, 448.8991, 449.1849, 447.8120, 447.7795, 449.1970,
        447.7284, 449.2024, 449.2081, 449.2435, 447.7883, 449.2236, 449.1569,
        449.1582, 447.7522, 448.6470, 449.1869, 449.1719, 449.2230, 449.1495,
        449.1605, 449.1530, 449.1954, 449.1576, 449.2621, 447.8131, 449.1512,
        449.1917, 449.1701, 449.2303, 447.7281, 449.1843, 449.1658, 449.1738,
        449.1506, 449.1791, 447.7709, 447.7684, 449.1691, 449.1505, 449.1616,
        449.2216, 449.1776, 449.2047, 449.1685, 449.1646, 449.1924, 449.1776,
        449.1655, 449.1578, 447.7300, 448.5237, 449.1768, 449.1945, 449.1799,
        449.1771, 447.7465, 447.8070, 447.9221, 449.1658, 449.1508, 449.1537,
        449.1571, 449.1501, 449.1767, 449.1577, 449.1699, 449.1530, 447.7281,
        449.1485, 449.2383, 447.7292, 448.1940, 447.7281, 449.1045, 449.1716,
        447.7519, 448.1475, 447.7681, 449.2286, 449.1544, 449.1768, 449.1835,
        449.1869, 447.7349, 449.1884, 449.1677, 447.7283, 449.1852, 449.1492,
        449.1520, 449.1525, 449.1807, 449.1866, 449.2283, 449.2330, 447.7538,
        449.1860, 447.7281, 449.1751, 449.1718, 448.5349, 449.1737, 447.7288,
        449.1749, 449.1568, 448.5238, 449.1753, 449.1824, 449.1023, 449.1890,
        447.7284, 449.1611, 449.1514, 447.8081, 448.5156, 447.8200, 448.5255,
        449.2496, 449.2077], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([410.9357], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2994],
             [112.2873],
             [112.2923],
             [112.2893]],

            [[112.2756],
             [112.2756],
             [112.2757],
             [112.2757]],

            [[112.3028],
             [112.3028],
             [112.3031],
             [112.3031]],

            ...,

            [[112.2896],
             [112.2896],
             [112.2883],
             [112.2883]],

            [[112.2756],
             [112.2756],
             [112.2756],
             [112.2756]],

            [[112.1168],
             [112.1168],
             [112.0490],
             [112.0490]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1684, 449.1026, 449.2119,  ..., 449.1558, 449.1025, 448.3315],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1684, 449.1026, 449.2119,  ..., 449.1558, 449.1025, 448.3315],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2803],
             [112.2803],
             [112.2792],
             [112.2792]],

            [[112.2868],
             [112.2781],
             [112.2910],
             [112.2836]],

            [[112.2780],
             [112.2780],
             [112.2781],
             [112.2781]],

            ...,

            [[112.1689],
             [111.9418],
             [111.9416],
             [112.2989]],

            [[112.2962],
             [112.2859],
             [112.2955],
             [112.2857]],

            [[112.2778],
             [112.2778],
             [112.2795],
             [112.2795]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1190, 449.1396, 449.1123,  ..., 448.3512, 449.1635, 449.1146],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1190, 449.1396, 449.1123,  ..., 448.3512, 449.1635, 449.1146],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9509],
             [112.3054],
             [111.9769],
             [111.9769]],

            [[112.2696],
             [112.2760],
             [112.2747],
             [112.2747]],

            [[111.9471],
             [111.9809],
             [111.9808],
             [111.9458]],

            ...,

            [[111.9684],
             [112.2851],
             [111.9684],
             [112.2851]],

            [[112.2720],
             [112.2701],
             [112.2729],
             [112.2802]],

            [[111.9458],
             [111.9460],
             [111.9459],
             [111.9459]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2100, 449.0949, 447.8546,  ..., 448.5071, 449.0952, 447.7836],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2100, 449.0949, 447.8546,  ..., 448.5071, 449.0952, 447.7836],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2761],
             [112.2991],
             [112.3158],
             [112.2750]],

            [[111.9483],
             [111.9484],
             [111.9484],
             [111.9484]],

            [[112.2748],
             [112.2629],
             [112.2665],
             [112.2665]],

            ...,

            [[112.2767],
             [112.2634],
             [112.2748],
             [112.2658]],

            [[112.2748],
             [112.2650],
             [112.2631],
             [112.2631]],

            [[112.2780],
             [112.2662],
             [112.2768],
             [112.2649]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1661, 447.7935, 449.0707,  ..., 449.0807, 449.0660, 449.0858],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1661, 447.7935, 449.0707,  ..., 449.0807, 449.0660, 449.0858],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2667],
             [112.2667],
             [112.2545],
             [112.2545]],

            [[112.2603],
             [112.2581],
             [112.2664],
             [112.2542]],

            [[112.2545],
             [112.2542],
             [112.2539],
             [112.2538]],

            ...,

            [[112.2542],
             [112.2542],
             [112.2545],
             [112.2545]],

            [[111.9781],
             [111.9781],
             [112.2695],
             [112.2695]],

            [[112.2615],
             [112.2538],
             [112.2539],
             [112.2539]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0424, 449.0390, 449.0165,  ..., 449.0175, 448.4953, 449.0230],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0424, 449.0390, 449.0165,  ..., 449.0175, 448.4953, 449.0230],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9576],
             [111.9936],
             [111.9936],
             [111.9563]],

            [[112.0335],
             [112.0335],
             [112.0179],
             [112.0179]],

            [[112.2714],
             [112.2596],
             [112.2747],
             [112.2584]],

            ...,

            [[112.2598],
             [112.2475],
             [112.2578],
             [112.2475]],

            [[112.2568],
             [112.2474],
             [112.2551],
             [112.2474]],

            [[112.2489],
             [112.2591],
             [112.2474],
             [112.2608]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9011, 448.1028, 449.0641,  ..., 449.0125, 449.0067, 449.0162],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9011, 448.1028, 449.0641,  ..., 449.0125, 449.0067, 449.0162],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2567],
             [112.2567],
             [112.2559],
             [112.2559]],

            [[112.2582],
             [111.9713],
             [111.9713],
             [112.2582]],

            [[111.9623],
             [111.9624],
             [111.9624],
             [111.9623]],

            ...,

            [[112.2468],
             [112.2495],
             [112.2417],
             [112.2403]],

            [[111.9633],
             [111.9933],
             [111.9636],
             [111.9992]],

            [[112.2804],
             [112.2583],
             [112.2524],
             [112.2497]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0252, 448.4589, 447.8494,  ..., 448.9783, 447.9194, 449.0408],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0252, 448.4589, 447.8494,  ..., 448.9783, 447.9194, 449.0408],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2460],
             [112.2364],
             [112.2454],
             [112.2369]],

            [[112.2421],
             [112.2468],
             [112.2467],
             [112.2380]],

            [[112.2364],
             [112.2358],
             [112.2359],
             [112.2363]],

            ...,

            [[112.2469],
             [112.2636],
             [112.2606],
             [112.2467]],

            [[111.9724],
             [111.9724],
             [111.9752],
             [111.9752]],

            [[112.2521],
             [112.2450],
             [112.2477],
             [112.2479]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9648, 448.9736, 448.9444,  ..., 449.0178, 447.8952, 448.9927],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9648, 448.9736, 448.9444,  ..., 449.0178, 447.8952, 448.9927],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2397],
             [112.2340],
             [112.2363],
             [112.2363]],

            [[111.9681],
             [111.9681],
             [111.9681],
             [111.9681]],

            [[112.2518],
             [112.2403],
             [112.2458],
             [112.2427]],

            ...,

            [[111.9681],
             [111.9686],
             [111.9682],
             [111.9682]],

            [[111.9688],
             [111.9809],
             [111.9688],
             [111.9826]],

            [[112.2322],
             [112.2322],
             [112.2322],
             [112.2322]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9463, 447.8725, 448.9806,  ..., 447.8731, 447.9011, 448.9290],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9463, 447.8725, 448.9806,  ..., 447.8731, 447.9011, 448.9290],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2766],
             [112.2616],
             [112.2400],
             [112.2400]],

            [[112.2400],
             [112.2299],
             [112.2391],
             [112.2286]],

            [[112.2338],
             [112.2299],
             [112.2366],
             [112.2398]],

            ...,

            [[111.9713],
             [111.9713],
             [111.9713],
             [111.9713]],

            [[112.2402],
             [112.2416],
             [112.2288],
             [112.2304]],

            [[111.9713],
             [111.9713],
             [111.9713],
             [111.9713]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0182, 448.9376, 448.9401,  ..., 447.8851, 448.9410, 447.8850],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0182, 448.9376, 448.9401,  ..., 447.8851, 448.9410, 447.8850],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2417],
             [112.2351],
             [112.2422],
             [112.2321]],

            [[112.2394],
             [112.2321],
             [112.2380],
             [112.2320]],

            [[111.9835],
             [112.0929],
             [112.2462],
             [112.2462]],

            ...,

            [[112.2403],
             [112.2320],
             [112.2432],
             [112.2380]],

            [[112.2438],
             [112.2439],
             [112.2331],
             [112.2331]],

            [[112.2344],
             [112.2344],
             [112.2325],
             [112.2325]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9512, 448.9415, 448.5688,  ..., 448.9536, 448.9539, 448.9339],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9512, 448.9415, 448.5688,  ..., 448.9536, 448.9539, 448.9339],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2400],
             [112.2342],
             [112.2460],
             [112.2450]],

            [[112.2423],
             [112.2424],
             [112.2446],
             [112.2388]],

            [[112.2457],
             [112.2414],
             [112.2360],
             [112.2360]],

            ...,

            [[112.2439],
             [112.2332],
             [112.2435],
             [112.2333]],

            [[112.2383],
             [112.2466],
             [112.2452],
             [112.2347]],

            [[112.2450],
             [112.0143],
             [112.2457],
             [112.2457]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9652, 448.9682, 448.9590,  ..., 448.9539, 448.9648, 448.7506],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9652, 448.9682, 448.9590,  ..., 448.9539, 448.9648, 448.7506],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9710],
             [112.1096],
             [111.9800],
             [111.9800]],

            [[112.2411],
             [112.2411],
             [112.2411],
             [112.2411]],

            [[112.2536],
             [111.9764],
             [111.9774],
             [112.2525]],

            ...,

            [[111.9731],
             [111.9731],
             [111.9731],
             [111.9731]],

            [[112.2368],
             [112.2368],
             [112.2336],
             [112.2336]],

            [[111.9693],
             [111.9693],
             [111.9693],
             [111.9693]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0406, 448.9644, 448.4599,  ..., 447.8924, 448.9408, 447.8771],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0406, 448.9644, 448.4599,  ..., 447.8924, 448.9408, 447.8771],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2340],
             [112.2381],
             [112.2357],
             [112.2340]],

            [[112.2336],
             [112.2336],
             [112.2339],
             [112.2339]],

            [[112.2337],
             [112.2337],
             [112.2340],
             [112.2340]],

            ...,

            [[111.9815],
             [111.9961],
             [111.9703],
             [112.2548]],

            [[112.2422],
             [112.2422],
             [112.2348],
             [112.2348]],

            [[112.2647],
             [112.2575],
             [112.2458],
             [112.2471]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9418, 448.9349, 448.9354,  ..., 448.2027, 448.9540, 449.0151],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9418, 448.9349, 448.9354,  ..., 448.2027, 448.9540, 449.0151],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2529],
             [112.2529],
             [112.2474],
             [112.2474]],

            [[111.9489],
             [111.9489],
             [111.9487],
             [111.9487]],

            [[112.2487],
             [112.2487],
             [112.2486],
             [112.2488]],

            ...,

            [[112.2528],
             [112.2579],
             [112.2466],
             [112.2565]],

            [[112.2498],
             [112.2595],
             [112.2475],
             [112.2475]],

            [[112.2486],
             [112.2486],
             [112.2469],
             [112.2469]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0007, 447.7952, 448.9948,  ..., 449.0137, 449.0043, 448.9909],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0007, 447.7952, 448.9948,  ..., 449.0137, 449.0043, 448.9909],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2681],
             [112.2580],
             [112.2678],
             [112.2629]],

            [[112.2698],
             [112.2623],
             [112.2570],
             [112.2686]],

            [[111.9362],
             [111.9365],
             [111.9362],
             [111.9365]],

            ...,

            [[112.2621],
             [112.2621],
             [112.2569],
             [112.2569]],

            [[112.2681],
             [112.2567],
             [112.2667],
             [112.2575]],

            [[111.9370],
             [111.9522],
             [111.9409],
             [111.9409]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0568, 449.0578, 447.7454,  ..., 449.0378, 449.0490, 447.7710],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0568, 449.0578, 447.7454,  ..., 449.0378, 449.0490, 447.7710],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2710],
             [112.2743],
             [112.2667],
             [112.2762]],

            [[112.2801],
             [112.2801],
             [112.2786],
             [112.2786]],

            [[111.9518],
             [111.9266],
             [111.9271],
             [111.9510]],

            ...,

            [[111.9302],
             [111.9302],
             [111.9310],
             [111.9310]],

            [[112.2749],
             [112.2665],
             [112.2753],
             [112.2663]],

            [[112.2772],
             [112.2773],
             [112.2860],
             [112.2703]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0882, 449.1172, 447.7565,  ..., 447.7225, 449.0831, 449.1108],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0882, 449.1172, 447.7565,  ..., 447.7225, 449.0831, 449.1108],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9226],
             [112.3032],
             [111.9465],
             [111.9465]],

            [[112.2807],
             [112.2840],
             [112.2756],
             [112.2801]],

            [[111.9213],
             [112.3110],
             [111.9236],
             [112.3019]],

            ...,

            [[112.2780],
             [112.2762],
             [112.2765],
             [112.2765]],

            [[112.2868],
             [112.2759],
             [112.2866],
             [112.2763]],

            [[112.2571],
             [112.2571],
             [111.9886],
             [111.9886]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1187, 449.1204, 448.4579,  ..., 449.1072, 449.1256, 448.4914],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1187, 449.1204, 448.4579,  ..., 449.1072, 449.1256, 448.4914],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0179e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2873],
             [112.2952],
             [112.2852],
             [112.2958]],

            [[111.9024],
             [111.9061],
             [111.9059],
             [111.9020]],

            [[112.2846],
             [112.2846],
             [112.2841],
             [112.2841]],

            ...,

            [[112.2967],
             [112.2945],
             [112.2940],
             [112.2849]],

            [[112.2935],
             [112.2888],
             [112.2928],
             [112.2841]],

            [[111.9020],
             [111.9020],
             [111.9020],
             [111.9020]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1635, 447.6163, 449.1373,  ..., 449.1700, 449.1592, 447.6079],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1635, 447.6163, 449.1373,  ..., 449.1700, 449.1592, 447.6079],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3015],
             [111.9206],
             [112.3049],
             [112.3049]],

            [[111.9020],
             [111.9025],
             [111.9021],
             [111.9021]],

            [[111.9059],
             [111.9036],
             [111.9034],
             [111.9074]],

            ...,

            [[111.9022],
             [111.9043],
             [111.9026],
             [111.9026]],

            [[111.9055],
             [112.0928],
             [111.9092],
             [111.9092]],

            [[112.2950],
             [112.3092],
             [112.2947],
             [112.2947]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8318, 447.6088, 447.6203,  ..., 447.6117, 447.8166, 449.1935],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8318, 447.6088, 447.6203,  ..., 447.6117, 447.8166, 449.1935],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9021],
             [111.9034],
             [111.9021],
             [111.9034]],

            [[112.3160],
             [112.3160],
             [112.3045],
             [112.3045]],

            [[112.2934],
             [112.2960],
             [112.2962],
             [112.2846]],

            ...,

            [[112.2892],
             [112.2944],
             [112.2843],
             [112.2932]],

            [[112.2878],
             [112.2952],
             [112.2949],
             [112.2883]],

            [[111.9021],
             [111.9027],
             [111.9021],
             [111.9030]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.6109, 449.2409, 449.1702, 449.1534, 449.1446, 447.6079, 447.6079,
            449.1454, 447.6080, 447.6080, 447.6256, 449.1443, 449.1652, 449.2606,
            448.0591, 447.6079, 449.1951, 447.6741, 449.1389, 448.9078, 448.1212,
            449.1735, 449.1435, 448.0485, 449.1599, 449.1588, 449.1581, 449.1753,
            449.1641, 449.1404, 449.1421, 448.8660, 448.1644, 449.1652, 449.1503,
            448.4432, 447.6320, 449.1472, 447.6079, 449.1434, 448.5546, 447.6080,
            449.1652, 449.1585, 449.1436, 449.1496, 449.1448, 447.6079, 449.1613,
            448.4688, 449.1564, 449.3032, 447.6079, 448.5732, 447.6079, 449.1623,
            449.1607, 447.6132, 448.8806, 449.1565, 449.1410, 447.6142, 449.1890,
            449.1905, 449.1851, 449.1924, 449.1807, 447.6089, 449.1646, 449.1569,
            449.1699, 449.1522, 449.1451, 449.1494, 449.1596, 449.1593, 449.1742,
            449.1642, 448.4473, 449.1786, 449.1719, 447.6457, 449.1813, 449.1491,
            447.6175, 449.1648, 449.1837, 449.1480, 449.1667, 449.1497, 447.6106,
            449.1614, 449.0018, 447.6092, 448.5581, 449.1781, 449.1649, 449.1592,
            449.1733, 447.6205, 449.1855, 449.1686, 448.4607, 449.1454, 449.1603,
            447.6111, 447.6102, 448.4589, 449.1457, 449.1487, 449.1632, 449.1649,
            447.6280, 449.1608, 449.1570, 449.1901, 449.1626, 449.1059, 449.1535,
            449.1530, 449.1624, 449.1612, 449.1585, 449.1805, 449.1710, 449.2067,
            447.6160, 449.1589, 449.1559, 448.8336, 449.1709, 449.1822, 447.6183,
            449.1610, 449.1609, 449.1611, 449.1630, 449.1710, 449.1625, 449.1582,
            449.1635, 449.1476, 449.1754, 447.6093, 449.1578, 449.1601, 449.1625,
            449.1600, 449.1811, 447.8759, 449.1617, 448.4517, 449.1830, 449.1581,
            449.1604, 449.1640, 449.1566, 449.1641, 448.3494, 449.1654, 447.6145,
            449.1925, 447.6385, 449.2093, 449.1523, 449.1209, 449.1706, 449.1908,
            447.6079, 447.6178, 449.1524, 449.1590, 449.1667, 449.2119, 449.1375,
            449.1588, 447.6778, 449.1643, 447.6176, 449.1689, 449.1595, 448.4559,
            448.8435, 449.1561, 449.1662, 448.4624, 449.1768, 448.4515, 449.1616,
            448.5530, 449.1455, 447.6083, 449.1731, 447.6185, 448.1429, 449.1737,
            449.1653, 448.4433, 447.6195, 449.1636, 449.1647, 449.1797, 449.1459,
            447.6400, 449.1667, 449.1608, 448.2367, 449.2413, 449.1702, 449.1450,
            449.1358, 447.6254, 449.1906, 449.1421, 447.6094, 449.1583, 449.1588,
            447.6144, 449.1434, 449.1553, 447.6082, 449.1522, 447.6079, 449.1470,
            448.4927, 449.1714, 449.1633, 447.6084, 449.1539, 449.1279, 449.1618,
            448.2698, 449.1557, 447.6109, 449.1567, 449.1630, 449.1458, 449.1580,
            449.2075, 449.1746, 449.1614, 449.1735, 447.6079, 447.6088, 449.1555,
            447.6081, 447.6079, 447.6079, 447.6094, 449.1501, 449.1582, 449.1664,
            449.1637, 447.6889, 449.1359, 448.9329, 447.6210, 449.1690, 449.1403,
            449.1622, 449.1664, 449.1848, 449.1591, 448.8301, 449.1404, 449.1600,
            449.1489, 449.1660, 449.1920, 448.8683, 447.6154, 447.6080, 447.6148,
            448.7530, 449.1614, 448.4451, 449.1608, 449.0937, 448.4472, 449.1658,
            447.6079, 447.6177, 449.2001, 449.1371, 449.1439, 449.1686, 449.1687,
            449.1552, 447.6691, 448.7546, 449.1519, 448.0701, 447.6734, 449.1627,
            447.6179, 449.1649, 449.2269, 449.1619, 447.6086, 449.1638, 449.1658,
            448.4713, 449.1631, 449.1689, 448.3480, 449.1736, 449.1658, 449.1556,
            448.8616, 449.1523, 449.1797, 447.6079, 449.1684, 449.1594, 447.6079,
            449.2101, 447.6079, 449.1724, 449.1882, 449.1492, 447.6130, 449.2317,
            448.1378, 448.4175, 449.1818, 449.1664, 449.1523, 449.1706, 447.6079,
            449.1660, 449.1670, 448.1089, 449.1866, 447.6079, 448.0528, 447.6544,
            449.1624, 449.1444, 449.1604, 449.1927, 447.6079, 449.0936, 449.1638,
            449.1478, 447.6079, 449.1497, 449.2147, 449.1529, 449.1598, 449.2145,
            447.6079, 448.0496, 449.1621, 449.1484, 449.2199, 447.6175, 449.1490,
            449.1592, 449.1521, 449.1506, 447.6079, 449.1367, 449.1453, 448.1008,
            449.1508, 449.1814, 447.6091, 447.6138, 448.4473, 449.1636, 449.1802,
            447.6312, 447.6079, 449.1569, 449.1666, 449.1632, 448.8055, 449.1588,
            448.4902, 449.1613, 449.1737, 449.1371, 449.1860, 449.1575, 449.1492,
            447.6160, 448.4538, 449.1570, 449.1824, 449.1983, 449.2067, 449.1512,
            449.2216, 449.1662, 448.4839, 449.1429, 447.6133, 449.1488, 449.1646,
            447.6190, 449.1582, 449.1695, 449.1360, 449.1690, 449.1496, 449.1666,
            449.1612, 447.6079, 449.1593, 449.1611, 448.0585, 449.1540, 447.6079,
            449.1429, 448.4926, 449.1450, 449.1526, 449.1654, 449.1591, 449.1581,
            447.6079, 449.1584, 447.6101, 447.6080, 449.1638, 449.2088, 449.1522,
            448.0676, 449.1562, 447.6079, 449.1487, 447.6152, 449.1486, 449.1651,
            449.1665, 447.6081, 447.6081, 449.1573, 449.1654, 449.1619, 449.1567,
            447.6805, 448.8300, 449.1656, 449.1713, 447.6079, 447.6079, 449.1625,
            447.6079, 449.1639, 449.1574, 449.1869, 449.1617, 449.1654, 449.1994,
            449.1558, 449.1639, 449.1638, 449.1628, 449.1658, 449.1724, 449.1456,
            449.2276, 447.6079, 449.1556, 449.1459, 449.1682, 447.6082, 449.1630,
            447.6082, 449.1642, 447.6080, 449.1452, 449.1429, 449.2307, 449.2334,
            449.1544, 449.1761, 449.2562, 449.1460, 449.2142, 447.6082, 447.6123,
            449.2097, 449.1793, 447.6106, 449.1622, 447.6079, 448.4654, 447.6117,
            447.6079, 449.1982, 449.0489, 449.1469, 447.6133, 449.1668, 449.1654,
            449.1450, 449.1693, 449.1149, 448.4499, 447.6098, 449.1454, 447.6195,
            449.1635, 449.1779, 449.1641, 448.4447, 449.1571, 449.1590, 449.1821,
            449.1381, 448.4479, 449.1469, 447.6469, 449.1635, 447.6079, 447.6608,
            449.1701, 449.1729, 449.1786, 447.6101, 447.6079, 449.1500, 447.6494,
            449.1592, 449.1855, 449.1721, 447.6647, 449.1665, 449.2285, 449.2213,
            447.6383, 449.1587, 449.1708, 449.1552, 449.1993, 449.1420, 448.8220,
            449.0943, 447.6101, 449.1503, 449.1502, 449.1665, 449.1580, 447.6157,
            447.6877, 449.2394, 449.1602, 449.1719, 449.1807, 449.1445, 449.1507,
            448.9950, 448.8010, 448.8439, 447.6082, 449.1581, 449.2009, 449.1619,
            449.1707, 449.1507, 449.1681, 448.0544, 447.8074, 447.6691, 449.1548,
            449.1642, 448.5165, 448.5338, 449.1659, 448.0200, 447.6284, 449.1620,
            449.1593, 449.1637, 447.6958, 449.1428, 449.1633, 448.6887, 447.6147,
            449.1614, 447.6349, 449.1633, 449.1584, 449.1604, 449.1429, 447.6080,
            447.6079, 449.1607, 449.1452, 449.1495, 449.1988, 449.1811, 449.1632,
            447.6206, 449.1707, 449.1710, 449.1598, 447.6085, 449.1442, 449.1424,
            449.1558, 449.1635, 449.1710, 447.6085, 449.1654, 449.1639, 449.2212,
            449.1783, 447.6082, 447.6079, 449.1455, 449.1656, 448.4872, 449.1616,
            448.4482, 449.1761, 449.2110, 449.2501, 447.6566, 449.1868, 449.1832,
            447.6079, 447.6131, 448.5367, 449.1496, 448.8404, 449.1638, 449.1596,
            449.1594, 449.1562, 449.1373, 449.1723, 449.1608, 447.6117, 448.5886,
            448.4439, 449.1476, 449.1660, 447.6289, 449.1649, 448.4806, 447.6079,
            449.1474, 447.6581, 447.6231, 449.2170, 449.1570, 449.1441, 449.1682,
            449.2029, 449.0022, 449.2258, 449.1469, 448.5399, 447.6528, 449.1553,
            447.6079, 449.1565, 449.1901, 449.2220, 447.6079, 449.1739, 449.1461,
            449.1739, 447.6085, 448.5483, 449.1578, 447.6252, 449.1631, 449.1755,
            449.1592, 449.1367, 449.1897, 449.1860, 447.6491, 449.1663, 449.2133,
            447.6353, 449.1635, 449.1974, 447.6079, 449.1605, 449.2501, 449.1412,
            447.6136, 449.1698, 449.1453, 449.1660, 447.6082, 449.1685, 449.2186,
            449.1627, 449.1861, 448.3025, 449.1661, 449.1620, 449.1608, 449.1365,
            447.6113, 447.6079, 447.6079, 448.0759, 447.6402, 447.6079, 449.1426,
            447.6246, 449.1562, 449.1776, 449.1705, 448.8646, 449.1817, 449.1641,
            449.1462, 449.1596, 449.1667, 449.1475, 449.1658, 449.1599, 447.6121,
            448.5059, 448.0638, 449.1632, 447.6113, 449.1661, 449.1638, 449.1564,
            447.6156, 447.6144, 449.1628, 449.1937, 449.1614, 449.2062, 449.1643,
            448.4517, 449.1609, 449.1592, 447.6079, 449.1361, 449.1829, 447.6118,
            449.1650, 447.6105, 449.1685, 449.1482, 449.1494, 449.1527, 447.6136,
            447.6079, 449.2208, 449.1581, 447.6570, 449.1594, 449.2200, 447.6241,
            449.1843, 449.1784, 449.1575, 449.1617, 449.2023, 448.4493, 449.1650,
            449.1810, 449.1426, 449.1849, 448.1722, 449.1607, 448.5936, 448.4417,
            447.6080, 449.1594, 449.1556, 447.6079, 447.6079, 449.1672, 449.1757,
            449.1743, 447.6083, 449.1617, 447.6085, 449.1624, 447.6251, 449.1796,
            449.1638, 449.1498, 449.1519, 449.1534, 447.6578, 449.1591, 449.1454,
            447.6126, 448.1099, 449.1964, 448.4692, 448.4473, 449.1664, 447.6307,
            449.1596, 449.1520, 447.6082, 449.1370, 449.1567, 449.1595, 449.1664,
            449.1553, 449.1669, 447.6080, 449.1739, 449.1614, 447.6079, 449.1712,
            449.1625, 449.1628, 448.1526, 449.1613, 449.2110, 449.1602, 449.1639,
            447.6130, 449.1784, 449.1493, 449.1620, 447.6168, 449.1609, 447.6079,
            449.1595, 449.1701, 447.6099, 449.1645, 447.6158, 448.4478, 449.1814,
            447.6099, 448.9796, 449.1811, 449.1617, 449.1458, 449.1404, 449.1739,
            449.1667, 449.1953, 447.6093, 449.1677, 449.2033, 447.6080, 449.1676,
            447.6646, 448.4787, 448.4545, 449.1610, 449.1473, 449.1512, 449.1604,
            449.1387, 449.1683, 449.1631, 449.1764, 449.2103, 447.6093, 449.1640,
            449.1708, 449.1789, 449.1799, 449.1639, 449.1529, 447.6096, 447.6110,
            447.6147, 447.6114, 449.1749, 449.1605, 448.8751, 449.1614, 449.1735,
            447.6228, 447.6080, 449.1992, 448.8926, 447.6080, 449.0954, 449.1620,
            449.1503, 449.1602, 449.1710, 447.9205, 447.6089, 449.2197, 449.1664,
            448.5388, 449.1439, 449.1558, 449.1560, 449.1586, 447.6079, 449.1464,
            447.6080, 449.1620, 447.6079, 449.1850, 449.1382, 447.6204, 449.1452,
            447.6084, 449.1996, 449.1825, 449.1926, 449.1592, 449.2050, 447.6081,
            449.1883, 447.6079, 448.8321, 447.8445, 447.6183, 449.1479, 449.2124,
            449.1906, 449.1565, 449.1392, 447.6476, 449.1445, 447.6079, 449.1611,
            449.1661, 447.6099], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.6109, 449.2409, 449.1702, 449.1534, 449.1446, 447.6079, 447.6079,
        449.1454, 447.6080, 447.6080, 447.6256, 449.1443, 449.1652, 449.2606,
        448.0591, 447.6079, 449.1951, 447.6741, 449.1389, 448.9078, 448.1212,
        449.1735, 449.1435, 448.0485, 449.1599, 449.1588, 449.1581, 449.1753,
        449.1641, 449.1404, 449.1421, 448.8660, 448.1644, 449.1652, 449.1503,
        448.4432, 447.6320, 449.1472, 447.6079, 449.1434, 448.5546, 447.6080,
        449.1652, 449.1585, 449.1436, 449.1496, 449.1448, 447.6079, 449.1613,
        448.4688, 449.1564, 449.3032, 447.6079, 448.5732, 447.6079, 449.1623,
        449.1607, 447.6132, 448.8806, 449.1565, 449.1410, 447.6142, 449.1890,
        449.1905, 449.1851, 449.1924, 449.1807, 447.6089, 449.1646, 449.1569,
        449.1699, 449.1522, 449.1451, 449.1494, 449.1596, 449.1593, 449.1742,
        449.1642, 448.4473, 449.1786, 449.1719, 447.6457, 449.1813, 449.1491,
        447.6175, 449.1648, 449.1837, 449.1480, 449.1667, 449.1497, 447.6106,
        449.1614, 449.0018, 447.6092, 448.5581, 449.1781, 449.1649, 449.1592,
        449.1733, 447.6205, 449.1855, 449.1686, 448.4607, 449.1454, 449.1603,
        447.6111, 447.6102, 448.4589, 449.1457, 449.1487, 449.1632, 449.1649,
        447.6280, 449.1608, 449.1570, 449.1901, 449.1626, 449.1059, 449.1535,
        449.1530, 449.1624, 449.1612, 449.1585, 449.1805, 449.1710, 449.2067,
        447.6160, 449.1589, 449.1559, 448.8336, 449.1709, 449.1822, 447.6183,
        449.1610, 449.1609, 449.1611, 449.1630, 449.1710, 449.1625, 449.1582,
        449.1635, 449.1476, 449.1754, 447.6093, 449.1578, 449.1601, 449.1625,
        449.1600, 449.1811, 447.8759, 449.1617, 448.4517, 449.1830, 449.1581,
        449.1604, 449.1640, 449.1566, 449.1641, 448.3494, 449.1654, 447.6145,
        449.1925, 447.6385, 449.2093, 449.1523, 449.1209, 449.1706, 449.1908,
        447.6079, 447.6178, 449.1524, 449.1590, 449.1667, 449.2119, 449.1375,
        449.1588, 447.6778, 449.1643, 447.6176, 449.1689, 449.1595, 448.4559,
        448.8435, 449.1561, 449.1662, 448.4624, 449.1768, 448.4515, 449.1616,
        448.5530, 449.1455, 447.6083, 449.1731, 447.6185, 448.1429, 449.1737,
        449.1653, 448.4433, 447.6195, 449.1636, 449.1647, 449.1797, 449.1459,
        447.6400, 449.1667, 449.1608, 448.2367, 449.2413, 449.1702, 449.1450,
        449.1358, 447.6254, 449.1906, 449.1421, 447.6094, 449.1583, 449.1588,
        447.6144, 449.1434, 449.1553, 447.6082, 449.1522, 447.6079, 449.1470,
        448.4927, 449.1714, 449.1633, 447.6084, 449.1539, 449.1279, 449.1618,
        448.2698, 449.1557, 447.6109, 449.1567, 449.1630, 449.1458, 449.1580,
        449.2075, 449.1746, 449.1614, 449.1735, 447.6079, 447.6088, 449.1555,
        447.6081, 447.6079, 447.6079, 447.6094, 449.1501, 449.1582, 449.1664,
        449.1637, 447.6889, 449.1359, 448.9329, 447.6210, 449.1690, 449.1403,
        449.1622, 449.1664, 449.1848, 449.1591, 448.8301, 449.1404, 449.1600,
        449.1489, 449.1660, 449.1920, 448.8683, 447.6154, 447.6080, 447.6148,
        448.7530, 449.1614, 448.4451, 449.1608, 449.0937, 448.4472, 449.1658,
        447.6079, 447.6177, 449.2001, 449.1371, 449.1439, 449.1686, 449.1687,
        449.1552, 447.6691, 448.7546, 449.1519, 448.0701, 447.6734, 449.1627,
        447.6179, 449.1649, 449.2269, 449.1619, 447.6086, 449.1638, 449.1658,
        448.4713, 449.1631, 449.1689, 448.3480, 449.1736, 449.1658, 449.1556,
        448.8616, 449.1523, 449.1797, 447.6079, 449.1684, 449.1594, 447.6079,
        449.2101, 447.6079, 449.1724, 449.1882, 449.1492, 447.6130, 449.2317,
        448.1378, 448.4175, 449.1818, 449.1664, 449.1523, 449.1706, 447.6079,
        449.1660, 449.1670, 448.1089, 449.1866, 447.6079, 448.0528, 447.6544,
        449.1624, 449.1444, 449.1604, 449.1927, 447.6079, 449.0936, 449.1638,
        449.1478, 447.6079, 449.1497, 449.2147, 449.1529, 449.1598, 449.2145,
        447.6079, 448.0496, 449.1621, 449.1484, 449.2199, 447.6175, 449.1490,
        449.1592, 449.1521, 449.1506, 447.6079, 449.1367, 449.1453, 448.1008,
        449.1508, 449.1814, 447.6091, 447.6138, 448.4473, 449.1636, 449.1802,
        447.6312, 447.6079, 449.1569, 449.1666, 449.1632, 448.8055, 449.1588,
        448.4902, 449.1613, 449.1737, 449.1371, 449.1860, 449.1575, 449.1492,
        447.6160, 448.4538, 449.1570, 449.1824, 449.1983, 449.2067, 449.1512,
        449.2216, 449.1662, 448.4839, 449.1429, 447.6133, 449.1488, 449.1646,
        447.6190, 449.1582, 449.1695, 449.1360, 449.1690, 449.1496, 449.1666,
        449.1612, 447.6079, 449.1593, 449.1611, 448.0585, 449.1540, 447.6079,
        449.1429, 448.4926, 449.1450, 449.1526, 449.1654, 449.1591, 449.1581,
        447.6079, 449.1584, 447.6101, 447.6080, 449.1638, 449.2088, 449.1522,
        448.0676, 449.1562, 447.6079, 449.1487, 447.6152, 449.1486, 449.1651,
        449.1665, 447.6081, 447.6081, 449.1573, 449.1654, 449.1619, 449.1567,
        447.6805, 448.8300, 449.1656, 449.1713, 447.6079, 447.6079, 449.1625,
        447.6079, 449.1639, 449.1574, 449.1869, 449.1617, 449.1654, 449.1994,
        449.1558, 449.1639, 449.1638, 449.1628, 449.1658, 449.1724, 449.1456,
        449.2276, 447.6079, 449.1556, 449.1459, 449.1682, 447.6082, 449.1630,
        447.6082, 449.1642, 447.6080, 449.1452, 449.1429, 449.2307, 449.2334,
        449.1544, 449.1761, 449.2562, 449.1460, 449.2142, 447.6082, 447.6123,
        449.2097, 449.1793, 447.6106, 449.1622, 447.6079, 448.4654, 447.6117,
        447.6079, 449.1982, 449.0489, 449.1469, 447.6133, 449.1668, 449.1654,
        449.1450, 449.1693, 449.1149, 448.4499, 447.6098, 449.1454, 447.6195,
        449.1635, 449.1779, 449.1641, 448.4447, 449.1571, 449.1590, 449.1821,
        449.1381, 448.4479, 449.1469, 447.6469, 449.1635, 447.6079, 447.6608,
        449.1701, 449.1729, 449.1786, 447.6101, 447.6079, 449.1500, 447.6494,
        449.1592, 449.1855, 449.1721, 447.6647, 449.1665, 449.2285, 449.2213,
        447.6383, 449.1587, 449.1708, 449.1552, 449.1993, 449.1420, 448.8220,
        449.0943, 447.6101, 449.1503, 449.1502, 449.1665, 449.1580, 447.6157,
        447.6877, 449.2394, 449.1602, 449.1719, 449.1807, 449.1445, 449.1507,
        448.9950, 448.8010, 448.8439, 447.6082, 449.1581, 449.2009, 449.1619,
        449.1707, 449.1507, 449.1681, 448.0544, 447.8074, 447.6691, 449.1548,
        449.1642, 448.5165, 448.5338, 449.1659, 448.0200, 447.6284, 449.1620,
        449.1593, 449.1637, 447.6958, 449.1428, 449.1633, 448.6887, 447.6147,
        449.1614, 447.6349, 449.1633, 449.1584, 449.1604, 449.1429, 447.6080,
        447.6079, 449.1607, 449.1452, 449.1495, 449.1988, 449.1811, 449.1632,
        447.6206, 449.1707, 449.1710, 449.1598, 447.6085, 449.1442, 449.1424,
        449.1558, 449.1635, 449.1710, 447.6085, 449.1654, 449.1639, 449.2212,
        449.1783, 447.6082, 447.6079, 449.1455, 449.1656, 448.4872, 449.1616,
        448.4482, 449.1761, 449.2110, 449.2501, 447.6566, 449.1868, 449.1832,
        447.6079, 447.6131, 448.5367, 449.1496, 448.8404, 449.1638, 449.1596,
        449.1594, 449.1562, 449.1373, 449.1723, 449.1608, 447.6117, 448.5886,
        448.4439, 449.1476, 449.1660, 447.6289, 449.1649, 448.4806, 447.6079,
        449.1474, 447.6581, 447.6231, 449.2170, 449.1570, 449.1441, 449.1682,
        449.2029, 449.0022, 449.2258, 449.1469, 448.5399, 447.6528, 449.1553,
        447.6079, 449.1565, 449.1901, 449.2220, 447.6079, 449.1739, 449.1461,
        449.1739, 447.6085, 448.5483, 449.1578, 447.6252, 449.1631, 449.1755,
        449.1592, 449.1367, 449.1897, 449.1860, 447.6491, 449.1663, 449.2133,
        447.6353, 449.1635, 449.1974, 447.6079, 449.1605, 449.2501, 449.1412,
        447.6136, 449.1698, 449.1453, 449.1660, 447.6082, 449.1685, 449.2186,
        449.1627, 449.1861, 448.3025, 449.1661, 449.1620, 449.1608, 449.1365,
        447.6113, 447.6079, 447.6079, 448.0759, 447.6402, 447.6079, 449.1426,
        447.6246, 449.1562, 449.1776, 449.1705, 448.8646, 449.1817, 449.1641,
        449.1462, 449.1596, 449.1667, 449.1475, 449.1658, 449.1599, 447.6121,
        448.5059, 448.0638, 449.1632, 447.6113, 449.1661, 449.1638, 449.1564,
        447.6156, 447.6144, 449.1628, 449.1937, 449.1614, 449.2062, 449.1643,
        448.4517, 449.1609, 449.1592, 447.6079, 449.1361, 449.1829, 447.6118,
        449.1650, 447.6105, 449.1685, 449.1482, 449.1494, 449.1527, 447.6136,
        447.6079, 449.2208, 449.1581, 447.6570, 449.1594, 449.2200, 447.6241,
        449.1843, 449.1784, 449.1575, 449.1617, 449.2023, 448.4493, 449.1650,
        449.1810, 449.1426, 449.1849, 448.1722, 449.1607, 448.5936, 448.4417,
        447.6080, 449.1594, 449.1556, 447.6079, 447.6079, 449.1672, 449.1757,
        449.1743, 447.6083, 449.1617, 447.6085, 449.1624, 447.6251, 449.1796,
        449.1638, 449.1498, 449.1519, 449.1534, 447.6578, 449.1591, 449.1454,
        447.6126, 448.1099, 449.1964, 448.4692, 448.4473, 449.1664, 447.6307,
        449.1596, 449.1520, 447.6082, 449.1370, 449.1567, 449.1595, 449.1664,
        449.1553, 449.1669, 447.6080, 449.1739, 449.1614, 447.6079, 449.1712,
        449.1625, 449.1628, 448.1526, 449.1613, 449.2110, 449.1602, 449.1639,
        447.6130, 449.1784, 449.1493, 449.1620, 447.6168, 449.1609, 447.6079,
        449.1595, 449.1701, 447.6099, 449.1645, 447.6158, 448.4478, 449.1814,
        447.6099, 448.9796, 449.1811, 449.1617, 449.1458, 449.1404, 449.1739,
        449.1667, 449.1953, 447.6093, 449.1677, 449.2033, 447.6080, 449.1676,
        447.6646, 448.4787, 448.4545, 449.1610, 449.1473, 449.1512, 449.1604,
        449.1387, 449.1683, 449.1631, 449.1764, 449.2103, 447.6093, 449.1640,
        449.1708, 449.1789, 449.1799, 449.1639, 449.1529, 447.6096, 447.6110,
        447.6147, 447.6114, 449.1749, 449.1605, 448.8751, 449.1614, 449.1735,
        447.6228, 447.6080, 449.1992, 448.8926, 447.6080, 449.0954, 449.1620,
        449.1503, 449.1602, 449.1710, 447.9205, 447.6089, 449.2197, 449.1664,
        448.5388, 449.1439, 449.1558, 449.1560, 449.1586, 447.6079, 449.1464,
        447.6080, 449.1620, 447.6079, 449.1850, 449.1382, 447.6204, 449.1452,
        447.6084, 449.1996, 449.1825, 449.1926, 449.1592, 449.2050, 447.6081,
        449.1883, 447.6079, 448.8321, 447.8445, 447.6183, 449.1479, 449.2124,
        449.1906, 449.1565, 449.1392, 447.6476, 449.1445, 447.6079, 449.1611,
        449.1661, 447.6099], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([400.7881], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2890],
             [112.2923],
             [112.2927],
             [112.2841]],

            [[112.2840],
             [112.2852],
             [112.2849],
             [112.2842]],

            [[112.2961],
             [112.2963],
             [112.2852],
             [112.2919]],

            ...,

            [[111.9118],
             [112.3088],
             [111.9118],
             [112.3088]],

            [[111.9020],
             [111.9020],
             [111.9020],
             [111.9020]],

            [[111.9040],
             [111.9053],
             [111.9351],
             [111.9351]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1581, 449.1383, 449.1695,  ..., 448.4412, 447.6079, 447.6795],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1581, 449.1383, 449.1695,  ..., 448.4412, 447.6079, 447.6795],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3028],
             [112.3198],
             [112.2974],
             [112.2980]],

            [[111.8977],
             [111.8977],
             [111.9261],
             [111.9261]],

            [[111.8948],
             [111.8949],
             [111.8948],
             [111.8948]],

            ...,

            [[111.8949],
             [111.8956],
             [111.8953],
             [111.8953]],

            [[111.8948],
             [111.8948],
             [111.8948],
             [111.8948]],

            [[111.9036],
             [111.9084],
             [112.3168],
             [112.3168]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2180, 447.6476, 447.5794,  ..., 447.5811, 447.5793, 448.4457],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2180, 447.6476, 447.5794,  ..., 447.5811, 447.5793, 448.4457],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3021],
             [112.2966],
             [112.2936],
             [112.2944]],

            [[112.2972],
             [112.2981],
             [112.2902],
             [112.2985]],

            [[112.3004],
             [112.2903],
             [112.3012],
             [112.3005]],

            ...,

            [[111.8880],
             [111.8880],
             [111.8880],
             [111.8880]],

            [[112.3008],
             [112.3008],
             [112.3008],
             [112.3008]],

            [[111.9162],
             [111.9122],
             [112.3057],
             [112.3057]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1867, 449.1841, 449.1924,  ..., 447.5520, 449.2032, 448.4398],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1867, 449.1841, 449.1924,  ..., 447.5520, 449.2032, 448.4398],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3065],
             [112.2988],
             [112.3082],
             [112.3010]],

            [[112.3063],
             [112.3063],
             [112.3052],
             [112.3052]],

            [[111.9262],
             [112.3110],
             [111.9406],
             [112.3107]],

            ...,

            [[111.9055],
             [111.9055],
             [112.3113],
             [112.3113]],

            [[112.3008],
             [111.8846],
             [111.8852],
             [112.3220]],

            [[111.8795],
             [111.8797],
             [111.8795],
             [111.8795]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2145, 449.2231, 448.4885,  ..., 448.4337, 448.3927, 447.5182],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2145, 449.2231, 448.4885,  ..., 448.4337, 448.3927, 447.5182],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3073],
             [112.3072],
             [112.3113],
             [112.3019]],

            [[111.8764],
             [111.8796],
             [111.8796],
             [111.8759]],

            [[112.3037],
             [112.2951],
             [112.3048],
             [112.3048]],

            ...,

            [[112.2845],
             [112.2843],
             [112.2845],
             [112.2843]],

            [[112.3093],
             [112.3041],
             [112.3104],
             [112.3046]],

            [[112.3055],
             [112.3019],
             [112.2997],
             [112.3020]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2277, 447.5115, 449.2084,  ..., 449.1376, 449.2285, 449.2091],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2277, 447.5115, 449.2084,  ..., 449.1376, 449.2285, 449.2091],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8688],
             [111.8688],
             [111.8688],
             [111.8688]],

            [[112.3101],
             [112.3101],
             [112.3056],
             [112.3056]],

            [[111.8825],
             [111.8825],
             [112.3191],
             [112.3191]],

            ...,

            [[111.8689],
             [111.8696],
             [111.8689],
             [111.8695]],

            [[112.3112],
             [112.3013],
             [112.3024],
             [112.3024]],

            [[111.8695],
             [111.8757],
             [111.8765],
             [111.8765]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4752, 449.2314, 448.4031,  ..., 447.4769, 449.2173, 447.4982],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4752, 449.2314, 448.4031,  ..., 447.4769, 449.2173, 447.4982],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8566],
             [111.8566],
             [111.8566],
             [111.8566]],

            [[111.8620],
             [112.1435],
             [111.8626],
             [112.2257]],

            [[112.3145],
             [112.3145],
             [112.3074],
             [112.3074]],

            ...,

            [[111.8566],
             [111.8566],
             [111.8567],
             [111.8567]],

            [[112.3192],
             [112.3097],
             [112.3187],
             [112.3119]],

            [[112.3192],
             [112.3192],
             [112.3106],
             [112.3106]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4266, 448.0938, 449.2438,  ..., 447.4266, 449.2596, 449.2595],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4266, 448.0938, 449.2438,  ..., 447.4266, 449.2596, 449.2595],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3209],
             [112.3191],
             [112.3121],
             [112.3227]],

            [[112.3211],
             [112.3211],
             [112.3214],
             [112.3214]],

            [[112.3240],
             [112.3181],
             [112.3164],
             [112.3208]],

            ...,

            [[112.3421],
             [112.3421],
             [112.3436],
             [112.3436]],

            [[112.3134],
             [112.3141],
             [112.3120],
             [112.3120]],

            [[111.8502],
             [111.8506],
             [111.8503],
             [111.8503]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2749, 449.2849, 449.2793,  ..., 449.3713, 449.2516, 447.4014],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2749, 449.2849, 449.2793,  ..., 449.3713, 449.2516, 447.4014],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8683],
             [111.8472],
             [111.8614],
             [111.8470]],

            [[112.3184],
             [112.3169],
             [112.3190],
             [112.3172]],

            [[112.3403],
             [112.3473],
             [112.3423],
             [112.3274]],

            ...,

            [[112.3176],
             [112.3199],
             [112.3210],
             [112.3210]],

            [[111.8444],
             [111.8444],
             [111.8444],
             [111.8444]],

            [[112.3321],
             [112.3260],
             [112.3326],
             [112.3261]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4238, 449.2715, 449.3573,  ..., 449.2794, 447.3775, 449.3168],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4238, 449.2715, 449.3573,  ..., 449.2794, 447.3775, 449.3168],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8506],
             [111.8506],
             [111.8506],
             [111.8506]],

            [[112.3235],
             [112.3238],
             [112.3150],
             [112.3230]],

            [[112.3232],
             [112.3234],
             [112.3227],
             [112.3127]],

            ...,

            [[112.3447],
             [112.3247],
             [112.3347],
             [112.3254]],

            [[112.3260],
             [112.3205],
             [112.3245],
             [112.3245]],

            [[111.8515],
             [111.8515],
             [111.8514],
             [111.8514]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.4025, 449.2852, 449.2820,  ..., 449.3295, 449.2954, 447.4057],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.4025, 449.2852, 449.2820,  ..., 449.3295, 449.2954, 447.4057],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3186],
             [112.3165],
             [112.3185],
             [112.3122]],

            [[111.8571],
             [111.8574],
             [111.8573],
             [111.8577]],

            [[112.3218],
             [112.3149],
             [112.3217],
             [112.3160]],

            ...,

            [[111.8605],
             [111.8605],
             [111.8718],
             [111.8718]],

            [[111.8572],
             [111.8572],
             [111.8584],
             [111.8584]],

            [[112.3256],
             [112.3211],
             [112.3242],
             [112.3195]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2659, 447.4294, 449.2744,  ..., 447.4645, 447.4312, 449.2904],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2659, 447.4294, 449.2744,  ..., 447.4645, 447.4312, 449.2904],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.8675],
             [111.9341],
             [111.8716],
             [112.3444]],

            [[112.3149],
             [112.3142],
             [112.3086],
             [112.3086]],

            [[112.3154],
             [112.3154],
             [112.3086],
             [112.3086]],

            ...,

            [[112.3238],
             [112.3216],
             [112.3182],
             [112.3094]],

            [[112.3152],
             [112.3152],
             [112.3084],
             [112.3084]],

            [[111.8628],
             [111.8628],
             [111.8628],
             [111.8628]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0176, 449.2463, 449.2480,  ..., 449.2729, 449.2472, 447.4514],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0176, 449.2463, 449.2480,  ..., 449.2729, 449.2472, 447.4514],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9585],
             [112.3202],
             [112.3446],
             [112.3446]],

            [[112.3146],
             [112.3050],
             [112.3151],
             [112.3126]],

            [[111.8733],
             [111.8735],
             [111.8733],
             [111.8733]],

            ...,

            [[112.3155],
             [112.3080],
             [112.3057],
             [112.3057]],

            [[111.8818],
             [112.3425],
             [112.3326],
             [112.3326]],

            [[112.3217],
             [112.3169],
             [112.3130],
             [112.3068]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9679, 449.2473, 447.4934,  ..., 449.2350, 448.8895, 449.2584],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9679, 449.2473, 447.4934,  ..., 449.2350, 448.8895, 449.2584],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3098],
             [112.3098],
             [112.3078],
             [112.3078]],

            [[112.3211],
             [112.3119],
             [112.3173],
             [112.3173]],

            [[112.0980],
             [112.3153],
             [112.3119],
             [112.3119]],

            ...,

            [[112.3062],
             [112.3141],
             [112.3087],
             [112.3029]],

            [[111.9114],
             [112.3207],
             [111.9153],
             [112.3203]],

            [[112.3095],
             [112.3077],
             [112.3019],
             [112.3019]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2352, 449.2677, 449.0371,  ..., 449.2319, 448.4679, 449.2210],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2352, 449.2677, 449.0371,  ..., 449.2319, 448.4679, 449.2210],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3091],
             [112.3091],
             [112.3030],
             [112.3030]],

            [[111.8974],
             [112.3099],
             [111.8965],
             [111.9058]],

            [[112.3040],
             [112.3006],
             [112.2990],
             [112.3003]],

            ...,

            [[112.3039],
             [112.3039],
             [112.3015],
             [112.3015]],

            [[112.3072],
             [112.2987],
             [112.3077],
             [112.3035]],

            [[112.3222],
             [112.3222],
             [112.3176],
             [112.3176]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2242, 448.0097, 449.2039,  ..., 449.2108, 449.2170, 449.2795],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2242, 448.0097, 449.2039,  ..., 449.2108, 449.2170, 449.2795],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2906],
             [112.2849],
             [112.2915],
             [112.2915]],

            [[112.2887],
             [112.2849],
             [112.2919],
             [112.2919]],

            [[111.9082],
             [111.9121],
             [111.9093],
             [111.9093]],

            ...,

            [[112.2921],
             [112.2848],
             [112.2937],
             [112.2915]],

            [[112.2965],
             [112.2965],
             [112.2908],
             [112.2908]],

            [[112.2932],
             [112.2847],
             [112.2947],
             [112.2942]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1584, 449.1573, 447.6390,  ..., 449.1621, 449.1746, 449.1669],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1584, 449.1573, 447.6390,  ..., 449.1621, 449.1746, 449.1669],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2841],
             [112.2834],
             [112.2786],
             [112.2786]],

            [[111.9244],
             [111.9244],
             [111.9364],
             [111.9364]],

            [[112.2833],
             [112.2821],
             [112.2772],
             [112.2772]],

            ...,

            [[112.2816],
             [112.2816],
             [112.2736],
             [112.2736]],

            [[112.2717],
             [112.2740],
             [112.2775],
             [112.2796]],

            [[111.9231],
             [111.9231],
             [111.9231],
             [111.9231]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1247, 447.7216, 449.1199,  ..., 449.1105, 449.1028, 447.6923],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1247, 447.7216, 449.1199,  ..., 449.1105, 449.1028, 447.6923],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2649],
             [112.2592],
             [112.2630],
             [112.2630]],

            [[111.9432],
             [111.9527],
             [111.9429],
             [111.9511]],

            [[112.2619],
             [112.2619],
             [112.2554],
             [112.2636]],

            ...,

            [[112.2538],
             [112.2538],
             [112.2536],
             [112.2536]],

            [[112.2607],
             [112.2540],
             [112.2543],
             [112.2543]],

            [[112.2577],
             [112.2577],
             [112.2540],
             [112.2540]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0500, 447.7899, 449.0429,  ..., 449.0149, 449.0233, 449.0234],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0500, 447.7899, 449.0429,  ..., 449.0149, 449.0233, 449.0234],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9917e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9766],
             [111.9594],
             [111.9598],
             [111.9797]],

            [[112.2773],
             [112.2485],
             [112.2808],
             [112.2489]],

            [[111.9579],
             [111.9579],
             [111.9579],
             [111.9579]],

            ...,

            [[111.9582],
             [111.9618],
             [111.9590],
             [111.9590]],

            [[111.9579],
             [111.9579],
             [111.9579],
             [111.9579]],

            [[112.2494],
             [112.2427],
             [112.2496],
             [112.2429]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8755, 449.0556, 447.8317,  ..., 447.8380, 447.8317, 448.9846],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8755, 449.0556, 447.8317,  ..., 447.8380, 447.8317, 448.9846],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2461],
             [112.2516],
             [112.2459],
             [112.2507]],

            [[112.2471],
             [112.2390],
             [112.2443],
             [112.2443]],

            [[111.9600],
             [111.9615],
             [111.9587],
             [111.9583]],

            ...,

            [[112.2853],
             [112.2484],
             [112.0326],
             [112.2492]],

            [[111.9580],
             [111.9583],
             [111.9581],
             [111.9581]],

            [[112.2293],
             [112.2291],
             [112.2292],
             [112.2292]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9943, 448.9747, 447.8384,  ..., 448.8155, 447.8325, 448.9167],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9943, 448.9747, 447.8384,  ..., 448.8155, 447.8325, 448.9167],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2428],
             [112.2428],
             [112.2391],
             [112.2391]],

            [[112.2432],
             [112.2477],
             [112.2397],
             [112.2397]],

            [[112.2493],
             [112.2483],
             [112.2455],
             [112.2434]],

            ...,

            [[111.9597],
             [111.9597],
             [111.9583],
             [111.9581]],

            [[112.2494],
             [112.2494],
             [112.2438],
             [112.2438]],

            [[111.9579],
             [111.9579],
             [111.9579],
             [111.9579]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9639, 448.9704, 448.9864, 448.9617, 448.1779, 447.8317, 448.9922,
            448.9896, 448.4887, 447.9440, 448.9789, 448.9163, 448.9653, 448.9935,
            447.8349, 447.8372, 449.0457, 448.9819, 448.9635, 448.9750, 448.9597,
            448.9752, 448.9629, 448.9578, 447.8317, 449.0315, 448.9647, 447.8317,
            448.9780, 449.0079, 448.9730, 447.8319, 448.9930, 447.8350, 448.9815,
            448.9774, 447.8318, 448.9765, 447.8401, 447.8982, 447.8676, 448.9776,
            447.8426, 448.4954, 448.9841, 448.9994, 448.5375, 448.9778, 447.8605,
            448.4655, 449.0209, 447.8324, 447.8317, 449.0029, 447.8438, 448.9832,
            448.9727, 448.9602, 447.8317, 449.0066, 447.9744, 449.0692, 448.9727,
            447.8317, 447.8317, 448.9639, 447.8373, 447.9611, 448.9792, 448.9824,
            448.9769, 448.9851, 447.8345, 448.9714, 448.9635, 448.9858, 448.9659,
            448.9778, 448.9757, 448.9850, 448.9891, 448.9749, 448.9751, 448.9964,
            448.9799, 449.0106, 448.9793, 448.9757, 448.9629, 448.8675, 448.0609,
            448.9871, 448.9755, 448.9733, 448.9888, 448.9639, 448.9880, 448.4610,
            448.9791, 447.8318, 449.0831, 448.9743, 447.8317, 448.9716, 448.9769,
            448.9740, 448.9774, 448.9498, 448.1791, 448.4820, 448.4591, 448.9788,
            448.9755, 448.9651, 448.9908, 448.7358, 448.9647, 448.9707, 447.8327,
            447.8439, 448.9643, 448.9778, 447.8323, 448.9556, 448.9786, 447.8619,
            448.4737, 447.8317, 448.9707, 447.8317, 448.9810, 448.9738, 449.0027,
            448.9863, 448.9763, 448.9780, 448.9713, 447.8317, 447.8317, 448.9728,
            448.9673, 447.8317, 448.9813, 448.9850, 447.8745, 449.0018, 448.9882,
            448.9558, 448.9814, 448.9826, 448.9783, 448.9633, 448.9713, 447.8317,
            449.0199, 447.8317, 448.9776, 448.9904, 448.9576, 448.9680, 448.9970,
            448.9689, 448.9613, 448.9903, 448.9548, 449.0000, 448.9783, 448.9796,
            448.9772, 448.9760, 449.1089, 448.9910, 447.8317, 448.9701, 448.4954,
            447.8366, 448.9628, 447.8318, 448.1732, 448.9679, 448.9558, 448.9736,
            447.8317, 447.8358, 447.8317, 448.9798, 447.8325, 448.9924, 447.8370,
            449.0053, 447.8317, 448.9780, 448.9769, 448.9669, 447.9767, 448.9767,
            448.9766, 448.4675, 448.9741, 447.8317, 448.9793, 448.9780, 448.9836,
            448.2188, 447.8317, 449.0032, 448.9855, 448.9614, 448.9835, 447.8690,
            448.9688, 448.9809, 447.8431, 448.9711, 449.0046, 448.9634, 447.8317,
            448.9597, 448.9788, 447.8328, 448.9578, 448.9771, 447.8317, 448.9890,
            448.9924, 448.9823, 448.9772, 447.8605, 448.9854, 449.0142, 448.9740,
            448.9760, 449.0806, 448.9979, 448.9725, 448.9737, 448.9908, 447.8317,
            448.9756, 448.9857, 448.7754, 448.9858, 447.8333, 447.8317, 447.8317,
            448.9899, 448.9767, 448.9674, 448.9861, 448.9743, 448.9750, 448.9762,
            447.8369, 448.9769, 448.9990, 448.9639, 448.9646, 448.9834, 447.8364,
            447.8318, 448.9684, 448.9686, 449.0152, 449.0203, 448.9555, 448.9774,
            447.8471, 447.8323, 448.9615, 448.9773, 447.8317, 447.8317, 447.8318,
            447.8322, 447.8344, 448.9648, 447.8345, 448.9762, 447.8317, 447.8317,
            448.9774, 447.8325, 448.9768, 448.9714, 448.9826, 448.6647, 448.9944,
            447.8357, 447.8577, 447.8317, 448.9728, 448.9828, 448.9816, 448.9783,
            448.9601, 448.9769, 448.9718, 448.9742, 447.8317, 448.9780, 448.9666,
            447.8324, 449.0474, 448.9830, 448.9876, 448.9718, 448.9703, 448.9702,
            447.8509, 448.9773, 448.9861, 448.5922, 448.9636, 447.8320, 448.9763,
            448.9664, 448.9789, 448.8448, 448.9722, 447.8339, 448.9624, 448.9716,
            447.8318, 447.8389, 447.8317, 448.2782, 448.9753, 448.9757, 448.9659,
            447.8325, 447.8322, 447.8317, 448.9170, 447.8317, 447.8345, 448.9975,
            448.9815, 448.9722, 448.9743, 448.9874, 447.8413, 448.9746, 448.9845,
            448.3323, 449.0504, 448.9601, 448.9792, 448.9747, 448.9593, 447.8317,
            448.9767, 448.9733, 448.9714, 448.9780, 447.8318, 448.9800, 447.8317,
            448.9958, 448.2409, 448.9787, 448.9792, 448.9932, 448.9774, 447.8317,
            448.9716, 448.9796, 447.8366, 448.9781, 448.9658, 447.8320, 448.9894,
            448.9693, 449.0670, 448.9575, 447.8325, 448.9792, 448.5760, 448.9703,
            448.9772, 448.9810, 448.9822, 448.5037, 448.9865, 448.9762, 448.9790,
            447.8364, 448.9789, 448.9767, 448.9664, 448.9629, 448.9717, 448.9776,
            448.9757, 448.9639, 447.9113, 448.9722, 449.0198, 448.9941, 447.8318,
            447.8317, 448.9756, 447.8317, 448.9559, 447.8344, 448.4519, 448.4843,
            448.9734, 448.9989, 448.9609, 448.4600, 448.9767, 448.9760, 448.9672,
            448.4731, 448.9789, 448.9645, 448.9715, 448.9729, 447.8332, 448.4927,
            448.9863, 448.9731, 448.1931, 449.0432, 447.8329, 448.9756, 447.9211,
            448.9792, 448.9890, 448.7585, 448.9642, 447.8324, 447.8640, 449.0002,
            448.9923, 448.9598, 447.8317, 448.9727, 447.8317, 448.4827, 447.8317,
            448.9769, 448.9643, 448.9753, 448.9778, 447.8324, 447.8967, 448.9887,
            448.9717, 448.9715, 447.9029, 448.9821, 448.5146, 448.9722, 448.9250,
            448.4713, 448.9763, 449.0100, 448.9644, 449.0045, 448.9811, 447.8346,
            448.9629, 447.8317, 447.8723, 447.8488, 448.9979, 448.9582, 449.0679,
            447.8322, 448.9572, 447.8317, 449.0481, 447.8397, 447.8317, 448.9654,
            447.8317, 448.9910, 448.9824, 448.9846, 447.8602, 447.8331, 447.8317,
            448.9608, 448.9631, 448.9620, 447.8369, 448.3249, 448.9759, 448.9733,
            449.0487, 447.8325, 448.9777, 448.9650, 448.9800, 447.8400, 448.9967,
            447.8359, 448.9630, 448.9757, 447.8326, 448.9742, 448.9732, 448.9775,
            449.0468, 448.9789, 448.9757, 448.9660, 448.9600, 448.1896, 448.4914,
            448.9761, 448.9777, 448.4592, 448.0673, 448.9784, 448.9666, 448.9752,
            449.0803, 448.9811, 448.9831, 448.9802, 448.9731, 448.9662, 448.9824,
            448.9969, 447.8317, 447.8317, 447.9030, 447.8463, 448.9796, 447.8322,
            448.9792, 448.9648, 448.9658, 447.9031, 448.5055, 447.8615, 448.9778,
            448.9865, 447.8317, 448.9768, 448.9835, 448.9838, 449.0389, 448.9616,
            447.8469, 448.9846, 447.8356, 448.9707, 448.9606, 448.9752, 448.4625,
            448.9656, 448.4853, 448.9731, 448.9672, 447.9335, 448.9800, 449.0698,
            448.9745, 449.0544, 448.9712, 448.9950, 448.9777, 448.9730, 448.9719,
            447.8453, 448.9811, 447.8318, 448.9611, 448.9787, 447.8508, 448.4825,
            448.9835, 447.8516, 447.8317, 448.9937, 448.9996, 448.9844, 449.0310,
            448.9718, 448.0112, 449.0380, 448.9810, 448.9678, 448.1689, 447.8416,
            448.9802, 447.8394, 448.4680, 447.9264, 449.0096, 447.8358, 448.9781,
            447.8317, 448.9449, 448.9712, 448.9965, 448.9650, 448.9774, 449.0049,
            447.8317, 449.0131, 448.9801, 448.9793, 448.9701, 448.9762, 447.8323,
            447.8380, 448.9738, 448.9707, 448.9765, 448.9817, 448.9902, 448.9799,
            447.8318, 447.8531, 448.9912, 448.4854, 448.9790, 448.9895, 448.9711,
            448.9722, 449.0139, 448.4751, 449.0004, 448.9769, 447.8392, 448.9949,
            448.9783, 448.9673, 449.0255, 449.0188, 449.0089, 448.9779, 449.0306,
            448.9813, 448.9922, 448.8044, 447.8746, 447.8317, 447.8459, 447.8404,
            448.9780, 449.0024, 448.9722, 448.9589, 447.8317, 448.9799, 448.9828,
            447.8322, 447.8586, 447.8469, 448.9946, 448.9790, 447.8318, 447.8630,
            447.8324, 448.9751, 448.2330, 448.9628, 447.8317, 448.9789, 447.8345,
            448.9636, 448.4592, 447.8347, 447.8457, 448.9671, 448.9825, 449.0314,
            448.2273, 447.8502, 449.0779, 448.9622, 448.9613, 448.9814, 448.4910,
            448.9763, 447.8415, 448.9731, 448.9938, 448.9579, 448.8879, 448.1147,
            448.9637, 447.8317, 448.9962, 448.9761, 448.9656, 448.9821, 448.9759,
            448.9641, 448.9733, 448.9780, 448.9895, 448.4707, 448.9937, 448.9752,
            448.9836, 447.8317, 449.0775, 448.9733, 448.9988, 449.0208, 448.9966,
            448.9807, 448.9163, 448.9745, 448.9706, 448.9748, 448.9842, 448.9555,
            448.4217, 448.9998, 448.9865, 447.8669, 448.4743, 448.9731, 447.8319,
            448.4623, 448.9957, 448.9793, 448.9566, 448.9642, 448.9700, 448.9896,
            447.8320, 448.9771, 448.0554, 448.9731, 447.8317, 448.9697, 448.9825,
            448.9790, 448.4686, 448.9575, 448.9847, 449.0248, 447.8502, 448.9792,
            448.9614, 449.0588, 448.9766, 448.9752, 448.9777, 447.8317, 448.9763,
            448.9976, 448.9711, 448.9579, 448.9630, 447.8326, 448.9643, 449.0308,
            448.9689, 448.9626, 448.9558, 448.9662, 448.9756, 447.9539, 448.9641,
            449.0323, 447.8629, 448.9774, 448.9819, 448.9758, 448.4918, 448.9681,
            447.8317, 448.9752, 448.9668, 448.9801, 448.5004, 449.0475, 448.4905,
            447.8317, 448.9735, 447.8319, 448.9162, 448.9840, 448.9850, 448.9727,
            448.9739, 449.0105, 447.8324, 448.9728, 448.9886, 447.8384, 448.7269,
            448.9904, 447.8533, 448.9658, 448.9659, 448.9896, 448.9927, 448.9653,
            449.0374, 448.9870, 448.9694, 447.8430, 448.9648, 447.8459, 448.9730,
            448.9735, 448.9783, 447.8330, 448.9780, 448.9791, 448.9780, 448.9737,
            448.9779, 448.4825, 447.8357, 448.9791, 447.8320, 448.9727, 448.4763,
            448.9554, 447.9908, 447.8317, 448.4867, 448.4908, 447.8317, 448.9888,
            448.9670, 448.9791, 448.9814, 447.8317, 448.9855, 449.0068, 447.8335,
            448.9780, 448.8627, 448.9608, 448.9867, 447.8333, 448.9706, 448.9860,
            448.9625, 448.9730, 449.0759, 447.8317, 448.9943, 448.9762, 447.8331,
            448.9820, 449.0006, 448.7638, 447.8325, 449.0297, 448.9969, 448.9940,
            448.9750, 447.8317, 448.4592, 448.9815, 448.9701, 448.9654, 448.9595,
            447.8369, 448.9758, 448.9741, 448.9575, 448.9783, 448.9659, 447.8317,
            448.9789, 448.8166, 448.9787, 448.2506, 448.9846, 448.9686, 449.0470,
            448.9770, 447.8333, 448.9605, 447.8376, 447.8318, 448.9752, 448.9592,
            448.9758, 448.9631, 448.9632, 447.8486, 448.9935, 447.8532, 448.9793,
            447.8318, 449.0087, 448.9896, 447.8317, 448.7338, 448.9650, 448.9724,
            448.9655, 447.8317, 448.9772, 449.0756, 448.9655, 449.0054, 448.9730,
            447.8318, 448.9901, 448.9758, 447.8387, 448.9691, 448.9603, 447.8317,
            448.9746, 448.9781, 449.0095, 448.9729, 447.8317, 449.0490, 448.9699,
            448.9962, 448.9736, 448.9822, 448.9932, 447.8317, 448.4676, 447.8358,
            448.9864, 447.8317], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9639, 448.9704, 448.9864, 448.9617, 448.1779, 447.8317, 448.9922,
        448.9896, 448.4887, 447.9440, 448.9789, 448.9163, 448.9653, 448.9935,
        447.8349, 447.8372, 449.0457, 448.9819, 448.9635, 448.9750, 448.9597,
        448.9752, 448.9629, 448.9578, 447.8317, 449.0315, 448.9647, 447.8317,
        448.9780, 449.0079, 448.9730, 447.8319, 448.9930, 447.8350, 448.9815,
        448.9774, 447.8318, 448.9765, 447.8401, 447.8982, 447.8676, 448.9776,
        447.8426, 448.4954, 448.9841, 448.9994, 448.5375, 448.9778, 447.8605,
        448.4655, 449.0209, 447.8324, 447.8317, 449.0029, 447.8438, 448.9832,
        448.9727, 448.9602, 447.8317, 449.0066, 447.9744, 449.0692, 448.9727,
        447.8317, 447.8317, 448.9639, 447.8373, 447.9611, 448.9792, 448.9824,
        448.9769, 448.9851, 447.8345, 448.9714, 448.9635, 448.9858, 448.9659,
        448.9778, 448.9757, 448.9850, 448.9891, 448.9749, 448.9751, 448.9964,
        448.9799, 449.0106, 448.9793, 448.9757, 448.9629, 448.8675, 448.0609,
        448.9871, 448.9755, 448.9733, 448.9888, 448.9639, 448.9880, 448.4610,
        448.9791, 447.8318, 449.0831, 448.9743, 447.8317, 448.9716, 448.9769,
        448.9740, 448.9774, 448.9498, 448.1791, 448.4820, 448.4591, 448.9788,
        448.9755, 448.9651, 448.9908, 448.7358, 448.9647, 448.9707, 447.8327,
        447.8439, 448.9643, 448.9778, 447.8323, 448.9556, 448.9786, 447.8619,
        448.4737, 447.8317, 448.9707, 447.8317, 448.9810, 448.9738, 449.0027,
        448.9863, 448.9763, 448.9780, 448.9713, 447.8317, 447.8317, 448.9728,
        448.9673, 447.8317, 448.9813, 448.9850, 447.8745, 449.0018, 448.9882,
        448.9558, 448.9814, 448.9826, 448.9783, 448.9633, 448.9713, 447.8317,
        449.0199, 447.8317, 448.9776, 448.9904, 448.9576, 448.9680, 448.9970,
        448.9689, 448.9613, 448.9903, 448.9548, 449.0000, 448.9783, 448.9796,
        448.9772, 448.9760, 449.1089, 448.9910, 447.8317, 448.9701, 448.4954,
        447.8366, 448.9628, 447.8318, 448.1732, 448.9679, 448.9558, 448.9736,
        447.8317, 447.8358, 447.8317, 448.9798, 447.8325, 448.9924, 447.8370,
        449.0053, 447.8317, 448.9780, 448.9769, 448.9669, 447.9767, 448.9767,
        448.9766, 448.4675, 448.9741, 447.8317, 448.9793, 448.9780, 448.9836,
        448.2188, 447.8317, 449.0032, 448.9855, 448.9614, 448.9835, 447.8690,
        448.9688, 448.9809, 447.8431, 448.9711, 449.0046, 448.9634, 447.8317,
        448.9597, 448.9788, 447.8328, 448.9578, 448.9771, 447.8317, 448.9890,
        448.9924, 448.9823, 448.9772, 447.8605, 448.9854, 449.0142, 448.9740,
        448.9760, 449.0806, 448.9979, 448.9725, 448.9737, 448.9908, 447.8317,
        448.9756, 448.9857, 448.7754, 448.9858, 447.8333, 447.8317, 447.8317,
        448.9899, 448.9767, 448.9674, 448.9861, 448.9743, 448.9750, 448.9762,
        447.8369, 448.9769, 448.9990, 448.9639, 448.9646, 448.9834, 447.8364,
        447.8318, 448.9684, 448.9686, 449.0152, 449.0203, 448.9555, 448.9774,
        447.8471, 447.8323, 448.9615, 448.9773, 447.8317, 447.8317, 447.8318,
        447.8322, 447.8344, 448.9648, 447.8345, 448.9762, 447.8317, 447.8317,
        448.9774, 447.8325, 448.9768, 448.9714, 448.9826, 448.6647, 448.9944,
        447.8357, 447.8577, 447.8317, 448.9728, 448.9828, 448.9816, 448.9783,
        448.9601, 448.9769, 448.9718, 448.9742, 447.8317, 448.9780, 448.9666,
        447.8324, 449.0474, 448.9830, 448.9876, 448.9718, 448.9703, 448.9702,
        447.8509, 448.9773, 448.9861, 448.5922, 448.9636, 447.8320, 448.9763,
        448.9664, 448.9789, 448.8448, 448.9722, 447.8339, 448.9624, 448.9716,
        447.8318, 447.8389, 447.8317, 448.2782, 448.9753, 448.9757, 448.9659,
        447.8325, 447.8322, 447.8317, 448.9170, 447.8317, 447.8345, 448.9975,
        448.9815, 448.9722, 448.9743, 448.9874, 447.8413, 448.9746, 448.9845,
        448.3323, 449.0504, 448.9601, 448.9792, 448.9747, 448.9593, 447.8317,
        448.9767, 448.9733, 448.9714, 448.9780, 447.8318, 448.9800, 447.8317,
        448.9958, 448.2409, 448.9787, 448.9792, 448.9932, 448.9774, 447.8317,
        448.9716, 448.9796, 447.8366, 448.9781, 448.9658, 447.8320, 448.9894,
        448.9693, 449.0670, 448.9575, 447.8325, 448.9792, 448.5760, 448.9703,
        448.9772, 448.9810, 448.9822, 448.5037, 448.9865, 448.9762, 448.9790,
        447.8364, 448.9789, 448.9767, 448.9664, 448.9629, 448.9717, 448.9776,
        448.9757, 448.9639, 447.9113, 448.9722, 449.0198, 448.9941, 447.8318,
        447.8317, 448.9756, 447.8317, 448.9559, 447.8344, 448.4519, 448.4843,
        448.9734, 448.9989, 448.9609, 448.4600, 448.9767, 448.9760, 448.9672,
        448.4731, 448.9789, 448.9645, 448.9715, 448.9729, 447.8332, 448.4927,
        448.9863, 448.9731, 448.1931, 449.0432, 447.8329, 448.9756, 447.9211,
        448.9792, 448.9890, 448.7585, 448.9642, 447.8324, 447.8640, 449.0002,
        448.9923, 448.9598, 447.8317, 448.9727, 447.8317, 448.4827, 447.8317,
        448.9769, 448.9643, 448.9753, 448.9778, 447.8324, 447.8967, 448.9887,
        448.9717, 448.9715, 447.9029, 448.9821, 448.5146, 448.9722, 448.9250,
        448.4713, 448.9763, 449.0100, 448.9644, 449.0045, 448.9811, 447.8346,
        448.9629, 447.8317, 447.8723, 447.8488, 448.9979, 448.9582, 449.0679,
        447.8322, 448.9572, 447.8317, 449.0481, 447.8397, 447.8317, 448.9654,
        447.8317, 448.9910, 448.9824, 448.9846, 447.8602, 447.8331, 447.8317,
        448.9608, 448.9631, 448.9620, 447.8369, 448.3249, 448.9759, 448.9733,
        449.0487, 447.8325, 448.9777, 448.9650, 448.9800, 447.8400, 448.9967,
        447.8359, 448.9630, 448.9757, 447.8326, 448.9742, 448.9732, 448.9775,
        449.0468, 448.9789, 448.9757, 448.9660, 448.9600, 448.1896, 448.4914,
        448.9761, 448.9777, 448.4592, 448.0673, 448.9784, 448.9666, 448.9752,
        449.0803, 448.9811, 448.9831, 448.9802, 448.9731, 448.9662, 448.9824,
        448.9969, 447.8317, 447.8317, 447.9030, 447.8463, 448.9796, 447.8322,
        448.9792, 448.9648, 448.9658, 447.9031, 448.5055, 447.8615, 448.9778,
        448.9865, 447.8317, 448.9768, 448.9835, 448.9838, 449.0389, 448.9616,
        447.8469, 448.9846, 447.8356, 448.9707, 448.9606, 448.9752, 448.4625,
        448.9656, 448.4853, 448.9731, 448.9672, 447.9335, 448.9800, 449.0698,
        448.9745, 449.0544, 448.9712, 448.9950, 448.9777, 448.9730, 448.9719,
        447.8453, 448.9811, 447.8318, 448.9611, 448.9787, 447.8508, 448.4825,
        448.9835, 447.8516, 447.8317, 448.9937, 448.9996, 448.9844, 449.0310,
        448.9718, 448.0112, 449.0380, 448.9810, 448.9678, 448.1689, 447.8416,
        448.9802, 447.8394, 448.4680, 447.9264, 449.0096, 447.8358, 448.9781,
        447.8317, 448.9449, 448.9712, 448.9965, 448.9650, 448.9774, 449.0049,
        447.8317, 449.0131, 448.9801, 448.9793, 448.9701, 448.9762, 447.8323,
        447.8380, 448.9738, 448.9707, 448.9765, 448.9817, 448.9902, 448.9799,
        447.8318, 447.8531, 448.9912, 448.4854, 448.9790, 448.9895, 448.9711,
        448.9722, 449.0139, 448.4751, 449.0004, 448.9769, 447.8392, 448.9949,
        448.9783, 448.9673, 449.0255, 449.0188, 449.0089, 448.9779, 449.0306,
        448.9813, 448.9922, 448.8044, 447.8746, 447.8317, 447.8459, 447.8404,
        448.9780, 449.0024, 448.9722, 448.9589, 447.8317, 448.9799, 448.9828,
        447.8322, 447.8586, 447.8469, 448.9946, 448.9790, 447.8318, 447.8630,
        447.8324, 448.9751, 448.2330, 448.9628, 447.8317, 448.9789, 447.8345,
        448.9636, 448.4592, 447.8347, 447.8457, 448.9671, 448.9825, 449.0314,
        448.2273, 447.8502, 449.0779, 448.9622, 448.9613, 448.9814, 448.4910,
        448.9763, 447.8415, 448.9731, 448.9938, 448.9579, 448.8879, 448.1147,
        448.9637, 447.8317, 448.9962, 448.9761, 448.9656, 448.9821, 448.9759,
        448.9641, 448.9733, 448.9780, 448.9895, 448.4707, 448.9937, 448.9752,
        448.9836, 447.8317, 449.0775, 448.9733, 448.9988, 449.0208, 448.9966,
        448.9807, 448.9163, 448.9745, 448.9706, 448.9748, 448.9842, 448.9555,
        448.4217, 448.9998, 448.9865, 447.8669, 448.4743, 448.9731, 447.8319,
        448.4623, 448.9957, 448.9793, 448.9566, 448.9642, 448.9700, 448.9896,
        447.8320, 448.9771, 448.0554, 448.9731, 447.8317, 448.9697, 448.9825,
        448.9790, 448.4686, 448.9575, 448.9847, 449.0248, 447.8502, 448.9792,
        448.9614, 449.0588, 448.9766, 448.9752, 448.9777, 447.8317, 448.9763,
        448.9976, 448.9711, 448.9579, 448.9630, 447.8326, 448.9643, 449.0308,
        448.9689, 448.9626, 448.9558, 448.9662, 448.9756, 447.9539, 448.9641,
        449.0323, 447.8629, 448.9774, 448.9819, 448.9758, 448.4918, 448.9681,
        447.8317, 448.9752, 448.9668, 448.9801, 448.5004, 449.0475, 448.4905,
        447.8317, 448.9735, 447.8319, 448.9162, 448.9840, 448.9850, 448.9727,
        448.9739, 449.0105, 447.8324, 448.9728, 448.9886, 447.8384, 448.7269,
        448.9904, 447.8533, 448.9658, 448.9659, 448.9896, 448.9927, 448.9653,
        449.0374, 448.9870, 448.9694, 447.8430, 448.9648, 447.8459, 448.9730,
        448.9735, 448.9783, 447.8330, 448.9780, 448.9791, 448.9780, 448.9737,
        448.9779, 448.4825, 447.8357, 448.9791, 447.8320, 448.9727, 448.4763,
        448.9554, 447.9908, 447.8317, 448.4867, 448.4908, 447.8317, 448.9888,
        448.9670, 448.9791, 448.9814, 447.8317, 448.9855, 449.0068, 447.8335,
        448.9780, 448.8627, 448.9608, 448.9867, 447.8333, 448.9706, 448.9860,
        448.9625, 448.9730, 449.0759, 447.8317, 448.9943, 448.9762, 447.8331,
        448.9820, 449.0006, 448.7638, 447.8325, 449.0297, 448.9969, 448.9940,
        448.9750, 447.8317, 448.4592, 448.9815, 448.9701, 448.9654, 448.9595,
        447.8369, 448.9758, 448.9741, 448.9575, 448.9783, 448.9659, 447.8317,
        448.9789, 448.8166, 448.9787, 448.2506, 448.9846, 448.9686, 449.0470,
        448.9770, 447.8333, 448.9605, 447.8376, 447.8318, 448.9752, 448.9592,
        448.9758, 448.9631, 448.9632, 447.8486, 448.9935, 447.8532, 448.9793,
        447.8318, 449.0087, 448.9896, 447.8317, 448.7338, 448.9650, 448.9724,
        448.9655, 447.8317, 448.9772, 449.0756, 448.9655, 449.0054, 448.9730,
        447.8318, 448.9901, 448.9758, 447.8387, 448.9691, 448.9603, 447.8317,
        448.9746, 448.9781, 449.0095, 448.9729, 447.8317, 449.0490, 448.9699,
        448.9962, 448.9736, 448.9822, 448.9932, 447.8317, 448.4676, 447.8358,
        448.9864, 447.8317], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([411.7093], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9588],
             [111.9685],
             [111.9587],
             [111.9616]],

            [[111.9597],
             [111.9597],
             [111.9601],
             [111.9601]],

            [[111.9818],
             [111.9619],
             [112.2565],
             [112.2645]],

            ...,

            [[112.2612],
             [112.2476],
             [112.2618],
             [112.2476]],

            [[111.9583],
             [111.9620],
             [111.9587],
             [111.9587]],

            [[111.9644],
             [112.2721],
             [111.9644],
             [112.2721]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8476, 447.8396, 448.4648,  ..., 449.0182, 447.8376, 448.4731],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8476, 447.8396, 448.4648,  ..., 449.0182, 447.8376, 448.4731],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2256],
             [112.2226],
             [112.2290],
             [112.2290]],

            [[112.2240],
             [112.2288],
             [112.2293],
             [112.2293]],

            [[112.2004],
             [112.2310],
             [112.2381],
             [112.2381]],

            ...,

            [[111.9812],
             [111.9814],
             [111.9935],
             [111.9935]],

            [[112.2305],
             [112.2305],
             [112.2286],
             [112.2286]],

            [[111.9807],
             [111.9872],
             [111.9812],
             [111.9812]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9062, 448.9114, 448.9075,  ..., 447.9496, 448.9182, 447.9303],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9062, 448.9114, 448.9075,  ..., 447.9496, 448.9182, 447.9303],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2102],
             [112.2102],
             [112.2052],
             [112.2052]],

            [[112.0022],
             [112.0028],
             [112.0022],
             [112.0028]],

            [[112.0021],
             [112.0021],
             [112.0021],
             [112.0021]],

            ...,

            [[112.2085],
             [112.2090],
             [112.2097],
             [112.2028]],

            [[112.2078],
             [112.2027],
             [112.2099],
             [112.2082]],

            [[112.2169],
             [112.2091],
             [112.2111],
             [112.2111]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8308, 448.0100, 448.0085,  ..., 448.8300, 448.8285, 448.8482],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8308, 448.0100, 448.0085,  ..., 448.8300, 448.8285, 448.8482],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2021],
             [112.1969],
             [112.2001],
             [112.2001]],

            [[112.1997],
             [112.1978],
             [112.1986],
             [112.1936]],

            [[112.0493],
             [112.0493],
             [112.0353],
             [112.0353]],

            ...,

            [[112.1974],
             [112.1936],
             [112.1939],
             [112.1979]],

            [[112.2012],
             [112.2012],
             [112.1950],
             [112.1950]],

            [[112.2004],
             [112.1932],
             [112.1957],
             [112.1957]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7991, 448.7897, 448.1691,  ..., 448.7827, 448.7922, 448.7851],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7991, 448.7897, 448.1691,  ..., 448.7827, 448.7922, 448.7851],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1903],
             [112.1905],
             [112.1868],
             [112.1846]],

            [[112.2145],
             [112.1933],
             [112.1942],
             [112.1895]],

            [[112.0598],
             [112.0329],
             [112.1952],
             [112.2328]],

            ...,

            [[112.0305],
             [112.0305],
             [112.0305],
             [112.0305]],

            [[112.1871],
             [112.1824],
             [112.1829],
             [112.1861]],

            [[112.1854],
             [112.1893],
             [112.1829],
             [112.1829]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7522, 448.7915, 448.5206,  ..., 448.1220, 448.7385, 448.7406],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7522, 448.7915, 448.5206,  ..., 448.1220, 448.7385, 448.7406],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1787],
             [112.1758],
             [112.1764],
             [112.1739]],

            [[112.1890],
             [112.1890],
             [112.1914],
             [112.1914]],

            [[112.0462],
             [112.0462],
             [112.0462],
             [112.0462]],

            ...,

            [[112.1711],
             [112.1690],
             [112.1700],
             [112.1732]],

            [[112.1703],
             [112.1693],
             [112.1695],
             [112.1694]],

            [[112.1845],
             [112.1972],
             [112.1777],
             [112.0717]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7048, 448.7607, 448.1850,  ..., 448.6832, 448.6785, 448.6311],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7048, 448.7607, 448.1850,  ..., 448.6832, 448.6785, 448.6311],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1758],
             [112.1613],
             [112.1759],
             [112.1613]],

            [[112.1618],
             [112.1580],
             [112.1591],
             [112.1591]],

            [[112.1633],
             [112.1588],
             [112.1577],
             [112.1571]],

            ...,

            [[112.1608],
             [112.1550],
             [112.1586],
             [112.1586]],

            [[112.1598],
             [112.1559],
             [112.1595],
             [112.1597]],

            [[112.1680],
             [112.1604],
             [112.1624],
             [112.1624]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6743, 448.6381, 448.6368,  ..., 448.6331, 448.6349, 448.6532],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6743, 448.6381, 448.6368,  ..., 448.6331, 448.6349, 448.6532],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1547],
             [112.1547],
             [112.1508],
             [112.1508]],

            [[112.1665],
             [112.1665],
             [112.1619],
             [112.1619]],

            [[112.0709],
             [112.0823],
             [112.0726],
             [112.0726]],

            ...,

            [[112.0700],
             [112.0710],
             [112.0704],
             [112.0704]],

            [[112.0711],
             [112.0751],
             [112.0891],
             [112.0891]],

            [[112.0700],
             [112.0700],
             [112.0700],
             [112.0700]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6110, 448.6569, 448.2984,  ..., 448.2819, 448.3245, 448.2799],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6110, 448.6569, 448.2984,  ..., 448.2819, 448.3245, 448.2799],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1721],
             [112.1504],
             [112.2218],
             [112.1523]],

            [[112.1515],
             [112.1474],
             [112.1524],
             [112.1478]],

            [[112.0870],
             [112.2091],
             [112.1889],
             [112.1506]],

            ...,

            [[112.1489],
             [112.1466],
             [112.1452],
             [112.1437]],

            [[112.1432],
             [112.1433],
             [112.1432],
             [112.1433]],

            [[112.1499],
             [112.1441],
             [112.1498],
             [112.1458]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6966, 448.5992, 448.6356,  ..., 448.5843, 448.5730, 448.5896],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6966, 448.5992, 448.6356,  ..., 448.5843, 448.5730, 448.5896],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1446],
             [112.1425],
             [112.1399],
             [112.1399]],

            [[112.1414],
             [112.1372],
             [112.1377],
             [112.1377]],

            [[112.1386],
             [112.1401],
             [112.1374],
             [112.1419]],

            ...,

            [[112.0867],
             [112.0867],
             [112.0867],
             [112.0867]],

            [[112.1380],
             [112.1435],
             [112.1375],
             [112.1437]],

            [[112.1423],
             [112.1393],
             [112.1385],
             [112.1373]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5668, 448.5540, 448.5581,  ..., 448.3468, 448.5628, 448.5575],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5668, 448.5540, 448.5581,  ..., 448.3468, 448.5628, 448.5575],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1352],
             [112.1403],
             [112.1385],
             [112.1343]],

            [[112.1372],
             [112.1340],
             [112.1334],
             [112.1320]],

            [[112.1377],
             [112.1319],
             [112.1317],
             [112.1317]],

            ...,

            [[112.1330],
             [112.1337],
             [112.1351],
             [112.1316]],

            [[112.1365],
             [112.1365],
             [112.1345],
             [112.1318]],

            [[112.1333],
             [112.1333],
             [112.1320],
             [112.1320]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5483, 448.5365, 448.5330,  ..., 448.5335, 448.5393, 448.5305],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5483, 448.5365, 448.5330,  ..., 448.5335, 448.5393, 448.5305],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1038],
             [112.1032],
             [112.1032],
             [112.1039]],

            [[112.1252],
             [112.1238],
             [112.1242],
             [112.1241]],

            [[112.1057],
             [112.1055],
             [112.1045],
             [112.1085]],

            ...,

            [[112.1303],
             [112.1303],
             [112.1287],
             [112.1287]],

            [[112.1232],
             [112.1286],
             [112.1277],
             [112.1241]],

            [[112.1305],
             [112.1324],
             [112.1276],
             [112.1290]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4141, 448.4973, 448.4243,  ..., 448.5179, 448.5034, 448.5195],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4141, 448.4973, 448.4243,  ..., 448.5179, 448.5034, 448.5195],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1228],
             [112.1228],
             [112.1190],
             [112.1190]],

            [[112.1251],
             [112.1256],
             [112.1202],
             [112.1202]],

            [[112.1203],
             [112.1156],
             [112.1186],
             [112.1186]],

            ...,

            [[112.1114],
             [112.1114],
             [112.1114],
             [112.1114]],

            [[112.1405],
             [112.1206],
             [112.1216],
             [112.1216]],

            [[112.1154],
             [112.1154],
             [112.1153],
             [112.1153]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4836, 448.4911, 448.4732,  ..., 448.4455, 448.5042, 448.4614],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4836, 448.4911, 448.4732,  ..., 448.4455, 448.5042, 448.4614],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1233],
             [112.1233],
             [112.1233],
             [112.1233]],

            [[112.1255],
             [112.1255],
             [112.1267],
             [112.1267]],

            [[112.1065],
             [112.1037],
             [112.1071],
             [112.1086]],

            ...,

            [[112.1075],
             [112.1075],
             [112.1070],
             [112.1070]],

            [[112.1509],
             [112.1246],
             [112.1244],
             [112.1468]],

            [[112.1276],
             [112.1243],
             [112.1270],
             [112.1260]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4931, 448.5045, 448.4260,  ..., 448.4290, 448.5466, 448.5049],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4931, 448.5045, 448.4260,  ..., 448.4290, 448.5466, 448.5049],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0842],
             [112.0842],
             [112.0842],
             [112.0842]],

            [[112.0973],
             [112.0973],
             [112.0961],
             [112.0961]],

            [[112.1344],
             [112.1358],
             [112.1358],
             [112.1342]],

            ...,

            [[112.1420],
             [112.1017],
             [112.1718],
             [112.1718]],

            [[112.0975],
             [112.0986],
             [112.1027],
             [112.1027]],

            [[112.0947],
             [112.0936],
             [112.0927],
             [112.0957]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3367, 448.3867, 448.5402,  ..., 448.5872, 448.4014, 448.3766],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3367, 448.3867, 448.5402,  ..., 448.5872, 448.4014, 448.3766],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0857],
             [112.0846],
             [112.0871],
             [112.0835]],

            [[112.1425],
             [112.1425],
             [112.1425],
             [112.1425]],

            [[112.0822],
             [112.0815],
             [112.0817],
             [112.0817]],

            ...,

            [[112.1426],
             [112.1426],
             [112.1426],
             [112.1426]],

            [[112.1521],
             [112.0911],
             [112.1568],
             [112.1568]],

            [[112.0880],
             [112.0912],
             [112.0913],
             [112.0870]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3409, 448.5700, 448.3271,  ..., 448.5704, 448.5568, 448.3575],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3409, 448.5700, 448.3271,  ..., 448.5704, 448.5568, 448.3575],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0740],
             [112.0730],
             [112.0746],
             [112.0730]],

            [[112.0752],
             [112.0769],
             [112.0758],
             [112.0736]],

            [[112.1524],
             [112.1524],
             [112.1524],
             [112.1524]],

            ...,

            [[112.0760],
             [112.0736],
             [112.0765],
             [112.0779]],

            [[112.0755],
             [112.0769],
             [112.0751],
             [112.0736]],

            [[112.0811],
             [112.0811],
             [112.0801],
             [112.0801]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2946, 448.3016, 448.6094,  ..., 448.3041, 448.3010, 448.3223],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2946, 448.3016, 448.6094,  ..., 448.3041, 448.3010, 448.3223],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0732],
             [112.0688],
             [112.0731],
             [112.0687]],

            [[112.1578],
             [112.1578],
             [112.1578],
             [112.1578]],

            [[112.0729],
             [112.0683],
             [112.0716],
             [112.0716]],

            ...,

            [[112.1582],
             [112.1602],
             [112.1590],
             [112.1806]],

            [[112.0716],
             [112.0716],
             [112.0688],
             [112.0688]],

            [[112.1590],
             [112.1863],
             [112.1588],
             [112.1815]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2838, 448.6312, 448.2845,  ..., 448.6581, 448.2808, 448.6856],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2838, 448.6312, 448.2845,  ..., 448.6581, 448.2808, 448.6856],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9922e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1655],
             [112.1650],
             [112.1650],
             [112.1661]],

            [[112.0647],
             [112.0623],
             [112.0611],
             [112.0648]],

            [[112.0643],
             [112.0616],
             [112.0629],
             [112.0630]],

            ...,

            [[112.0651],
             [112.0612],
             [112.0646],
             [112.0646]],

            [[112.0664],
             [112.0634],
             [112.0635],
             [112.0661]],

            [[112.0609],
             [112.0609],
             [112.0610],
             [112.0610]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6615, 448.2529, 448.2519,  ..., 448.2554, 448.2594, 448.2437],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6615, 448.2529, 448.2519,  ..., 448.2554, 448.2594, 448.2437],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0652],
             [112.0638],
             [112.0609],
             [112.0609]],

            [[112.0607],
             [112.0611],
             [112.0621],
             [112.0623]],

            [[112.0648],
             [112.0634],
             [112.0616],
             [112.0616]],

            ...,

            [[112.0657],
             [112.0619],
             [112.0640],
             [112.0640]],

            [[112.0769],
             [112.0660],
             [112.0648],
             [112.0648]],

            [[112.0637],
             [112.0607],
             [112.0632],
             [112.0608]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2509, 448.2462, 448.2514,  ..., 448.2556, 448.2726, 448.2484],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2509, 448.2462, 448.2514,  ..., 448.2556, 448.2726, 448.2484],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0626],
             [112.0607],
             [112.0617],
             [112.0607]],

            [[112.0652],
             [112.0653],
             [112.0613],
             [112.0613]],

            [[112.0642],
             [112.0637],
             [112.0625],
             [112.0611]],

            ...,

            [[112.0610],
             [112.0610],
             [112.0608],
             [112.0608]],

            [[112.0641],
             [112.0615],
             [112.0608],
             [112.0638]],

            [[112.1835],
             [112.0653],
             [112.1916],
             [112.0655]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2458, 448.2532, 448.2515, 448.6600, 448.2533, 448.2659, 448.2599,
            448.2499, 448.6598, 448.2556, 448.2457, 448.2558, 448.2550, 448.2700,
            448.2518, 448.2740, 448.6724, 448.5946, 448.2685, 448.6601, 448.6632,
            448.2667, 448.2601, 448.2556, 448.2537, 448.2555, 448.6597, 448.2494,
            448.2521, 448.6596, 448.2618, 448.2552, 448.2534, 448.4852, 448.2451,
            448.2527, 448.2530, 448.6829, 448.2521, 448.2391, 448.2174, 448.4905,
            448.2684, 448.2428, 448.2534, 448.6596, 448.5091, 448.2850, 448.6385,
            448.2516, 448.2643, 448.2506, 448.2527, 448.2467, 448.2606, 448.6759,
            448.2526, 448.2521, 448.6620, 448.2607, 448.2483, 448.2575, 448.2484,
            448.6596, 448.2598, 448.2464, 448.2569, 448.2636, 448.2450, 448.2476,
            448.2489, 448.2427, 448.6597, 448.2999, 448.2472, 448.6599, 448.2604,
            448.6047, 448.6599, 448.6601, 448.2562, 448.2494, 448.6129, 448.5182,
            448.6046, 448.2607, 448.4800, 448.6597, 448.2554, 448.2775, 448.2424,
            448.2514, 448.2579, 448.2574, 448.2442, 448.3810, 448.6596, 448.2450,
            448.2541, 448.2173, 448.6880, 448.2509, 448.2442, 448.2491, 448.4918,
            448.2543, 448.2520, 448.2499, 448.6606, 448.2465, 448.2620, 448.2598,
            448.3167, 448.6597, 448.6784, 448.6596, 448.6651, 448.2509, 448.2570,
            448.6596, 448.2472, 448.2501, 448.6597, 448.6600, 448.2481, 448.2620,
            448.6596, 448.2455, 448.4827, 448.2513, 448.2684, 448.2482, 448.6501,
            448.5237, 448.2514, 448.2553, 448.6703, 448.2440, 448.2818, 448.2528,
            448.2475, 448.3022, 448.2519, 448.6596, 448.2581, 448.6598, 448.6601,
            448.2532, 448.6601, 448.2464, 448.2513, 448.2504, 448.7225, 448.2525,
            448.2580, 448.2531, 448.6858, 448.2520, 448.6605, 448.2471, 448.2579,
            448.2518, 448.6689, 448.4992, 448.2527, 448.2637, 448.2512, 448.2533,
            448.2426, 448.6607, 448.2522, 448.6596, 448.2428, 448.6743, 448.6602,
            448.2499, 448.6599, 448.4074, 448.2515, 448.2515, 448.2774, 448.6713,
            448.6596, 448.2505, 448.2505, 448.2534, 448.2523, 448.2513, 448.6596,
            448.2445, 448.2530, 448.2561, 448.4128, 448.2616, 448.2460, 448.2523,
            448.2523, 448.6176, 448.6596, 448.2462, 448.2464, 448.2796, 448.6833,
            448.6598, 448.6596, 448.6639, 448.2471, 448.2497, 448.6649, 448.2611,
            448.2717, 448.2608, 448.2549, 448.2175, 448.2526, 448.3812, 448.2608,
            448.6596, 448.2563, 448.6791, 448.2549, 448.6615, 448.2623, 448.2473,
            448.2431, 448.2528, 448.2427, 448.6663, 448.6603, 448.6622, 448.6596,
            448.2531, 448.2595, 448.2508, 448.5230, 448.4904, 448.2553, 448.2457,
            448.6598, 448.2464, 448.6712, 448.2548, 448.2722, 448.2173, 448.2541,
            448.2618, 448.5421, 448.5007, 448.4613, 448.2767, 448.4957, 448.3754,
            448.2521, 448.2524, 448.5430, 448.4819, 448.2505, 448.2533, 448.4823,
            448.6596, 448.6596, 448.2566, 448.2460, 448.6596, 448.2563, 448.2540,
            448.6935, 448.2507, 448.2516, 448.2535, 448.3820, 448.2522, 448.2424,
            448.6609, 448.2617, 448.6858, 448.4836, 448.6596, 448.2503, 448.6596,
            448.3953, 448.6596, 448.6724, 448.2530, 448.2572, 448.2424, 448.2534,
            448.6637, 448.2438, 448.2517, 448.2515, 448.2575, 448.2541, 448.2515,
            448.2536, 448.2523, 448.2550, 448.2884, 448.6598, 448.2567, 448.6596,
            448.6618, 448.2656, 448.2526, 448.2664, 448.2443, 448.2554, 448.2441,
            448.2596, 448.2556, 448.2576, 448.2522, 448.2538, 448.2447, 448.6597,
            448.2519, 448.6596, 448.2430, 448.6812, 448.2652, 448.2580, 448.6615,
            448.2472, 448.6596, 448.6700, 448.2755, 448.2521, 448.6024, 448.2500,
            448.2516, 448.2567, 448.2512, 448.2515, 448.2504, 448.4267, 448.2472,
            448.7006, 448.2518, 448.6596, 448.2666, 448.6822, 448.2849, 448.2660,
            448.2701, 448.2545, 448.2537, 448.2513, 448.2474, 448.2524, 448.6659,
            448.2454, 448.2562, 448.6603, 448.6642, 448.6596, 448.2542, 448.6596,
            448.6827, 448.2430, 448.4852, 448.6603, 448.2591, 448.2553, 448.3923,
            448.2474, 448.2458, 448.2684, 448.6846, 448.2530, 448.6596, 448.2650,
            448.2457, 448.2527, 448.2460, 448.6717, 448.2570, 448.2571, 448.2227,
            448.6598, 448.2492, 448.2538, 448.2520, 448.5858, 448.4820, 448.2617,
            448.6641, 448.2426, 448.2596, 448.4902, 448.2470, 448.6324, 448.2633,
            448.2740, 448.6596, 448.7342, 448.2608, 448.2550, 448.6683, 448.2498,
            448.2554, 448.6596, 448.6599, 448.2531, 448.2542, 448.2540, 448.2512,
            448.4858, 448.2526, 448.2500, 448.2563, 448.2430, 448.2464, 448.2576,
            448.2548, 448.2694, 448.6846, 448.2426, 448.2438, 448.2538, 448.2524,
            448.2510, 448.2641, 448.6596, 448.6597, 448.2536, 448.6650, 448.2620,
            448.2506, 448.2562, 448.2788, 448.6033, 448.2517, 448.2810, 448.6596,
            448.2498, 448.4732, 448.2503, 448.4917, 448.2513, 448.6596, 448.6647,
            448.2931, 448.2467, 448.2766, 448.6608, 448.6755, 448.2629, 448.2612,
            448.2596, 448.2492, 448.2457, 448.6694, 448.6614, 448.2532, 448.6597,
            448.6755, 448.6596, 448.5819, 448.2448, 448.2688, 448.2559, 448.2496,
            448.6619, 448.3216, 448.6632, 448.2452, 448.2559, 448.2467, 448.2720,
            448.6597, 448.6599, 448.2573, 448.4488, 448.4838, 448.6596, 448.2500,
            448.2601, 448.2543, 448.2529, 448.2900, 448.2446, 448.2591, 448.2559,
            448.2530, 448.6597, 448.2468, 448.2456, 448.2476, 448.2515, 448.2630,
            448.2469, 448.2610, 448.2534, 448.6620, 448.2175, 448.2478, 448.2559,
            448.2625, 448.2458, 448.2575, 448.2467, 448.6596, 448.2520, 448.2529,
            448.6613, 448.3074, 448.6628, 448.2495, 448.5071, 448.2664, 448.2714,
            448.4337, 448.4806, 448.2574, 448.2535, 448.6827, 448.2875, 448.2482,
            448.2585, 448.2455, 448.2464, 448.4901, 448.6599, 448.2512, 448.6596,
            448.2651, 448.4496, 448.6596, 448.6596, 448.6622, 448.2602, 448.3116,
            448.6701, 448.6661, 448.6636, 448.2509, 448.2496, 448.2541, 448.6596,
            448.2654, 448.2609, 448.2539, 448.2571, 448.2614, 448.6912, 448.6801,
            448.2514, 448.2427, 448.2493, 448.2518, 448.2602, 448.2541, 448.6738,
            448.2576, 448.6627, 448.2458, 448.2599, 448.2526, 448.3292, 448.2542,
            448.2525, 448.6596, 448.2513, 448.2531, 448.2531, 448.2462, 448.6996,
            448.2459, 448.5001, 448.4971, 448.6748, 448.2487, 448.2490, 448.2499,
            448.2593, 448.4831, 448.6605, 448.2523, 448.2607, 448.2546, 448.2575,
            448.6597, 448.2661, 448.2424, 448.3902, 448.6794, 448.2707, 448.2473,
            448.3950, 448.2511, 448.6596, 448.2457, 448.6597, 448.2540, 448.2533,
            448.4835, 448.6638, 448.2522, 448.2542, 448.2462, 448.6765, 448.2480,
            448.2529, 448.2641, 448.2543, 448.2516, 448.2474, 448.2540, 448.4956,
            448.2517, 448.6596, 448.6627, 448.2492, 448.2520, 448.2542, 448.2510,
            448.2658, 448.2714, 448.3753, 448.2493, 448.2498, 448.2468, 448.6602,
            448.3987, 448.6598, 448.2690, 448.2429, 448.6674, 448.6616, 448.2555,
            448.2531, 448.6599, 448.6642, 448.2532, 448.6600, 448.6609, 448.5968,
            448.6623, 448.2480, 448.2528, 448.3751, 448.6618, 448.2540, 448.2194,
            448.2681, 448.2489, 448.4994, 448.2635, 448.6638, 448.2486, 448.2563,
            448.5341, 448.6755, 448.6608, 448.4935, 448.2669, 448.2471, 448.2876,
            448.2515, 448.2664, 448.2938, 448.2505, 448.2522, 448.6596, 448.5552,
            448.2462, 448.6626, 448.2469, 448.2512, 448.2509, 448.2488, 448.2575,
            448.2540, 448.4980, 448.6783, 448.2572, 448.2960, 448.2515, 448.6609,
            448.2540, 448.6623, 448.2791, 448.3442, 448.2865, 448.2526, 448.2603,
            448.2530, 448.6596, 448.6597, 448.2568, 448.7479, 448.2617, 448.6828,
            448.2538, 448.2558, 448.2499, 448.2462, 448.2520, 448.2527, 448.6721,
            448.6596, 448.6601, 448.2428, 448.2505, 448.2523, 448.6599, 448.5963,
            448.6596, 448.2431, 448.6604, 448.4992, 448.2495, 448.5099, 448.2461,
            448.2516, 448.2507, 448.2477, 448.2519, 448.2499, 448.2514, 448.2517,
            448.3155, 448.2458, 448.7293, 448.4922, 448.2536, 448.2705, 448.2568,
            448.2530, 448.2622, 448.2579, 448.6600, 448.2486, 448.6596, 448.2532,
            448.3005, 448.6098, 448.2526, 448.6630, 448.2571, 448.6596, 448.2591,
            448.2566, 448.2526, 448.6091, 448.6791, 448.6596, 448.2571, 448.2528,
            448.6630, 448.2657, 448.2853, 448.2599, 448.2570, 448.2664, 448.2638,
            448.6596, 448.6596, 448.2520, 448.2533, 448.4844, 448.2515, 448.2502,
            448.2484, 448.2557, 448.2449, 448.4802, 448.6608, 448.6596, 448.2572,
            448.6619, 448.5137, 448.6596, 448.6612, 448.2533, 448.4848, 448.2529,
            448.2506, 448.5070, 448.6701, 448.6150, 448.2511, 448.6631, 448.4847,
            448.2548, 448.5299, 448.2453, 448.2475, 448.2726, 448.2701, 448.2482,
            448.4852, 448.2536, 448.3472, 448.6596, 448.2528, 448.2461, 448.6652,
            448.6601, 448.7766, 448.2612, 448.6596, 448.2540, 448.4929, 448.2707,
            448.6596, 448.2560, 448.2460, 448.5138, 448.6596, 448.2634, 448.2522,
            448.6596, 448.2552, 448.2568, 448.2429, 448.2475, 448.2531, 448.2532,
            448.2504, 448.2539, 448.2487, 448.2522, 448.2521, 448.2513, 448.2722,
            448.6596, 448.2500, 448.6617, 448.5101, 448.2458, 448.6597, 448.2576,
            448.2569, 448.4932, 448.2541, 448.5040, 448.2638, 448.2563, 448.2466,
            448.6600, 448.4461, 448.2431, 448.2512, 448.6845, 448.2512, 448.2587,
            448.6596, 448.2512, 448.2567, 448.2526, 448.2535, 448.2486, 448.2569,
            448.2668, 448.2551, 448.2523, 448.2508, 448.2521, 448.2463, 448.2565,
            448.2437, 448.6608, 448.6631, 448.2848, 448.6931, 448.2534, 448.2523,
            448.6596, 448.2462, 448.6619, 448.2480, 448.2543, 448.6609, 448.4927,
            448.2972, 448.6758, 448.2503, 448.6603, 448.2552, 448.2474, 448.2537,
            448.6596, 448.2523, 448.2515, 448.2471, 448.2522, 448.6596, 448.2430,
            448.2425, 448.2509, 448.2497, 448.2482, 448.2499, 448.6640, 448.6615,
            448.6599, 448.6599, 448.6606, 448.6816, 448.2549, 448.2530, 448.2607,
            448.2534, 448.2629, 448.2580, 448.6596, 448.6596, 448.6596, 448.2521,
            448.7310, 448.2683, 448.2512, 448.2524, 448.6668, 448.6726, 448.2501,
            448.3783, 448.6598, 448.2570, 448.2564, 448.2513, 448.2573, 448.2435,
            448.2503, 448.5059], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2458, 448.2532, 448.2515, 448.6600, 448.2533, 448.2659, 448.2599,
        448.2499, 448.6598, 448.2556, 448.2457, 448.2558, 448.2550, 448.2700,
        448.2518, 448.2740, 448.6724, 448.5946, 448.2685, 448.6601, 448.6632,
        448.2667, 448.2601, 448.2556, 448.2537, 448.2555, 448.6597, 448.2494,
        448.2521, 448.6596, 448.2618, 448.2552, 448.2534, 448.4852, 448.2451,
        448.2527, 448.2530, 448.6829, 448.2521, 448.2391, 448.2174, 448.4905,
        448.2684, 448.2428, 448.2534, 448.6596, 448.5091, 448.2850, 448.6385,
        448.2516, 448.2643, 448.2506, 448.2527, 448.2467, 448.2606, 448.6759,
        448.2526, 448.2521, 448.6620, 448.2607, 448.2483, 448.2575, 448.2484,
        448.6596, 448.2598, 448.2464, 448.2569, 448.2636, 448.2450, 448.2476,
        448.2489, 448.2427, 448.6597, 448.2999, 448.2472, 448.6599, 448.2604,
        448.6047, 448.6599, 448.6601, 448.2562, 448.2494, 448.6129, 448.5182,
        448.6046, 448.2607, 448.4800, 448.6597, 448.2554, 448.2775, 448.2424,
        448.2514, 448.2579, 448.2574, 448.2442, 448.3810, 448.6596, 448.2450,
        448.2541, 448.2173, 448.6880, 448.2509, 448.2442, 448.2491, 448.4918,
        448.2543, 448.2520, 448.2499, 448.6606, 448.2465, 448.2620, 448.2598,
        448.3167, 448.6597, 448.6784, 448.6596, 448.6651, 448.2509, 448.2570,
        448.6596, 448.2472, 448.2501, 448.6597, 448.6600, 448.2481, 448.2620,
        448.6596, 448.2455, 448.4827, 448.2513, 448.2684, 448.2482, 448.6501,
        448.5237, 448.2514, 448.2553, 448.6703, 448.2440, 448.2818, 448.2528,
        448.2475, 448.3022, 448.2519, 448.6596, 448.2581, 448.6598, 448.6601,
        448.2532, 448.6601, 448.2464, 448.2513, 448.2504, 448.7225, 448.2525,
        448.2580, 448.2531, 448.6858, 448.2520, 448.6605, 448.2471, 448.2579,
        448.2518, 448.6689, 448.4992, 448.2527, 448.2637, 448.2512, 448.2533,
        448.2426, 448.6607, 448.2522, 448.6596, 448.2428, 448.6743, 448.6602,
        448.2499, 448.6599, 448.4074, 448.2515, 448.2515, 448.2774, 448.6713,
        448.6596, 448.2505, 448.2505, 448.2534, 448.2523, 448.2513, 448.6596,
        448.2445, 448.2530, 448.2561, 448.4128, 448.2616, 448.2460, 448.2523,
        448.2523, 448.6176, 448.6596, 448.2462, 448.2464, 448.2796, 448.6833,
        448.6598, 448.6596, 448.6639, 448.2471, 448.2497, 448.6649, 448.2611,
        448.2717, 448.2608, 448.2549, 448.2175, 448.2526, 448.3812, 448.2608,
        448.6596, 448.2563, 448.6791, 448.2549, 448.6615, 448.2623, 448.2473,
        448.2431, 448.2528, 448.2427, 448.6663, 448.6603, 448.6622, 448.6596,
        448.2531, 448.2595, 448.2508, 448.5230, 448.4904, 448.2553, 448.2457,
        448.6598, 448.2464, 448.6712, 448.2548, 448.2722, 448.2173, 448.2541,
        448.2618, 448.5421, 448.5007, 448.4613, 448.2767, 448.4957, 448.3754,
        448.2521, 448.2524, 448.5430, 448.4819, 448.2505, 448.2533, 448.4823,
        448.6596, 448.6596, 448.2566, 448.2460, 448.6596, 448.2563, 448.2540,
        448.6935, 448.2507, 448.2516, 448.2535, 448.3820, 448.2522, 448.2424,
        448.6609, 448.2617, 448.6858, 448.4836, 448.6596, 448.2503, 448.6596,
        448.3953, 448.6596, 448.6724, 448.2530, 448.2572, 448.2424, 448.2534,
        448.6637, 448.2438, 448.2517, 448.2515, 448.2575, 448.2541, 448.2515,
        448.2536, 448.2523, 448.2550, 448.2884, 448.6598, 448.2567, 448.6596,
        448.6618, 448.2656, 448.2526, 448.2664, 448.2443, 448.2554, 448.2441,
        448.2596, 448.2556, 448.2576, 448.2522, 448.2538, 448.2447, 448.6597,
        448.2519, 448.6596, 448.2430, 448.6812, 448.2652, 448.2580, 448.6615,
        448.2472, 448.6596, 448.6700, 448.2755, 448.2521, 448.6024, 448.2500,
        448.2516, 448.2567, 448.2512, 448.2515, 448.2504, 448.4267, 448.2472,
        448.7006, 448.2518, 448.6596, 448.2666, 448.6822, 448.2849, 448.2660,
        448.2701, 448.2545, 448.2537, 448.2513, 448.2474, 448.2524, 448.6659,
        448.2454, 448.2562, 448.6603, 448.6642, 448.6596, 448.2542, 448.6596,
        448.6827, 448.2430, 448.4852, 448.6603, 448.2591, 448.2553, 448.3923,
        448.2474, 448.2458, 448.2684, 448.6846, 448.2530, 448.6596, 448.2650,
        448.2457, 448.2527, 448.2460, 448.6717, 448.2570, 448.2571, 448.2227,
        448.6598, 448.2492, 448.2538, 448.2520, 448.5858, 448.4820, 448.2617,
        448.6641, 448.2426, 448.2596, 448.4902, 448.2470, 448.6324, 448.2633,
        448.2740, 448.6596, 448.7342, 448.2608, 448.2550, 448.6683, 448.2498,
        448.2554, 448.6596, 448.6599, 448.2531, 448.2542, 448.2540, 448.2512,
        448.4858, 448.2526, 448.2500, 448.2563, 448.2430, 448.2464, 448.2576,
        448.2548, 448.2694, 448.6846, 448.2426, 448.2438, 448.2538, 448.2524,
        448.2510, 448.2641, 448.6596, 448.6597, 448.2536, 448.6650, 448.2620,
        448.2506, 448.2562, 448.2788, 448.6033, 448.2517, 448.2810, 448.6596,
        448.2498, 448.4732, 448.2503, 448.4917, 448.2513, 448.6596, 448.6647,
        448.2931, 448.2467, 448.2766, 448.6608, 448.6755, 448.2629, 448.2612,
        448.2596, 448.2492, 448.2457, 448.6694, 448.6614, 448.2532, 448.6597,
        448.6755, 448.6596, 448.5819, 448.2448, 448.2688, 448.2559, 448.2496,
        448.6619, 448.3216, 448.6632, 448.2452, 448.2559, 448.2467, 448.2720,
        448.6597, 448.6599, 448.2573, 448.4488, 448.4838, 448.6596, 448.2500,
        448.2601, 448.2543, 448.2529, 448.2900, 448.2446, 448.2591, 448.2559,
        448.2530, 448.6597, 448.2468, 448.2456, 448.2476, 448.2515, 448.2630,
        448.2469, 448.2610, 448.2534, 448.6620, 448.2175, 448.2478, 448.2559,
        448.2625, 448.2458, 448.2575, 448.2467, 448.6596, 448.2520, 448.2529,
        448.6613, 448.3074, 448.6628, 448.2495, 448.5071, 448.2664, 448.2714,
        448.4337, 448.4806, 448.2574, 448.2535, 448.6827, 448.2875, 448.2482,
        448.2585, 448.2455, 448.2464, 448.4901, 448.6599, 448.2512, 448.6596,
        448.2651, 448.4496, 448.6596, 448.6596, 448.6622, 448.2602, 448.3116,
        448.6701, 448.6661, 448.6636, 448.2509, 448.2496, 448.2541, 448.6596,
        448.2654, 448.2609, 448.2539, 448.2571, 448.2614, 448.6912, 448.6801,
        448.2514, 448.2427, 448.2493, 448.2518, 448.2602, 448.2541, 448.6738,
        448.2576, 448.6627, 448.2458, 448.2599, 448.2526, 448.3292, 448.2542,
        448.2525, 448.6596, 448.2513, 448.2531, 448.2531, 448.2462, 448.6996,
        448.2459, 448.5001, 448.4971, 448.6748, 448.2487, 448.2490, 448.2499,
        448.2593, 448.4831, 448.6605, 448.2523, 448.2607, 448.2546, 448.2575,
        448.6597, 448.2661, 448.2424, 448.3902, 448.6794, 448.2707, 448.2473,
        448.3950, 448.2511, 448.6596, 448.2457, 448.6597, 448.2540, 448.2533,
        448.4835, 448.6638, 448.2522, 448.2542, 448.2462, 448.6765, 448.2480,
        448.2529, 448.2641, 448.2543, 448.2516, 448.2474, 448.2540, 448.4956,
        448.2517, 448.6596, 448.6627, 448.2492, 448.2520, 448.2542, 448.2510,
        448.2658, 448.2714, 448.3753, 448.2493, 448.2498, 448.2468, 448.6602,
        448.3987, 448.6598, 448.2690, 448.2429, 448.6674, 448.6616, 448.2555,
        448.2531, 448.6599, 448.6642, 448.2532, 448.6600, 448.6609, 448.5968,
        448.6623, 448.2480, 448.2528, 448.3751, 448.6618, 448.2540, 448.2194,
        448.2681, 448.2489, 448.4994, 448.2635, 448.6638, 448.2486, 448.2563,
        448.5341, 448.6755, 448.6608, 448.4935, 448.2669, 448.2471, 448.2876,
        448.2515, 448.2664, 448.2938, 448.2505, 448.2522, 448.6596, 448.5552,
        448.2462, 448.6626, 448.2469, 448.2512, 448.2509, 448.2488, 448.2575,
        448.2540, 448.4980, 448.6783, 448.2572, 448.2960, 448.2515, 448.6609,
        448.2540, 448.6623, 448.2791, 448.3442, 448.2865, 448.2526, 448.2603,
        448.2530, 448.6596, 448.6597, 448.2568, 448.7479, 448.2617, 448.6828,
        448.2538, 448.2558, 448.2499, 448.2462, 448.2520, 448.2527, 448.6721,
        448.6596, 448.6601, 448.2428, 448.2505, 448.2523, 448.6599, 448.5963,
        448.6596, 448.2431, 448.6604, 448.4992, 448.2495, 448.5099, 448.2461,
        448.2516, 448.2507, 448.2477, 448.2519, 448.2499, 448.2514, 448.2517,
        448.3155, 448.2458, 448.7293, 448.4922, 448.2536, 448.2705, 448.2568,
        448.2530, 448.2622, 448.2579, 448.6600, 448.2486, 448.6596, 448.2532,
        448.3005, 448.6098, 448.2526, 448.6630, 448.2571, 448.6596, 448.2591,
        448.2566, 448.2526, 448.6091, 448.6791, 448.6596, 448.2571, 448.2528,
        448.6630, 448.2657, 448.2853, 448.2599, 448.2570, 448.2664, 448.2638,
        448.6596, 448.6596, 448.2520, 448.2533, 448.4844, 448.2515, 448.2502,
        448.2484, 448.2557, 448.2449, 448.4802, 448.6608, 448.6596, 448.2572,
        448.6619, 448.5137, 448.6596, 448.6612, 448.2533, 448.4848, 448.2529,
        448.2506, 448.5070, 448.6701, 448.6150, 448.2511, 448.6631, 448.4847,
        448.2548, 448.5299, 448.2453, 448.2475, 448.2726, 448.2701, 448.2482,
        448.4852, 448.2536, 448.3472, 448.6596, 448.2528, 448.2461, 448.6652,
        448.6601, 448.7766, 448.2612, 448.6596, 448.2540, 448.4929, 448.2707,
        448.6596, 448.2560, 448.2460, 448.5138, 448.6596, 448.2634, 448.2522,
        448.6596, 448.2552, 448.2568, 448.2429, 448.2475, 448.2531, 448.2532,
        448.2504, 448.2539, 448.2487, 448.2522, 448.2521, 448.2513, 448.2722,
        448.6596, 448.2500, 448.6617, 448.5101, 448.2458, 448.6597, 448.2576,
        448.2569, 448.4932, 448.2541, 448.5040, 448.2638, 448.2563, 448.2466,
        448.6600, 448.4461, 448.2431, 448.2512, 448.6845, 448.2512, 448.2587,
        448.6596, 448.2512, 448.2567, 448.2526, 448.2535, 448.2486, 448.2569,
        448.2668, 448.2551, 448.2523, 448.2508, 448.2521, 448.2463, 448.2565,
        448.2437, 448.6608, 448.6631, 448.2848, 448.6931, 448.2534, 448.2523,
        448.6596, 448.2462, 448.6619, 448.2480, 448.2543, 448.6609, 448.4927,
        448.2972, 448.6758, 448.2503, 448.6603, 448.2552, 448.2474, 448.2537,
        448.6596, 448.2523, 448.2515, 448.2471, 448.2522, 448.6596, 448.2430,
        448.2425, 448.2509, 448.2497, 448.2482, 448.2499, 448.6640, 448.6615,
        448.6599, 448.6599, 448.6606, 448.6816, 448.2549, 448.2530, 448.2607,
        448.2534, 448.2629, 448.2580, 448.6596, 448.6596, 448.6596, 448.2521,
        448.7310, 448.2683, 448.2512, 448.2524, 448.6668, 448.6726, 448.2501,
        448.3783, 448.6598, 448.2570, 448.2564, 448.2513, 448.2573, 448.2435,
        448.2503, 448.5059], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([411.4843], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0676],
             [112.0635],
             [112.0661],
             [112.0629]],

            [[112.0649],
             [112.0649],
             [112.0611],
             [112.0611]],

            [[112.0624],
             [112.0657],
             [112.0628],
             [112.0666]],

            ...,

            [[112.0606],
             [112.0606],
             [112.0608],
             [112.0608]],

            [[112.1655],
             [112.1725],
             [112.1654],
             [112.1719]],

            [[112.0743],
             [112.0743],
             [112.0711],
             [112.0711]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2601, 448.2521, 448.2575,  ..., 448.2429, 448.6754, 448.2908],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2601, 448.2521, 448.2575,  ..., 448.2429, 448.6754, 448.2908],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1742],
             [112.1742],
             [112.1742],
             [112.1742]],

            [[112.0533],
             [112.0505],
             [112.0513],
             [112.0513]],

            [[112.0523],
             [112.0551],
             [112.0543],
             [112.0506]],

            ...,

            [[112.1753],
             [112.1842],
             [112.1751],
             [112.1751]],

            [[112.0537],
             [112.0537],
             [112.0533],
             [112.0533]],

            [[112.0552],
             [112.0552],
             [112.0546],
             [112.0546]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6969, 448.2063, 448.2122,  ..., 448.7096, 448.2141, 448.2198],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6969, 448.2063, 448.2122,  ..., 448.7096, 448.2141, 448.2198],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0452],
             [112.0450],
             [112.0459],
             [112.0425]],

            [[112.0459],
             [112.0588],
             [112.0594],
             [112.0453]],

            [[112.0435],
             [112.0425],
             [112.0442],
             [112.0422]],

            ...,

            [[112.0450],
             [112.0417],
             [112.0457],
             [112.0436]],

            [[112.0484],
             [112.0484],
             [112.0449],
             [112.0449]],

            [[112.0450],
             [112.0418],
             [112.0458],
             [112.0444]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1786, 448.2094, 448.1724,  ..., 448.1761, 448.1867, 448.1770],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1786, 448.2094, 448.1724,  ..., 448.1761, 448.1867, 448.1770],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0365],
             [112.0365],
             [112.0338],
             [112.0350]],

            [[112.0384],
             [112.0372],
             [112.0374],
             [112.0352]],

            [[112.0342],
             [112.0387],
             [112.0345],
             [112.0345]],

            ...,

            [[112.0351],
             [112.0340],
             [112.0349],
             [112.0341]],

            [[112.0388],
             [112.0359],
             [112.0386],
             [112.0359]],

            [[112.1887],
             [112.1887],
             [112.1887],
             [112.1887]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1419, 448.1481, 448.1419,  ..., 448.1381, 448.1491, 448.7549],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1419, 448.1481, 448.1419,  ..., 448.1381, 448.1491, 448.7549],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0377],
             [112.0299],
             [112.0306],
             [112.0306]],

            [[112.0313],
             [112.0314],
             [112.0287],
             [112.0287]],

            [[112.0306],
             [112.0271],
             [112.0290],
             [112.0290]],

            ...,

            [[112.0289],
             [112.0272],
             [112.0305],
             [112.0296]],

            [[112.1946],
             [112.1984],
             [112.1957],
             [112.1957]],

            [[112.1995],
             [112.1947],
             [112.1948],
             [112.1999]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1288, 448.1201, 448.1157,  ..., 448.1161, 448.7844, 448.7888],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1288, 448.1201, 448.1157,  ..., 448.1161, 448.7844, 448.7888],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0395],
             [112.0284],
             [112.0273],
             [112.0273]],

            [[112.1971],
             [112.1971],
             [112.1972],
             [112.1972]],

            [[112.0250],
             [112.0270],
             [112.0243],
             [112.0250]],

            ...,

            [[112.1987],
             [112.2027],
             [112.2094],
             [112.0444]],

            [[112.0241],
             [112.0241],
             [112.0240],
             [112.0240]],

            [[112.0248],
             [112.0278],
             [112.0260],
             [112.0243]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1226, 448.7885, 448.1012,  ..., 448.6552, 448.0962, 448.1030],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1226, 448.7885, 448.1012,  ..., 448.6552, 448.0962, 448.1030],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0231],
             [112.0241],
             [112.0214],
             [112.0246]],

            [[112.2025],
             [112.2143],
             [112.2062],
             [112.0267]],

            [[112.0252],
             [112.0223],
             [112.0256],
             [112.0230]],

            ...,

            [[112.0230],
             [112.0215],
             [112.0245],
             [112.0233]],

            [[112.1996],
             [112.1996],
             [112.1996],
             [112.1996]],

            [[112.0232],
             [112.0232],
             [112.0229],
             [112.0229]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0931, 448.6497, 448.0960,  ..., 448.0922, 448.7986, 448.0923],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0931, 448.6497, 448.0960,  ..., 448.0922, 448.7986, 448.0923],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0208],
             [112.0180],
             [112.0195],
             [112.0195]],

            [[112.0195],
             [112.0177],
             [112.0200],
             [112.0172]],

            [[112.2082],
             [112.2082],
             [112.0464],
             [112.0464]],

            ...,

            [[112.0171],
             [112.0198],
             [112.0190],
             [112.0190]],

            [[112.0201],
             [112.0181],
             [112.0185],
             [112.0172]],

            [[112.0234],
             [112.0197],
             [112.0209],
             [112.0209]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0779, 448.0744, 448.5092,  ..., 448.0750, 448.0740, 448.0850],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0779, 448.0744, 448.5092,  ..., 448.0750, 448.0740, 448.0850],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0202],
             [112.0211],
             [112.0213],
             [112.0190]],

            [[112.2123],
             [112.0232],
             [112.2073],
             [112.0237]],

            [[112.0227],
             [112.0227],
             [112.0200],
             [112.0200]],

            ...,

            [[112.0187],
             [112.0187],
             [112.0187],
             [112.0187]],

            [[112.0220],
             [112.0210],
             [112.0192],
             [112.0192]],

            [[112.0200],
             [112.0200],
             [112.0188],
             [112.0188]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0816, 448.4665, 448.0855,  ..., 448.0748, 448.0815, 448.0776],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0816, 448.4665, 448.0855,  ..., 448.0748, 448.0815, 448.0776],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0278],
             [112.0301],
             [112.0271],
             [112.0271]],

            [[112.1970],
             [112.1978],
             [112.1970],
             [112.1976]],

            [[112.0284],
             [112.0284],
             [112.0284],
             [112.0284]],

            ...,

            [[112.1976],
             [112.2057],
             [112.1974],
             [112.2043]],

            [[112.1972],
             [112.1972],
             [112.1973],
             [112.1973]],

            [[112.2081],
             [112.0304],
             [112.2082],
             [112.0304]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1122, 448.7895, 448.1135,  ..., 448.8051, 448.7890, 448.4771],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1122, 448.7895, 448.1135,  ..., 448.8051, 448.7890, 448.4771],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0483],
             [112.0393],
             [112.0411],
             [112.0411]],

            [[112.0401],
             [112.0378],
             [112.0380],
             [112.0380]],

            [[112.1897],
             [112.1894],
             [112.1893],
             [112.1907]],

            ...,

            [[112.1901],
             [112.1901],
             [112.1896],
             [112.1914]],

            [[112.0382],
             [112.0365],
             [112.0387],
             [112.0387]],

            [[112.1894],
             [112.1912],
             [112.1912],
             [112.1892]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1698, 448.1539, 448.7591,  ..., 448.7611, 448.1521, 448.7611],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1698, 448.1539, 448.7591,  ..., 448.7611, 448.1521, 448.7611],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0460],
             [112.0464],
             [112.0432],
             [112.0432]],

            [[112.0459],
             [112.0429],
             [112.0455],
             [112.0429]],

            [[112.1846],
             [112.1857],
             [112.1856],
             [112.1845]],

            ...,

            [[112.0441],
             [112.0456],
             [112.0452],
             [112.0431]],

            [[112.0453],
             [112.0432],
             [112.0432],
             [112.0432]],

            [[112.0472],
             [112.0472],
             [112.0460],
             [112.0460]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1789, 448.1772, 448.7404,  ..., 448.1781, 448.1748, 448.1863],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1789, 448.1772, 448.7404,  ..., 448.1781, 448.1748, 448.1863],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0514],
             [112.0525],
             [112.0518],
             [112.0526]],

            [[112.0522],
             [112.0536],
             [112.0522],
             [112.0513]],

            [[112.1786],
             [112.1787],
             [112.1800],
             [112.1800]],

            ...,

            [[112.0536],
             [112.0536],
             [112.0536],
             [112.0536]],

            [[112.1784],
             [112.1784],
             [112.1784],
             [112.1784]],

            [[112.0524],
             [112.0514],
             [112.0537],
             [112.0526]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2083, 448.2094, 448.7173,  ..., 448.2142, 448.7137, 448.2101],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2083, 448.2094, 448.7173,  ..., 448.2142, 448.7137, 448.2101],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1179],
             [112.0594],
             [112.2088],
             [112.0595]],

            [[112.0577],
             [112.0577],
             [112.0574],
             [112.0574]],

            [[112.0584],
             [112.0579],
             [112.0579],
             [112.0572]],

            ...,

            [[112.0532],
             [112.0514],
             [112.0548],
             [112.0510]],

            [[112.0575],
             [112.0575],
             [112.0577],
             [112.0574]],

            [[112.1746],
             [112.1757],
             [112.1757],
             [112.1745]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4455, 448.2303, 448.2313,  ..., 448.2104, 448.2300, 448.7006],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4455, 448.2303, 448.2313,  ..., 448.2104, 448.2300, 448.7006],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0593],
             [112.0580],
             [112.0595],
             [112.0572]],

            [[112.1761],
             [112.0696],
             [112.1763],
             [112.0691]],

            [[112.0571],
             [112.0583],
             [112.0571],
             [112.0572]],

            ...,

            [[112.1777],
             [112.0619],
             [112.0702],
             [112.0702]],

            [[112.0586],
             [112.0604],
             [112.0600],
             [112.0574]],

            [[112.0679],
             [112.0601],
             [112.0596],
             [112.0596]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2339, 448.4911, 448.2298,  ..., 448.3799, 448.2365, 448.2473],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2339, 448.4911, 448.2298,  ..., 448.3799, 448.2365, 448.2473],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0549],
             [112.0555],
             [112.0545],
             [112.0550]],

            [[112.1907],
             [112.0571],
             [112.1855],
             [112.0573]],

            [[112.0563],
             [112.0563],
             [112.0546],
             [112.0537]],

            ...,

            [[112.0540],
             [112.0540],
             [112.0541],
             [112.0541]],

            [[112.0584],
             [112.0564],
             [112.0563],
             [112.0549]],

            [[112.0536],
             [112.0569],
             [112.0536],
             [112.0569]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2199, 448.4907, 448.2208,  ..., 448.2162, 448.2259, 448.2210],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2199, 448.4907, 448.2208,  ..., 448.2162, 448.2259, 448.2210],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0564],
             [112.0564],
             [112.0543],
             [112.0543]],

            [[112.1864],
             [112.1864],
             [112.0569],
             [112.0569]],

            [[112.1753],
             [112.1749],
             [112.1749],
             [112.1757]],

            ...,

            [[112.1749],
             [112.1749],
             [112.1760],
             [112.1760]],

            [[112.0727],
             [112.0560],
             [112.0587],
             [112.0587]],

            [[112.0565],
             [112.0565],
             [112.0564],
             [112.0564]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2214, 448.4865, 448.7007,  ..., 448.7018, 448.2461, 448.2259],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2214, 448.4865, 448.7007,  ..., 448.7018, 448.2461, 448.2259],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0545],
             [112.0542],
             [112.0558],
             [112.0539]],

            [[112.0522],
             [112.0522],
             [112.0523],
             [112.0523]],

            [[112.0542],
             [112.0544],
             [112.0535],
             [112.0527]],

            ...,

            [[112.0556],
             [112.0535],
             [112.0542],
             [112.0542]],

            [[112.0533],
             [112.0530],
             [112.0531],
             [112.0531]],

            [[112.1757],
             [112.1757],
             [112.1773],
             [112.1773]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2184, 448.2089, 448.2148,  ..., 448.2175, 448.2124, 448.7059],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2184, 448.2089, 448.2148,  ..., 448.2175, 448.2124, 448.7059],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0056e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1783],
             [112.1783],
             [112.1783],
             [112.1783]],

            [[112.0501],
             [112.0501],
             [112.0483],
             [112.0483]],

            [[112.0499],
             [112.0499],
             [112.0492],
             [112.0492]],

            ...,

            [[112.0492],
             [112.0510],
             [112.0518],
             [112.0493]],

            [[112.0513],
             [112.0498],
             [112.0485],
             [112.0485]],

            [[112.1784],
             [112.1794],
             [112.1794],
             [112.1783]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7130, 448.1969, 448.1982,  ..., 448.2014, 448.1981, 448.7153],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7130, 448.1969, 448.1982,  ..., 448.2014, 448.1981, 448.7153],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1784],
             [112.1794],
             [112.1785],
             [112.1785]],

            [[112.0487],
             [112.0492],
             [112.0492],
             [112.0482]],

            [[112.0502],
             [112.0502],
             [112.0482],
             [112.0482]],

            ...,

            [[112.0499],
             [112.0483],
             [112.0500],
             [112.0480]],

            [[112.1783],
             [112.1783],
             [112.1783],
             [112.1783]],

            [[112.0825],
             [112.0503],
             [112.0562],
             [112.0562]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7147, 448.1953, 448.1969,  ..., 448.1963, 448.7130, 448.2452],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7147, 448.1953, 448.1969,  ..., 448.1963, 448.7130, 448.2452],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0492],
             [112.0492],
             [112.0494],
             [112.0489]],

            [[112.0620],
             [112.0500],
             [112.0531],
             [112.0531]],

            [[112.0528],
             [112.0528],
             [112.0497],
             [112.0497]],

            ...,

            [[112.0500],
             [112.0487],
             [112.0489],
             [112.0484]],

            [[112.0482],
             [112.0497],
             [112.0490],
             [112.0490]],

            [[112.0500],
             [112.0500],
             [112.0495],
             [112.0495]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1967, 448.2183, 448.2051, 448.2089, 448.7191, 448.1979, 448.2141,
            448.7130, 448.1937, 448.1949, 448.1982, 448.1916, 448.5665, 448.3602,
            448.1973, 448.1986, 448.1964, 448.1933, 448.1973, 448.7130, 448.1960,
            448.7130, 448.1967, 448.1985, 448.1978, 448.7134, 448.2138, 448.7204,
            448.1952, 448.3416, 448.7132, 448.7130, 448.1967, 448.1954, 448.1979,
            448.1918, 448.1950, 448.1960, 448.1973, 448.1976, 448.1972, 448.4686,
            448.4995, 448.2024, 448.1962, 448.3798, 448.1965, 448.7251, 448.7130,
            448.2000, 448.1985, 448.1977, 448.1963, 448.7130, 448.1936, 448.1961,
            448.1928, 448.1989, 448.7146, 448.7161, 448.7131, 448.7144, 448.4731,
            448.2997, 448.1917, 448.1963, 448.1978, 448.2058, 448.6091, 448.1972,
            448.1923, 448.4741, 448.1942, 448.1761, 448.1940, 448.1970, 448.7130,
            448.1963, 448.1962, 448.7131, 448.1954, 448.1927, 448.1984, 448.1996,
            448.4100, 448.3638, 448.6024, 448.7136, 448.7187, 448.7143, 448.2124,
            448.3376, 448.1951, 448.1967, 448.7143, 448.1916, 448.1974, 448.1980,
            448.2004, 448.4785, 448.1976, 448.1931, 448.2032, 448.1967, 448.5932,
            448.1993, 448.1962, 448.1921, 448.7130, 448.1966, 448.4753, 448.2879,
            448.1965, 448.1934, 448.1953, 448.5945, 448.2007, 448.7132, 448.1916,
            448.6135, 448.1915, 448.2001, 448.2023, 448.6058, 448.1961, 448.1916,
            448.7138, 448.3537, 448.1967, 448.1963, 448.7131, 448.7149, 448.1932,
            448.1938, 448.1968, 448.1924, 448.1957, 448.3336, 448.1996, 448.7131,
            448.3068, 448.1920, 448.2000, 448.1929, 448.1967, 448.1940, 448.4691,
            448.7205, 448.7280, 448.1963, 448.1971, 448.1940, 448.7131, 448.4064,
            448.7224, 448.7134, 448.2019, 448.2022, 448.1969, 448.2000, 448.7140,
            448.1949, 448.1935, 448.1954, 448.1946, 448.1956, 448.1961, 448.7130,
            448.7130, 448.7135, 448.1965, 448.1990, 448.1940, 448.1984, 448.3395,
            448.2156, 448.7130, 448.1987, 448.7131, 448.1963, 448.7251, 448.1934,
            448.7155, 448.7130, 448.2052, 448.1799, 448.4714, 448.1996, 448.4747,
            448.4687, 448.1947, 448.4696, 448.1982, 448.7130, 448.2082, 448.1956,
            448.2065, 448.1982, 448.7153, 448.1969, 448.4728, 448.7320, 448.1938,
            448.1954, 448.1953, 448.7132, 448.2002, 448.7131, 448.4729, 448.2029,
            448.2009, 448.1953, 448.1934, 448.7130, 448.7167, 448.1971, 448.7408,
            448.7194, 448.1813, 448.6403, 448.1952, 448.7130, 448.1960, 448.1947,
            448.7173, 448.2011, 448.4694, 448.1967, 448.2002, 448.1997, 448.1756,
            448.7155, 448.7130, 448.1957, 448.2013, 448.7136, 448.1929, 448.1959,
            448.1982, 448.1962, 448.7131, 448.2004, 448.1988, 448.1967, 448.7137,
            448.1961, 448.1960, 448.1965, 448.1964, 448.1962, 448.2107, 448.1967,
            448.7131, 448.7196, 448.1956, 448.1984, 448.2028, 448.2130, 448.1931,
            448.5588, 448.1917, 448.2076, 448.7130, 448.1941, 448.1978, 448.7264,
            448.1972, 448.7285, 448.7133, 448.7200, 448.7140, 448.1943, 448.2232,
            448.6817, 448.1974, 448.1747, 448.2002, 448.7145, 448.6056, 448.1961,
            448.1965, 448.1954, 448.1965, 448.1978, 448.1967, 448.7183, 448.7131,
            448.1990, 448.4731, 448.1968, 448.1951, 448.4730, 448.1963, 448.1915,
            448.2042, 448.1979, 448.1977, 448.1962, 448.7131, 448.1920, 448.1967,
            448.1951, 448.4745, 448.1967, 448.7184, 448.1947, 448.7131, 448.7137,
            448.3242, 448.1940, 448.2008, 448.1970, 448.7133, 448.1970, 448.2016,
            448.2029, 448.7331, 448.1965, 448.1958, 448.7162, 448.3409, 448.1953,
            448.1946, 448.1973, 448.2015, 448.1932, 448.4719, 448.1970, 448.2046,
            448.1977, 448.3322, 448.7153, 448.2012, 448.5584, 448.1964, 448.2039,
            448.7130, 448.1920, 448.1963, 448.1974, 448.2250, 448.1933, 448.7132,
            448.1951, 448.7145, 448.7130, 448.2167, 448.7141, 448.1953, 448.1984,
            448.7130, 448.1978, 448.7158, 448.2019, 448.1967, 448.1959, 448.7133,
            448.1964, 448.1964, 448.7136, 448.2188, 448.2000, 448.1962, 448.1940,
            448.1932, 448.1999, 448.7130, 448.1967, 448.4694, 448.3395, 448.4699,
            448.7526, 448.1982, 448.2008, 448.1956, 448.1995, 448.2029, 448.1970,
            448.1939, 448.7131, 448.1932, 448.1970, 448.1942, 448.7196, 448.1984,
            448.7130, 448.1977, 448.1996, 448.7130, 448.7263, 448.1954, 448.1956,
            448.1973, 448.2035, 448.1995, 448.1956, 448.1938, 448.1979, 448.2116,
            448.1962, 448.3632, 448.4682, 448.1975, 448.1968, 448.1926, 448.7191,
            448.7147, 448.1952, 448.4052, 448.2176, 448.1968, 448.1931, 448.1956,
            448.7168, 448.1934, 448.1950, 448.7293, 448.1965, 448.1966, 448.1983,
            448.1937, 448.7158, 448.1957, 448.1968, 448.2065, 448.7150, 448.7187,
            448.1959, 448.1984, 448.7131, 448.1938, 448.1959, 448.1970, 448.7180,
            448.4696, 448.7131, 448.1968, 448.1996, 448.1933, 448.1917, 448.2019,
            448.7146, 448.1964, 448.7133, 448.1961, 448.1929, 448.1961, 448.7131,
            448.2003, 448.1979, 448.1750, 448.1953, 448.1964, 448.1976, 448.1964,
            448.7130, 448.4838, 448.2027, 448.1941, 448.1916, 448.7167, 448.1953,
            448.1929, 448.7131, 448.1940, 448.7131, 448.1985, 448.7181, 448.1957,
            448.1921, 448.1975, 448.1936, 448.7132, 448.7130, 448.1974, 448.1938,
            448.7156, 448.7197, 448.5103, 448.7203, 448.2049, 448.7151, 448.1943,
            448.1924, 448.1917, 448.1961, 448.1920, 448.1970, 448.7237, 448.1962,
            448.1943, 448.7178, 448.7131, 448.2032, 448.1916, 448.1957, 448.1918,
            448.1916, 448.1962, 448.1962, 448.4729, 448.1985, 448.1949, 448.4715,
            448.1983, 448.1918, 448.2192, 448.1925, 448.7136, 448.7130, 448.4779,
            448.6027, 448.1953, 448.7149, 448.1981, 448.1965, 448.1935, 448.7138,
            448.7136, 448.1941, 448.1974, 448.1957, 448.1935, 448.1974, 448.7130,
            448.4682, 448.1986, 448.1965, 448.2039, 448.2155, 448.7130, 448.1980,
            448.5664, 448.1960, 448.1942, 448.7242, 448.1953, 448.7139, 448.2170,
            448.1959, 448.2000, 448.1947, 448.7148, 448.1974, 448.1978, 448.1959,
            448.1955, 448.1940, 448.1941, 448.1931, 448.2263, 448.1981, 448.1966,
            448.7194, 448.1967, 448.1917, 448.1965, 448.7131, 448.1968, 448.1942,
            448.3348, 448.1970, 448.1950, 448.7144, 448.1980, 448.1964, 448.2014,
            448.1990, 448.1941, 448.1970, 448.1987, 448.7130, 448.1964, 448.1974,
            448.1966, 448.3690, 448.1918, 448.1966, 448.1967, 448.1949, 448.7225,
            448.1945, 448.7131, 448.1978, 448.4771, 448.1925, 448.7154, 448.2036,
            448.1965, 448.1933, 448.1952, 448.1962, 448.1963, 448.2014, 448.7160,
            448.1935, 448.1931, 448.2014, 448.1964, 448.2179, 448.7252, 448.7135,
            448.1938, 448.1937, 448.1974, 448.7152, 448.7134, 448.1956, 448.1980,
            448.7064, 448.7144, 448.3298, 448.1951, 448.1928, 448.1948, 448.2006,
            448.7131, 448.7139, 448.1923, 448.7130, 448.2163, 448.1951, 448.1941,
            448.6075, 448.7185, 448.1954, 448.1950, 448.1960, 448.7132, 448.7131,
            448.7258, 448.7202, 448.7153, 448.1968, 448.1974, 448.1949, 448.1953,
            448.5665, 448.1987, 448.1958, 448.2065, 448.1932, 448.1970, 448.1936,
            448.2005, 448.7130, 448.1943, 448.1949, 448.7133, 448.1961, 448.2088,
            448.2137, 448.1945, 448.1964, 448.7131, 448.1983, 448.1979, 448.7131,
            448.1951, 448.2009, 448.7291, 448.7220, 448.2048, 448.1944, 448.2041,
            448.7130, 448.1952, 448.1961, 448.1992, 448.7150, 448.1958, 448.2004,
            448.4897, 448.2169, 448.4767, 448.1968, 448.2003, 448.1933, 448.4739,
            448.7131, 448.1963, 448.1935, 448.7144, 448.6173, 448.1964, 448.1921,
            448.1975, 448.7239, 448.2059, 448.1917, 448.7277, 448.1939, 448.1984,
            448.1957, 448.7231, 448.7177, 448.1747, 448.2292, 448.2064, 448.2110,
            448.7222, 448.2165, 448.1965, 448.1995, 448.4772, 448.1955, 448.2003,
            448.2016, 448.1965, 448.1964, 448.1974, 448.7134, 448.1983, 448.2016,
            448.7314, 448.1968, 448.1966, 448.1985, 448.1974, 448.7130, 448.7131,
            448.1931, 448.6201, 448.4729, 448.3071, 448.1914, 448.7152, 448.1918,
            448.7159, 448.7162, 448.1932, 448.1976, 448.4722, 448.4723, 448.7138,
            448.1932, 448.1960, 448.6077, 448.1747, 448.1970, 448.2001, 448.1974,
            448.1956, 448.1954, 448.1970, 448.1963, 448.1943, 448.7141, 448.2355,
            448.1986, 448.1931, 448.1977, 448.2030, 448.1938, 448.2058, 448.2031,
            448.2218, 448.1985, 448.2034, 448.1967, 448.7209, 448.1962, 448.4724,
            448.1931, 448.2029, 448.1993, 448.7130, 448.1956, 448.2006, 448.1962,
            448.1967, 448.4694, 448.1959, 448.1964, 448.7131, 448.1962, 448.7133,
            448.1953, 448.1967, 448.1985, 448.1942, 448.7130, 448.7132, 448.1971,
            448.1937, 448.1968, 448.1967, 448.1944, 448.2858, 448.5665, 448.1977,
            448.7134, 448.1967, 448.1960, 448.7161, 448.1962, 448.1964, 448.7136,
            448.2011, 448.2320, 448.2486, 448.2091, 448.1937, 448.2213, 448.7131,
            448.7282, 448.1984, 448.1984, 448.1952, 448.1920, 448.7347, 448.7171,
            448.2090, 448.7154, 448.1938, 448.1942, 448.7218, 448.1940, 448.1961,
            448.7296, 448.1949, 448.1970, 448.7162, 448.2096, 448.2400, 448.1945,
            448.1962, 448.1967, 448.1916, 448.7135, 448.7455, 448.7141, 448.7130,
            448.1942, 448.7131, 448.1979, 448.1961, 448.2023, 448.1958, 448.1965,
            448.1959, 448.2015, 448.1971, 448.2004, 448.1984, 448.1960, 448.1946,
            448.1935, 448.7162, 448.1965, 448.7161, 448.7158, 448.1962, 448.1974,
            448.1958, 448.1960, 448.1956, 448.7131, 448.1969, 448.1922, 448.1959,
            448.1924, 448.6159, 448.7134, 448.7275, 448.2065, 448.2308, 448.2523,
            448.7407, 448.1979, 448.1989, 448.1921, 448.7254, 448.1938, 448.7132,
            448.4727, 448.7130, 448.1979, 448.1960, 448.1995, 448.1941, 448.2025,
            448.7130, 448.1929, 448.7130, 448.4778, 448.1948, 448.1971, 448.2247,
            448.1932, 448.7151, 448.4781, 448.7170, 448.4693, 448.7137, 448.7201,
            448.1964, 448.1965, 448.7130, 448.7147, 448.7280, 448.7150, 448.1974,
            448.1928, 448.1970, 448.1933, 448.7142, 448.5217, 448.1972, 448.2971,
            448.1917, 448.2017, 448.1960, 448.2035, 448.1948, 448.1948, 448.7145,
            448.7131, 448.1945, 448.1915, 448.1961, 448.1961, 448.1936, 448.1960,
            448.1959, 448.1990], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1967, 448.2183, 448.2051, 448.2089, 448.7191, 448.1979, 448.2141,
        448.7130, 448.1937, 448.1949, 448.1982, 448.1916, 448.5665, 448.3602,
        448.1973, 448.1986, 448.1964, 448.1933, 448.1973, 448.7130, 448.1960,
        448.7130, 448.1967, 448.1985, 448.1978, 448.7134, 448.2138, 448.7204,
        448.1952, 448.3416, 448.7132, 448.7130, 448.1967, 448.1954, 448.1979,
        448.1918, 448.1950, 448.1960, 448.1973, 448.1976, 448.1972, 448.4686,
        448.4995, 448.2024, 448.1962, 448.3798, 448.1965, 448.7251, 448.7130,
        448.2000, 448.1985, 448.1977, 448.1963, 448.7130, 448.1936, 448.1961,
        448.1928, 448.1989, 448.7146, 448.7161, 448.7131, 448.7144, 448.4731,
        448.2997, 448.1917, 448.1963, 448.1978, 448.2058, 448.6091, 448.1972,
        448.1923, 448.4741, 448.1942, 448.1761, 448.1940, 448.1970, 448.7130,
        448.1963, 448.1962, 448.7131, 448.1954, 448.1927, 448.1984, 448.1996,
        448.4100, 448.3638, 448.6024, 448.7136, 448.7187, 448.7143, 448.2124,
        448.3376, 448.1951, 448.1967, 448.7143, 448.1916, 448.1974, 448.1980,
        448.2004, 448.4785, 448.1976, 448.1931, 448.2032, 448.1967, 448.5932,
        448.1993, 448.1962, 448.1921, 448.7130, 448.1966, 448.4753, 448.2879,
        448.1965, 448.1934, 448.1953, 448.5945, 448.2007, 448.7132, 448.1916,
        448.6135, 448.1915, 448.2001, 448.2023, 448.6058, 448.1961, 448.1916,
        448.7138, 448.3537, 448.1967, 448.1963, 448.7131, 448.7149, 448.1932,
        448.1938, 448.1968, 448.1924, 448.1957, 448.3336, 448.1996, 448.7131,
        448.3068, 448.1920, 448.2000, 448.1929, 448.1967, 448.1940, 448.4691,
        448.7205, 448.7280, 448.1963, 448.1971, 448.1940, 448.7131, 448.4064,
        448.7224, 448.7134, 448.2019, 448.2022, 448.1969, 448.2000, 448.7140,
        448.1949, 448.1935, 448.1954, 448.1946, 448.1956, 448.1961, 448.7130,
        448.7130, 448.7135, 448.1965, 448.1990, 448.1940, 448.1984, 448.3395,
        448.2156, 448.7130, 448.1987, 448.7131, 448.1963, 448.7251, 448.1934,
        448.7155, 448.7130, 448.2052, 448.1799, 448.4714, 448.1996, 448.4747,
        448.4687, 448.1947, 448.4696, 448.1982, 448.7130, 448.2082, 448.1956,
        448.2065, 448.1982, 448.7153, 448.1969, 448.4728, 448.7320, 448.1938,
        448.1954, 448.1953, 448.7132, 448.2002, 448.7131, 448.4729, 448.2029,
        448.2009, 448.1953, 448.1934, 448.7130, 448.7167, 448.1971, 448.7408,
        448.7194, 448.1813, 448.6403, 448.1952, 448.7130, 448.1960, 448.1947,
        448.7173, 448.2011, 448.4694, 448.1967, 448.2002, 448.1997, 448.1756,
        448.7155, 448.7130, 448.1957, 448.2013, 448.7136, 448.1929, 448.1959,
        448.1982, 448.1962, 448.7131, 448.2004, 448.1988, 448.1967, 448.7137,
        448.1961, 448.1960, 448.1965, 448.1964, 448.1962, 448.2107, 448.1967,
        448.7131, 448.7196, 448.1956, 448.1984, 448.2028, 448.2130, 448.1931,
        448.5588, 448.1917, 448.2076, 448.7130, 448.1941, 448.1978, 448.7264,
        448.1972, 448.7285, 448.7133, 448.7200, 448.7140, 448.1943, 448.2232,
        448.6817, 448.1974, 448.1747, 448.2002, 448.7145, 448.6056, 448.1961,
        448.1965, 448.1954, 448.1965, 448.1978, 448.1967, 448.7183, 448.7131,
        448.1990, 448.4731, 448.1968, 448.1951, 448.4730, 448.1963, 448.1915,
        448.2042, 448.1979, 448.1977, 448.1962, 448.7131, 448.1920, 448.1967,
        448.1951, 448.4745, 448.1967, 448.7184, 448.1947, 448.7131, 448.7137,
        448.3242, 448.1940, 448.2008, 448.1970, 448.7133, 448.1970, 448.2016,
        448.2029, 448.7331, 448.1965, 448.1958, 448.7162, 448.3409, 448.1953,
        448.1946, 448.1973, 448.2015, 448.1932, 448.4719, 448.1970, 448.2046,
        448.1977, 448.3322, 448.7153, 448.2012, 448.5584, 448.1964, 448.2039,
        448.7130, 448.1920, 448.1963, 448.1974, 448.2250, 448.1933, 448.7132,
        448.1951, 448.7145, 448.7130, 448.2167, 448.7141, 448.1953, 448.1984,
        448.7130, 448.1978, 448.7158, 448.2019, 448.1967, 448.1959, 448.7133,
        448.1964, 448.1964, 448.7136, 448.2188, 448.2000, 448.1962, 448.1940,
        448.1932, 448.1999, 448.7130, 448.1967, 448.4694, 448.3395, 448.4699,
        448.7526, 448.1982, 448.2008, 448.1956, 448.1995, 448.2029, 448.1970,
        448.1939, 448.7131, 448.1932, 448.1970, 448.1942, 448.7196, 448.1984,
        448.7130, 448.1977, 448.1996, 448.7130, 448.7263, 448.1954, 448.1956,
        448.1973, 448.2035, 448.1995, 448.1956, 448.1938, 448.1979, 448.2116,
        448.1962, 448.3632, 448.4682, 448.1975, 448.1968, 448.1926, 448.7191,
        448.7147, 448.1952, 448.4052, 448.2176, 448.1968, 448.1931, 448.1956,
        448.7168, 448.1934, 448.1950, 448.7293, 448.1965, 448.1966, 448.1983,
        448.1937, 448.7158, 448.1957, 448.1968, 448.2065, 448.7150, 448.7187,
        448.1959, 448.1984, 448.7131, 448.1938, 448.1959, 448.1970, 448.7180,
        448.4696, 448.7131, 448.1968, 448.1996, 448.1933, 448.1917, 448.2019,
        448.7146, 448.1964, 448.7133, 448.1961, 448.1929, 448.1961, 448.7131,
        448.2003, 448.1979, 448.1750, 448.1953, 448.1964, 448.1976, 448.1964,
        448.7130, 448.4838, 448.2027, 448.1941, 448.1916, 448.7167, 448.1953,
        448.1929, 448.7131, 448.1940, 448.7131, 448.1985, 448.7181, 448.1957,
        448.1921, 448.1975, 448.1936, 448.7132, 448.7130, 448.1974, 448.1938,
        448.7156, 448.7197, 448.5103, 448.7203, 448.2049, 448.7151, 448.1943,
        448.1924, 448.1917, 448.1961, 448.1920, 448.1970, 448.7237, 448.1962,
        448.1943, 448.7178, 448.7131, 448.2032, 448.1916, 448.1957, 448.1918,
        448.1916, 448.1962, 448.1962, 448.4729, 448.1985, 448.1949, 448.4715,
        448.1983, 448.1918, 448.2192, 448.1925, 448.7136, 448.7130, 448.4779,
        448.6027, 448.1953, 448.7149, 448.1981, 448.1965, 448.1935, 448.7138,
        448.7136, 448.1941, 448.1974, 448.1957, 448.1935, 448.1974, 448.7130,
        448.4682, 448.1986, 448.1965, 448.2039, 448.2155, 448.7130, 448.1980,
        448.5664, 448.1960, 448.1942, 448.7242, 448.1953, 448.7139, 448.2170,
        448.1959, 448.2000, 448.1947, 448.7148, 448.1974, 448.1978, 448.1959,
        448.1955, 448.1940, 448.1941, 448.1931, 448.2263, 448.1981, 448.1966,
        448.7194, 448.1967, 448.1917, 448.1965, 448.7131, 448.1968, 448.1942,
        448.3348, 448.1970, 448.1950, 448.7144, 448.1980, 448.1964, 448.2014,
        448.1990, 448.1941, 448.1970, 448.1987, 448.7130, 448.1964, 448.1974,
        448.1966, 448.3690, 448.1918, 448.1966, 448.1967, 448.1949, 448.7225,
        448.1945, 448.7131, 448.1978, 448.4771, 448.1925, 448.7154, 448.2036,
        448.1965, 448.1933, 448.1952, 448.1962, 448.1963, 448.2014, 448.7160,
        448.1935, 448.1931, 448.2014, 448.1964, 448.2179, 448.7252, 448.7135,
        448.1938, 448.1937, 448.1974, 448.7152, 448.7134, 448.1956, 448.1980,
        448.7064, 448.7144, 448.3298, 448.1951, 448.1928, 448.1948, 448.2006,
        448.7131, 448.7139, 448.1923, 448.7130, 448.2163, 448.1951, 448.1941,
        448.6075, 448.7185, 448.1954, 448.1950, 448.1960, 448.7132, 448.7131,
        448.7258, 448.7202, 448.7153, 448.1968, 448.1974, 448.1949, 448.1953,
        448.5665, 448.1987, 448.1958, 448.2065, 448.1932, 448.1970, 448.1936,
        448.2005, 448.7130, 448.1943, 448.1949, 448.7133, 448.1961, 448.2088,
        448.2137, 448.1945, 448.1964, 448.7131, 448.1983, 448.1979, 448.7131,
        448.1951, 448.2009, 448.7291, 448.7220, 448.2048, 448.1944, 448.2041,
        448.7130, 448.1952, 448.1961, 448.1992, 448.7150, 448.1958, 448.2004,
        448.4897, 448.2169, 448.4767, 448.1968, 448.2003, 448.1933, 448.4739,
        448.7131, 448.1963, 448.1935, 448.7144, 448.6173, 448.1964, 448.1921,
        448.1975, 448.7239, 448.2059, 448.1917, 448.7277, 448.1939, 448.1984,
        448.1957, 448.7231, 448.7177, 448.1747, 448.2292, 448.2064, 448.2110,
        448.7222, 448.2165, 448.1965, 448.1995, 448.4772, 448.1955, 448.2003,
        448.2016, 448.1965, 448.1964, 448.1974, 448.7134, 448.1983, 448.2016,
        448.7314, 448.1968, 448.1966, 448.1985, 448.1974, 448.7130, 448.7131,
        448.1931, 448.6201, 448.4729, 448.3071, 448.1914, 448.7152, 448.1918,
        448.7159, 448.7162, 448.1932, 448.1976, 448.4722, 448.4723, 448.7138,
        448.1932, 448.1960, 448.6077, 448.1747, 448.1970, 448.2001, 448.1974,
        448.1956, 448.1954, 448.1970, 448.1963, 448.1943, 448.7141, 448.2355,
        448.1986, 448.1931, 448.1977, 448.2030, 448.1938, 448.2058, 448.2031,
        448.2218, 448.1985, 448.2034, 448.1967, 448.7209, 448.1962, 448.4724,
        448.1931, 448.2029, 448.1993, 448.7130, 448.1956, 448.2006, 448.1962,
        448.1967, 448.4694, 448.1959, 448.1964, 448.7131, 448.1962, 448.7133,
        448.1953, 448.1967, 448.1985, 448.1942, 448.7130, 448.7132, 448.1971,
        448.1937, 448.1968, 448.1967, 448.1944, 448.2858, 448.5665, 448.1977,
        448.7134, 448.1967, 448.1960, 448.7161, 448.1962, 448.1964, 448.7136,
        448.2011, 448.2320, 448.2486, 448.2091, 448.1937, 448.2213, 448.7131,
        448.7282, 448.1984, 448.1984, 448.1952, 448.1920, 448.7347, 448.7171,
        448.2090, 448.7154, 448.1938, 448.1942, 448.7218, 448.1940, 448.1961,
        448.7296, 448.1949, 448.1970, 448.7162, 448.2096, 448.2400, 448.1945,
        448.1962, 448.1967, 448.1916, 448.7135, 448.7455, 448.7141, 448.7130,
        448.1942, 448.7131, 448.1979, 448.1961, 448.2023, 448.1958, 448.1965,
        448.1959, 448.2015, 448.1971, 448.2004, 448.1984, 448.1960, 448.1946,
        448.1935, 448.7162, 448.1965, 448.7161, 448.7158, 448.1962, 448.1974,
        448.1958, 448.1960, 448.1956, 448.7131, 448.1969, 448.1922, 448.1959,
        448.1924, 448.6159, 448.7134, 448.7275, 448.2065, 448.2308, 448.2523,
        448.7407, 448.1979, 448.1989, 448.1921, 448.7254, 448.1938, 448.7132,
        448.4727, 448.7130, 448.1979, 448.1960, 448.1995, 448.1941, 448.2025,
        448.7130, 448.1929, 448.7130, 448.4778, 448.1948, 448.1971, 448.2247,
        448.1932, 448.7151, 448.4781, 448.7170, 448.4693, 448.7137, 448.7201,
        448.1964, 448.1965, 448.7130, 448.7147, 448.7280, 448.7150, 448.1974,
        448.1928, 448.1970, 448.1933, 448.7142, 448.5217, 448.1972, 448.2971,
        448.1917, 448.2017, 448.1960, 448.2035, 448.1948, 448.1948, 448.7145,
        448.7131, 448.1945, 448.1915, 448.1961, 448.1961, 448.1936, 448.1960,
        448.1959, 448.1990], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([405.9622], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0497],
             [112.0552],
             [112.0566],
             [112.0498]],

            [[112.0509],
             [112.0491],
             [112.0500],
             [112.0500]],

            [[112.0478],
             [112.0479],
             [112.0479],
             [112.0479]],

            ...,

            [[112.0439],
             [112.0436],
             [112.0440],
             [112.0437]],

            [[112.0499],
             [112.0499],
             [112.0486],
             [112.0486]],

            [[112.1783],
             [112.1783],
             [112.1783],
             [112.1783]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2113, 448.2001, 448.1915,  ..., 448.1753, 448.1970, 448.7130],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2113, 448.2001, 448.1915,  ..., 448.1753, 448.1970, 448.7130],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0449],
             [112.0438],
             [112.0451],
             [112.0433]],

            [[112.0451],
             [112.0432],
             [112.0442],
             [112.0442]],

            [[112.1864],
             [112.0459],
             [112.0473],
             [112.0473]],

            ...,

            [[112.1829],
             [112.1829],
             [112.1833],
             [112.1833]],

            [[112.0439],
             [112.0431],
             [112.0432],
             [112.0432]],

            [[112.0435],
             [112.0450],
             [112.0433],
             [112.0433]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1771, 448.1767, 448.3268,  ..., 448.7323, 448.1735, 448.1752],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1771, 448.1767, 448.3268,  ..., 448.7323, 448.1735, 448.1752],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0407],
             [112.0388],
             [112.0402],
             [112.0402]],

            [[112.0393],
             [112.0389],
             [112.0388],
             [112.0396]],

            [[112.0393],
             [112.0393],
             [112.0390],
             [112.0390]],

            ...,

            [[112.0393],
             [112.0390],
             [112.0390],
             [112.0390]],

            [[112.1848],
             [112.1848],
             [112.1848],
             [112.1848]],

            [[112.0395],
             [112.0388],
             [112.0388],
             [112.0388]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1598, 448.1566, 448.1564,  ..., 448.1564, 448.7392, 448.1560],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1598, 448.1566, 448.1564,  ..., 448.1564, 448.7392, 448.1560],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1878],
             [112.0494],
             [112.0407],
             [112.0407]],

            [[112.0377],
             [112.0388],
             [112.0388],
             [112.0370]],

            [[112.1860],
             [112.1860],
             [112.1860],
             [112.1860]],

            ...,

            [[112.0382],
             [112.0382],
             [112.0370],
             [112.0370]],

            [[112.0386],
             [112.0395],
             [112.0383],
             [112.0371]],

            [[112.1861],
             [112.1863],
             [112.1861],
             [112.1863]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3185, 448.1523, 448.7440,  ..., 448.1503, 448.1534, 448.7448],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3185, 448.1523, 448.7440,  ..., 448.1503, 448.1534, 448.7448],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1878],
             [112.1858],
             [112.1876],
             [112.1858]],

            [[112.0393],
             [112.0391],
             [112.0405],
             [112.0405]],

            [[112.1859],
             [112.1874],
             [112.0428],
             [112.0810]],

            ...,

            [[112.1861],
             [112.1882],
             [112.1858],
             [112.1858]],

            [[112.1876],
             [112.0420],
             [112.1878],
             [112.0418]],

            [[112.0399],
             [112.0399],
             [112.0389],
             [112.0384]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7470, 448.1593, 448.4972,  ..., 448.7459, 448.4592, 448.1571],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7470, 448.1593, 448.4972,  ..., 448.7459, 448.4592, 448.1571],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0401],
             [112.0401],
             [112.0401],
             [112.0401]],

            [[112.0402],
             [112.0402],
             [112.0394],
             [112.0394]],

            [[112.0393],
             [112.0388],
             [112.0394],
             [112.0390]],

            ...,

            [[112.0507],
             [112.0507],
             [112.0460],
             [112.0460]],

            [[112.0403],
             [112.0394],
             [112.0401],
             [112.0388]],

            [[112.1871],
             [112.1871],
             [112.1871],
             [112.1871]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1602, 448.1592, 448.1565,  ..., 448.1934, 448.1587, 448.7483],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1602, 448.1592, 448.1565,  ..., 448.1934, 448.1587, 448.7483],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0446],
             [112.0435],
             [112.0445],
             [112.0437]],

            [[112.0508],
             [112.0488],
             [112.0465],
             [112.1865]],

            [[112.0446],
             [112.0438],
             [112.0443],
             [112.0443]],

            ...,

            [[112.0478],
             [112.0448],
             [112.0485],
             [112.0449]],

            [[112.0447],
             [112.0441],
             [112.0435],
             [112.0435]],

            [[112.1851],
             [112.1851],
             [112.1851],
             [112.1851]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1764, 448.3326, 448.1771,  ..., 448.1860, 448.1757, 448.7403],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1764, 448.3326, 448.1771,  ..., 448.1860, 448.1757, 448.7403],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1867],
             [112.1875],
             [112.1871],
             [112.1871]],

            [[112.0436],
             [112.0446],
             [112.0448],
             [112.0440]],

            [[112.0428],
             [112.0428],
             [112.0433],
             [112.0433]],

            ...,

            [[112.0430],
             [112.0429],
             [112.0429],
             [112.0429]],

            [[112.0444],
             [112.0444],
             [112.0443],
             [112.0443]],

            [[112.1867],
             [112.1867],
             [112.1867],
             [112.1867]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7484, 448.1770, 448.1722,  ..., 448.1718, 448.1775, 448.7467],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7484, 448.1770, 448.1722,  ..., 448.1718, 448.1775, 448.7467],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0476],
             [112.0477],
             [112.0463],
             [112.0463]],

            [[112.0468],
             [112.0473],
             [112.0465],
             [112.0462]],

            [[112.0480],
             [112.0480],
             [112.0468],
             [112.0468]],

            ...,

            [[112.0472],
             [112.0460],
             [112.0476],
             [112.0470]],

            [[112.1819],
             [112.1819],
             [112.1819],
             [112.1819]],

            [[112.0469],
             [112.0470],
             [112.0473],
             [112.0463]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1878, 448.1867, 448.1896,  ..., 448.1878, 448.7275, 448.1874],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1878, 448.1867, 448.1896,  ..., 448.1878, 448.7275, 448.1874],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0528],
             [112.0463],
             [112.0467],
             [112.0467]],

            [[112.1815],
             [112.1815],
             [112.1815],
             [112.1815]],

            [[112.0463],
             [112.0574],
             [112.0511],
             [112.0463]],

            ...,

            [[112.0463],
             [112.0460],
             [112.0465],
             [112.0451]],

            [[112.1807],
             [112.1815],
             [112.1815],
             [112.1806]],

            [[112.0455],
             [112.0455],
             [112.0449],
             [112.0449]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1924, 448.7261, 448.2011,  ..., 448.1840, 448.7244, 448.1808],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1924, 448.7261, 448.2011,  ..., 448.1840, 448.7244, 448.1808],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0452],
             [112.0455],
             [112.0451],
             [112.0451]],

            [[112.1792],
             [112.1792],
             [112.1791],
             [112.1791]],

            [[112.0464],
             [112.0451],
             [112.0464],
             [112.0450]],

            ...,

            [[112.1786],
             [112.1790],
             [112.1788],
             [112.1789]],

            [[112.1800],
             [112.0499],
             [112.1817],
             [112.1817]],

            [[112.0473],
             [112.0473],
             [112.0460],
             [112.0460]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1809, 448.7167, 448.1829,  ..., 448.7153, 448.5933, 448.1866],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1809, 448.7167, 448.1829,  ..., 448.7153, 448.5933, 448.1866],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0432],
             [112.0421],
             [112.0437],
             [112.0434]],

            [[112.1554],
             [112.0438],
             [112.0467],
             [112.0467]],

            [[112.0431],
             [112.0430],
             [112.0431],
             [112.0420]],

            ...,

            [[112.0428],
             [112.0420],
             [112.0434],
             [112.0427]],

            [[112.0441],
             [112.0436],
             [112.0422],
             [112.0419]],

            [[112.0416],
             [112.0416],
             [112.0417],
             [112.0417]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1725, 448.2927, 448.1711,  ..., 448.1709, 448.1718, 448.1666],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1725, 448.2927, 448.1711,  ..., 448.1709, 448.1718, 448.1666],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0392],
             [112.0406],
             [112.0404],
             [112.0386]],

            [[112.0403],
             [112.0384],
             [112.0401],
             [112.0386]],

            [[112.1802],
             [112.1826],
             [112.1803],
             [112.1809]],

            ...,

            [[112.1802],
             [112.1801],
             [112.1800],
             [112.1806]],

            [[112.0399],
             [112.0385],
             [112.0383],
             [112.0383]],

            [[112.0400],
             [112.0399],
             [112.0396],
             [112.0383]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1588, 448.1574, 448.7241,  ..., 448.7209, 448.1550, 448.1578],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1588, 448.1574, 448.7241,  ..., 448.7209, 448.1550, 448.1578],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0404],
             [112.0411],
             [112.0406],
             [112.0397]],

            [[112.0441],
             [112.0404],
             [112.0410],
             [112.0410]],

            [[112.1817],
             [112.1817],
             [112.0411],
             [112.0411]],

            ...,

            [[112.1784],
             [112.1784],
             [112.1784],
             [112.1784]],

            [[112.0408],
             [112.0402],
             [112.0394],
             [112.0394]],

            [[112.0397],
             [112.0389],
             [112.0389],
             [112.0390]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1618, 448.1664, 448.4455,  ..., 448.7135, 448.1598, 448.1566],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1618, 448.1664, 448.4455,  ..., 448.7135, 448.1598, 448.1566],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1796],
             [112.1796],
             [112.1796],
             [112.1796]],

            [[112.1800],
             [112.1800],
             [112.1812],
             [112.1812]],

            [[112.0368],
             [112.0368],
             [112.0356],
             [112.0356]],

            ...,

            [[112.0405],
             [112.0372],
             [112.0405],
             [112.0372]],

            [[112.0373],
             [112.0373],
             [112.0451],
             [112.0451]],

            [[112.1796],
             [112.1796],
             [112.1796],
             [112.1796]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7185, 448.7225, 448.1447,  ..., 448.1553, 448.1646, 448.7185],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7185, 448.7225, 448.1447,  ..., 448.1553, 448.1646, 448.7185],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0321],
             [112.0321],
             [112.0321],
             [112.0310]],

            [[112.0327],
             [112.0360],
             [112.0410],
             [112.0326]],

            [[112.0327],
             [112.0318],
             [112.0309],
             [112.0309]],

            ...,

            [[112.1835],
             [112.1835],
             [112.1835],
             [112.1835]],

            [[112.0305],
             [112.0305],
             [112.0307],
             [112.0308]],

            [[112.1836],
             [112.1839],
             [112.1836],
             [112.1836]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1273, 448.1423, 448.1264,  ..., 448.7342, 448.1226, 448.7346],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1273, 448.1423, 448.1264,  ..., 448.7342, 448.1226, 448.7346],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0293],
             [112.0274],
             [112.0274],
             [112.0294]],

            [[112.1863],
             [112.1860],
             [112.1863],
             [112.1860]],

            [[112.0281],
             [112.0295],
             [112.0296],
             [112.0278]],

            ...,

            [[112.1864],
             [112.1864],
             [112.1864],
             [112.1864]],

            [[112.0288],
             [112.0290],
             [112.0292],
             [112.0273]],

            [[112.0272],
             [112.0273],
             [112.0273],
             [112.0276]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1136, 448.7447, 448.1150,  ..., 448.7457, 448.1144, 448.1094],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1136, 448.7447, 448.1150,  ..., 448.7457, 448.1144, 448.1094],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0335],
             [112.0335],
             [112.0337],
             [112.0337]],

            [[112.0292],
             [112.0288],
             [112.0296],
             [112.0289]],

            [[112.0309],
             [112.0308],
             [112.0293],
             [112.0308]],

            ...,

            [[112.0302],
             [112.0299],
             [112.0288],
             [112.0307]],

            [[112.0352],
             [112.0307],
             [112.0310],
             [112.0310]],

            [[112.0306],
             [112.0297],
             [112.0288],
             [112.0306]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1343, 448.1165, 448.1218,  ..., 448.1196, 448.1278, 448.1198],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1343, 448.1165, 448.1218,  ..., 448.1196, 448.1278, 448.1198],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0119e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1850],
             [112.1849],
             [112.1849],
             [112.1853]],

            [[112.1862],
             [112.1850],
             [112.1850],
             [112.1861]],

            [[112.0325],
             [112.0308],
             [112.0303],
             [112.0321]],

            ...,

            [[112.1849],
             [112.1849],
             [112.1849],
             [112.1849]],

            [[112.1850],
             [112.1863],
             [112.1850],
             [112.1863]],

            [[112.0386],
             [112.0323],
             [112.0790],
             [112.0324]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7401, 448.7423, 448.1257,  ..., 448.7394, 448.7426, 448.1823],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7401, 448.7423, 448.1257,  ..., 448.7394, 448.7426, 448.1823],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0319],
             [112.0303],
             [112.0302],
             [112.0302]],

            [[112.1849],
             [112.1849],
             [112.1849],
             [112.1849]],

            [[112.0264],
             [112.0264],
             [112.0264],
             [112.0264]],

            ...,

            [[112.1850],
             [112.1850],
             [112.1856],
             [112.1856]],

            [[112.0331],
             [112.0319],
             [112.0338],
             [112.0320]],

            [[112.0358],
             [112.0322],
             [112.0328],
             [112.0328]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1226, 448.7394, 448.1057,  ..., 448.7410, 448.1309, 448.1335],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1226, 448.7394, 448.1057,  ..., 448.7410, 448.1309, 448.1335],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0324],
             [112.0324],
             [112.0316],
             [112.0316]],

            [[112.1849],
             [112.1849],
             [112.1849],
             [112.1849]],

            [[112.0395],
             [112.0395],
             [112.0323],
             [112.0323]],

            ...,

            [[112.0324],
             [112.0304],
             [112.0322],
             [112.0305]],

            [[112.0309],
             [112.0301],
             [112.0304],
             [112.0301]],

            [[112.0306],
             [112.0302],
             [112.0321],
             [112.0301]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1279, 448.7396, 448.1436, 448.1298, 448.1278, 448.1236, 448.7394,
            448.1245, 448.7418, 448.7394, 448.1241, 448.1213, 448.1254, 448.1257,
            448.1283, 448.1207, 448.1286, 448.7385, 448.1274, 448.7396, 448.1212,
            448.7428, 448.6015, 448.7395, 448.1263, 448.7394, 448.1231, 448.1254,
            448.1205, 448.1302, 448.5850, 448.7394, 448.1303, 448.1297, 448.4415,
            448.7394, 448.1201, 448.1249, 448.1259, 448.6308, 448.1259, 448.1284,
            448.1282, 448.1232, 448.7398, 448.7405, 448.1372, 448.1242, 448.2993,
            448.7441, 448.1227, 448.1254, 448.7402, 448.1230, 448.1075, 448.7394,
            448.1235, 448.1296, 448.1273, 448.1216, 448.7399, 448.1215, 448.4335,
            448.7407, 448.1232, 448.4426, 448.7407, 448.1267, 448.1244, 448.1252,
            448.1058, 448.7396, 448.1225, 448.1300, 448.1233, 448.1250, 448.1222,
            448.7404, 448.1252, 448.1283, 448.1237, 448.1274, 448.1252, 448.1288,
            448.7395, 448.1244, 448.1290, 448.1223, 448.1263, 448.1252, 448.1237,
            448.7396, 448.1235, 448.1282, 448.1257, 448.1228, 448.1254, 448.1207,
            448.1240, 448.2820, 448.7440, 448.1257, 448.4331, 448.1255, 448.1240,
            448.7394, 448.1345, 448.1255, 448.1305, 448.1293, 448.1221, 448.1254,
            448.1261, 448.1252, 448.4436, 448.1319, 448.1347, 448.1225, 448.1241,
            448.1763, 448.1235, 448.7409, 448.1287, 448.7396, 448.7396, 448.1263,
            448.4458, 448.1250, 448.1312, 448.7407, 448.1250, 448.4396, 448.1248,
            448.1252, 448.1253, 448.1279, 448.1268, 448.1240, 448.7399, 448.4407,
            448.1250, 448.1258, 448.1251, 448.1230, 448.7398, 448.7402, 448.1248,
            448.7423, 448.1268, 448.1259, 448.1279, 448.1305, 448.1234, 448.4416,
            448.7436, 448.7419, 448.1260, 448.1218, 448.1061, 448.7394, 448.1271,
            448.7399, 448.1339, 448.1251, 448.1270, 448.1254, 448.1257, 448.1252,
            448.1272, 448.1383, 448.1274, 448.1303, 448.1243, 448.7396, 448.1259,
            448.1268, 448.1302, 448.1219, 448.1248, 448.1286, 448.1224, 448.1242,
            448.1248, 448.5930, 448.1248, 448.7394, 448.1235, 448.1246, 448.1283,
            448.1257, 448.7419, 448.1392, 448.1255, 448.7407, 448.1252, 448.1252,
            448.7403, 448.1219, 448.1248, 448.1249, 448.1251, 448.3179, 448.2361,
            448.1240, 448.7399, 448.1263, 448.1312, 448.1242, 448.1257, 448.1254,
            448.1253, 448.7394, 448.1275, 448.1293, 448.1286, 448.1262, 448.7421,
            448.1212, 448.1236, 448.7395, 448.7397, 448.1262, 448.1262, 448.7399,
            448.4419, 448.1247, 448.3126, 448.2899, 448.7408, 448.1056, 448.1243,
            448.1254, 448.1243, 448.1262, 448.1296, 448.1252, 448.1201, 448.4406,
            448.7394, 448.1299, 448.1293, 448.1250, 448.7398, 448.4402, 448.1245,
            448.1266, 448.7411, 448.1255, 448.1240, 448.1373, 448.1254, 448.1249,
            448.1250, 448.1274, 448.7394, 448.1255, 448.1291, 448.7394, 448.1286,
            448.5527, 448.1228, 448.1288, 448.1063, 448.7394, 448.7401, 448.1231,
            448.1260, 448.1243, 448.1243, 448.1241, 448.1251, 448.7401, 448.1309,
            448.1238, 448.1261, 448.1217, 448.1373, 448.7394, 448.7405, 448.7439,
            448.7401, 448.1283, 448.1235, 448.1266, 448.1248, 448.7417, 448.1709,
            448.1262, 448.1304, 448.7405, 448.7397, 448.1208, 448.7395, 448.2886,
            448.1412, 448.1321, 448.1269, 448.1287, 448.1248, 448.7394, 448.1286,
            448.7419, 448.1283, 448.1286, 448.1221, 448.1253, 448.1268, 448.1233,
            448.1250, 448.6149, 448.1235, 448.1271, 448.7394, 448.1256, 448.1271,
            448.7394, 448.1274, 448.7408, 448.1233, 448.1312, 448.7394, 448.1221,
            448.1261, 448.1226, 448.1258, 448.1237, 448.4111, 448.1260, 448.7416,
            448.1485, 448.7430, 448.1305, 448.1281, 448.1210, 448.1229, 448.1252,
            448.7395, 448.7394, 448.7452, 448.7394, 448.4459, 448.1462, 448.1251,
            448.1306, 448.2590, 448.1295, 448.1268, 448.1237, 448.1263, 448.1277,
            448.1284, 448.1253, 448.1223, 448.1261, 448.1252, 448.1280, 448.1284,
            448.1250, 448.7395, 448.1278, 448.1374, 448.1255, 448.7394, 448.1210,
            448.1261, 448.1216, 448.1219, 448.1294, 448.1248, 448.7404, 448.1268,
            448.1241, 448.1288, 448.4255, 448.1218, 448.7422, 448.1268, 448.1247,
            448.7422, 448.7394, 448.1265, 448.1234, 448.5942, 448.1222, 448.1057,
            448.4491, 448.1320, 448.7380, 448.1225, 448.4544, 448.3239, 448.1245,
            448.1421, 448.1248, 448.7395, 448.7402, 448.7407, 448.1555, 448.1245,
            448.1255, 448.1281, 448.7394, 448.4414, 448.1224, 448.1254, 448.1355,
            448.1270, 448.4430, 448.1224, 448.1497, 448.1252, 448.7395, 448.1255,
            448.7397, 448.1262, 448.7394, 448.4406, 448.1271, 448.1224, 448.1216,
            448.7421, 448.1253, 448.7397, 448.1229, 448.5797, 448.4346, 448.7399,
            448.1252, 448.7394, 448.1278, 448.1213, 448.7436, 448.1282, 448.1273,
            448.1290, 448.7399, 448.1215, 448.1223, 448.7408, 448.1244, 448.1252,
            448.1256, 448.7432, 448.1235, 448.1227, 448.5935, 448.7395, 448.1429,
            448.1244, 448.7429, 448.7395, 448.7394, 448.4402, 448.1247, 448.4525,
            448.7234, 448.1256, 448.1246, 448.7394, 448.7404, 448.1250, 448.4335,
            448.7405, 448.1276, 448.1253, 448.7394, 448.7394, 448.7403, 448.1253,
            448.1254, 448.1218, 448.7421, 448.1252, 448.1732, 448.7397, 448.1221,
            448.7397, 448.1235, 448.1279, 448.1255, 448.7395, 448.1248, 448.1229,
            448.7394, 448.1229, 448.7399, 448.4366, 448.1259, 448.1269, 448.1261,
            448.1213, 448.1205, 448.1332, 448.1257, 448.1220, 448.5593, 448.7457,
            448.7054, 448.7394, 448.1257, 448.1201, 448.1447, 448.1254, 448.1244,
            448.1322, 448.7406, 448.7403, 448.1264, 448.1227, 448.1247, 448.1302,
            448.1300, 448.1319, 448.1290, 448.7398, 448.1285, 448.1249, 448.1392,
            448.1208, 448.1287, 448.1250, 448.1205, 448.1219, 448.4243, 448.1254,
            448.1290, 448.1271, 448.1258, 448.7394, 448.1284, 448.4411, 448.1218,
            448.1303, 448.1251, 448.1240, 448.7397, 448.1257, 448.1292, 448.1226,
            448.1246, 448.1329, 448.1318, 448.1251, 448.7467, 448.4408, 448.1310,
            448.7405, 448.7417, 448.1208, 448.1257, 448.1260, 448.1226, 448.1295,
            448.1295, 448.1223, 448.1249, 448.1218, 448.7395, 448.1214, 448.1229,
            448.1221, 448.1238, 448.1251, 448.1253, 448.7394, 448.1251, 448.1284,
            448.1205, 448.1224, 448.1222, 448.1266, 448.1240, 448.1268, 448.1251,
            448.7429, 448.1254, 448.2850, 448.1256, 448.1209, 448.4417, 448.1257,
            448.5027, 448.7394, 448.7395, 448.1454, 448.1298, 448.1286, 448.4407,
            448.1223, 448.7420, 448.7394, 448.7426, 448.1319, 448.1287, 448.2903,
            448.7394, 448.7394, 448.1275, 448.5966, 448.1313, 448.1279, 448.1265,
            448.1201, 448.7394, 448.1378, 448.6895, 448.1247, 448.1458, 448.7379,
            448.1215, 448.1218, 448.7410, 448.7396, 448.1251, 448.2604, 448.2951,
            448.1246, 448.1228, 448.1254, 448.4528, 448.1255, 448.1290, 448.1351,
            448.1257, 448.1253, 448.7396, 448.1269, 448.1200, 448.1221, 448.7414,
            448.7394, 448.7404, 448.7394, 448.1318, 448.1344, 448.1254, 448.1223,
            448.1248, 448.1244, 448.7396, 448.1245, 448.1281, 448.1220, 448.7394,
            448.1245, 448.1248, 448.7432, 448.1265, 448.1252, 448.1288, 448.1251,
            448.1239, 448.5957, 448.1202, 448.1251, 448.7395, 448.1275, 448.1266,
            448.1224, 448.7394, 448.1255, 448.7394, 448.7394, 448.1244, 448.1212,
            448.1252, 448.7401, 448.7396, 448.2858, 448.1286, 448.1274, 448.1250,
            448.1249, 448.1238, 448.1319, 448.1229, 448.7394, 448.1253, 448.1281,
            448.1294, 448.1228, 448.2918, 448.1258, 448.1201, 448.1259, 448.1251,
            448.1223, 448.1264, 448.1244, 448.7394, 448.7398, 448.7401, 448.7397,
            448.1251, 448.1231, 448.1235, 448.1293, 448.1426, 448.1201, 448.1263,
            448.7411, 448.1265, 448.4400, 448.1275, 448.7406, 448.1241, 448.4417,
            448.7395, 448.7427, 448.1241, 448.6054, 448.7395, 448.1273, 448.1263,
            448.1286, 448.1252, 448.1240, 448.1260, 448.1230, 448.7395, 448.1242,
            448.2841, 448.1309, 448.1222, 448.1230, 448.1252, 448.7396, 448.7395,
            448.4424, 448.7396, 448.1270, 448.4385, 448.1252, 448.1237, 448.7394,
            448.1218, 448.7433, 448.7372, 448.1295, 448.1263, 448.1253, 448.1404,
            448.1263, 448.1595, 448.4406, 448.1266, 448.1270, 448.7410, 448.1253,
            448.6547, 448.4941, 448.1233, 448.1260, 448.4932, 448.1284, 448.7394,
            448.7394, 448.7394, 448.1292, 448.1427, 448.7395, 448.1255, 448.7422,
            448.7355, 448.1254, 448.1241, 448.1255, 448.1310, 448.7394, 448.7400,
            448.1218, 448.7431, 448.6249, 448.1266, 448.4370, 448.1261, 448.7419,
            448.1377, 448.1262, 448.1244, 448.6176, 448.1306, 448.1225, 448.1217,
            448.4359, 448.1320, 448.7394, 448.1270, 448.1256, 448.7408, 448.1255,
            448.4435, 448.1219, 448.1301, 448.1216, 448.1230, 448.1251, 448.1249,
            448.1373, 448.1257, 448.1211, 448.1208, 448.7394, 448.1251, 448.1237,
            448.1265, 448.1257, 448.1251, 448.1205, 448.1207, 448.7397, 448.1248,
            448.4468, 448.7458, 448.4402, 448.1266, 448.7396, 448.1267, 448.1272,
            448.1208, 448.1246, 448.1271, 448.1259, 448.1238, 448.1226, 448.1289,
            448.7394, 448.1224, 448.7394, 448.4417, 448.1297, 448.1258, 448.1265,
            448.1275, 448.7408, 448.1277, 448.4627, 448.1230, 448.1228, 448.1280,
            448.1255, 448.1217, 448.7397, 448.4443, 448.1213, 448.1288, 448.1242,
            448.4414, 448.7394, 448.1267, 448.7407, 448.2942, 448.7435, 448.7394,
            448.1220, 448.7394, 448.2803, 448.1250, 448.1207, 448.7396, 448.1211,
            448.1246, 448.1233, 448.7395, 448.1232, 448.1233, 448.1326, 448.7406,
            448.1252, 448.2885, 448.1247, 448.1205, 448.7399, 448.6015, 448.1251,
            448.1258, 448.7399, 448.1252, 448.2286, 448.7351, 448.7399, 448.1272,
            448.1255, 448.1306, 448.7385, 448.1271, 448.7393, 448.7394, 448.1254,
            448.7399, 448.1265, 448.1259, 448.1247, 448.1243, 448.1499, 448.1223,
            448.7394, 448.7459, 448.1297, 448.1324, 448.1209, 448.1288, 448.1292,
            448.1310, 448.7400, 448.1263, 448.7402, 448.7397, 448.1217, 448.1279,
            448.1249, 448.1245, 448.1289, 448.1241, 448.7408, 448.7396, 448.1250,
            448.1292, 448.5926, 448.1386, 448.7394, 448.7426, 448.2177, 448.1255,
            448.1214, 448.1230], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1279, 448.7396, 448.1436, 448.1298, 448.1278, 448.1236, 448.7394,
        448.1245, 448.7418, 448.7394, 448.1241, 448.1213, 448.1254, 448.1257,
        448.1283, 448.1207, 448.1286, 448.7385, 448.1274, 448.7396, 448.1212,
        448.7428, 448.6015, 448.7395, 448.1263, 448.7394, 448.1231, 448.1254,
        448.1205, 448.1302, 448.5850, 448.7394, 448.1303, 448.1297, 448.4415,
        448.7394, 448.1201, 448.1249, 448.1259, 448.6308, 448.1259, 448.1284,
        448.1282, 448.1232, 448.7398, 448.7405, 448.1372, 448.1242, 448.2993,
        448.7441, 448.1227, 448.1254, 448.7402, 448.1230, 448.1075, 448.7394,
        448.1235, 448.1296, 448.1273, 448.1216, 448.7399, 448.1215, 448.4335,
        448.7407, 448.1232, 448.4426, 448.7407, 448.1267, 448.1244, 448.1252,
        448.1058, 448.7396, 448.1225, 448.1300, 448.1233, 448.1250, 448.1222,
        448.7404, 448.1252, 448.1283, 448.1237, 448.1274, 448.1252, 448.1288,
        448.7395, 448.1244, 448.1290, 448.1223, 448.1263, 448.1252, 448.1237,
        448.7396, 448.1235, 448.1282, 448.1257, 448.1228, 448.1254, 448.1207,
        448.1240, 448.2820, 448.7440, 448.1257, 448.4331, 448.1255, 448.1240,
        448.7394, 448.1345, 448.1255, 448.1305, 448.1293, 448.1221, 448.1254,
        448.1261, 448.1252, 448.4436, 448.1319, 448.1347, 448.1225, 448.1241,
        448.1763, 448.1235, 448.7409, 448.1287, 448.7396, 448.7396, 448.1263,
        448.4458, 448.1250, 448.1312, 448.7407, 448.1250, 448.4396, 448.1248,
        448.1252, 448.1253, 448.1279, 448.1268, 448.1240, 448.7399, 448.4407,
        448.1250, 448.1258, 448.1251, 448.1230, 448.7398, 448.7402, 448.1248,
        448.7423, 448.1268, 448.1259, 448.1279, 448.1305, 448.1234, 448.4416,
        448.7436, 448.7419, 448.1260, 448.1218, 448.1061, 448.7394, 448.1271,
        448.7399, 448.1339, 448.1251, 448.1270, 448.1254, 448.1257, 448.1252,
        448.1272, 448.1383, 448.1274, 448.1303, 448.1243, 448.7396, 448.1259,
        448.1268, 448.1302, 448.1219, 448.1248, 448.1286, 448.1224, 448.1242,
        448.1248, 448.5930, 448.1248, 448.7394, 448.1235, 448.1246, 448.1283,
        448.1257, 448.7419, 448.1392, 448.1255, 448.7407, 448.1252, 448.1252,
        448.7403, 448.1219, 448.1248, 448.1249, 448.1251, 448.3179, 448.2361,
        448.1240, 448.7399, 448.1263, 448.1312, 448.1242, 448.1257, 448.1254,
        448.1253, 448.7394, 448.1275, 448.1293, 448.1286, 448.1262, 448.7421,
        448.1212, 448.1236, 448.7395, 448.7397, 448.1262, 448.1262, 448.7399,
        448.4419, 448.1247, 448.3126, 448.2899, 448.7408, 448.1056, 448.1243,
        448.1254, 448.1243, 448.1262, 448.1296, 448.1252, 448.1201, 448.4406,
        448.7394, 448.1299, 448.1293, 448.1250, 448.7398, 448.4402, 448.1245,
        448.1266, 448.7411, 448.1255, 448.1240, 448.1373, 448.1254, 448.1249,
        448.1250, 448.1274, 448.7394, 448.1255, 448.1291, 448.7394, 448.1286,
        448.5527, 448.1228, 448.1288, 448.1063, 448.7394, 448.7401, 448.1231,
        448.1260, 448.1243, 448.1243, 448.1241, 448.1251, 448.7401, 448.1309,
        448.1238, 448.1261, 448.1217, 448.1373, 448.7394, 448.7405, 448.7439,
        448.7401, 448.1283, 448.1235, 448.1266, 448.1248, 448.7417, 448.1709,
        448.1262, 448.1304, 448.7405, 448.7397, 448.1208, 448.7395, 448.2886,
        448.1412, 448.1321, 448.1269, 448.1287, 448.1248, 448.7394, 448.1286,
        448.7419, 448.1283, 448.1286, 448.1221, 448.1253, 448.1268, 448.1233,
        448.1250, 448.6149, 448.1235, 448.1271, 448.7394, 448.1256, 448.1271,
        448.7394, 448.1274, 448.7408, 448.1233, 448.1312, 448.7394, 448.1221,
        448.1261, 448.1226, 448.1258, 448.1237, 448.4111, 448.1260, 448.7416,
        448.1485, 448.7430, 448.1305, 448.1281, 448.1210, 448.1229, 448.1252,
        448.7395, 448.7394, 448.7452, 448.7394, 448.4459, 448.1462, 448.1251,
        448.1306, 448.2590, 448.1295, 448.1268, 448.1237, 448.1263, 448.1277,
        448.1284, 448.1253, 448.1223, 448.1261, 448.1252, 448.1280, 448.1284,
        448.1250, 448.7395, 448.1278, 448.1374, 448.1255, 448.7394, 448.1210,
        448.1261, 448.1216, 448.1219, 448.1294, 448.1248, 448.7404, 448.1268,
        448.1241, 448.1288, 448.4255, 448.1218, 448.7422, 448.1268, 448.1247,
        448.7422, 448.7394, 448.1265, 448.1234, 448.5942, 448.1222, 448.1057,
        448.4491, 448.1320, 448.7380, 448.1225, 448.4544, 448.3239, 448.1245,
        448.1421, 448.1248, 448.7395, 448.7402, 448.7407, 448.1555, 448.1245,
        448.1255, 448.1281, 448.7394, 448.4414, 448.1224, 448.1254, 448.1355,
        448.1270, 448.4430, 448.1224, 448.1497, 448.1252, 448.7395, 448.1255,
        448.7397, 448.1262, 448.7394, 448.4406, 448.1271, 448.1224, 448.1216,
        448.7421, 448.1253, 448.7397, 448.1229, 448.5797, 448.4346, 448.7399,
        448.1252, 448.7394, 448.1278, 448.1213, 448.7436, 448.1282, 448.1273,
        448.1290, 448.7399, 448.1215, 448.1223, 448.7408, 448.1244, 448.1252,
        448.1256, 448.7432, 448.1235, 448.1227, 448.5935, 448.7395, 448.1429,
        448.1244, 448.7429, 448.7395, 448.7394, 448.4402, 448.1247, 448.4525,
        448.7234, 448.1256, 448.1246, 448.7394, 448.7404, 448.1250, 448.4335,
        448.7405, 448.1276, 448.1253, 448.7394, 448.7394, 448.7403, 448.1253,
        448.1254, 448.1218, 448.7421, 448.1252, 448.1732, 448.7397, 448.1221,
        448.7397, 448.1235, 448.1279, 448.1255, 448.7395, 448.1248, 448.1229,
        448.7394, 448.1229, 448.7399, 448.4366, 448.1259, 448.1269, 448.1261,
        448.1213, 448.1205, 448.1332, 448.1257, 448.1220, 448.5593, 448.7457,
        448.7054, 448.7394, 448.1257, 448.1201, 448.1447, 448.1254, 448.1244,
        448.1322, 448.7406, 448.7403, 448.1264, 448.1227, 448.1247, 448.1302,
        448.1300, 448.1319, 448.1290, 448.7398, 448.1285, 448.1249, 448.1392,
        448.1208, 448.1287, 448.1250, 448.1205, 448.1219, 448.4243, 448.1254,
        448.1290, 448.1271, 448.1258, 448.7394, 448.1284, 448.4411, 448.1218,
        448.1303, 448.1251, 448.1240, 448.7397, 448.1257, 448.1292, 448.1226,
        448.1246, 448.1329, 448.1318, 448.1251, 448.7467, 448.4408, 448.1310,
        448.7405, 448.7417, 448.1208, 448.1257, 448.1260, 448.1226, 448.1295,
        448.1295, 448.1223, 448.1249, 448.1218, 448.7395, 448.1214, 448.1229,
        448.1221, 448.1238, 448.1251, 448.1253, 448.7394, 448.1251, 448.1284,
        448.1205, 448.1224, 448.1222, 448.1266, 448.1240, 448.1268, 448.1251,
        448.7429, 448.1254, 448.2850, 448.1256, 448.1209, 448.4417, 448.1257,
        448.5027, 448.7394, 448.7395, 448.1454, 448.1298, 448.1286, 448.4407,
        448.1223, 448.7420, 448.7394, 448.7426, 448.1319, 448.1287, 448.2903,
        448.7394, 448.7394, 448.1275, 448.5966, 448.1313, 448.1279, 448.1265,
        448.1201, 448.7394, 448.1378, 448.6895, 448.1247, 448.1458, 448.7379,
        448.1215, 448.1218, 448.7410, 448.7396, 448.1251, 448.2604, 448.2951,
        448.1246, 448.1228, 448.1254, 448.4528, 448.1255, 448.1290, 448.1351,
        448.1257, 448.1253, 448.7396, 448.1269, 448.1200, 448.1221, 448.7414,
        448.7394, 448.7404, 448.7394, 448.1318, 448.1344, 448.1254, 448.1223,
        448.1248, 448.1244, 448.7396, 448.1245, 448.1281, 448.1220, 448.7394,
        448.1245, 448.1248, 448.7432, 448.1265, 448.1252, 448.1288, 448.1251,
        448.1239, 448.5957, 448.1202, 448.1251, 448.7395, 448.1275, 448.1266,
        448.1224, 448.7394, 448.1255, 448.7394, 448.7394, 448.1244, 448.1212,
        448.1252, 448.7401, 448.7396, 448.2858, 448.1286, 448.1274, 448.1250,
        448.1249, 448.1238, 448.1319, 448.1229, 448.7394, 448.1253, 448.1281,
        448.1294, 448.1228, 448.2918, 448.1258, 448.1201, 448.1259, 448.1251,
        448.1223, 448.1264, 448.1244, 448.7394, 448.7398, 448.7401, 448.7397,
        448.1251, 448.1231, 448.1235, 448.1293, 448.1426, 448.1201, 448.1263,
        448.7411, 448.1265, 448.4400, 448.1275, 448.7406, 448.1241, 448.4417,
        448.7395, 448.7427, 448.1241, 448.6054, 448.7395, 448.1273, 448.1263,
        448.1286, 448.1252, 448.1240, 448.1260, 448.1230, 448.7395, 448.1242,
        448.2841, 448.1309, 448.1222, 448.1230, 448.1252, 448.7396, 448.7395,
        448.4424, 448.7396, 448.1270, 448.4385, 448.1252, 448.1237, 448.7394,
        448.1218, 448.7433, 448.7372, 448.1295, 448.1263, 448.1253, 448.1404,
        448.1263, 448.1595, 448.4406, 448.1266, 448.1270, 448.7410, 448.1253,
        448.6547, 448.4941, 448.1233, 448.1260, 448.4932, 448.1284, 448.7394,
        448.7394, 448.7394, 448.1292, 448.1427, 448.7395, 448.1255, 448.7422,
        448.7355, 448.1254, 448.1241, 448.1255, 448.1310, 448.7394, 448.7400,
        448.1218, 448.7431, 448.6249, 448.1266, 448.4370, 448.1261, 448.7419,
        448.1377, 448.1262, 448.1244, 448.6176, 448.1306, 448.1225, 448.1217,
        448.4359, 448.1320, 448.7394, 448.1270, 448.1256, 448.7408, 448.1255,
        448.4435, 448.1219, 448.1301, 448.1216, 448.1230, 448.1251, 448.1249,
        448.1373, 448.1257, 448.1211, 448.1208, 448.7394, 448.1251, 448.1237,
        448.1265, 448.1257, 448.1251, 448.1205, 448.1207, 448.7397, 448.1248,
        448.4468, 448.7458, 448.4402, 448.1266, 448.7396, 448.1267, 448.1272,
        448.1208, 448.1246, 448.1271, 448.1259, 448.1238, 448.1226, 448.1289,
        448.7394, 448.1224, 448.7394, 448.4417, 448.1297, 448.1258, 448.1265,
        448.1275, 448.7408, 448.1277, 448.4627, 448.1230, 448.1228, 448.1280,
        448.1255, 448.1217, 448.7397, 448.4443, 448.1213, 448.1288, 448.1242,
        448.4414, 448.7394, 448.1267, 448.7407, 448.2942, 448.7435, 448.7394,
        448.1220, 448.7394, 448.2803, 448.1250, 448.1207, 448.7396, 448.1211,
        448.1246, 448.1233, 448.7395, 448.1232, 448.1233, 448.1326, 448.7406,
        448.1252, 448.2885, 448.1247, 448.1205, 448.7399, 448.6015, 448.1251,
        448.1258, 448.7399, 448.1252, 448.2286, 448.7351, 448.7399, 448.1272,
        448.1255, 448.1306, 448.7385, 448.1271, 448.7393, 448.7394, 448.1254,
        448.7399, 448.1265, 448.1259, 448.1247, 448.1243, 448.1499, 448.1223,
        448.7394, 448.7459, 448.1297, 448.1324, 448.1209, 448.1288, 448.1292,
        448.1310, 448.7400, 448.1263, 448.7402, 448.7397, 448.1217, 448.1279,
        448.1249, 448.1245, 448.1289, 448.1241, 448.7408, 448.7396, 448.1250,
        448.1292, 448.5926, 448.1386, 448.7394, 448.7426, 448.2177, 448.1255,
        448.1214, 448.1230], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([403.3255], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0300],
             [112.0302],
             [112.0301],
             [112.0301]],

            [[112.0363],
             [112.0322],
             [112.0347],
             [112.0322]],

            [[112.0307],
             [112.0307],
             [112.0301],
             [112.0301]],

            ...,

            [[112.0372],
             [112.1858],
             [112.0356],
             [112.0356]],

            [[112.0309],
             [112.0305],
             [112.0314],
             [112.0314]],

            [[112.0313],
             [112.0302],
             [112.0305],
             [112.0305]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1205, 448.1354, 448.1216,  ..., 448.2942, 448.1242, 448.1224],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1205, 448.1354, 448.1216,  ..., 448.2942, 448.1242, 448.1224],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0360],
             [112.0360],
             [112.0346],
             [112.0346]],

            [[112.0365],
             [112.0365],
             [112.0351],
             [112.0351]],

            [[112.0365],
             [112.0365],
             [112.0377],
             [112.0377]],

            ...,

            [[112.0368],
             [112.0350],
             [112.0362],
             [112.0362]],

            [[112.1828],
             [112.1828],
             [112.1825],
             [112.1825]],

            [[112.0369],
             [112.0369],
             [112.0358],
             [112.0358]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1413, 448.1434, 448.1482,  ..., 448.1442, 448.7308, 448.1453],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1413, 448.1434, 448.1482,  ..., 448.1442, 448.7308, 448.1453],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1756],
             [112.1765],
             [112.1759],
             [112.1759]],

            [[112.0453],
             [112.0440],
             [112.0450],
             [112.0432]],

            [[112.0452],
             [112.0435],
             [112.0432],
             [112.0432]],

            ...,

            [[112.0455],
             [112.0440],
             [112.0453],
             [112.0439]],

            [[112.1759],
             [112.1759],
             [112.1759],
             [112.1759]],

            [[112.1756],
             [112.1766],
             [112.1766],
             [112.1755]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7039, 448.1776, 448.1750,  ..., 448.1787, 448.7037, 448.7043],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7039, 448.1776, 448.1750,  ..., 448.1787, 448.7037, 448.7043],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0496],
             [112.0496],
             [112.0492],
             [112.0492]],

            [[112.1745],
             [112.0517],
             [112.0512],
             [112.0673]],

            [[112.0497],
             [112.0501],
             [112.0504],
             [112.0493]],

            ...,

            [[112.0512],
             [112.1748],
             [112.0511],
             [112.0511]],

            [[112.0510],
             [112.1773],
             [112.0910],
             [112.0510]],

            [[112.0509],
             [112.0494],
             [112.0508],
             [112.0491]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1976, 448.3446, 448.1996,  ..., 448.3282, 448.3703, 448.2002],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1976, 448.3446, 448.1996,  ..., 448.3282, 448.3703, 448.2002],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0582],
             [112.0575],
             [112.0588],
             [112.0583]],

            [[112.0586],
             [112.0586],
             [112.0578],
             [112.0578]],

            [[112.0587],
             [112.0580],
             [112.0587],
             [112.0573]],

            ...,

            [[112.0655],
             [112.0589],
             [112.0610],
             [112.0610]],

            [[112.1700],
             [112.1700],
             [112.1699],
             [112.1699]],

            [[112.1694],
             [112.1695],
             [112.1728],
             [112.1728]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2327, 448.2328, 448.2327,  ..., 448.2465, 448.6797, 448.6846],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2327, 448.2328, 448.2327,  ..., 448.2465, 448.6797, 448.6846],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0642],
             [112.0630],
             [112.0632],
             [112.0632]],

            [[112.0644],
             [112.0630],
             [112.0638],
             [112.0638]],

            [[112.0646],
             [112.0644],
             [112.0707],
             [112.0707]],

            ...,

            [[112.1716],
             [112.1670],
             [112.1688],
             [112.1716]],

            [[112.0641],
             [112.0641],
             [112.0638],
             [112.0638]],

            [[112.0635],
             [112.0645],
             [112.0631],
             [112.0644]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2536, 448.2550, 448.2704,  ..., 448.6789, 448.2558, 448.2555],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2536, 448.2550, 448.2704,  ..., 448.6789, 448.2558, 448.2555],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0713],
             [112.0704],
             [112.0699],
             [112.0721]],

            [[112.1637],
             [112.1643],
             [112.0716],
             [112.0719]],

            [[112.0699],
             [112.0713],
             [112.0701],
             [112.0714]],

            ...,

            [[112.0698],
             [112.0703],
             [112.0704],
             [112.0698]],

            [[112.1670],
             [112.0724],
             [112.1668],
             [112.0723]],

            [[112.1630],
             [112.1634],
             [112.1631],
             [112.1631]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2837, 448.4714, 448.2827,  ..., 448.2802, 448.4785, 448.6525],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2837, 448.4714, 448.2827,  ..., 448.2802, 448.4785, 448.6525],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0783],
             [112.0792],
             [112.0780],
             [112.0791]],

            [[112.0789],
             [112.0780],
             [112.0781],
             [112.0781]],

            [[112.1585],
             [112.1585],
             [112.1586],
             [112.1586]],

            ...,

            [[112.0788],
             [112.0788],
             [112.0782],
             [112.0782]],

            [[112.0791],
             [112.0788],
             [112.0795],
             [112.0801]],

            [[112.1647],
             [112.1601],
             [112.1609],
             [112.0826]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3146, 448.3132, 448.6344,  ..., 448.3140, 448.3176, 448.5683],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3146, 448.3132, 448.6344,  ..., 448.3140, 448.3176, 448.5683],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0917],
             [112.0917],
             [112.0906],
             [112.0906]],

            [[112.1501],
             [112.1501],
             [112.1530],
             [112.1502]],

            [[112.1499],
             [112.1498],
             [112.1498],
             [112.1499]],

            ...,

            [[112.1512],
             [112.1588],
             [112.1516],
             [112.0961]],

            [[112.0904],
             [112.0904],
             [112.0907],
             [112.0907]],

            [[112.0919],
             [112.0905],
             [112.0916],
             [112.0905]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3646, 448.6034, 448.5994,  ..., 448.5577, 448.3621, 448.3645],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3646, 448.6034, 448.5994,  ..., 448.5577, 448.3621, 448.3645],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1441],
             [112.1441],
             [112.1449],
             [112.1449]],

            [[112.1441],
             [112.1447],
             [112.1447],
             [112.1440]],

            [[112.1440],
             [112.1441],
             [112.1440],
             [112.1440]],

            ...,

            [[112.0994],
             [112.0995],
             [112.0995],
             [112.0995]],

            [[112.1010],
             [112.1002],
             [112.0996],
             [112.1009]],

            [[112.1073],
             [112.1007],
             [112.1511],
             [112.1009]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5779, 448.5775, 448.5762,  ..., 448.3979, 448.4017, 448.4601],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5779, 448.5775, 448.5762,  ..., 448.3979, 448.4017, 448.4601],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1445],
             [112.1453],
             [112.1446],
             [112.1446]],

            [[112.1060],
             [112.1051],
             [112.1062],
             [112.1051]],

            [[112.1048],
             [112.1051],
             [112.1046],
             [112.1049]],

            ...,

            [[112.1058],
             [112.1047],
             [112.1056],
             [112.1046]],

            [[112.1051],
             [112.1059],
             [112.1052],
             [112.1052]],

            [[112.1052],
             [112.1050],
             [112.1049],
             [112.1048]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5791, 448.4224, 448.4193,  ..., 448.4207, 448.4214, 448.4199],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5791, 448.4224, 448.4193,  ..., 448.4207, 448.4214, 448.4199],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1213],
             [112.1220],
             [112.1116],
             [112.1116]],

            [[112.1136],
             [112.1136],
             [112.1147],
             [112.1147]],

            [[112.1110],
             [112.1108],
             [112.1120],
             [112.1109]],

            ...,

            [[112.1107],
             [112.1107],
             [112.1117],
             [112.1117]],

            [[112.1456],
             [112.1456],
             [112.1466],
             [112.1466]],

            [[112.1113],
             [112.1113],
             [112.1109],
             [112.1109]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4666, 448.4567, 448.4446,  ..., 448.4448, 448.5845, 448.4443],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4666, 448.4567, 448.4446,  ..., 448.4448, 448.5845, 448.4443],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1448],
             [112.1483],
             [112.1449],
             [112.1507]],

            [[112.1477],
             [112.1477],
             [112.1553],
             [112.1449]],

            [[112.1103],
             [112.1103],
             [112.1108],
             [112.1108]],

            ...,

            [[112.1121],
             [112.1106],
             [112.1122],
             [112.1106]],

            [[112.1103],
             [112.1107],
             [112.1112],
             [112.1103]],

            [[112.1467],
             [112.1142],
             [112.1467],
             [112.1143]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5887, 448.5956, 448.4422,  ..., 448.4455, 448.4424, 448.5219],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5887, 448.5956, 448.4422,  ..., 448.4455, 448.4424, 448.5219],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1081],
             [112.1081],
             [112.1078],
             [112.1078]],

            [[112.1098],
             [112.1080],
             [112.1083],
             [112.1083]],

            [[112.1079],
             [112.1085],
             [112.1082],
             [112.1079]],

            ...,

            [[112.1081],
             [112.1081],
             [112.1080],
             [112.1080]],

            [[112.1571],
             [112.1183],
             [112.1538],
             [112.1093]],

            [[112.1505],
             [112.1509],
             [112.1507],
             [112.1507]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4318, 448.4344, 448.4325,  ..., 448.4322, 448.5384, 448.6028],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4318, 448.4344, 448.4325,  ..., 448.4322, 448.5384, 448.6028],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1595],
             [112.1595],
             [112.1595],
             [112.1595]],

            [[112.1013],
             [112.1013],
             [112.1009],
             [112.1009]],

            [[112.1031],
             [112.1014],
             [112.1012],
             [112.1631]],

            ...,

            [[112.1010],
             [112.1013],
             [112.1012],
             [112.1009]],

            [[112.1012],
             [112.1011],
             [112.1015],
             [112.1010]],

            [[112.1596],
             [112.1595],
             [112.1595],
             [112.1597]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6381, 448.4045, 448.4688,  ..., 448.4044, 448.4047, 448.6384],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6381, 448.4045, 448.4688,  ..., 448.4044, 448.4047, 448.6384],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1053],
             [112.1053],
             [112.0981],
             [112.0981]],

            [[112.0980],
             [112.0980],
             [112.0986],
             [112.0986]],

            [[112.1625],
             [112.1621],
             [112.1621],
             [112.1628]],

            ...,

            [[112.0978],
             [112.0989],
             [112.0979],
             [112.0981]],

            [[112.1621],
             [112.1669],
             [112.1624],
             [112.1624]],

            [[112.0983],
             [112.0979],
             [112.0983],
             [112.0979]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4069, 448.3932, 448.6495,  ..., 448.3926, 448.6537, 448.3924],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4069, 448.3932, 448.6495,  ..., 448.3926, 448.6537, 448.3924],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0930],
             [112.0930],
             [112.0940],
             [112.0940]],

            [[112.0931],
             [112.0929],
             [112.0930],
             [112.0931]],

            [[112.1663],
             [112.1658],
             [112.1665],
             [112.1658]],

            ...,

            [[112.0933],
             [112.0947],
             [112.0930],
             [112.0937]],

            [[112.0929],
             [112.0931],
             [112.0938],
             [112.0929]],

            [[112.0929],
             [112.0937],
             [112.0929],
             [112.0929]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3741, 448.3721, 448.6643,  ..., 448.3747, 448.3727, 448.3725],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3741, 448.3721, 448.6643,  ..., 448.3747, 448.3727, 448.3725],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0905],
             [112.0905],
             [112.0904],
             [112.0905]],

            [[112.0905],
             [112.0906],
             [112.0904],
             [112.0908]],

            [[112.0905],
             [112.0904],
             [112.0909],
             [112.0909]],

            ...,

            [[112.0905],
             [112.0905],
             [112.0907],
             [112.0905]],

            [[112.1677],
             [112.1677],
             [112.1677],
             [112.1677]],

            [[112.0909],
             [112.0904],
             [112.0904],
             [112.0904]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3619, 448.3623, 448.3626,  ..., 448.3622, 448.6709, 448.3620],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3619, 448.3623, 448.3626,  ..., 448.3622, 448.6709, 448.3620],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0278e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0861],
             [112.0862],
             [112.0870],
             [112.0870]],

            [[112.0881],
             [112.1724],
             [112.1725],
             [112.0873]],

            [[112.0866],
             [112.0866],
             [112.0865],
             [112.0865]],

            ...,

            [[112.1715],
             [112.1715],
             [112.1749],
             [112.1749]],

            [[112.1711],
             [112.1711],
             [112.1711],
             [112.1711]],

            [[112.0862],
             [112.0862],
             [112.0861],
             [112.0861]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3462, 448.5202, 448.3463,  ..., 448.6927, 448.6844, 448.3446],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3462, 448.5202, 448.3463,  ..., 448.6927, 448.6844, 448.3446],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0864],
             [112.0861],
             [112.0862],
             [112.0867]],

            [[112.0866],
             [112.0893],
             [112.0863],
             [112.0922]],

            [[112.0861],
             [112.0862],
             [112.0862],
             [112.0874]],

            ...,

            [[112.0862],
             [112.0862],
             [112.0862],
             [112.0862]],

            [[112.1712],
             [112.1712],
             [112.1712],
             [112.1712]],

            [[112.0862],
             [112.0867],
             [112.0862],
             [112.0862]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3455, 448.3545, 448.3460,  ..., 448.3446, 448.6846, 448.3453],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3455, 448.3545, 448.3460,  ..., 448.3446, 448.6846, 448.3453],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0861],
             [112.0920],
             [112.0862],
             [112.0862]],

            [[112.1710],
             [112.1710],
             [112.1710],
             [112.1710]],

            [[112.1710],
             [112.1710],
             [112.1710],
             [112.1710]],

            ...,

            [[112.0862],
             [112.0863],
             [112.0867],
             [112.0862]],

            [[112.0861],
             [112.0867],
             [112.0861],
             [112.0863]],

            [[112.0862],
             [112.0861],
             [112.0866],
             [112.0862]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3505, 448.6842, 448.6842, 448.5226, 448.3453, 448.6852, 448.3450,
            448.3484, 448.6101, 448.6842, 448.6842, 448.3452, 448.3447, 448.3452,
            448.3448, 448.3455, 448.3462, 448.3451, 448.3449, 448.3454, 448.6875,
            448.3461, 448.6842, 448.3452, 448.3444, 448.3451, 448.5220, 448.3507,
            448.3458, 448.6842, 448.3450, 448.3448, 448.3464, 448.3453, 448.3444,
            448.3447, 448.3445, 448.6842, 448.3445, 448.6523, 448.3456, 448.6924,
            448.3474, 448.3453, 448.3453, 448.6842, 448.3451, 448.3457, 448.5451,
            448.6842, 448.3444, 448.3453, 448.3453, 448.3469, 448.3450, 448.3460,
            448.3549, 448.3453, 448.6843, 448.3451, 448.5315, 448.6848, 448.6893,
            448.3472, 448.6844, 448.3480, 448.3452, 448.3593, 448.3456, 448.3442,
            448.5204, 448.3461, 448.6843, 448.3472, 448.3452, 448.3454, 448.3456,
            448.6843, 448.6850, 448.3449, 448.4218, 448.6903, 448.3454, 448.3460,
            448.3456, 448.3456, 448.3524, 448.5247, 448.3469, 448.3452, 448.3452,
            448.3456, 448.6842, 448.3456, 448.3455, 448.3375, 448.6843, 448.3506,
            448.3455, 448.3346, 448.6845, 448.5235, 448.3452, 448.3459, 448.3450,
            448.6843, 448.3462, 448.3455, 448.6842, 448.3452, 448.3449, 448.6853,
            448.6857, 448.5216, 448.5306, 448.5091, 448.3449, 448.3446, 448.3456,
            448.6877, 448.3458, 448.6096, 448.6895, 448.6846, 448.6093, 448.3464,
            448.6859, 448.3455, 448.6855, 448.3443, 448.6851, 448.6846, 448.3467,
            448.3443, 448.3447, 448.3451, 448.3450, 448.6841, 448.3454, 448.5204,
            448.3468, 448.3453, 448.3464, 448.3454, 448.3447, 448.3504, 448.3455,
            448.3468, 448.3448, 448.6287, 448.6843, 448.3447, 448.3458, 448.6842,
            448.6838, 448.3455, 448.3449, 448.3452, 448.6841, 448.3449, 448.3458,
            448.4646, 448.3452, 448.3445, 448.3455, 448.3454, 448.5243, 448.6853,
            448.3444, 448.6852, 448.3450, 448.3459, 448.3452, 448.3452, 448.6887,
            448.4478, 448.3474, 448.3448, 448.3453, 448.3452, 448.3463, 448.3452,
            448.3454, 448.3471, 448.3453, 448.3877, 448.6872, 448.3450, 448.3448,
            448.3486, 448.6844, 448.6868, 448.3455, 448.6842, 448.3459, 448.3456,
            448.3450, 448.3451, 448.3451, 448.3450, 448.3515, 448.5212, 448.6842,
            448.6843, 448.3454, 448.3455, 448.3451, 448.6882, 448.6842, 448.6850,
            448.6852, 448.3455, 448.3473, 448.3459, 448.6842, 448.3451, 448.3453,
            448.3452, 448.3454, 448.3632, 448.3450, 448.6858, 448.3347, 448.3461,
            448.3611, 448.3457, 448.3456, 448.3452, 448.6846, 448.5218, 448.3448,
            448.3444, 448.3453, 448.3458, 448.6854, 448.3455, 448.3449, 448.3456,
            448.3454, 448.6843, 448.3452, 448.5384, 448.6842, 448.6877, 448.3448,
            448.3454, 448.3452, 448.6848, 448.3458, 448.6842, 448.6844, 448.3449,
            448.6842, 448.3450, 448.3457, 448.3447, 448.6842, 448.3455, 448.3458,
            448.3444, 448.3448, 448.3448, 448.6843, 448.5201, 448.6762, 448.3456,
            448.3448, 448.6842, 448.3455, 448.3454, 448.3471, 448.6910, 448.3458,
            448.4717, 448.3462, 448.3458, 448.3474, 448.6869, 448.6843, 448.5491,
            448.3450, 448.6842, 448.4450, 448.3448, 448.3460, 448.6856, 448.3467,
            448.6864, 448.4396, 448.3450, 448.3456, 448.3449, 448.3463, 448.3456,
            448.3457, 448.3453, 448.3457, 448.3451, 448.3463, 448.3451, 448.3451,
            448.3459, 448.6842, 448.6869, 448.3453, 448.3455, 448.3452, 448.3448,
            448.6842, 448.3347, 448.3451, 448.6933, 448.3444, 448.6631, 448.3452,
            448.6901, 448.6842, 448.3452, 448.3458, 448.3457, 448.6842, 448.3446,
            448.3452, 448.6866, 448.5259, 448.3455, 448.3450, 448.3470, 448.3465,
            448.3444, 448.3452, 448.6843, 448.3453, 448.3454, 448.3452, 448.3453,
            448.3447, 448.6842, 448.3456, 448.6892, 448.3461, 448.6849, 448.3451,
            448.3446, 448.5233, 448.6879, 448.3464, 448.3454, 448.5984, 448.3559,
            448.6884, 448.3455, 448.3455, 448.3456, 448.6854, 448.6848, 448.3452,
            448.3517, 448.6882, 448.3452, 448.3455, 448.6843, 448.3451, 448.5202,
            448.3447, 448.6216, 448.3452, 448.6842, 448.3465, 448.3453, 448.6842,
            448.3472, 448.6842, 448.3452, 448.3452, 448.3454, 448.6850, 448.4465,
            448.4051, 448.3461, 448.6852, 448.6842, 448.3448, 448.3453, 448.6892,
            448.6915, 448.3449, 448.3452, 448.6846, 448.3452, 448.6328, 448.4937,
            448.6846, 448.6878, 448.3454, 448.6906, 448.6848, 448.3452, 448.3464,
            448.6091, 448.3728, 448.3451, 448.3458, 448.5549, 448.3446, 448.3447,
            448.3468, 448.3444, 448.3453, 448.3443, 448.6529, 448.3452, 448.3459,
            448.6854, 448.3467, 448.4165, 448.3452, 448.3506, 448.3462, 448.3454,
            448.3455, 448.3449, 448.6859, 448.3457, 448.6842, 448.3467, 448.6844,
            448.6842, 448.6862, 448.3444, 448.3456, 448.3466, 448.3457, 448.6844,
            448.3450, 448.3452, 448.3451, 448.3454, 448.6846, 448.3452, 448.3456,
            448.3452, 448.6856, 448.6842, 448.3457, 448.3456, 448.3460, 448.3348,
            448.3452, 448.5213, 448.3458, 448.3454, 448.6499, 448.3455, 448.3454,
            448.6843, 448.3451, 448.3517, 448.6091, 448.6846, 448.5576, 448.3459,
            448.6842, 448.3449, 448.3448, 448.3500, 448.3455, 448.3455, 448.3513,
            448.3452, 448.3457, 448.6842, 448.3455, 448.6842, 448.5225, 448.3450,
            448.6842, 448.3458, 448.3453, 448.3451, 448.3511, 448.6705, 448.3470,
            448.5218, 448.6842, 448.6842, 448.6929, 448.3455, 448.3455, 448.3448,
            448.3455, 448.6868, 448.5203, 448.3450, 448.3470, 448.3453, 448.6872,
            448.4173, 448.3447, 448.3456, 448.3458, 448.3458, 448.5231, 448.3447,
            448.6846, 448.3455, 448.3460, 448.3450, 448.3500, 448.3449, 448.6842,
            448.3458, 448.6842, 448.3457, 448.3458, 448.6973, 448.3452, 448.3463,
            448.3449, 448.6843, 448.4385, 448.3448, 448.3446, 448.4383, 448.3451,
            448.3459, 448.6842, 448.3454, 448.3444, 448.3459, 448.3448, 448.3450,
            448.3455, 448.3453, 448.3455, 448.3448, 448.5217, 448.3463, 448.3347,
            448.6844, 448.3444, 448.3451, 448.4323, 448.3720, 448.3455, 448.5201,
            448.3644, 448.6842, 448.4062, 448.6844, 448.3457, 448.4201, 448.3479,
            448.6846, 448.6852, 448.3455, 448.6863, 448.3456, 448.3458, 448.3452,
            448.6842, 448.3467, 448.3528, 448.3452, 448.6868, 448.3449, 448.3463,
            448.3455, 448.6876, 448.3462, 448.3449, 448.3468, 448.3469, 448.3469,
            448.6871, 448.5215, 448.3454, 448.3455, 448.3447, 448.3455, 448.3448,
            448.5233, 448.3452, 448.3452, 448.3459, 448.3462, 448.5218, 448.3449,
            448.6222, 448.6843, 448.3454, 448.3458, 448.3452, 448.3452, 448.6842,
            448.3451, 448.3449, 448.6889, 448.3465, 448.3453, 448.3448, 448.6063,
            448.6850, 448.3449, 448.3452, 448.6861, 448.5157, 448.6854, 448.6841,
            448.3388, 448.3450, 448.3459, 448.3448, 448.3453, 448.3456, 448.6843,
            448.3467, 448.3346, 448.3448, 448.3449, 448.6842, 448.3450, 448.3456,
            448.3455, 448.3459, 448.6076, 448.5204, 448.3458, 448.3451, 448.3464,
            448.3447, 448.3458, 448.3457, 448.3452, 448.3450, 448.3452, 448.3468,
            448.6433, 448.3449, 448.6845, 448.3455, 448.3459, 448.6887, 448.3453,
            448.3451, 448.6842, 448.3451, 448.3466, 448.3446, 448.3457, 448.6859,
            448.3451, 448.3455, 448.5240, 448.6844, 448.3445, 448.3965, 448.4331,
            448.3459, 448.3452, 448.3445, 448.3446, 448.3459, 448.3466, 448.5219,
            448.3451, 448.5204, 448.3459, 448.6880, 448.3453, 448.4430, 448.3448,
            448.6094, 448.3469, 448.3463, 448.6788, 448.3456, 448.3450, 448.6855,
            448.3454, 448.6842, 448.3452, 448.3457, 448.3454, 448.3446, 448.6905,
            448.3453, 448.6858, 448.3444, 448.6842, 448.3448, 448.4372, 448.4401,
            448.3454, 448.3450, 448.3459, 448.3455, 448.5213, 448.3456, 448.3452,
            448.3449, 448.3452, 448.6849, 448.3465, 448.6844, 448.3449, 448.6074,
            448.6850, 448.3459, 448.6842, 448.3454, 448.3453, 448.3452, 448.6859,
            448.3448, 448.3453, 448.3458, 448.5212, 448.3452, 448.6842, 448.3463,
            448.3444, 448.3452, 448.6848, 448.3449, 448.3448, 448.3456, 448.3463,
            448.6843, 448.3458, 448.3910, 448.3451, 448.3456, 448.3446, 448.3455,
            448.3449, 448.6842, 448.5212, 448.3381, 448.6842, 448.6854, 448.6895,
            448.3458, 448.6862, 448.3452, 448.3452, 448.6854, 448.5524, 448.3459,
            448.6842, 448.6842, 448.6852, 448.3459, 448.6842, 448.3456, 448.6896,
            448.3453, 448.3811, 448.3456, 448.5203, 448.3447, 448.4388, 448.6950,
            448.3445, 448.3557, 448.5224, 448.3463, 448.3470, 448.6858, 448.5204,
            448.3448, 448.3459, 448.3451, 448.3466, 448.4731, 448.5211, 448.3459,
            448.3455, 448.6841, 448.3458, 448.5229, 448.6859, 448.3452, 448.3453,
            448.6844, 448.3453, 448.6857, 448.3443, 448.6844, 448.3452, 448.3456,
            448.3464, 448.3443, 448.6901, 448.6845, 448.6853, 448.3459, 448.6844,
            448.3444, 448.3451, 448.3473, 448.6842, 448.4589, 448.3784, 448.6842,
            448.3445, 448.3456, 448.3457, 448.3457, 448.3448, 448.3455, 448.5224,
            448.3458, 448.3463, 448.3471, 448.3456, 448.3465, 448.3447, 448.3459,
            448.4574, 448.6101, 448.3482, 448.6924, 448.3460, 448.3454, 448.3448,
            448.6081, 448.3458, 448.3452, 448.3502, 448.6847, 448.3451, 448.4322,
            448.3464, 448.6842, 448.3454, 448.3452, 448.3452, 448.6848, 448.6882,
            448.3462, 448.3454, 448.3455, 448.3453, 448.3450, 448.6898, 448.3458,
            448.3456, 448.3450, 448.3453, 448.3453, 448.3464, 448.3455, 448.6842,
            448.3455, 448.3447, 448.3448, 448.6854, 448.3453, 448.3479, 448.3450,
            448.3449, 448.6912, 448.5283, 448.3480, 448.5232, 448.3442, 448.3452,
            448.3449, 448.3455, 448.6847, 448.5123, 448.3460, 448.6853, 448.3463,
            448.3568, 448.3457, 448.3480, 448.4321, 448.6842, 448.4182, 448.3448,
            448.3455, 448.3454, 448.3458, 448.3454, 448.3514, 448.3465, 448.6842,
            448.3466, 448.3458, 448.5226, 448.3450, 448.6035, 448.6848, 448.6901,
            448.3456, 448.3465, 448.3458, 448.3449, 448.5291, 448.3451, 448.3454,
            448.6842, 448.3461, 448.3454, 448.3453, 448.6842, 448.3448, 448.3457,
            448.3450, 448.6842, 448.3472, 448.3458, 448.6843, 448.3456, 448.3458,
            448.5212, 448.6861, 448.3475, 448.3459, 448.3458, 448.3453, 448.3454,
            448.3452, 448.3452], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3505, 448.6842, 448.6842, 448.5226, 448.3453, 448.6852, 448.3450,
        448.3484, 448.6101, 448.6842, 448.6842, 448.3452, 448.3447, 448.3452,
        448.3448, 448.3455, 448.3462, 448.3451, 448.3449, 448.3454, 448.6875,
        448.3461, 448.6842, 448.3452, 448.3444, 448.3451, 448.5220, 448.3507,
        448.3458, 448.6842, 448.3450, 448.3448, 448.3464, 448.3453, 448.3444,
        448.3447, 448.3445, 448.6842, 448.3445, 448.6523, 448.3456, 448.6924,
        448.3474, 448.3453, 448.3453, 448.6842, 448.3451, 448.3457, 448.5451,
        448.6842, 448.3444, 448.3453, 448.3453, 448.3469, 448.3450, 448.3460,
        448.3549, 448.3453, 448.6843, 448.3451, 448.5315, 448.6848, 448.6893,
        448.3472, 448.6844, 448.3480, 448.3452, 448.3593, 448.3456, 448.3442,
        448.5204, 448.3461, 448.6843, 448.3472, 448.3452, 448.3454, 448.3456,
        448.6843, 448.6850, 448.3449, 448.4218, 448.6903, 448.3454, 448.3460,
        448.3456, 448.3456, 448.3524, 448.5247, 448.3469, 448.3452, 448.3452,
        448.3456, 448.6842, 448.3456, 448.3455, 448.3375, 448.6843, 448.3506,
        448.3455, 448.3346, 448.6845, 448.5235, 448.3452, 448.3459, 448.3450,
        448.6843, 448.3462, 448.3455, 448.6842, 448.3452, 448.3449, 448.6853,
        448.6857, 448.5216, 448.5306, 448.5091, 448.3449, 448.3446, 448.3456,
        448.6877, 448.3458, 448.6096, 448.6895, 448.6846, 448.6093, 448.3464,
        448.6859, 448.3455, 448.6855, 448.3443, 448.6851, 448.6846, 448.3467,
        448.3443, 448.3447, 448.3451, 448.3450, 448.6841, 448.3454, 448.5204,
        448.3468, 448.3453, 448.3464, 448.3454, 448.3447, 448.3504, 448.3455,
        448.3468, 448.3448, 448.6287, 448.6843, 448.3447, 448.3458, 448.6842,
        448.6838, 448.3455, 448.3449, 448.3452, 448.6841, 448.3449, 448.3458,
        448.4646, 448.3452, 448.3445, 448.3455, 448.3454, 448.5243, 448.6853,
        448.3444, 448.6852, 448.3450, 448.3459, 448.3452, 448.3452, 448.6887,
        448.4478, 448.3474, 448.3448, 448.3453, 448.3452, 448.3463, 448.3452,
        448.3454, 448.3471, 448.3453, 448.3877, 448.6872, 448.3450, 448.3448,
        448.3486, 448.6844, 448.6868, 448.3455, 448.6842, 448.3459, 448.3456,
        448.3450, 448.3451, 448.3451, 448.3450, 448.3515, 448.5212, 448.6842,
        448.6843, 448.3454, 448.3455, 448.3451, 448.6882, 448.6842, 448.6850,
        448.6852, 448.3455, 448.3473, 448.3459, 448.6842, 448.3451, 448.3453,
        448.3452, 448.3454, 448.3632, 448.3450, 448.6858, 448.3347, 448.3461,
        448.3611, 448.3457, 448.3456, 448.3452, 448.6846, 448.5218, 448.3448,
        448.3444, 448.3453, 448.3458, 448.6854, 448.3455, 448.3449, 448.3456,
        448.3454, 448.6843, 448.3452, 448.5384, 448.6842, 448.6877, 448.3448,
        448.3454, 448.3452, 448.6848, 448.3458, 448.6842, 448.6844, 448.3449,
        448.6842, 448.3450, 448.3457, 448.3447, 448.6842, 448.3455, 448.3458,
        448.3444, 448.3448, 448.3448, 448.6843, 448.5201, 448.6762, 448.3456,
        448.3448, 448.6842, 448.3455, 448.3454, 448.3471, 448.6910, 448.3458,
        448.4717, 448.3462, 448.3458, 448.3474, 448.6869, 448.6843, 448.5491,
        448.3450, 448.6842, 448.4450, 448.3448, 448.3460, 448.6856, 448.3467,
        448.6864, 448.4396, 448.3450, 448.3456, 448.3449, 448.3463, 448.3456,
        448.3457, 448.3453, 448.3457, 448.3451, 448.3463, 448.3451, 448.3451,
        448.3459, 448.6842, 448.6869, 448.3453, 448.3455, 448.3452, 448.3448,
        448.6842, 448.3347, 448.3451, 448.6933, 448.3444, 448.6631, 448.3452,
        448.6901, 448.6842, 448.3452, 448.3458, 448.3457, 448.6842, 448.3446,
        448.3452, 448.6866, 448.5259, 448.3455, 448.3450, 448.3470, 448.3465,
        448.3444, 448.3452, 448.6843, 448.3453, 448.3454, 448.3452, 448.3453,
        448.3447, 448.6842, 448.3456, 448.6892, 448.3461, 448.6849, 448.3451,
        448.3446, 448.5233, 448.6879, 448.3464, 448.3454, 448.5984, 448.3559,
        448.6884, 448.3455, 448.3455, 448.3456, 448.6854, 448.6848, 448.3452,
        448.3517, 448.6882, 448.3452, 448.3455, 448.6843, 448.3451, 448.5202,
        448.3447, 448.6216, 448.3452, 448.6842, 448.3465, 448.3453, 448.6842,
        448.3472, 448.6842, 448.3452, 448.3452, 448.3454, 448.6850, 448.4465,
        448.4051, 448.3461, 448.6852, 448.6842, 448.3448, 448.3453, 448.6892,
        448.6915, 448.3449, 448.3452, 448.6846, 448.3452, 448.6328, 448.4937,
        448.6846, 448.6878, 448.3454, 448.6906, 448.6848, 448.3452, 448.3464,
        448.6091, 448.3728, 448.3451, 448.3458, 448.5549, 448.3446, 448.3447,
        448.3468, 448.3444, 448.3453, 448.3443, 448.6529, 448.3452, 448.3459,
        448.6854, 448.3467, 448.4165, 448.3452, 448.3506, 448.3462, 448.3454,
        448.3455, 448.3449, 448.6859, 448.3457, 448.6842, 448.3467, 448.6844,
        448.6842, 448.6862, 448.3444, 448.3456, 448.3466, 448.3457, 448.6844,
        448.3450, 448.3452, 448.3451, 448.3454, 448.6846, 448.3452, 448.3456,
        448.3452, 448.6856, 448.6842, 448.3457, 448.3456, 448.3460, 448.3348,
        448.3452, 448.5213, 448.3458, 448.3454, 448.6499, 448.3455, 448.3454,
        448.6843, 448.3451, 448.3517, 448.6091, 448.6846, 448.5576, 448.3459,
        448.6842, 448.3449, 448.3448, 448.3500, 448.3455, 448.3455, 448.3513,
        448.3452, 448.3457, 448.6842, 448.3455, 448.6842, 448.5225, 448.3450,
        448.6842, 448.3458, 448.3453, 448.3451, 448.3511, 448.6705, 448.3470,
        448.5218, 448.6842, 448.6842, 448.6929, 448.3455, 448.3455, 448.3448,
        448.3455, 448.6868, 448.5203, 448.3450, 448.3470, 448.3453, 448.6872,
        448.4173, 448.3447, 448.3456, 448.3458, 448.3458, 448.5231, 448.3447,
        448.6846, 448.3455, 448.3460, 448.3450, 448.3500, 448.3449, 448.6842,
        448.3458, 448.6842, 448.3457, 448.3458, 448.6973, 448.3452, 448.3463,
        448.3449, 448.6843, 448.4385, 448.3448, 448.3446, 448.4383, 448.3451,
        448.3459, 448.6842, 448.3454, 448.3444, 448.3459, 448.3448, 448.3450,
        448.3455, 448.3453, 448.3455, 448.3448, 448.5217, 448.3463, 448.3347,
        448.6844, 448.3444, 448.3451, 448.4323, 448.3720, 448.3455, 448.5201,
        448.3644, 448.6842, 448.4062, 448.6844, 448.3457, 448.4201, 448.3479,
        448.6846, 448.6852, 448.3455, 448.6863, 448.3456, 448.3458, 448.3452,
        448.6842, 448.3467, 448.3528, 448.3452, 448.6868, 448.3449, 448.3463,
        448.3455, 448.6876, 448.3462, 448.3449, 448.3468, 448.3469, 448.3469,
        448.6871, 448.5215, 448.3454, 448.3455, 448.3447, 448.3455, 448.3448,
        448.5233, 448.3452, 448.3452, 448.3459, 448.3462, 448.5218, 448.3449,
        448.6222, 448.6843, 448.3454, 448.3458, 448.3452, 448.3452, 448.6842,
        448.3451, 448.3449, 448.6889, 448.3465, 448.3453, 448.3448, 448.6063,
        448.6850, 448.3449, 448.3452, 448.6861, 448.5157, 448.6854, 448.6841,
        448.3388, 448.3450, 448.3459, 448.3448, 448.3453, 448.3456, 448.6843,
        448.3467, 448.3346, 448.3448, 448.3449, 448.6842, 448.3450, 448.3456,
        448.3455, 448.3459, 448.6076, 448.5204, 448.3458, 448.3451, 448.3464,
        448.3447, 448.3458, 448.3457, 448.3452, 448.3450, 448.3452, 448.3468,
        448.6433, 448.3449, 448.6845, 448.3455, 448.3459, 448.6887, 448.3453,
        448.3451, 448.6842, 448.3451, 448.3466, 448.3446, 448.3457, 448.6859,
        448.3451, 448.3455, 448.5240, 448.6844, 448.3445, 448.3965, 448.4331,
        448.3459, 448.3452, 448.3445, 448.3446, 448.3459, 448.3466, 448.5219,
        448.3451, 448.5204, 448.3459, 448.6880, 448.3453, 448.4430, 448.3448,
        448.6094, 448.3469, 448.3463, 448.6788, 448.3456, 448.3450, 448.6855,
        448.3454, 448.6842, 448.3452, 448.3457, 448.3454, 448.3446, 448.6905,
        448.3453, 448.6858, 448.3444, 448.6842, 448.3448, 448.4372, 448.4401,
        448.3454, 448.3450, 448.3459, 448.3455, 448.5213, 448.3456, 448.3452,
        448.3449, 448.3452, 448.6849, 448.3465, 448.6844, 448.3449, 448.6074,
        448.6850, 448.3459, 448.6842, 448.3454, 448.3453, 448.3452, 448.6859,
        448.3448, 448.3453, 448.3458, 448.5212, 448.3452, 448.6842, 448.3463,
        448.3444, 448.3452, 448.6848, 448.3449, 448.3448, 448.3456, 448.3463,
        448.6843, 448.3458, 448.3910, 448.3451, 448.3456, 448.3446, 448.3455,
        448.3449, 448.6842, 448.5212, 448.3381, 448.6842, 448.6854, 448.6895,
        448.3458, 448.6862, 448.3452, 448.3452, 448.6854, 448.5524, 448.3459,
        448.6842, 448.6842, 448.6852, 448.3459, 448.6842, 448.3456, 448.6896,
        448.3453, 448.3811, 448.3456, 448.5203, 448.3447, 448.4388, 448.6950,
        448.3445, 448.3557, 448.5224, 448.3463, 448.3470, 448.6858, 448.5204,
        448.3448, 448.3459, 448.3451, 448.3466, 448.4731, 448.5211, 448.3459,
        448.3455, 448.6841, 448.3458, 448.5229, 448.6859, 448.3452, 448.3453,
        448.6844, 448.3453, 448.6857, 448.3443, 448.6844, 448.3452, 448.3456,
        448.3464, 448.3443, 448.6901, 448.6845, 448.6853, 448.3459, 448.6844,
        448.3444, 448.3451, 448.3473, 448.6842, 448.4589, 448.3784, 448.6842,
        448.3445, 448.3456, 448.3457, 448.3457, 448.3448, 448.3455, 448.5224,
        448.3458, 448.3463, 448.3471, 448.3456, 448.3465, 448.3447, 448.3459,
        448.4574, 448.6101, 448.3482, 448.6924, 448.3460, 448.3454, 448.3448,
        448.6081, 448.3458, 448.3452, 448.3502, 448.6847, 448.3451, 448.4322,
        448.3464, 448.6842, 448.3454, 448.3452, 448.3452, 448.6848, 448.6882,
        448.3462, 448.3454, 448.3455, 448.3453, 448.3450, 448.6898, 448.3458,
        448.3456, 448.3450, 448.3453, 448.3453, 448.3464, 448.3455, 448.6842,
        448.3455, 448.3447, 448.3448, 448.6854, 448.3453, 448.3479, 448.3450,
        448.3449, 448.6912, 448.5283, 448.3480, 448.5232, 448.3442, 448.3452,
        448.3449, 448.3455, 448.6847, 448.5123, 448.3460, 448.6853, 448.3463,
        448.3568, 448.3457, 448.3480, 448.4321, 448.6842, 448.4182, 448.3448,
        448.3455, 448.3454, 448.3458, 448.3454, 448.3514, 448.3465, 448.6842,
        448.3466, 448.3458, 448.5226, 448.3450, 448.6035, 448.6848, 448.6901,
        448.3456, 448.3465, 448.3458, 448.3449, 448.5291, 448.3451, 448.3454,
        448.6842, 448.3461, 448.3454, 448.3453, 448.6842, 448.3448, 448.3457,
        448.3450, 448.6842, 448.3472, 448.3458, 448.6843, 448.3456, 448.3458,
        448.5212, 448.6861, 448.3475, 448.3459, 448.3458, 448.3453, 448.3454,
        448.3452, 448.3452], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([396.6483], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0851],
             [112.0838],
             [112.0863],
             [112.0835]],

            [[112.0859],
             [112.0866],
             [112.0869],
             [112.0869]],

            [[112.0860],
             [112.0874],
             [112.0860],
             [112.0861]],

            ...,

            [[112.0863],
             [112.0863],
             [112.0864],
             [112.0864]],

            [[112.0864],
             [112.0864],
             [112.0862],
             [112.0862]],

            [[112.0861],
             [112.0861],
             [112.0874],
             [112.0861]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3388, 448.3464, 448.3456,  ..., 448.3454, 448.3451, 448.3457],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3388, 448.3464, 448.3456,  ..., 448.3454, 448.3451, 448.3457],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0901],
             [112.0899],
             [112.0898],
             [112.0904]],

            [[112.0899],
             [112.0899],
             [112.0903],
             [112.0903]],

            [[112.0907],
             [112.1038],
             [112.1001],
             [112.0899]],

            ...,

            [[112.1682],
             [112.1686],
             [112.1686],
             [112.1682]],

            [[112.1697],
             [112.0909],
             [112.0922],
             [112.0922]],

            [[112.0899],
             [112.0899],
             [112.0899],
             [112.0899]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3602, 448.3605, 448.3845,  ..., 448.6736, 448.4451, 448.3597],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3602, 448.3605, 448.3845,  ..., 448.6736, 448.4451, 448.3597],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0885],
             [112.0892],
             [112.0888],
             [112.0901]],

            [[112.0885],
             [112.0889],
             [112.0887],
             [112.0897]],

            [[112.1696],
             [112.1696],
             [112.1692],
             [112.1692]],

            ...,

            [[112.0891],
             [112.1304],
             [112.0891],
             [112.1717]],

            [[112.1693],
             [112.1700],
             [112.1694],
             [112.1694]],

            [[112.0886],
             [112.0886],
             [112.0886],
             [112.0886]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3566, 448.3559, 448.6776,  ..., 448.4803, 448.6779, 448.3543],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3566, 448.3559, 448.6776,  ..., 448.4803, 448.6779, 448.3543],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0859],
             [112.0859],
             [112.0859],
             [112.0859]],

            [[112.1714],
             [112.1714],
             [112.1713],
             [112.1713]],

            [[112.1714],
             [112.1724],
             [112.1716],
             [112.1716]],

            ...,

            [[112.0870],
             [112.0870],
             [112.0870],
             [112.0870]],

            [[112.0866],
             [112.0859],
             [112.0860],
             [112.0862]],

            [[112.0861],
             [112.0860],
             [112.0860],
             [112.0875]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3434, 448.6854, 448.6870,  ..., 448.3480, 448.3448, 448.3456],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3434, 448.6854, 448.6870,  ..., 448.3480, 448.3448, 448.3456],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0976],
             [112.0822],
             [112.0893],
             [112.0822]],

            [[112.0841],
             [112.0832],
             [112.0830],
             [112.0834]],

            [[112.0839],
             [112.0839],
             [112.0839],
             [112.0839]],

            ...,

            [[112.0822],
             [112.0823],
             [112.0823],
             [112.0841]],

            [[112.0822],
             [112.0826],
             [112.0826],
             [112.0846]],

            [[112.1745],
             [112.1745],
             [112.1763],
             [112.1763]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3513, 448.3337, 448.3355,  ..., 448.3309, 448.3319, 448.7014],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3513, 448.3337, 448.3355,  ..., 448.3309, 448.3319, 448.7014],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0777],
             [112.0786],
             [112.0804],
             [112.0778]],

            [[112.0779],
             [112.0784],
             [112.0789],
             [112.0785]],

            [[112.0781],
             [112.0799],
             [112.0786],
             [112.0796]],

            ...,

            [[112.1778],
             [112.1778],
             [112.1778],
             [112.1778]],

            [[112.1778],
             [112.1778],
             [112.1778],
             [112.1778]],

            [[112.0795],
             [112.0791],
             [112.0778],
             [112.0778]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3145, 448.3137, 448.3162,  ..., 448.7111, 448.7112, 448.3142],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3145, 448.3137, 448.3162,  ..., 448.7111, 448.7112, 448.3142],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0857],
             [112.0834],
             [112.0837],
             [112.0837]],

            [[112.1743],
             [112.0852],
             [112.1744],
             [112.0850]],

            [[112.0835],
             [112.0836],
             [112.0835],
             [112.0836]],

            ...,

            [[112.0838],
             [112.0860],
             [112.0839],
             [112.0839]],

            [[112.0831],
             [112.1748],
             [112.1750],
             [112.0831]],

            [[112.0830],
             [112.0837],
             [112.0832],
             [112.0850]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3365, 448.5188, 448.3342,  ..., 448.3375, 448.5160, 448.3350],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3365, 448.5188, 448.3342,  ..., 448.3375, 448.5160, 448.3350],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0899],
             [112.0899],
             [112.0909],
             [112.0909]],

            [[112.0897],
             [112.0897],
             [112.0915],
             [112.0916]],

            [[112.1688],
             [112.1696],
             [112.1692],
             [112.1692]],

            ...,

            [[112.0897],
             [112.0908],
             [112.0914],
             [112.0906]],

            [[112.1133],
             [112.0898],
             [112.0898],
             [112.1704]],

            [[112.0901],
             [112.0897],
             [112.0901],
             [112.0901]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3617, 448.3625, 448.6768,  ..., 448.3625, 448.4633, 448.3599],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3617, 448.3625, 448.6768,  ..., 448.3625, 448.4633, 448.3599],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1022],
             [112.0994],
             [112.1000],
             [112.1000]],

            [[112.0989],
             [112.1012],
             [112.1027],
             [112.0989]],

            [[112.1621],
             [112.1620],
             [112.1630],
             [112.1039]],

            ...,

            [[112.1617],
             [112.1617],
             [112.1617],
             [112.1617]],

            [[112.1004],
             [112.1004],
             [112.1016],
             [112.1016]],

            [[112.1621],
             [112.1621],
             [112.1625],
             [112.1625]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4015, 448.4016, 448.5909,  ..., 448.6467, 448.4041, 448.6492],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4015, 448.4016, 448.5909,  ..., 448.6467, 448.4041, 448.6492],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1077],
             [112.1090],
             [112.1104],
             [112.1077]],

            [[112.1077],
             [112.1100],
             [112.1083],
             [112.1083]],

            [[112.1547],
             [112.1555],
             [112.1547],
             [112.1554]],

            ...,

            [[112.1077],
             [112.1090],
             [112.1077],
             [112.1089]],

            [[112.1081],
             [112.1081],
             [112.1077],
             [112.1077]],

            [[112.1088],
             [112.1077],
             [112.1104],
             [112.1079]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4348, 448.4342, 448.6202,  ..., 448.4334, 448.4316, 448.4348],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4348, 448.4342, 448.6202,  ..., 448.4334, 448.4316, 448.4348],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1156],
             [112.1156],
             [112.1156],
             [112.1156]],

            [[112.1149],
             [112.1139],
             [112.1139],
             [112.1158]],

            [[112.1140],
             [112.1142],
             [112.1139],
             [112.1148]],

            ...,

            [[112.1498],
             [112.1498],
             [112.1498],
             [112.1498]],

            [[112.1500],
             [112.1518],
             [112.1502],
             [112.1502]],

            [[112.1154],
             [112.1139],
             [112.1147],
             [112.1168]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4625, 448.4585, 448.4568,  ..., 448.5992, 448.6022, 448.4608],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4625, 448.4585, 448.4568,  ..., 448.5992, 448.6022, 448.4608],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1453],
             [112.1453],
             [112.1453],
             [112.1453]],

            [[112.1198],
             [112.1214],
             [112.1201],
             [112.1232]],

            [[112.1213],
             [112.1213],
             [112.1200],
             [112.1200]],

            ...,

            [[112.1215],
             [112.1214],
             [112.1198],
             [112.1211]],

            [[112.1197],
             [112.1198],
             [112.1214],
             [112.1228]],

            [[112.1214],
             [112.1197],
             [112.1200],
             [112.1229]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5812, 448.4845, 448.4828,  ..., 448.4838, 448.4837, 448.4840],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5812, 448.4845, 448.4828,  ..., 448.4838, 448.4837, 448.4840],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1425],
             [112.1401],
             [112.1413],
             [112.1401]],

            [[112.1407],
             [112.1399],
             [112.1399],
             [112.1408]],

            [[112.1410],
             [112.1399],
             [112.1399],
             [112.1414]],

            ...,

            [[112.1258],
             [112.1273],
             [112.1274],
             [112.1277]],

            [[112.1297],
             [112.1263],
             [112.1268],
             [112.1268]],

            [[112.1272],
             [112.1272],
             [112.1291],
             [112.1291]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5640, 448.5613, 448.5622,  ..., 448.5082, 448.5095, 448.5125],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5640, 448.5613, 448.5622,  ..., 448.5082, 448.5095, 448.5125],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1351],
             [112.1351],
             [112.1351],
             [112.1351]],

            [[112.1340],
             [112.1313],
             [112.1337],
             [112.1337]],

            [[112.1354],
             [112.1319],
             [112.1323],
             [112.1323]],

            ...,

            [[112.1322],
             [112.1322],
             [112.1312],
             [112.1312]],

            [[112.1312],
             [112.1312],
             [112.1333],
             [112.1333]],

            [[112.1329],
             [112.1313],
             [112.1312],
             [112.1312]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5405, 448.5328, 448.5319,  ..., 448.5269, 448.5291, 448.5266],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5405, 448.5328, 448.5319,  ..., 448.5269, 448.5291, 448.5266],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1269],
             [112.1303],
             [112.1273],
             [112.1273]],

            [[112.1382],
             [112.1382],
             [112.1385],
             [112.1385]],

            [[112.1268],
             [112.1294],
             [112.1268],
             [112.1287]],

            ...,

            [[112.1382],
             [112.1382],
             [112.1389],
             [112.1389]],

            [[112.1381],
             [112.1398],
             [112.1384],
             [112.1384]],

            [[112.1283],
             [112.1269],
             [112.1268],
             [112.1297]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5118, 448.5535, 448.5117,  ..., 448.5542, 448.5547, 448.5117],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5118, 448.5535, 448.5117,  ..., 448.5542, 448.5547, 448.5117],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1507],
             [112.1507],
             [112.1527],
             [112.1527]],

            [[112.1079],
             [112.1080],
             [112.1079],
             [112.1079]],

            [[112.1079],
             [112.1079],
             [112.1079],
             [112.1079]],

            ...,

            [[112.1113],
             [112.1113],
             [112.1109],
             [112.1109]],

            [[112.1079],
             [112.1079],
             [112.1080],
             [112.1080]],

            [[112.1079],
             [112.1079],
             [112.1079],
             [112.1079]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6070, 448.4318, 448.4316,  ..., 448.4444, 448.4319, 448.4316],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6070, 448.4318, 448.4316,  ..., 448.4444, 448.4319, 448.4316],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1741],
             [112.1741],
             [112.1737],
             [112.1784]],

            [[112.1007],
             [112.1473],
             [112.1809],
             [112.0862]],

            [[112.1737],
             [112.1753],
             [112.1737],
             [112.1750]],

            ...,

            [[112.1743],
             [112.1737],
             [112.1764],
             [112.1738]],

            [[112.1764],
             [112.0844],
             [112.0841],
             [112.1766]],

            [[112.0820],
             [112.0829],
             [112.0829],
             [112.0819]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7003, 448.5151, 448.6977,  ..., 448.6982, 448.5215, 448.3297],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7003, 448.5151, 448.6977,  ..., 448.6982, 448.5215, 448.3297],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1926],
             [112.1926],
             [112.1918],
             [112.1918]],

            [[112.1919],
             [112.1928],
             [112.1919],
             [112.1926]],

            [[112.1933],
             [112.1918],
             [112.1940],
             [112.1917]],

            ...,

            [[112.1918],
             [112.1934],
             [112.1917],
             [112.1944]],

            [[112.1931],
             [112.1940],
             [112.1933],
             [112.1945]],

            [[112.1917],
             [112.1942],
             [112.1918],
             [112.1920]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7690, 448.7692, 448.7708,  ..., 448.7713, 448.7749, 448.7697],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7690, 448.7692, 448.7708,  ..., 448.7713, 448.7749, 448.7697],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0277e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2060],
             [112.2060],
             [112.2069],
             [112.2069]],

            [[112.2049],
             [112.2049],
             [112.2088],
             [112.2057]],

            [[112.2049],
             [112.2049],
             [112.2070],
             [112.2070]],

            ...,

            [[112.2050],
             [112.2053],
             [112.2053],
             [112.2053]],

            [[112.2051],
             [112.2053],
             [112.2051],
             [112.2079]],

            [[112.2084],
             [112.2051],
             [112.2054],
             [112.2054]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8258, 448.8244, 448.8237,  ..., 448.8208, 448.8234, 448.8243],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8258, 448.8244, 448.8237,  ..., 448.8208, 448.8234, 448.8243],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2051],
             [112.2051],
             [112.2076],
             [112.2076]],

            [[112.0438],
             [112.0447],
             [112.0440],
             [112.0440]],

            [[112.0442],
             [112.0550],
             [112.0465],
             [112.0465]],

            ...,

            [[112.2050],
             [112.2050],
             [112.2065],
             [112.2076]],

            [[112.0501],
             [112.2058],
             [112.0530],
             [112.2054]],

            [[112.2049],
             [112.2051],
             [112.2061],
             [112.2058]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8253, 448.1765, 448.1921,  ..., 448.8240, 448.5143, 448.8220],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8253, 448.1765, 448.1921,  ..., 448.8240, 448.5143, 448.8220],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2049],
             [112.2058],
             [112.2077],
             [112.2051]],

            [[112.2054],
             [112.2054],
             [112.2089],
             [112.2089]],

            [[112.0437],
             [112.0437],
             [112.0437],
             [112.0437]],

            ...,

            [[112.0438],
             [112.0449],
             [112.0449],
             [112.0437]],

            [[112.2050],
             [112.2056],
             [112.2068],
             [112.2053]],

            [[112.0631],
             [112.0744],
             [112.2054],
             [112.2054]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8235, 448.8287, 448.1749, 448.8205, 448.8213, 448.8225, 448.8214,
            448.8290, 448.8242, 448.8265, 448.1749, 448.8210, 448.8212, 448.8210,
            448.8203, 448.8310, 448.1833, 448.8306, 448.8259, 448.8216, 448.8232,
            448.8246, 448.8245, 448.1758, 448.1749, 448.1765, 448.8207, 448.1828,
            448.8212, 448.8292, 448.8315, 448.8231, 448.8253, 448.8242, 448.8221,
            448.8227, 448.8227, 448.8252, 448.8225, 448.8215, 448.8285, 448.8228,
            448.1749, 448.8203, 448.8298, 448.2492, 448.8256, 448.8250, 448.8254,
            448.1749, 448.1830, 448.5191, 448.5093, 448.1801, 448.8226, 448.1800,
            448.8229, 448.4415, 448.8255, 448.3515, 448.1750, 448.8249, 448.5104,
            448.6721, 448.8232, 448.8197, 448.1764, 448.8252, 448.1754, 448.8235,
            448.7039, 448.7235, 448.1770, 448.8214, 448.7102, 448.8228, 448.1755,
            448.8272, 448.8210, 448.1764, 448.3546, 448.8333, 448.8233, 448.8262,
            448.8262, 448.5355, 448.8206, 448.1783, 448.1749, 448.1766, 448.8303,
            448.8292, 448.8280, 448.1749, 448.8325, 448.8229, 448.8220, 448.8231,
            448.8225, 448.8248, 448.8221, 448.8213, 448.8252, 448.1937, 448.8217,
            448.8327, 448.8243, 448.8203, 448.1758, 448.1982, 448.8232, 448.8227,
            448.1973, 448.8207, 448.8250, 448.5059, 448.8228, 448.1778, 448.3777,
            448.1794, 448.8222, 448.8239, 448.8230, 448.8242, 448.8228, 448.8285,
            448.8217, 448.1749, 448.8230, 448.8244, 448.8223, 448.8257, 448.1749,
            448.8271, 448.8293, 448.1753, 448.3550, 448.8235, 448.8227, 448.8229,
            448.8244, 448.8227, 448.8311, 448.8369, 448.8217, 448.8231, 448.1758,
            448.8224, 448.8411, 448.8386, 448.8418, 448.8221, 448.8231, 448.8209,
            448.6700, 448.8269, 448.8200, 448.1749, 448.8218, 448.8397, 448.8238,
            448.8259, 448.8305, 448.8229, 448.8243, 448.8242, 448.8300, 448.8244,
            448.8202, 448.8214, 448.1760, 448.8215, 448.8201, 448.8246, 448.8205,
            448.8224, 448.8296, 448.6668, 448.8215, 448.1750, 448.5216, 448.1750,
            448.1750, 448.8286, 448.8276, 448.8223, 448.8292, 448.7958, 448.8239,
            448.8271, 448.8239, 448.8344, 448.8256, 448.8481, 448.8252, 448.8274,
            448.8201, 448.3922, 448.1749, 448.8232, 448.8217, 448.8212, 448.8228,
            448.8250, 448.8247, 448.8286, 448.8252, 448.8264, 448.8227, 448.1752,
            448.2046, 448.8272, 448.1764, 448.7181, 448.1750, 448.8367, 448.1920,
            448.8215, 448.8222, 448.8212, 448.1750, 448.8221, 448.1749, 448.1772,
            448.1775, 448.1749, 448.1749, 448.8203, 448.1751, 448.8294, 448.1749,
            448.3564, 448.8233, 448.8236, 448.8286, 448.8208, 448.8229, 448.8197,
            448.8222, 448.1789, 448.8236, 448.8282, 448.8219, 448.8269, 448.8217,
            448.8297, 448.8282, 448.8252, 448.8254, 448.1813, 448.8286, 448.8226,
            448.8214, 448.1752, 448.1749, 448.1751, 448.8231, 448.8240, 448.8223,
            448.5153, 448.8245, 448.3647, 448.8216, 448.1843, 448.1749, 448.5181,
            448.5121, 448.8250, 448.8256, 448.8227, 448.1754, 448.8265, 448.8322,
            448.3398, 448.1791, 448.8309, 448.8254, 448.8246, 448.8204, 448.8225,
            448.8248, 448.8225, 448.8200, 448.8232, 448.1796, 448.8233, 448.8204,
            448.8292, 448.8257, 448.1754, 448.8241, 448.8256, 448.5077, 448.1884,
            448.2731, 448.8246, 448.8228, 448.8291, 448.8248, 448.8303, 448.8238,
            448.8237, 448.8253, 448.8210, 448.8148, 448.8375, 448.1761, 448.1974,
            448.8246, 448.6854, 448.8224, 448.1863, 448.7014, 448.6628, 448.4012,
            448.8290, 448.8261, 448.8248, 448.8295, 448.8209, 448.8251, 448.8216,
            448.1785, 448.8284, 448.8249, 448.1780, 448.8245, 448.8287, 448.1749,
            448.1858, 448.8257, 448.1781, 448.8222, 448.8210, 448.8224, 448.1829,
            448.8257, 448.1749, 448.8266, 448.8229, 448.8221, 448.8324, 448.8239,
            448.8266, 448.8246, 448.1749, 448.8218, 448.1757, 448.3766, 448.8227,
            448.8231, 448.8221, 448.1765, 448.8237, 448.8239, 448.8240, 448.1749,
            448.1769, 448.8209, 448.8270, 448.8231, 448.6680, 448.8275, 448.1778,
            448.8228, 448.8217, 448.8225, 448.8228, 448.8278, 448.8245, 448.8232,
            448.8224, 448.8237, 448.8215, 448.8232, 448.1749, 448.8219, 448.8290,
            448.8239, 448.8227, 448.8260, 448.8260, 448.7994, 448.8226, 448.1779,
            448.8284, 448.8201, 448.8216, 448.8249, 448.8198, 448.8286, 448.8207,
            448.8230, 448.1762, 448.8314, 448.8221, 448.8251, 448.5278, 448.2031,
            448.8210, 448.8231, 448.8209, 448.8261, 448.1750, 448.6727, 448.8204,
            448.5145, 448.8276, 448.8220, 448.8235, 448.8241, 448.5117, 448.8278,
            448.1772, 448.8234, 448.8268, 448.8198, 448.8244, 448.8216, 448.1749,
            448.8239, 448.8281, 448.8229, 448.1788, 448.8211, 448.8229, 448.1886,
            448.3540, 448.8245, 448.1749, 448.1791, 448.8205, 448.1750, 448.8514,
            448.8237, 448.8241, 448.1770, 448.1749, 448.1749, 448.8229, 448.1750,
            448.8239, 448.5115, 448.8254, 448.8246, 448.8281, 448.8236, 448.8218,
            448.8214, 448.8241, 448.8237, 448.8254, 448.8243, 448.6642, 448.8233,
            448.8219, 448.8264, 448.2012, 448.8249, 448.8247, 448.8237, 448.8291,
            448.8299, 448.8226, 448.8232, 448.8315, 448.8237, 448.3555, 448.8225,
            448.8249, 448.8278, 448.8217, 448.8256, 448.8268, 448.8300, 448.3550,
            448.1750, 448.8211, 448.5507, 448.1791, 448.8236, 448.8248, 448.5128,
            448.1749, 448.6573, 448.8255, 448.6822, 448.8232, 448.8262, 448.8275,
            448.7887, 448.8234, 448.1847, 448.8210, 448.8285, 448.8245, 448.5314,
            448.8241, 448.8376, 448.2581, 448.6898, 448.8216, 448.8238, 448.8245,
            448.1750, 448.8235, 448.1756, 448.8277, 448.8330, 448.8395, 448.1784,
            448.8217, 448.8242, 448.5105, 448.8237, 448.8275, 448.8213, 448.8301,
            448.1749, 448.1749, 448.8226, 448.8295, 448.1749, 448.8290, 448.8225,
            448.1763, 448.8266, 448.6809, 448.8203, 448.8237, 448.8230, 448.8279,
            448.8286, 448.1859, 448.5163, 448.8286, 448.5088, 448.8212, 448.8224,
            448.8206, 448.7316, 448.8234, 448.8231, 448.1749, 448.1749, 448.8244,
            448.8220, 448.8274, 448.1749, 448.2036, 448.8313, 448.1749, 448.8242,
            448.8253, 448.1756, 448.8295, 448.1768, 448.1886, 448.8280, 448.8279,
            448.8217, 448.1862, 448.8217, 448.8213, 448.1750, 448.5131, 448.1750,
            448.8226, 448.8307, 448.8220, 448.8225, 448.3549, 448.8267, 448.8240,
            448.1861, 448.8284, 448.8214, 448.3858, 448.8263, 448.8213, 448.1871,
            448.1788, 448.5107, 448.8207, 448.8223, 448.8254, 448.8272, 448.8203,
            448.1750, 448.1776, 448.8268, 448.8272, 448.8296, 448.2089, 448.8231,
            448.3727, 448.1755, 448.1954, 448.8213, 448.1791, 448.1750, 448.1904,
            448.8289, 448.1760, 448.8209, 448.8234, 448.8217, 448.7066, 448.8234,
            448.1755, 448.8219, 448.8221, 448.8273, 448.8239, 448.8286, 448.8226,
            448.8235, 448.6827, 448.8238, 448.8268, 448.8237, 448.8298, 448.1766,
            448.8221, 448.8286, 448.8264, 448.5112, 448.7039, 448.8235, 448.6965,
            448.8307, 448.8285, 448.5803, 448.8265, 448.5093, 448.8286, 448.1898,
            448.5279, 448.8311, 448.1749, 448.8284, 448.8224, 448.8215, 448.1767,
            448.5106, 448.8256, 448.8302, 448.1750, 448.4667, 448.2760, 448.8313,
            448.6817, 448.8210, 448.8309, 448.8224, 448.8197, 448.8232, 448.8237,
            448.8210, 448.3788, 448.5111, 448.8246, 448.1749, 448.1837, 448.8231,
            448.5215, 448.8237, 448.8204, 448.8240, 448.1749, 448.1818, 448.8225,
            448.8238, 448.1753, 448.8233, 448.8229, 448.8204, 448.8279, 448.8211,
            448.8242, 448.1750, 448.8211, 448.1755, 448.8217, 448.5114, 448.8230,
            448.8246, 448.8207, 448.1750, 448.8241, 448.8217, 448.1865, 448.8204,
            448.8235, 448.8213, 448.8209, 448.8238, 448.8204, 448.8215, 448.8234,
            448.8229, 448.1770, 448.8271, 448.1754, 448.1749, 448.1749, 448.8303,
            448.8249, 448.8329, 448.8205, 448.8202, 448.8221, 448.8244, 448.8243,
            448.8244, 448.8292, 448.8229, 448.1749, 448.6730, 448.4746, 448.8261,
            448.7692, 448.1749, 448.8246, 448.8300, 448.8282, 448.5238, 448.8232,
            448.8279, 448.1750, 448.1749, 448.8214, 448.8228, 448.8213, 448.8225,
            448.8283, 448.8210, 448.8246, 448.8223, 448.8279, 448.8293, 448.8251,
            448.1749, 448.3514, 448.7907, 448.8204, 448.3539, 448.8260, 448.8259,
            448.8321, 448.8218, 448.1755, 448.8241, 448.8239, 448.8222, 448.5208,
            448.8231, 448.8223, 448.1764, 448.5104, 448.8246, 448.1893, 448.8212,
            448.8196, 448.8277, 448.8299, 448.8237, 448.8232, 448.8307, 448.8234,
            448.8213, 448.8210, 448.1750, 448.8217, 448.8245, 448.4516, 448.8272,
            448.2075, 448.1799, 448.8228, 448.1763, 448.8241, 448.8247, 448.8242,
            448.1784, 448.8273, 448.8229, 448.8208, 448.8211, 448.8241, 448.8224,
            448.1786, 448.8245, 448.8284, 448.1751, 448.8225, 448.8301, 448.1749,
            448.8279, 448.8250, 448.8197, 448.8248, 448.8186, 448.3561, 448.1750,
            448.1758, 448.8275, 448.8269, 448.8217, 448.1753, 448.1884, 448.8247,
            448.8219, 448.8215, 448.8241, 448.8215, 448.8279, 448.8248, 448.8225,
            448.8254, 448.1818, 448.1749, 448.8301, 448.1819, 448.8273, 448.8195,
            448.1788, 448.1750, 448.8241, 448.8275, 448.1779, 448.8223, 448.2060,
            448.8241, 448.8265, 448.8231, 448.8281, 448.8256, 448.8252, 448.8208,
            448.8284, 448.8224, 448.1882, 448.1749, 448.8296, 448.1750, 448.8233,
            448.5123, 448.8374, 448.8235, 448.1752, 448.8224, 448.5138, 448.8235,
            448.8258, 448.1750, 448.8310, 448.8209, 448.1865, 448.1755, 448.8306,
            448.1842, 448.8279, 448.8242, 448.8217, 448.8242, 448.1788, 448.8402,
            448.8238, 448.1752, 448.8255, 448.6575, 448.8247, 448.8243, 448.1749,
            448.7007, 448.8282, 448.8197, 448.5129, 448.2038, 448.1751, 448.1753,
            448.7199, 448.1752, 448.4199, 448.8244, 448.2196, 448.1754, 448.1918,
            448.8264, 448.1763, 448.1750, 448.8259, 448.1857, 448.6820, 448.8272,
            448.8299, 448.8240, 448.8230, 448.8212, 448.8215, 448.8256, 448.8212,
            448.8221, 448.8217, 448.1944, 448.8233, 448.1776, 448.8240, 448.1816,
            448.5214, 448.8207, 448.1749, 448.1994, 448.8276, 448.5120, 448.1749,
            448.8222, 448.1750, 448.8222, 448.1770, 448.8237, 448.8259, 448.1773,
            448.8228, 448.5483], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8235, 448.8287, 448.1749, 448.8205, 448.8213, 448.8225, 448.8214,
        448.8290, 448.8242, 448.8265, 448.1749, 448.8210, 448.8212, 448.8210,
        448.8203, 448.8310, 448.1833, 448.8306, 448.8259, 448.8216, 448.8232,
        448.8246, 448.8245, 448.1758, 448.1749, 448.1765, 448.8207, 448.1828,
        448.8212, 448.8292, 448.8315, 448.8231, 448.8253, 448.8242, 448.8221,
        448.8227, 448.8227, 448.8252, 448.8225, 448.8215, 448.8285, 448.8228,
        448.1749, 448.8203, 448.8298, 448.2492, 448.8256, 448.8250, 448.8254,
        448.1749, 448.1830, 448.5191, 448.5093, 448.1801, 448.8226, 448.1800,
        448.8229, 448.4415, 448.8255, 448.3515, 448.1750, 448.8249, 448.5104,
        448.6721, 448.8232, 448.8197, 448.1764, 448.8252, 448.1754, 448.8235,
        448.7039, 448.7235, 448.1770, 448.8214, 448.7102, 448.8228, 448.1755,
        448.8272, 448.8210, 448.1764, 448.3546, 448.8333, 448.8233, 448.8262,
        448.8262, 448.5355, 448.8206, 448.1783, 448.1749, 448.1766, 448.8303,
        448.8292, 448.8280, 448.1749, 448.8325, 448.8229, 448.8220, 448.8231,
        448.8225, 448.8248, 448.8221, 448.8213, 448.8252, 448.1937, 448.8217,
        448.8327, 448.8243, 448.8203, 448.1758, 448.1982, 448.8232, 448.8227,
        448.1973, 448.8207, 448.8250, 448.5059, 448.8228, 448.1778, 448.3777,
        448.1794, 448.8222, 448.8239, 448.8230, 448.8242, 448.8228, 448.8285,
        448.8217, 448.1749, 448.8230, 448.8244, 448.8223, 448.8257, 448.1749,
        448.8271, 448.8293, 448.1753, 448.3550, 448.8235, 448.8227, 448.8229,
        448.8244, 448.8227, 448.8311, 448.8369, 448.8217, 448.8231, 448.1758,
        448.8224, 448.8411, 448.8386, 448.8418, 448.8221, 448.8231, 448.8209,
        448.6700, 448.8269, 448.8200, 448.1749, 448.8218, 448.8397, 448.8238,
        448.8259, 448.8305, 448.8229, 448.8243, 448.8242, 448.8300, 448.8244,
        448.8202, 448.8214, 448.1760, 448.8215, 448.8201, 448.8246, 448.8205,
        448.8224, 448.8296, 448.6668, 448.8215, 448.1750, 448.5216, 448.1750,
        448.1750, 448.8286, 448.8276, 448.8223, 448.8292, 448.7958, 448.8239,
        448.8271, 448.8239, 448.8344, 448.8256, 448.8481, 448.8252, 448.8274,
        448.8201, 448.3922, 448.1749, 448.8232, 448.8217, 448.8212, 448.8228,
        448.8250, 448.8247, 448.8286, 448.8252, 448.8264, 448.8227, 448.1752,
        448.2046, 448.8272, 448.1764, 448.7181, 448.1750, 448.8367, 448.1920,
        448.8215, 448.8222, 448.8212, 448.1750, 448.8221, 448.1749, 448.1772,
        448.1775, 448.1749, 448.1749, 448.8203, 448.1751, 448.8294, 448.1749,
        448.3564, 448.8233, 448.8236, 448.8286, 448.8208, 448.8229, 448.8197,
        448.8222, 448.1789, 448.8236, 448.8282, 448.8219, 448.8269, 448.8217,
        448.8297, 448.8282, 448.8252, 448.8254, 448.1813, 448.8286, 448.8226,
        448.8214, 448.1752, 448.1749, 448.1751, 448.8231, 448.8240, 448.8223,
        448.5153, 448.8245, 448.3647, 448.8216, 448.1843, 448.1749, 448.5181,
        448.5121, 448.8250, 448.8256, 448.8227, 448.1754, 448.8265, 448.8322,
        448.3398, 448.1791, 448.8309, 448.8254, 448.8246, 448.8204, 448.8225,
        448.8248, 448.8225, 448.8200, 448.8232, 448.1796, 448.8233, 448.8204,
        448.8292, 448.8257, 448.1754, 448.8241, 448.8256, 448.5077, 448.1884,
        448.2731, 448.8246, 448.8228, 448.8291, 448.8248, 448.8303, 448.8238,
        448.8237, 448.8253, 448.8210, 448.8148, 448.8375, 448.1761, 448.1974,
        448.8246, 448.6854, 448.8224, 448.1863, 448.7014, 448.6628, 448.4012,
        448.8290, 448.8261, 448.8248, 448.8295, 448.8209, 448.8251, 448.8216,
        448.1785, 448.8284, 448.8249, 448.1780, 448.8245, 448.8287, 448.1749,
        448.1858, 448.8257, 448.1781, 448.8222, 448.8210, 448.8224, 448.1829,
        448.8257, 448.1749, 448.8266, 448.8229, 448.8221, 448.8324, 448.8239,
        448.8266, 448.8246, 448.1749, 448.8218, 448.1757, 448.3766, 448.8227,
        448.8231, 448.8221, 448.1765, 448.8237, 448.8239, 448.8240, 448.1749,
        448.1769, 448.8209, 448.8270, 448.8231, 448.6680, 448.8275, 448.1778,
        448.8228, 448.8217, 448.8225, 448.8228, 448.8278, 448.8245, 448.8232,
        448.8224, 448.8237, 448.8215, 448.8232, 448.1749, 448.8219, 448.8290,
        448.8239, 448.8227, 448.8260, 448.8260, 448.7994, 448.8226, 448.1779,
        448.8284, 448.8201, 448.8216, 448.8249, 448.8198, 448.8286, 448.8207,
        448.8230, 448.1762, 448.8314, 448.8221, 448.8251, 448.5278, 448.2031,
        448.8210, 448.8231, 448.8209, 448.8261, 448.1750, 448.6727, 448.8204,
        448.5145, 448.8276, 448.8220, 448.8235, 448.8241, 448.5117, 448.8278,
        448.1772, 448.8234, 448.8268, 448.8198, 448.8244, 448.8216, 448.1749,
        448.8239, 448.8281, 448.8229, 448.1788, 448.8211, 448.8229, 448.1886,
        448.3540, 448.8245, 448.1749, 448.1791, 448.8205, 448.1750, 448.8514,
        448.8237, 448.8241, 448.1770, 448.1749, 448.1749, 448.8229, 448.1750,
        448.8239, 448.5115, 448.8254, 448.8246, 448.8281, 448.8236, 448.8218,
        448.8214, 448.8241, 448.8237, 448.8254, 448.8243, 448.6642, 448.8233,
        448.8219, 448.8264, 448.2012, 448.8249, 448.8247, 448.8237, 448.8291,
        448.8299, 448.8226, 448.8232, 448.8315, 448.8237, 448.3555, 448.8225,
        448.8249, 448.8278, 448.8217, 448.8256, 448.8268, 448.8300, 448.3550,
        448.1750, 448.8211, 448.5507, 448.1791, 448.8236, 448.8248, 448.5128,
        448.1749, 448.6573, 448.8255, 448.6822, 448.8232, 448.8262, 448.8275,
        448.7887, 448.8234, 448.1847, 448.8210, 448.8285, 448.8245, 448.5314,
        448.8241, 448.8376, 448.2581, 448.6898, 448.8216, 448.8238, 448.8245,
        448.1750, 448.8235, 448.1756, 448.8277, 448.8330, 448.8395, 448.1784,
        448.8217, 448.8242, 448.5105, 448.8237, 448.8275, 448.8213, 448.8301,
        448.1749, 448.1749, 448.8226, 448.8295, 448.1749, 448.8290, 448.8225,
        448.1763, 448.8266, 448.6809, 448.8203, 448.8237, 448.8230, 448.8279,
        448.8286, 448.1859, 448.5163, 448.8286, 448.5088, 448.8212, 448.8224,
        448.8206, 448.7316, 448.8234, 448.8231, 448.1749, 448.1749, 448.8244,
        448.8220, 448.8274, 448.1749, 448.2036, 448.8313, 448.1749, 448.8242,
        448.8253, 448.1756, 448.8295, 448.1768, 448.1886, 448.8280, 448.8279,
        448.8217, 448.1862, 448.8217, 448.8213, 448.1750, 448.5131, 448.1750,
        448.8226, 448.8307, 448.8220, 448.8225, 448.3549, 448.8267, 448.8240,
        448.1861, 448.8284, 448.8214, 448.3858, 448.8263, 448.8213, 448.1871,
        448.1788, 448.5107, 448.8207, 448.8223, 448.8254, 448.8272, 448.8203,
        448.1750, 448.1776, 448.8268, 448.8272, 448.8296, 448.2089, 448.8231,
        448.3727, 448.1755, 448.1954, 448.8213, 448.1791, 448.1750, 448.1904,
        448.8289, 448.1760, 448.8209, 448.8234, 448.8217, 448.7066, 448.8234,
        448.1755, 448.8219, 448.8221, 448.8273, 448.8239, 448.8286, 448.8226,
        448.8235, 448.6827, 448.8238, 448.8268, 448.8237, 448.8298, 448.1766,
        448.8221, 448.8286, 448.8264, 448.5112, 448.7039, 448.8235, 448.6965,
        448.8307, 448.8285, 448.5803, 448.8265, 448.5093, 448.8286, 448.1898,
        448.5279, 448.8311, 448.1749, 448.8284, 448.8224, 448.8215, 448.1767,
        448.5106, 448.8256, 448.8302, 448.1750, 448.4667, 448.2760, 448.8313,
        448.6817, 448.8210, 448.8309, 448.8224, 448.8197, 448.8232, 448.8237,
        448.8210, 448.3788, 448.5111, 448.8246, 448.1749, 448.1837, 448.8231,
        448.5215, 448.8237, 448.8204, 448.8240, 448.1749, 448.1818, 448.8225,
        448.8238, 448.1753, 448.8233, 448.8229, 448.8204, 448.8279, 448.8211,
        448.8242, 448.1750, 448.8211, 448.1755, 448.8217, 448.5114, 448.8230,
        448.8246, 448.8207, 448.1750, 448.8241, 448.8217, 448.1865, 448.8204,
        448.8235, 448.8213, 448.8209, 448.8238, 448.8204, 448.8215, 448.8234,
        448.8229, 448.1770, 448.8271, 448.1754, 448.1749, 448.1749, 448.8303,
        448.8249, 448.8329, 448.8205, 448.8202, 448.8221, 448.8244, 448.8243,
        448.8244, 448.8292, 448.8229, 448.1749, 448.6730, 448.4746, 448.8261,
        448.7692, 448.1749, 448.8246, 448.8300, 448.8282, 448.5238, 448.8232,
        448.8279, 448.1750, 448.1749, 448.8214, 448.8228, 448.8213, 448.8225,
        448.8283, 448.8210, 448.8246, 448.8223, 448.8279, 448.8293, 448.8251,
        448.1749, 448.3514, 448.7907, 448.8204, 448.3539, 448.8260, 448.8259,
        448.8321, 448.8218, 448.1755, 448.8241, 448.8239, 448.8222, 448.5208,
        448.8231, 448.8223, 448.1764, 448.5104, 448.8246, 448.1893, 448.8212,
        448.8196, 448.8277, 448.8299, 448.8237, 448.8232, 448.8307, 448.8234,
        448.8213, 448.8210, 448.1750, 448.8217, 448.8245, 448.4516, 448.8272,
        448.2075, 448.1799, 448.8228, 448.1763, 448.8241, 448.8247, 448.8242,
        448.1784, 448.8273, 448.8229, 448.8208, 448.8211, 448.8241, 448.8224,
        448.1786, 448.8245, 448.8284, 448.1751, 448.8225, 448.8301, 448.1749,
        448.8279, 448.8250, 448.8197, 448.8248, 448.8186, 448.3561, 448.1750,
        448.1758, 448.8275, 448.8269, 448.8217, 448.1753, 448.1884, 448.8247,
        448.8219, 448.8215, 448.8241, 448.8215, 448.8279, 448.8248, 448.8225,
        448.8254, 448.1818, 448.1749, 448.8301, 448.1819, 448.8273, 448.8195,
        448.1788, 448.1750, 448.8241, 448.8275, 448.1779, 448.8223, 448.2060,
        448.8241, 448.8265, 448.8231, 448.8281, 448.8256, 448.8252, 448.8208,
        448.8284, 448.8224, 448.1882, 448.1749, 448.8296, 448.1750, 448.8233,
        448.5123, 448.8374, 448.8235, 448.1752, 448.8224, 448.5138, 448.8235,
        448.8258, 448.1750, 448.8310, 448.8209, 448.1865, 448.1755, 448.8306,
        448.1842, 448.8279, 448.8242, 448.8217, 448.8242, 448.1788, 448.8402,
        448.8238, 448.1752, 448.8255, 448.6575, 448.8247, 448.8243, 448.1749,
        448.7007, 448.8282, 448.8197, 448.5129, 448.2038, 448.1751, 448.1753,
        448.7199, 448.1752, 448.4199, 448.8244, 448.2196, 448.1754, 448.1918,
        448.8264, 448.1763, 448.1750, 448.8259, 448.1857, 448.6820, 448.8272,
        448.8299, 448.8240, 448.8230, 448.8212, 448.8215, 448.8256, 448.8212,
        448.8221, 448.8217, 448.1944, 448.8233, 448.1776, 448.8240, 448.1816,
        448.5214, 448.8207, 448.1749, 448.1994, 448.8276, 448.5120, 448.1749,
        448.8222, 448.1750, 448.8222, 448.1770, 448.8237, 448.8259, 448.1773,
        448.8228, 448.5483], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([396.7271], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2056],
             [112.2049],
             [112.2083],
             [112.2049]],

            [[112.2054],
             [112.2054],
             [112.2050],
             [112.2050]],

            [[112.0471],
             [112.2081],
             [112.0526],
             [112.0526]],

            ...,

            [[112.2095],
             [112.0465],
             [112.0466],
             [112.2093]],

            [[112.2055],
             [112.2049],
             [112.2050],
             [112.2088]],

            [[112.2049],
             [112.2049],
             [112.2053],
             [112.2065]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8237, 448.8208, 448.3604,  ..., 448.5120, 448.8242, 448.8217],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8237, 448.8208, 448.3604,  ..., 448.5120, 448.8242, 448.8217],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2123],
             [112.2132],
             [112.2122],
             [112.2155]],

            [[112.2120],
             [112.2125],
             [112.2119],
             [112.2119]],

            [[112.0325],
             [112.0325],
             [112.0325],
             [112.0325]],

            ...,

            [[112.2119],
             [112.2119],
             [112.2134],
             [112.2134]],

            [[112.0331],
             [112.0331],
             [112.0439],
             [112.0439]],

            [[112.0362],
             [112.0327],
             [112.0328],
             [112.0366]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8532, 448.8483, 448.1299,  ..., 448.8506, 448.1540, 448.1384],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8532, 448.8483, 448.1299,  ..., 448.8506, 448.1540, 448.1384],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2200],
             [112.2244],
             [112.2203],
             [112.2201]],

            [[112.2202],
             [112.2202],
             [112.2200],
             [112.2245]],

            [[112.0255],
             [112.0213],
             [112.0256],
             [112.0213]],

            ...,

            [[112.2201],
             [112.2201],
             [112.2216],
             [112.2216]],

            [[112.2207],
             [112.2210],
             [112.2201],
             [112.2220]],

            [[112.2200],
             [112.2212],
             [112.2240],
             [112.2240]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8847, 448.8849, 448.0937,  ..., 448.8834, 448.8838, 448.8892],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8847, 448.8849, 448.0937,  ..., 448.8834, 448.8838, 448.8892],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2266],
             [112.2273],
             [112.2251],
             [112.2251]],

            [[112.2259],
             [112.2261],
             [112.2252],
             [112.2273]],

            [[112.2255],
             [112.2252],
             [112.2271],
             [112.2270]],

            ...,

            [[112.2251],
             [112.2251],
             [112.2254],
             [112.2265]],

            [[112.2264],
             [112.2251],
             [112.2254],
             [112.2282]],

            [[112.0433],
             [112.2257],
             [112.0332],
             [112.2257]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9042, 448.9044, 448.9048,  ..., 448.9021, 448.9052, 448.5280],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9042, 448.9044, 448.9048,  ..., 448.9021, 448.9052, 448.5280],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2388],
             [112.2395],
             [112.2388],
             [112.2395]],

            [[112.2398],
             [112.2398],
             [112.2421],
             [112.2421]],

            [[112.2388],
             [112.2388],
             [112.2390],
             [112.2424]],

            ...,

            [[112.2389],
             [112.2418],
             [112.2397],
             [112.2388]],

            [[112.2498],
             [112.2498],
             [112.2450],
             [112.2450]],

            [[112.2392],
             [112.2389],
             [112.2395],
             [112.2395]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9565, 448.9637, 448.9590,  ..., 448.9591, 448.9897, 448.9570],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9565, 448.9637, 448.9590,  ..., 448.9591, 448.9897, 448.9570],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2484],
             [112.2511],
             [112.2484],
             [112.2484]],

            [[111.9858],
             [111.9859],
             [111.9859],
             [111.9859]],

            [[112.2496],
             [112.2503],
             [112.2494],
             [112.2501]],

            ...,

            [[111.9863],
             [111.9913],
             [111.9862],
             [111.9879]],

            [[112.2485],
             [112.2485],
             [112.2484],
             [112.2484]],

            [[112.2481],
             [112.2481],
             [112.2495],
             [112.2495]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9964, 447.9434, 448.9994,  ..., 447.9518, 448.9938, 448.9954],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9964, 447.9434, 448.9994,  ..., 447.9518, 448.9938, 448.9954],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2617],
             [112.2617],
             [112.2624],
             [112.2624]],

            [[112.2616],
             [112.2635],
             [112.2616],
             [112.2637]],

            [[112.2630],
             [112.2638],
             [112.2619],
             [112.2619]],

            ...,

            [[112.2619],
             [112.2615],
             [112.2644],
             [112.2616]],

            [[112.2617],
             [112.2617],
             [112.2628],
             [112.2628]],

            [[112.2616],
             [112.2628],
             [112.2629],
             [112.2616]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0481, 449.0503, 449.0505,  ..., 449.0494, 449.0490, 449.0489],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0481, 449.0503, 449.0505,  ..., 449.0494, 449.0490, 449.0489],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2773],
             [112.2759],
             [112.2756],
             [112.2756]],

            [[111.9578],
             [111.9596],
             [111.9596],
             [111.9577]],

            [[112.2757],
             [112.2757],
             [112.2792],
             [112.2792]],

            ...,

            [[111.9584],
             [111.9584],
             [111.9693],
             [111.9687]],

            [[112.0047],
             [112.2790],
             [112.2768],
             [112.2755]],

            [[112.2755],
             [112.2763],
             [112.2767],
             [112.2764]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1044, 447.8347, 449.1097,  ..., 447.8549, 448.8361, 449.1048],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1044, 447.8347, 449.1097,  ..., 447.8549, 448.8361, 449.1048],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2873],
             [112.2873],
             [112.2876],
             [112.2876]],

            [[112.2882],
             [112.2872],
             [112.2871],
             [112.2898]],

            [[111.9501],
             [112.2941],
             [111.9626],
             [111.9626]],

            ...,

            [[112.2934],
             [112.2926],
             [112.2873],
             [112.2873]],

            [[111.9511],
             [112.2952],
             [111.9539],
             [112.2906]],

            [[112.2889],
             [112.2889],
             [112.2899],
             [112.2899]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1498, 449.1522, 448.1694,  ..., 449.1607, 448.4908, 449.1575],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1498, 449.1522, 448.1694,  ..., 449.1607, 448.4908, 449.1575],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2969],
             [112.2969],
             [112.3000],
             [112.3000]],

            [[112.2984],
             [112.2964],
             [112.2980],
             [112.2964]],

            [[111.9642],
             [112.2973],
             [111.9642],
             [112.2973]],

            ...,

            [[112.2963],
             [112.2963],
             [112.2963],
             [112.2963]],

            [[112.2964],
             [112.2965],
             [112.2964],
             [112.2985]],

            [[111.9381],
             [112.3108],
             [111.9373],
             [111.9752]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1938, 449.1891, 448.5230,  ..., 449.1854, 449.1879, 448.1614],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1938, 449.1891, 448.5230,  ..., 449.1854, 449.1879, 448.1614],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3006],
             [112.3006],
             [112.3003],
             [112.3003]],

            [[112.3019],
             [112.3148],
             [112.3022],
             [112.2902]],

            [[112.3004],
             [112.3014],
             [112.3004],
             [112.3030]],

            ...,

            [[111.9305],
             [111.9307],
             [111.9306],
             [111.9306]],

            [[112.3002],
             [112.3002],
             [112.3002],
             [112.3027]],

            [[111.9305],
             [111.9306],
             [111.9305],
             [111.9305]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2019, 449.2092, 449.2052,  ..., 447.7223, 449.2034, 447.7221],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2019, 449.2092, 449.2052,  ..., 447.7223, 449.2034, 447.7221],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3028],
             [112.3036],
             [112.3032],
             [112.3057]],

            [[112.3030],
             [112.3028],
             [112.3057],
             [112.3031]],

            [[111.9345],
             [111.9345],
             [112.3083],
             [112.3083]],

            ...,

            [[112.3032],
             [112.3039],
             [112.3028],
             [112.3044]],

            [[112.3090],
             [112.3090],
             [112.3085],
             [112.3085]],

            [[112.3032],
             [112.3029],
             [112.3038],
             [112.3038]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2155, 449.2146, 448.4858,  ..., 449.2144, 449.2350, 449.2137],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2155, 449.2146, 448.4858,  ..., 449.2144, 449.2350, 449.2137],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.3039],
             [112.3039],
             [112.3042],
             [112.3042]],

            [[112.3049],
             [112.3049],
             [112.3061],
             [112.3061]],

            [[112.3040],
             [112.3064],
             [112.3039],
             [112.3039]],

            ...,

            [[112.3043],
             [112.3051],
             [112.3040],
             [112.3040]],

            [[112.3050],
             [112.3050],
             [112.3050],
             [112.3050]],

            [[111.9240],
             [111.9285],
             [111.9240],
             [111.9285]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.2161, 449.2220, 449.2182,  ..., 449.2174, 449.2202, 447.7049],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.2161, 449.2220, 449.2182,  ..., 449.2174, 449.2202, 447.7049],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2956],
             [112.2956],
             [112.2966],
             [112.2966]],

            [[112.2960],
             [112.2957],
             [112.2956],
             [112.2963]],

            [[112.2960],
             [112.2970],
             [112.2956],
             [112.2960]],

            ...,

            [[111.9285],
             [111.9285],
             [111.9285],
             [111.9285]],

            [[112.3102],
             [112.2962],
             [112.1106],
             [112.2962]],

            [[112.2956],
             [112.2982],
             [112.2959],
             [112.2956]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1844, 449.1835, 449.1847,  ..., 447.7141, 449.0131, 449.1852],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1844, 449.1835, 449.1847,  ..., 447.7141, 449.0131, 449.1852],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2854],
             [112.2854],
             [112.2856],
             [112.2857]],

            [[111.9830],
             [111.9830],
             [112.2866],
             [112.2866]],

            [[112.2858],
             [112.2853],
             [112.2853],
             [112.2879]],

            ...,

            [[112.2839],
             [112.2843],
             [112.2849],
             [112.2842]],

            [[112.2858],
             [112.2858],
             [112.2859],
             [112.2853]],

            [[112.2856],
             [112.2864],
             [112.2855],
             [112.2855]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1421, 448.5391, 449.1443,  ..., 449.1373, 449.1428, 449.1431],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1421, 448.5391, 449.1443,  ..., 449.1373, 449.1428, 449.1431],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9332],
             [111.9332],
             [111.9332],
             [111.9332]],

            [[112.2870],
             [112.2857],
             [112.2876],
             [112.2855]],

            [[112.2859],
             [112.2855],
             [112.2881],
             [112.2881]],

            ...,

            [[112.2856],
             [112.2855],
             [112.2855],
             [112.2882]],

            [[112.2854],
             [112.2855],
             [112.2854],
             [112.2879]],

            [[111.9368],
             [112.2938],
             [111.9484],
             [111.9484]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7326, 449.1457, 449.1477,  ..., 449.1448, 449.1443, 448.1275],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7326, 449.1457, 449.1477,  ..., 449.1448, 449.1443, 448.1275],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2860],
             [112.2860],
             [112.2867],
             [112.2867]],

            [[112.2873],
             [112.2864],
             [112.2860],
             [112.2860]],

            [[112.2863],
             [112.2863],
             [112.2864],
             [112.2864]],

            ...,

            [[112.2867],
             [112.2868],
             [112.2870],
             [112.2869]],

            [[112.2860],
             [112.2860],
             [112.2865],
             [112.2865]],

            [[112.2860],
             [112.2860],
             [112.2886],
             [112.2886]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1455, 449.1457, 449.1454,  ..., 449.1474, 449.1451, 449.1492],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1455, 449.1457, 449.1454,  ..., 449.1474, 449.1451, 449.1492],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9328],
             [111.9328],
             [111.9328],
             [111.9329]],

            [[112.2823],
             [112.2825],
             [112.2820],
             [112.2836]],

            [[112.2827],
             [112.2870],
             [112.2824],
             [112.2934]],

            ...,

            [[111.9669],
             [111.9374],
             [112.2838],
             [112.2901]],

            [[112.2820],
             [112.2825],
             [112.2827],
             [112.2824]],

            [[111.9328],
             [111.9328],
             [111.9328],
             [111.9328]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7313, 449.1304, 449.1454,  ..., 448.4782, 449.1297, 447.7312],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7313, 449.1304, 449.1454,  ..., 448.4782, 449.1297, 447.7312],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0171e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9382],
             [111.9382],
             [111.9382],
             [111.9382]],

            [[112.2838],
             [112.2845],
             [112.2770],
             [112.2770]],

            [[112.2779],
             [112.2764],
             [112.2773],
             [112.2764]],

            ...,

            [[112.2767],
             [112.2767],
             [112.2767],
             [112.2767]],

            [[112.2904],
             [112.2772],
             [112.2903],
             [112.2772]],

            [[112.2775],
             [112.2775],
             [112.2775],
             [112.2775]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7527, 449.1222, 449.1079,  ..., 449.1070, 449.1351, 449.1100],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7527, 449.1222, 449.1079,  ..., 449.1070, 449.1351, 449.1100],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2769],
             [112.2770],
             [112.2778],
             [112.2778]],

            [[112.2768],
             [112.2764],
             [112.2764],
             [112.2785]],

            [[112.2774],
             [112.2767],
             [112.2765],
             [112.2765]],

            ...,

            [[111.9387],
             [111.9392],
             [111.9383],
             [111.9399]],

            [[112.2769],
             [112.2769],
             [112.2764],
             [112.2764]],

            [[112.2771],
             [112.2771],
             [112.2764],
             [112.2764]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1094, 449.1081, 449.1071,  ..., 447.7561, 449.1067, 449.1070],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1094, 449.1081, 449.1071,  ..., 447.7561, 449.1067, 449.1070],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9382],
             [111.9382],
             [111.9382],
             [111.9382]],

            [[112.2768],
             [112.2765],
             [112.2769],
             [112.2770]],

            [[112.2763],
             [112.2763],
             [112.2790],
             [112.2790]],

            ...,

            [[112.2764],
             [112.2764],
             [112.2765],
             [112.2787]],

            [[111.9470],
             [112.2793],
             [111.9706],
             [111.9706]],

            [[112.2765],
             [112.2765],
             [112.2769],
             [112.2769]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7527, 449.1071, 449.1107, 449.1088, 447.7527, 447.7527, 449.1100,
            449.1079, 448.1216, 449.1267, 449.1053, 449.1076, 449.1070, 449.1069,
            449.1084, 449.1057, 449.1080, 447.7536, 449.1151, 449.1348, 447.7527,
            449.1081, 447.7595, 447.7554, 447.7538, 449.1099, 449.1086, 448.4523,
            448.4520, 449.1078, 447.7527, 448.5795, 448.4995, 449.1071, 449.1068,
            449.1083, 447.7527, 449.1077, 449.1087, 449.1075, 449.1056, 447.7527,
            447.7881, 448.1675, 448.4500, 449.1102, 449.1075, 449.1198, 449.1187,
            449.1082, 449.1105, 448.5166, 447.7557, 448.4500, 449.1084, 449.1070,
            447.7527, 449.1147, 449.1069, 449.1072, 449.1066, 449.1066, 449.1087,
            449.1074, 447.7531, 449.1072, 449.1070, 447.7578, 449.1071, 449.1087,
            449.1059, 449.1100, 449.1091, 447.7717, 447.7528, 447.7527, 447.7535,
            447.7580, 447.7527, 449.1067, 447.7567, 447.7532, 447.7527, 449.1076,
            449.1062, 449.1059, 447.7530, 447.7528, 449.1077, 449.1056, 449.1080,
            449.1068, 449.1075, 447.7527, 449.1058, 449.1071, 449.1087, 447.7589,
            447.7527, 447.7527, 449.1069, 447.7544, 449.1085, 447.7528, 448.9761,
            449.1082, 448.5182, 449.1074, 449.1084, 449.1178, 448.8133, 449.1099,
            449.1070, 447.7529, 449.1080, 449.1082, 449.1116, 448.4571, 449.1092,
            447.7531, 449.1073, 447.7681, 449.1085, 449.1079, 447.7542, 449.1084,
            447.7534, 448.4581, 449.1074, 447.7775, 447.7576, 449.1078, 449.1082,
            449.1083, 449.1091, 449.1217, 449.1066, 448.4539, 449.1064, 449.1089,
            449.1067, 449.1303, 447.7560, 449.1086, 449.1085, 449.1077, 449.1073,
            448.4532, 449.1077, 449.1075, 449.1071, 449.1079, 449.1068, 447.7700,
            447.7527, 449.1093, 449.1078, 449.1083, 448.4868, 447.7732, 449.1097,
            449.1310, 447.7555, 449.1069, 449.1103, 449.1077, 449.1069, 449.1104,
            448.4535, 449.1082, 449.1080, 449.1071, 449.1080, 449.1075, 449.1069,
            447.7528, 447.7527, 449.1077, 447.7528, 447.7579, 449.1097, 449.1079,
            447.7569, 447.7532, 447.7544, 449.1078, 447.7635, 449.1060, 449.1075,
            449.1196, 448.4500, 449.1096, 449.1080, 447.7552, 447.7527, 449.1080,
            449.1072, 449.1087, 449.1110, 447.7561, 448.4861, 449.1071, 449.1063,
            449.1074, 449.1075, 449.1082, 449.1078, 449.1080, 449.1077, 447.7564,
            449.1085, 448.5791, 447.7766, 449.1086, 449.1087, 449.1076, 449.1076,
            449.1063, 448.4550, 449.1551, 449.1084, 449.1094, 449.1354, 447.7599,
            447.7529, 447.7528, 449.1080, 449.1091, 449.1180, 449.1084, 449.1075,
            447.7527, 449.1089, 449.1069, 447.7768, 449.1094, 447.7527, 449.1100,
            449.1078, 449.1082, 449.1085, 449.1082, 448.4562, 449.1081, 449.1080,
            449.1080, 447.7610, 449.1108, 449.1106, 448.8453, 449.1078, 449.1141,
            449.1076, 448.4527, 447.7562, 449.1077, 449.1080, 449.1080, 447.7530,
            449.1078, 449.1075, 449.1084, 449.1079, 449.1108, 449.1074, 449.1073,
            449.1084, 449.1076, 447.7723, 447.7694, 447.7531, 449.1077, 449.1073,
            449.1085, 447.7539, 449.1201, 449.1080, 449.1081, 449.1090, 449.1159,
            448.1282, 449.1088, 449.1072, 449.1287, 447.7527, 448.4509, 448.4626,
            449.1082, 449.1214, 449.1063, 449.1077, 448.4534, 447.7527, 449.1061,
            447.8395, 447.7661, 449.1074, 447.7528, 447.8104, 449.1093, 449.1074,
            449.1093, 448.4520, 449.1081, 449.1170, 449.1080, 449.1058, 449.1083,
            449.1081, 447.7527, 449.1064, 449.1064, 447.7527, 447.7671, 449.1078,
            449.1110, 449.1220, 449.1080, 449.1067, 449.1140, 449.1072, 448.4500,
            449.1250, 447.7533, 449.1072, 449.1126, 449.1073, 449.1093, 449.1066,
            449.1141, 449.1078, 447.7528, 447.7540, 449.1097, 447.7531, 448.9894,
            449.1073, 447.8122, 449.1072, 449.1071, 449.1073, 449.1082, 447.7566,
            449.1079, 447.7527, 448.4944, 447.7540, 449.1080, 449.1096, 449.1219,
            449.1093, 447.7537, 449.1069, 447.7527, 449.1104, 448.4547, 449.1075,
            449.1080, 448.4678, 448.6490, 447.7534, 448.5242, 447.8346, 447.7553,
            447.7666, 449.1081, 447.7527, 449.1093, 449.1244, 449.1088, 449.1080,
            447.7609, 449.1080, 449.1075, 449.1107, 447.7527, 449.1077, 449.1061,
            449.1079, 447.7763, 447.7610, 449.1082, 447.7527, 449.1098, 449.1069,
            449.1072, 447.7582, 449.1075, 448.7839, 449.1089, 447.7603, 449.1077,
            447.7532, 449.1069, 447.7530, 448.6055, 449.1104, 448.5283, 449.1119,
            447.7689, 449.1086, 447.7610, 447.7552, 447.7563, 449.1071, 449.1071,
            449.1286, 447.7527, 449.1073, 449.1083, 449.1084, 449.1066, 449.1078,
            447.7529, 449.1077, 447.7762, 449.1078, 449.1075, 449.1077, 449.1108,
            449.1082, 447.7527, 449.1075, 447.7768, 449.1080, 449.1104, 449.1078,
            449.1071, 448.4518, 449.1086, 449.1078, 449.1088, 449.1102, 449.1106,
            449.1067, 449.1073, 449.1102, 449.1079, 449.1082, 449.1075, 447.7527,
            447.7574, 448.4478, 447.7672, 449.1059, 449.1080, 449.1079, 449.1077,
            447.7554, 447.7529, 449.1342, 449.1074, 447.7693, 449.1077, 449.1075,
            449.1323, 447.7621, 449.1107, 447.7527, 449.1072, 449.1064, 449.1097,
            447.7527, 448.7948, 449.1158, 449.1077, 449.1059, 449.1078, 447.7559,
            449.1065, 449.1099, 447.8611, 448.9630, 449.1082, 448.4522, 449.1105,
            449.1074, 449.1093, 449.1064, 447.7530, 449.1093, 447.7769, 449.1181,
            449.1084, 447.7546, 447.8284, 447.7557, 447.7552, 449.1071, 448.7825,
            448.8441, 449.1074, 449.1189, 449.1072, 447.7998, 449.1142, 449.1079,
            449.1077, 449.1062, 449.1103, 447.7568, 449.1077, 447.7527, 449.1080,
            449.1069, 449.1065, 449.1076, 449.1066, 449.1104, 448.5020, 449.1101,
            447.7527, 449.1080, 449.1058, 447.7644, 447.7545, 449.1101, 449.1059,
            449.1080, 449.1063, 448.4608, 449.1078, 447.7527, 449.1075, 449.1076,
            449.1082, 449.1105, 447.7529, 448.4605, 447.7527, 448.7877, 449.1080,
            449.1077, 449.1082, 449.1103, 448.4664, 449.1074, 449.1085, 449.1062,
            449.1078, 449.1106, 449.1081, 447.7582, 449.1091, 449.1075, 449.1065,
            447.7537, 449.1066, 449.1080, 449.1086, 449.1082, 449.1081, 449.1070,
            449.1084, 449.1143, 449.1082, 449.1075, 449.1080, 449.1094, 447.7527,
            449.1072, 448.8216, 448.6649, 449.1078, 447.7533, 447.7568, 449.1079,
            449.1091, 449.1089, 449.1081, 449.1088, 448.7745, 448.7848, 449.1006,
            447.7669, 449.1092, 449.1076, 449.1069, 449.1075, 449.1135, 449.1093,
            448.7340, 449.1100, 449.1084, 449.1076, 447.7533, 449.1261, 447.7529,
            447.7527, 447.7667, 449.1076, 449.1088, 449.1074, 449.1083, 447.7567,
            449.1083, 448.1651, 449.1081, 448.4500, 449.1068, 449.1083, 449.1132,
            449.1062, 449.1118, 449.1072, 447.7542, 449.1083, 449.1074, 449.1079,
            449.1075, 449.1092, 449.1068, 447.7529, 447.7535, 448.0685, 449.1130,
            447.7559, 449.1093, 449.1074, 449.1075, 449.1071, 447.7527, 447.7532,
            449.1091, 447.8127, 447.7556, 449.1076, 447.8218, 447.7581, 448.7798,
            447.7527, 449.1092, 447.7533, 449.1082, 449.1085, 449.1099, 449.1075,
            447.7787, 449.1085, 447.7585, 449.1077, 447.7675, 449.1113, 449.1075,
            447.7572, 448.4528, 447.7527, 449.1078, 447.7527, 449.1073, 449.1153,
            447.7527, 449.1080, 447.7622, 449.1073, 449.1074, 449.1072, 449.1076,
            448.5775, 449.1225, 449.1080, 447.7601, 449.1070, 449.1075, 449.1133,
            449.1086, 449.1083, 449.1077, 449.1097, 449.1067, 448.1151, 449.1085,
            449.1072, 447.7527, 449.1089, 447.7532, 449.1159, 449.1067, 449.1076,
            449.1093, 447.7608, 449.1104, 449.1158, 449.1106, 449.1089, 448.8217,
            449.1075, 449.1074, 449.1091, 448.8398, 448.4624, 447.7527, 447.8356,
            447.7528, 447.7536, 447.7538, 449.1075, 449.1071, 449.1088, 449.1082,
            449.1074, 449.1097, 449.1105, 449.1091, 449.1080, 448.2507, 449.1076,
            449.1072, 447.7527, 449.1082, 447.7544, 449.1068, 447.7527, 447.7528,
            449.1077, 449.1073, 449.1077, 448.8165, 449.1062, 447.7527, 449.1108,
            447.7527, 449.1095, 448.4686, 449.1094, 448.9593, 447.7573, 449.1061,
            448.4547, 449.1092, 449.1086, 449.1097, 449.1093, 449.1076, 449.1075,
            449.1074, 449.1079, 447.7530, 449.1080, 449.1071, 449.1071, 449.1104,
            449.1078, 449.1261, 449.1096, 449.1073, 449.1067, 448.7979, 449.1078,
            447.7527, 449.1070, 449.1067, 449.1176, 449.1075, 449.1066, 447.7533,
            449.1084, 447.8694, 449.1074, 447.7527, 447.7528, 449.1089, 447.7528,
            448.4530, 448.5106, 448.1262, 449.1069, 449.1089, 449.1071, 449.1100,
            447.7528, 449.1077, 447.7551, 449.1101, 447.7891, 448.1300, 447.7609,
            449.1075, 449.1083, 449.1080, 447.7653, 449.0363, 449.1107, 447.7527,
            447.7528, 447.7570, 449.1069, 449.1076, 447.7859, 447.8971, 449.1071,
            449.1109, 448.5363, 449.1081, 447.7554, 448.4663, 447.7610, 447.7527,
            447.7540, 449.1077, 449.1080, 449.1080, 449.1108, 449.1077, 449.1434,
            447.7546, 449.1074, 447.7568, 449.1081, 449.1075, 447.7574, 449.1080,
            449.1109, 449.1089, 449.1080, 449.1060, 449.1094, 449.1069, 448.4571,
            449.1360, 447.7569, 447.7537, 449.1076, 449.1069, 449.1081, 449.1065,
            449.1088, 449.1074, 449.1073, 449.1064, 449.1071, 449.1071, 449.1056,
            447.8720, 449.1088, 449.1077, 447.7623, 447.7593, 449.1063, 447.8145,
            449.1079, 449.1069, 449.1086, 449.1081, 449.1295, 449.1076, 449.1097,
            447.7538, 449.1091, 449.1082, 449.1078, 449.1074, 449.1079, 449.1095,
            447.7549, 449.1085, 449.1086, 447.7539, 449.1076, 447.7527, 449.1075,
            449.1062, 447.7660, 449.1078, 449.1085, 448.2360, 448.1494, 449.1076,
            447.7564, 449.1075, 448.4921, 447.7701, 447.7527, 449.1105, 449.1091,
            447.9035, 449.1083, 449.1082, 449.1094, 449.1061, 449.1092, 447.7543,
            449.1086, 449.1109, 447.7534, 449.1075, 449.1177, 449.1094, 449.1076,
            447.7603, 449.1085, 449.1071, 449.1089, 448.4650, 449.1091, 447.7527,
            449.1081, 447.7596, 449.1076, 447.7532, 447.7951, 449.1412, 449.1167,
            447.7527, 449.1075, 449.1069, 449.1082, 449.1072, 448.4500, 447.7628,
            449.1075, 448.8789, 449.1082, 449.1087, 449.1061, 449.1098, 449.1418,
            449.1074, 449.1095, 447.7527, 449.1076, 447.7577, 449.1082, 449.1079,
            448.1676, 449.1069], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7527, 449.1071, 449.1107, 449.1088, 447.7527, 447.7527, 449.1100,
        449.1079, 448.1216, 449.1267, 449.1053, 449.1076, 449.1070, 449.1069,
        449.1084, 449.1057, 449.1080, 447.7536, 449.1151, 449.1348, 447.7527,
        449.1081, 447.7595, 447.7554, 447.7538, 449.1099, 449.1086, 448.4523,
        448.4520, 449.1078, 447.7527, 448.5795, 448.4995, 449.1071, 449.1068,
        449.1083, 447.7527, 449.1077, 449.1087, 449.1075, 449.1056, 447.7527,
        447.7881, 448.1675, 448.4500, 449.1102, 449.1075, 449.1198, 449.1187,
        449.1082, 449.1105, 448.5166, 447.7557, 448.4500, 449.1084, 449.1070,
        447.7527, 449.1147, 449.1069, 449.1072, 449.1066, 449.1066, 449.1087,
        449.1074, 447.7531, 449.1072, 449.1070, 447.7578, 449.1071, 449.1087,
        449.1059, 449.1100, 449.1091, 447.7717, 447.7528, 447.7527, 447.7535,
        447.7580, 447.7527, 449.1067, 447.7567, 447.7532, 447.7527, 449.1076,
        449.1062, 449.1059, 447.7530, 447.7528, 449.1077, 449.1056, 449.1080,
        449.1068, 449.1075, 447.7527, 449.1058, 449.1071, 449.1087, 447.7589,
        447.7527, 447.7527, 449.1069, 447.7544, 449.1085, 447.7528, 448.9761,
        449.1082, 448.5182, 449.1074, 449.1084, 449.1178, 448.8133, 449.1099,
        449.1070, 447.7529, 449.1080, 449.1082, 449.1116, 448.4571, 449.1092,
        447.7531, 449.1073, 447.7681, 449.1085, 449.1079, 447.7542, 449.1084,
        447.7534, 448.4581, 449.1074, 447.7775, 447.7576, 449.1078, 449.1082,
        449.1083, 449.1091, 449.1217, 449.1066, 448.4539, 449.1064, 449.1089,
        449.1067, 449.1303, 447.7560, 449.1086, 449.1085, 449.1077, 449.1073,
        448.4532, 449.1077, 449.1075, 449.1071, 449.1079, 449.1068, 447.7700,
        447.7527, 449.1093, 449.1078, 449.1083, 448.4868, 447.7732, 449.1097,
        449.1310, 447.7555, 449.1069, 449.1103, 449.1077, 449.1069, 449.1104,
        448.4535, 449.1082, 449.1080, 449.1071, 449.1080, 449.1075, 449.1069,
        447.7528, 447.7527, 449.1077, 447.7528, 447.7579, 449.1097, 449.1079,
        447.7569, 447.7532, 447.7544, 449.1078, 447.7635, 449.1060, 449.1075,
        449.1196, 448.4500, 449.1096, 449.1080, 447.7552, 447.7527, 449.1080,
        449.1072, 449.1087, 449.1110, 447.7561, 448.4861, 449.1071, 449.1063,
        449.1074, 449.1075, 449.1082, 449.1078, 449.1080, 449.1077, 447.7564,
        449.1085, 448.5791, 447.7766, 449.1086, 449.1087, 449.1076, 449.1076,
        449.1063, 448.4550, 449.1551, 449.1084, 449.1094, 449.1354, 447.7599,
        447.7529, 447.7528, 449.1080, 449.1091, 449.1180, 449.1084, 449.1075,
        447.7527, 449.1089, 449.1069, 447.7768, 449.1094, 447.7527, 449.1100,
        449.1078, 449.1082, 449.1085, 449.1082, 448.4562, 449.1081, 449.1080,
        449.1080, 447.7610, 449.1108, 449.1106, 448.8453, 449.1078, 449.1141,
        449.1076, 448.4527, 447.7562, 449.1077, 449.1080, 449.1080, 447.7530,
        449.1078, 449.1075, 449.1084, 449.1079, 449.1108, 449.1074, 449.1073,
        449.1084, 449.1076, 447.7723, 447.7694, 447.7531, 449.1077, 449.1073,
        449.1085, 447.7539, 449.1201, 449.1080, 449.1081, 449.1090, 449.1159,
        448.1282, 449.1088, 449.1072, 449.1287, 447.7527, 448.4509, 448.4626,
        449.1082, 449.1214, 449.1063, 449.1077, 448.4534, 447.7527, 449.1061,
        447.8395, 447.7661, 449.1074, 447.7528, 447.8104, 449.1093, 449.1074,
        449.1093, 448.4520, 449.1081, 449.1170, 449.1080, 449.1058, 449.1083,
        449.1081, 447.7527, 449.1064, 449.1064, 447.7527, 447.7671, 449.1078,
        449.1110, 449.1220, 449.1080, 449.1067, 449.1140, 449.1072, 448.4500,
        449.1250, 447.7533, 449.1072, 449.1126, 449.1073, 449.1093, 449.1066,
        449.1141, 449.1078, 447.7528, 447.7540, 449.1097, 447.7531, 448.9894,
        449.1073, 447.8122, 449.1072, 449.1071, 449.1073, 449.1082, 447.7566,
        449.1079, 447.7527, 448.4944, 447.7540, 449.1080, 449.1096, 449.1219,
        449.1093, 447.7537, 449.1069, 447.7527, 449.1104, 448.4547, 449.1075,
        449.1080, 448.4678, 448.6490, 447.7534, 448.5242, 447.8346, 447.7553,
        447.7666, 449.1081, 447.7527, 449.1093, 449.1244, 449.1088, 449.1080,
        447.7609, 449.1080, 449.1075, 449.1107, 447.7527, 449.1077, 449.1061,
        449.1079, 447.7763, 447.7610, 449.1082, 447.7527, 449.1098, 449.1069,
        449.1072, 447.7582, 449.1075, 448.7839, 449.1089, 447.7603, 449.1077,
        447.7532, 449.1069, 447.7530, 448.6055, 449.1104, 448.5283, 449.1119,
        447.7689, 449.1086, 447.7610, 447.7552, 447.7563, 449.1071, 449.1071,
        449.1286, 447.7527, 449.1073, 449.1083, 449.1084, 449.1066, 449.1078,
        447.7529, 449.1077, 447.7762, 449.1078, 449.1075, 449.1077, 449.1108,
        449.1082, 447.7527, 449.1075, 447.7768, 449.1080, 449.1104, 449.1078,
        449.1071, 448.4518, 449.1086, 449.1078, 449.1088, 449.1102, 449.1106,
        449.1067, 449.1073, 449.1102, 449.1079, 449.1082, 449.1075, 447.7527,
        447.7574, 448.4478, 447.7672, 449.1059, 449.1080, 449.1079, 449.1077,
        447.7554, 447.7529, 449.1342, 449.1074, 447.7693, 449.1077, 449.1075,
        449.1323, 447.7621, 449.1107, 447.7527, 449.1072, 449.1064, 449.1097,
        447.7527, 448.7948, 449.1158, 449.1077, 449.1059, 449.1078, 447.7559,
        449.1065, 449.1099, 447.8611, 448.9630, 449.1082, 448.4522, 449.1105,
        449.1074, 449.1093, 449.1064, 447.7530, 449.1093, 447.7769, 449.1181,
        449.1084, 447.7546, 447.8284, 447.7557, 447.7552, 449.1071, 448.7825,
        448.8441, 449.1074, 449.1189, 449.1072, 447.7998, 449.1142, 449.1079,
        449.1077, 449.1062, 449.1103, 447.7568, 449.1077, 447.7527, 449.1080,
        449.1069, 449.1065, 449.1076, 449.1066, 449.1104, 448.5020, 449.1101,
        447.7527, 449.1080, 449.1058, 447.7644, 447.7545, 449.1101, 449.1059,
        449.1080, 449.1063, 448.4608, 449.1078, 447.7527, 449.1075, 449.1076,
        449.1082, 449.1105, 447.7529, 448.4605, 447.7527, 448.7877, 449.1080,
        449.1077, 449.1082, 449.1103, 448.4664, 449.1074, 449.1085, 449.1062,
        449.1078, 449.1106, 449.1081, 447.7582, 449.1091, 449.1075, 449.1065,
        447.7537, 449.1066, 449.1080, 449.1086, 449.1082, 449.1081, 449.1070,
        449.1084, 449.1143, 449.1082, 449.1075, 449.1080, 449.1094, 447.7527,
        449.1072, 448.8216, 448.6649, 449.1078, 447.7533, 447.7568, 449.1079,
        449.1091, 449.1089, 449.1081, 449.1088, 448.7745, 448.7848, 449.1006,
        447.7669, 449.1092, 449.1076, 449.1069, 449.1075, 449.1135, 449.1093,
        448.7340, 449.1100, 449.1084, 449.1076, 447.7533, 449.1261, 447.7529,
        447.7527, 447.7667, 449.1076, 449.1088, 449.1074, 449.1083, 447.7567,
        449.1083, 448.1651, 449.1081, 448.4500, 449.1068, 449.1083, 449.1132,
        449.1062, 449.1118, 449.1072, 447.7542, 449.1083, 449.1074, 449.1079,
        449.1075, 449.1092, 449.1068, 447.7529, 447.7535, 448.0685, 449.1130,
        447.7559, 449.1093, 449.1074, 449.1075, 449.1071, 447.7527, 447.7532,
        449.1091, 447.8127, 447.7556, 449.1076, 447.8218, 447.7581, 448.7798,
        447.7527, 449.1092, 447.7533, 449.1082, 449.1085, 449.1099, 449.1075,
        447.7787, 449.1085, 447.7585, 449.1077, 447.7675, 449.1113, 449.1075,
        447.7572, 448.4528, 447.7527, 449.1078, 447.7527, 449.1073, 449.1153,
        447.7527, 449.1080, 447.7622, 449.1073, 449.1074, 449.1072, 449.1076,
        448.5775, 449.1225, 449.1080, 447.7601, 449.1070, 449.1075, 449.1133,
        449.1086, 449.1083, 449.1077, 449.1097, 449.1067, 448.1151, 449.1085,
        449.1072, 447.7527, 449.1089, 447.7532, 449.1159, 449.1067, 449.1076,
        449.1093, 447.7608, 449.1104, 449.1158, 449.1106, 449.1089, 448.8217,
        449.1075, 449.1074, 449.1091, 448.8398, 448.4624, 447.7527, 447.8356,
        447.7528, 447.7536, 447.7538, 449.1075, 449.1071, 449.1088, 449.1082,
        449.1074, 449.1097, 449.1105, 449.1091, 449.1080, 448.2507, 449.1076,
        449.1072, 447.7527, 449.1082, 447.7544, 449.1068, 447.7527, 447.7528,
        449.1077, 449.1073, 449.1077, 448.8165, 449.1062, 447.7527, 449.1108,
        447.7527, 449.1095, 448.4686, 449.1094, 448.9593, 447.7573, 449.1061,
        448.4547, 449.1092, 449.1086, 449.1097, 449.1093, 449.1076, 449.1075,
        449.1074, 449.1079, 447.7530, 449.1080, 449.1071, 449.1071, 449.1104,
        449.1078, 449.1261, 449.1096, 449.1073, 449.1067, 448.7979, 449.1078,
        447.7527, 449.1070, 449.1067, 449.1176, 449.1075, 449.1066, 447.7533,
        449.1084, 447.8694, 449.1074, 447.7527, 447.7528, 449.1089, 447.7528,
        448.4530, 448.5106, 448.1262, 449.1069, 449.1089, 449.1071, 449.1100,
        447.7528, 449.1077, 447.7551, 449.1101, 447.7891, 448.1300, 447.7609,
        449.1075, 449.1083, 449.1080, 447.7653, 449.0363, 449.1107, 447.7527,
        447.7528, 447.7570, 449.1069, 449.1076, 447.7859, 447.8971, 449.1071,
        449.1109, 448.5363, 449.1081, 447.7554, 448.4663, 447.7610, 447.7527,
        447.7540, 449.1077, 449.1080, 449.1080, 449.1108, 449.1077, 449.1434,
        447.7546, 449.1074, 447.7568, 449.1081, 449.1075, 447.7574, 449.1080,
        449.1109, 449.1089, 449.1080, 449.1060, 449.1094, 449.1069, 448.4571,
        449.1360, 447.7569, 447.7537, 449.1076, 449.1069, 449.1081, 449.1065,
        449.1088, 449.1074, 449.1073, 449.1064, 449.1071, 449.1071, 449.1056,
        447.8720, 449.1088, 449.1077, 447.7623, 447.7593, 449.1063, 447.8145,
        449.1079, 449.1069, 449.1086, 449.1081, 449.1295, 449.1076, 449.1097,
        447.7538, 449.1091, 449.1082, 449.1078, 449.1074, 449.1079, 449.1095,
        447.7549, 449.1085, 449.1086, 447.7539, 449.1076, 447.7527, 449.1075,
        449.1062, 447.7660, 449.1078, 449.1085, 448.2360, 448.1494, 449.1076,
        447.7564, 449.1075, 448.4921, 447.7701, 447.7527, 449.1105, 449.1091,
        447.9035, 449.1083, 449.1082, 449.1094, 449.1061, 449.1092, 447.7543,
        449.1086, 449.1109, 447.7534, 449.1075, 449.1177, 449.1094, 449.1076,
        447.7603, 449.1085, 449.1071, 449.1089, 448.4650, 449.1091, 447.7527,
        449.1081, 447.7596, 449.1076, 447.7532, 447.7951, 449.1412, 449.1167,
        447.7527, 449.1075, 449.1069, 449.1082, 449.1072, 448.4500, 447.7628,
        449.1075, 448.8789, 449.1082, 449.1087, 449.1061, 449.1098, 449.1418,
        449.1074, 449.1095, 447.7527, 449.1076, 447.7577, 449.1082, 449.1079,
        448.1676, 449.1069], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([401.2022], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2778],
             [112.2764],
             [112.2771],
             [112.2764]],

            [[112.2768],
             [112.2783],
             [112.2766],
             [112.2766]],

            [[111.9387],
             [111.9398],
             [111.9393],
             [111.9398]],

            ...,

            [[112.2766],
             [112.2768],
             [112.2765],
             [112.2786]],

            [[111.9383],
             [111.9383],
             [111.9383],
             [111.9383]],

            [[112.2867],
             [112.2794],
             [112.2771],
             [112.2767]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1077, 449.1082, 447.7576,  ..., 449.1085, 447.7533, 449.1199],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1077, 449.1082, 447.7576,  ..., 449.1085, 447.7533, 449.1199],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2752],
             [112.2752],
             [112.2757],
             [112.2757]],

            [[112.2750],
             [112.2747],
             [112.2749],
             [112.2748]],

            [[112.2750],
             [112.2743],
             [112.2743],
             [112.2743]],

            ...,

            [[111.9449],
             [111.9449],
             [111.9453],
             [111.9453]],

            [[112.2746],
             [112.2743],
             [112.2755],
             [112.2743]],

            [[112.2743],
             [112.2743],
             [112.2742],
             [112.2742]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1019, 449.0995, 449.0978,  ..., 447.7804, 449.0988, 449.0970],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1019, 449.0995, 449.0978,  ..., 447.7804, 449.0988, 449.0970],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9414],
             [111.9414],
             [111.9412],
             [111.9412]],

            [[112.2763],
             [112.2763],
             [112.2783],
             [112.2783]],

            [[112.2764],
             [112.2769],
             [112.2767],
             [112.2763]],

            ...,

            [[112.2763],
             [112.2763],
             [112.2766],
             [112.2766]],

            [[111.9448],
             [111.9445],
             [112.2834],
             [112.2834]],

            [[112.2771],
             [112.2771],
             [112.2778],
             [112.2778]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.7653, 449.1093, 449.1064,  ..., 449.1057, 448.4562, 449.1098],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.7653, 449.1093, 449.1064,  ..., 449.1057, 448.4562, 449.1098],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2787],
             [112.2779],
             [112.2800],
             [112.2780]],

            [[112.2779],
             [112.2782],
             [112.2779],
             [112.2804]],

            [[111.9438],
             [112.2845],
             [111.9444],
             [112.2835]],

            ...,

            [[112.2780],
             [112.2780],
             [112.2797],
             [112.2797]],

            [[112.2788],
             [112.2781],
             [112.2810],
             [112.2780]],

            [[112.2857],
             [112.2857],
             [112.2784],
             [112.2784]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1145, 449.1143, 448.4561,  ..., 449.1154, 449.1158, 449.1283],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1145, 449.1143, 448.4561,  ..., 449.1154, 449.1158, 449.1283],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2788],
             [112.2800],
             [112.2790],
             [112.2785]],

            [[112.2786],
             [112.2785],
             [112.2804],
             [112.2787]],

            [[112.2787],
             [112.2787],
             [112.2794],
             [112.2794]],

            ...,

            [[111.9609],
             [111.9609],
             [111.9928],
             [111.9928]],

            [[112.2790],
             [112.2790],
             [112.2789],
             [112.2789]],

            [[112.2788],
             [112.2788],
             [112.2808],
             [112.2808]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.1162, 449.1162, 449.1162,  ..., 447.9073, 449.1158, 449.1191],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.1162, 449.1162, 449.1162,  ..., 447.9073, 449.1158, 449.1191],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9558],
             [111.9558],
             [111.9617],
             [111.9617]],

            [[111.9458],
             [111.9462],
             [111.9459],
             [111.9459]],

            [[112.2722],
             [112.2767],
             [112.2840],
             [112.2729]],

            ...,

            [[112.2743],
             [112.2743],
             [112.2743],
             [112.2743]],

            [[112.2715],
             [112.2715],
             [112.2736],
             [112.2736]],

            [[112.2719],
             [112.2540],
             [112.2721],
             [112.2721]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8350, 447.7839, 449.1058,  ..., 449.0972, 449.0900, 449.0701],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8350, 447.7839, 449.1058,  ..., 449.0972, 449.0900, 449.0701],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2656],
             [112.2656],
             [112.2652],
             [112.2652]],

            [[112.2654],
             [112.2656],
             [112.2663],
             [112.2654]],

            [[112.2665],
             [112.2665],
             [112.2665],
             [112.2665]],

            ...,

            [[112.2654],
             [112.2654],
             [112.2651],
             [112.2651]],

            [[111.9514],
             [111.9514],
             [111.9514],
             [111.9514]],

            [[111.9514],
             [111.9514],
             [111.9514],
             [111.9514]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0617, 449.0627, 449.0661,  ..., 449.0610, 447.8057, 447.8057],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0617, 449.0627, 449.0661,  ..., 449.0610, 447.8057, 447.8057],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2573],
             [112.2573],
             [112.2568],
             [112.2568]],

            [[111.9618],
             [112.2600],
             [111.9615],
             [112.2613]],

            [[112.2567],
             [112.2567],
             [112.2571],
             [112.2571]],

            ...,

            [[112.2569],
             [112.2573],
             [112.2571],
             [112.2576]],

            [[112.2574],
             [112.2574],
             [112.2590],
             [112.2590]],

            [[111.9585],
             [111.9585],
             [111.9585],
             [111.9585]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0283, 448.4446, 449.0277,  ..., 449.0288, 449.0328, 447.8340],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0283, 448.4446, 449.0277,  ..., 449.0288, 449.0328, 447.8340],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2561],
             [112.2574],
             [112.2563],
             [112.2559]],

            [[112.2562],
             [112.2567],
             [112.2565],
             [112.2573]],

            [[112.2558],
             [112.2571],
             [112.2558],
             [112.2571]],

            ...,

            [[112.2560],
             [112.2560],
             [112.2561],
             [112.2561]],

            [[112.2583],
             [112.2561],
             [112.2559],
             [112.2559]],

            [[112.2562],
             [112.2560],
             [112.2562],
             [112.2564]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0257, 449.0267, 449.0258,  ..., 449.0242, 449.0262, 449.0248],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0257, 449.0267, 449.0258,  ..., 449.0242, 449.0262, 449.0248],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2510],
             [112.2510],
             [112.2531],
             [112.2531]],

            [[112.2511],
             [112.2529],
             [112.2511],
             [112.2529]],

            [[111.9666],
             [111.9666],
             [112.2589],
             [112.2614]],

            ...,

            [[112.2527],
             [112.2519],
             [112.2510],
             [112.2510]],

            [[112.2512],
             [112.2511],
             [112.2526],
             [112.2534]],

            [[112.2521],
             [112.2522],
             [112.2521],
             [112.2522]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0083, 449.0080, 448.4536,  ..., 449.0066, 449.0083, 449.0086],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0083, 449.0080, 448.4536,  ..., 449.0066, 449.0083, 449.0086],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9729],
             [111.9704],
             [111.9704],
             [111.9731]],

            [[112.2462],
             [112.2437],
             [112.2449],
             [112.2436]],

            [[112.2436],
             [112.2435],
             [112.2457],
             [112.2437]],

            ...,

            [[112.2437],
             [112.2435],
             [112.2436],
             [112.2457]],

            [[111.9707],
             [111.9702],
             [111.9708],
             [111.9702]],

            [[112.2443],
             [112.2436],
             [112.2437],
             [112.2439]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.8868, 448.9784, 448.9765,  ..., 448.9765, 447.8820, 448.9755],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.8868, 448.9784, 448.9765,  ..., 448.9765, 447.8820, 448.9755],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9778],
             [111.9824],
             [111.9778],
             [111.9825]],

            [[112.2371],
             [112.2371],
             [112.2374],
             [112.2374]],

            [[112.2463],
             [112.2364],
             [112.2439],
             [112.2364]],

            ...,

            [[112.2380],
             [112.2360],
             [112.2361],
             [112.2364]],

            [[112.2366],
             [112.2366],
             [112.2360],
             [112.2360]],

            [[112.2361],
             [112.2361],
             [112.2361],
             [112.2361]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9204, 448.9490, 448.9629,  ..., 448.9465, 448.9452, 448.9445],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9204, 448.9490, 448.9629,  ..., 448.9465, 448.9452, 448.9445],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2296],
             [112.2294],
             [112.2294],
             [112.2308]],

            [[112.2296],
             [112.2294],
             [112.2300],
             [112.2300]],

            [[112.2301],
             [112.2296],
             [112.2302],
             [112.2295]],

            ...,

            [[112.2312],
             [112.2294],
             [112.2297],
             [112.2297]],

            [[111.9848],
             [112.0246],
             [111.9847],
             [112.0221]],

            [[112.2299],
             [112.2297],
             [112.2297],
             [112.2297]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9192, 448.9191, 448.9194,  ..., 448.9200, 448.0162, 448.9189],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9192, 448.9191, 448.9194,  ..., 448.9200, 448.0162, 448.9189],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9919],
             [112.2325],
             [111.9913],
             [112.2241]],

            [[111.9902],
             [111.9902],
             [111.9920],
             [111.9920]],

            [[111.9900],
             [111.9900],
             [111.9900],
             [111.9900]],

            ...,

            [[111.9904],
             [111.9902],
             [111.9901],
             [111.9911]],

            [[112.2224],
             [112.2224],
             [112.2225],
             [112.2225]],

            [[111.9900],
             [111.9900],
             [111.9900],
             [111.9900]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4398, 447.9644, 447.9600,  ..., 447.9618, 448.8897, 447.9600],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4398, 447.9644, 447.9600,  ..., 447.9618, 448.8897, 447.9600],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0024],
             [112.2178],
             [112.1842],
             [112.1841]],

            [[112.2171],
             [112.2171],
             [112.2171],
             [112.2171]],

            [[112.2167],
             [112.2161],
             [112.2164],
             [112.2161]],

            ...,

            [[111.9953],
             [111.9972],
             [111.9953],
             [111.9975]],

            [[111.9952],
             [111.9963],
             [111.9955],
             [111.9955]],

            [[112.2161],
             [112.2161],
             [112.2162],
             [112.2162]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5885, 448.8684, 448.8653,  ..., 447.9853, 447.9824, 448.8646],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5885, 448.8684, 448.8653,  ..., 447.9853, 447.9824, 448.8646],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2106],
             [112.2111],
             [112.2110],
             [112.2117]],

            [[112.2104],
             [112.2121],
             [112.2104],
             [112.2110]],

            [[112.2104],
             [112.2125],
             [112.2106],
             [112.2104]],

            ...,

            [[112.0011],
             [112.1477],
             [112.2110],
             [112.2113]],

            [[112.2110],
             [112.2107],
             [112.2105],
             [112.2111]],

            [[112.2111],
             [112.2108],
             [112.2108],
             [112.2111]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8444, 448.8439, 448.8440,  ..., 448.5712, 448.8433, 448.8438],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8444, 448.8439, 448.8440,  ..., 448.5712, 448.8433, 448.8438],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0022],
             [112.0039],
             [112.0027],
             [112.0027]],

            [[112.2080],
             [112.0347],
             [112.2080],
             [112.2080]],

            [[112.0109],
             [112.0048],
             [112.0045],
             [112.0133]],

            ...,

            [[112.0021],
             [112.0024],
             [112.0022],
             [112.0022]],

            [[112.2077],
             [112.2090],
             [112.2083],
             [112.2083]],

            [[112.0021],
             [112.0027],
             [112.0021],
             [112.0026]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0114, 448.6586, 448.0335,  ..., 448.0090, 448.8333, 448.0096],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0114, 448.6586, 448.0335,  ..., 448.0090, 448.8333, 448.0096],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0035],
             [112.0035],
             [112.0036],
             [112.0036]],

            [[112.2060],
             [112.2064],
             [112.2067],
             [112.2064]],

            [[112.0074],
             [112.2128],
             [112.1989],
             [112.2081]],

            ...,

            [[112.2060],
             [112.2062],
             [112.2065],
             [112.2071]],

            [[112.0033],
             [112.0069],
             [112.0044],
             [112.0044]],

            [[112.2063],
             [112.2063],
             [112.2062],
             [112.2062]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0142, 448.8254, 448.6273,  ..., 448.8258, 448.0190, 448.8250],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0142, 448.8254, 448.6273,  ..., 448.8258, 448.0190, 448.8250],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0077e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1065],
             [112.2052],
             [112.2088],
             [112.2051]],

            [[112.0127],
             [112.0115],
             [112.0058],
             [112.0067]],

            [[112.2047],
             [112.2056],
             [112.2049],
             [112.2047]],

            ...,

            [[112.2051],
             [112.1848],
             [112.2111],
             [112.2076]],

            [[112.2047],
             [112.2050],
             [112.2048],
             [112.2067]],

            [[112.2048],
             [112.2062],
             [112.2050],
             [112.2054]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7256, 448.0366, 448.8199,  ..., 448.8087, 448.8212, 448.8215],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7256, 448.0366, 448.8199,  ..., 448.8087, 448.8212, 448.8215],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0034],
             [112.0034],
             [112.0034],
             [112.0034]],

            [[112.2048],
             [112.2048],
             [112.2063],
             [112.2063]],

            [[112.0065],
             [112.2073],
             [112.2079],
             [112.2079]],

            ...,

            [[112.2066],
             [112.2052],
             [112.2048],
             [112.2048]],

            [[112.0034],
             [112.0034],
             [112.0037],
             [112.0037]],

            [[112.2078],
             [112.2048],
             [112.2082],
             [112.2049]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0135, 448.8222, 448.6296,  ..., 448.8213, 448.0143, 448.8257],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0135, 448.8222, 448.6296,  ..., 448.8213, 448.0143, 448.8257],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2055],
             [112.0206],
             [112.2062],
             [112.0146]],

            [[112.2046],
             [112.2057],
             [112.2046],
             [112.2059]],

            [[112.2065],
             [112.2065],
             [112.2048],
             [112.2048]],

            ...,

            [[112.2048],
             [112.2073],
             [112.2049],
             [112.2127]],

            [[112.0138],
             [112.2054],
             [112.2093],
             [112.2093]],

            [[112.2053],
             [112.2053],
             [112.2058],
             [112.2058]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4468, 448.8208, 448.8226, 448.0145, 448.4943, 448.0135, 448.8197,
            448.4818, 448.8361, 448.4550, 448.0135, 448.8212, 448.8221, 448.0248,
            448.8203, 448.8208, 448.0135, 448.0453, 448.6374, 448.1411, 448.0189,
            448.8219, 448.8209, 448.8218, 448.8190, 448.8206, 448.8267, 448.8213,
            448.8219, 448.8209, 448.8196, 448.8227, 448.0135, 448.8191, 448.4214,
            448.8203, 448.0165, 448.0163, 448.8235, 448.8195, 448.8340, 448.8217,
            448.8190, 448.0135, 448.8189, 448.8211, 448.0135, 448.8208, 448.8198,
            448.8194, 448.8206, 448.0139, 448.8106, 448.8192, 448.8206, 448.8232,
            448.8214, 448.8230, 448.6274, 448.0153, 448.0142, 448.8206, 448.8201,
            448.8207, 448.2325, 448.0147, 448.8192, 448.0135, 448.8187, 448.4286,
            448.8201, 448.8206, 448.4897, 448.8200, 448.6593, 448.8202, 448.0160,
            448.8196, 448.8221, 448.8205, 448.2377, 448.0319, 448.0135, 448.0204,
            448.8196, 448.0139, 448.8187, 448.8204, 448.0139, 448.8210, 448.0137,
            448.8212, 448.0177, 448.8189, 448.8209, 448.8206, 448.8205, 448.0305,
            448.8210, 448.0135, 448.0569, 448.8206, 448.8220, 448.0135, 448.0135,
            448.0135, 448.8201, 448.8271, 448.4677, 448.0135, 448.8216, 448.0146,
            448.0253, 448.8232, 448.8199, 448.4648, 448.8199, 448.8214, 448.8207,
            448.0370, 448.8211, 448.8204, 448.8211, 448.4938, 448.7692, 448.8200,
            448.8208, 448.0165, 448.8214, 448.8205, 448.8229, 448.0139, 448.8236,
            448.8210, 448.8199, 448.8209, 448.8217, 448.8192, 448.8209, 448.3146,
            448.8216, 448.0563, 448.8090, 448.8201, 448.0566, 448.0365, 448.0365,
            448.8210, 448.2454, 448.8203, 448.0140, 448.8197, 448.8196, 448.6390,
            448.8187, 448.8220, 448.8209, 448.8198, 448.8208, 448.8210, 448.8219,
            448.8198, 448.8212, 448.8200, 448.0135, 448.8200, 448.8199, 448.0154,
            448.0135, 448.8199, 448.0142, 448.8203, 448.8206, 448.8201, 448.8208,
            448.8205, 448.8273, 448.8217, 448.8212, 448.8208, 448.8212, 448.8200,
            448.8219, 448.0135, 448.8235, 448.8194, 448.0291, 448.2309, 448.8207,
            448.0251, 448.8199, 448.8304, 448.8242, 448.8192, 448.8230, 448.8198,
            448.8208, 448.8217, 448.8209, 448.8205, 448.8194, 448.8201, 448.8198,
            448.8197, 448.8214, 448.8212, 448.8216, 448.0135, 448.8199, 448.8195,
            448.8203, 448.7183, 448.8249, 448.8205, 448.0563, 448.8364, 448.2572,
            448.8215, 448.0135, 448.8227, 448.0379, 448.8198, 448.8222, 448.8201,
            448.0140, 448.8206, 448.8211, 448.8381, 448.8203, 448.4302, 448.8326,
            448.8206, 448.8193, 448.8206, 448.8198, 448.8208, 448.8200, 448.8219,
            448.8226, 448.4302, 448.0187, 448.8203, 448.0170, 448.8226, 448.8194,
            448.0135, 448.8347, 448.8209, 448.4297, 448.8206, 448.8189, 448.8221,
            448.8204, 448.8204, 448.8199, 448.8188, 448.0260, 448.8254, 448.8344,
            448.6146, 448.8206, 448.8219, 448.8207, 448.8195, 448.8209, 448.8209,
            448.0135, 448.0137, 448.0141, 448.8210, 448.8195, 448.8203, 448.0138,
            448.8199, 448.8210, 448.8192, 448.8212, 448.6914, 448.0142, 448.8204,
            448.8213, 448.2980, 448.8198, 448.8326, 448.0217, 448.0222, 448.8204,
            448.0139, 448.0135, 448.8211, 448.8194, 448.8204, 448.0135, 448.8196,
            448.8286, 448.8205, 448.8207, 448.6339, 448.8201, 448.8212, 448.8304,
            448.0135, 448.5087, 448.8222, 448.8218, 448.8211, 448.8200, 448.8231,
            448.8232, 448.8212, 448.8206, 448.0209, 448.8217, 448.0135, 448.8225,
            448.4675, 448.8221, 448.0140, 448.0239, 448.8193, 448.4343, 448.8201,
            448.0135, 448.8256, 448.8202, 448.8204, 448.8240, 448.0141, 448.0137,
            448.8196, 448.8232, 448.8203, 448.8231, 448.0135, 448.0186, 448.8224,
            448.8192, 448.0135, 448.8210, 448.0165, 448.4878, 448.8202, 448.0135,
            448.6898, 448.0392, 448.8203, 448.8204, 448.8214, 448.8270, 448.8208,
            448.8217, 448.0161, 448.0136, 448.6603, 448.8215, 448.8207, 448.8262,
            448.8280, 448.4243, 448.8214, 448.8205, 448.0211, 448.0139, 448.8206,
            448.8278, 448.8209, 448.4333, 448.4376, 448.8223, 448.8208, 448.8205,
            448.8212, 448.8204, 448.8203, 448.8190, 448.8196, 448.8198, 448.8230,
            448.4376, 448.0927, 448.0348, 448.8218, 448.8204, 448.0135, 448.8209,
            448.8513, 448.8200, 448.8214, 448.8301, 448.8204, 448.8209, 448.8208,
            448.8212, 448.8202, 448.0135, 448.8202, 448.8201, 448.8214, 448.8208,
            448.8209, 448.8224, 448.8188, 448.0140, 448.8192, 448.4353, 448.8202,
            448.8211, 448.0135, 448.8198, 448.8203, 448.8207, 448.8190, 448.4325,
            448.8198, 448.0351, 448.8204, 448.8212, 448.8190, 448.0386, 448.8236,
            448.0135, 448.0411, 448.0147, 448.0277, 448.0256, 448.8201, 448.8197,
            448.8199, 448.8212, 448.8192, 448.8210, 448.0139, 448.8215, 448.0165,
            448.0146, 448.8223, 448.8214, 448.8214, 448.8226, 448.8213, 448.8204,
            448.8292, 448.8201, 448.8203, 448.0135, 448.0135, 448.0509, 448.8234,
            448.8200, 448.8225, 448.8212, 448.0167, 448.0135, 448.4884, 448.0256,
            448.8214, 448.0148, 448.8192, 448.8195, 448.0137, 448.0257, 448.8229,
            448.8211, 448.8221, 448.8246, 448.8205, 448.8216, 448.8195, 448.8202,
            448.8212, 448.8232, 448.8207, 448.0135, 448.8209, 448.8209, 448.8200,
            448.4401, 448.8210, 448.8212, 448.0135, 448.8210, 448.8208, 448.8200,
            448.8230, 448.8203, 448.8209, 448.8196, 448.0148, 448.8189, 448.6066,
            448.0245, 448.8206, 448.8199, 448.8214, 448.4467, 448.8209, 448.8212,
            448.0140, 448.8211, 448.8225, 448.8328, 448.4370, 448.8193, 448.8235,
            448.8199, 448.8200, 448.8206, 448.8357, 448.8213, 448.8216, 448.8211,
            448.8203, 448.0160, 448.0212, 448.4316, 448.8193, 448.8206, 448.8199,
            448.0235, 448.4212, 448.8187, 448.0135, 448.0277, 448.8211, 448.0135,
            448.8206, 448.8201, 448.8210, 448.8209, 448.8201, 448.8226, 448.8210,
            448.8196, 448.8209, 448.8209, 448.0136, 448.8202, 448.8219, 448.8197,
            448.8369, 448.8211, 448.8199, 448.8215, 448.8204, 448.8199, 448.8209,
            448.8192, 448.0135, 448.8216, 448.8236, 448.0135, 448.0135, 448.8232,
            448.8202, 448.8210, 448.8208, 448.0141, 448.8207, 448.8198, 448.8209,
            448.8201, 448.8204, 448.7315, 448.8202, 448.8199, 448.0352, 448.8202,
            448.8196, 448.8206, 448.8211, 448.8270, 448.4319, 448.4347, 448.8210,
            448.8205, 448.8204, 448.8210, 448.8223, 448.8205, 448.8215, 448.0137,
            448.8196, 448.8230, 448.0192, 448.0135, 448.8201, 448.0261, 448.8206,
            448.8198, 448.8221, 448.8194, 448.8208, 448.8215, 448.1310, 448.8208,
            448.8196, 448.8202, 448.8212, 448.8236, 448.5941, 448.8221, 448.0135,
            448.0135, 448.0148, 448.8208, 448.8210, 448.4286, 448.8195, 448.8271,
            448.8206, 448.1026, 448.0140, 448.0225, 448.8197, 448.8198, 448.8250,
            448.8323, 448.8195, 448.8209, 448.0142, 448.8212, 448.8203, 448.8210,
            448.1627, 448.0135, 448.0135, 448.0542, 448.0135, 448.8197, 448.0167,
            448.8197, 448.2495, 448.8215, 448.8226, 448.8216, 448.6325, 448.0135,
            448.8208, 448.8226, 448.0170, 448.0185, 448.8196, 448.0135, 448.8209,
            448.8201, 448.0282, 448.8193, 448.8204, 448.8192, 448.8248, 448.8220,
            448.3248, 448.4304, 448.8204, 448.8358, 448.0147, 448.0152, 448.8195,
            448.0266, 448.0135, 448.8206, 448.8210, 448.8245, 448.8286, 448.8207,
            448.0135, 448.4439, 448.4310, 448.8202, 448.0300, 448.6392, 448.8212,
            448.0203, 448.8201, 448.0135, 448.8196, 448.8193, 448.4419, 448.8208,
            448.0150, 448.8203, 448.6430, 448.8198, 448.0314, 448.8197, 448.8202,
            448.8198, 448.7354, 448.8226, 448.0135, 448.8205, 448.7976, 448.0175,
            448.8218, 448.8204, 448.8201, 448.8201, 448.8203, 448.4626, 448.8204,
            448.8235, 448.0135, 448.8235, 448.0140, 448.8202, 448.0435, 448.8219,
            448.8209, 448.8214, 448.8193, 448.8211, 448.8200, 448.8197, 448.8206,
            448.8210, 448.0135, 448.0139, 448.8199, 448.8268, 448.8208, 448.5226,
            448.0135, 448.8215, 448.8226, 448.8199, 448.8201, 448.8189, 448.8212,
            448.8206, 448.8237, 448.8307, 448.8229, 448.8202, 448.0135, 448.4618,
            448.0137, 448.8194, 448.8194, 448.8275, 448.8217, 448.8196, 448.8222,
            448.8193, 448.8192, 448.8293, 448.0193, 448.8225, 448.8195, 448.0160,
            448.8238, 448.0142, 448.0295, 448.4425, 448.8202, 448.8201, 448.4296,
            448.8213, 448.8195, 448.8209, 448.6328, 448.8339, 448.0135, 448.8215,
            448.8209, 448.0186, 448.0162, 448.0137, 448.8189, 448.6302, 448.8201,
            448.8197, 448.8296, 448.8488, 448.0182, 448.0176, 448.8211, 448.4315,
            448.0173, 448.0141, 448.8203, 448.8236, 448.8194, 448.8195, 448.8204,
            448.8201, 448.0167, 448.8236, 448.0137, 448.8214, 448.8232, 448.8215,
            448.8196, 448.8203, 448.8205, 448.8158, 448.0155, 448.8197, 448.8204,
            448.8358, 448.0182, 448.4626, 448.0135, 448.0180, 448.8223, 448.8203,
            448.0135, 448.8332, 448.8199, 448.0135, 448.0165, 448.8210, 448.0507,
            448.0135, 448.8204, 448.8207, 448.8211, 448.6448, 448.8200, 448.8210,
            448.8187, 448.8201, 448.8198, 448.8260, 448.8239, 448.0135, 448.8210,
            448.8212, 448.7120, 448.8212, 448.8194, 448.8208, 448.8202, 448.8205,
            448.8232, 448.8195, 448.8190, 448.2937, 448.7475, 448.8212, 448.8246,
            448.8203, 448.0135, 448.8229, 448.8198, 448.8234, 448.8207, 448.8221,
            448.8219, 448.8206, 448.8207, 448.8203, 448.8207, 448.4302, 448.8196,
            448.8195, 448.8198, 448.8203, 448.8198, 448.8274, 448.4514, 448.8209,
            448.8197, 448.8195, 448.4946, 448.8208, 448.0135, 448.8194, 448.8333,
            448.0156, 448.8234, 448.0135, 448.8203, 448.8201, 448.8224, 448.8198,
            448.8235, 448.8202, 448.8204, 448.8201, 448.8205, 448.8210, 448.8201,
            448.0171, 448.4303, 448.6394, 448.0263, 448.0343, 448.8226, 448.8207,
            448.0190, 448.8235, 448.8211, 448.0147, 448.0137, 448.8194, 448.8188,
            448.8210, 448.8223, 448.8195, 448.4432, 448.8212, 448.0135, 448.0349,
            448.0284, 448.8196, 448.0136, 448.0180, 448.0135, 448.8226, 448.3099,
            448.8207, 448.0141, 448.8196, 448.8200, 448.8210, 448.8216, 448.8226,
            448.8207, 448.8205, 448.0135, 448.8311, 448.5883, 448.5465, 448.8297,
            448.6378, 448.8223], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4468, 448.8208, 448.8226, 448.0145, 448.4943, 448.0135, 448.8197,
        448.4818, 448.8361, 448.4550, 448.0135, 448.8212, 448.8221, 448.0248,
        448.8203, 448.8208, 448.0135, 448.0453, 448.6374, 448.1411, 448.0189,
        448.8219, 448.8209, 448.8218, 448.8190, 448.8206, 448.8267, 448.8213,
        448.8219, 448.8209, 448.8196, 448.8227, 448.0135, 448.8191, 448.4214,
        448.8203, 448.0165, 448.0163, 448.8235, 448.8195, 448.8340, 448.8217,
        448.8190, 448.0135, 448.8189, 448.8211, 448.0135, 448.8208, 448.8198,
        448.8194, 448.8206, 448.0139, 448.8106, 448.8192, 448.8206, 448.8232,
        448.8214, 448.8230, 448.6274, 448.0153, 448.0142, 448.8206, 448.8201,
        448.8207, 448.2325, 448.0147, 448.8192, 448.0135, 448.8187, 448.4286,
        448.8201, 448.8206, 448.4897, 448.8200, 448.6593, 448.8202, 448.0160,
        448.8196, 448.8221, 448.8205, 448.2377, 448.0319, 448.0135, 448.0204,
        448.8196, 448.0139, 448.8187, 448.8204, 448.0139, 448.8210, 448.0137,
        448.8212, 448.0177, 448.8189, 448.8209, 448.8206, 448.8205, 448.0305,
        448.8210, 448.0135, 448.0569, 448.8206, 448.8220, 448.0135, 448.0135,
        448.0135, 448.8201, 448.8271, 448.4677, 448.0135, 448.8216, 448.0146,
        448.0253, 448.8232, 448.8199, 448.4648, 448.8199, 448.8214, 448.8207,
        448.0370, 448.8211, 448.8204, 448.8211, 448.4938, 448.7692, 448.8200,
        448.8208, 448.0165, 448.8214, 448.8205, 448.8229, 448.0139, 448.8236,
        448.8210, 448.8199, 448.8209, 448.8217, 448.8192, 448.8209, 448.3146,
        448.8216, 448.0563, 448.8090, 448.8201, 448.0566, 448.0365, 448.0365,
        448.8210, 448.2454, 448.8203, 448.0140, 448.8197, 448.8196, 448.6390,
        448.8187, 448.8220, 448.8209, 448.8198, 448.8208, 448.8210, 448.8219,
        448.8198, 448.8212, 448.8200, 448.0135, 448.8200, 448.8199, 448.0154,
        448.0135, 448.8199, 448.0142, 448.8203, 448.8206, 448.8201, 448.8208,
        448.8205, 448.8273, 448.8217, 448.8212, 448.8208, 448.8212, 448.8200,
        448.8219, 448.0135, 448.8235, 448.8194, 448.0291, 448.2309, 448.8207,
        448.0251, 448.8199, 448.8304, 448.8242, 448.8192, 448.8230, 448.8198,
        448.8208, 448.8217, 448.8209, 448.8205, 448.8194, 448.8201, 448.8198,
        448.8197, 448.8214, 448.8212, 448.8216, 448.0135, 448.8199, 448.8195,
        448.8203, 448.7183, 448.8249, 448.8205, 448.0563, 448.8364, 448.2572,
        448.8215, 448.0135, 448.8227, 448.0379, 448.8198, 448.8222, 448.8201,
        448.0140, 448.8206, 448.8211, 448.8381, 448.8203, 448.4302, 448.8326,
        448.8206, 448.8193, 448.8206, 448.8198, 448.8208, 448.8200, 448.8219,
        448.8226, 448.4302, 448.0187, 448.8203, 448.0170, 448.8226, 448.8194,
        448.0135, 448.8347, 448.8209, 448.4297, 448.8206, 448.8189, 448.8221,
        448.8204, 448.8204, 448.8199, 448.8188, 448.0260, 448.8254, 448.8344,
        448.6146, 448.8206, 448.8219, 448.8207, 448.8195, 448.8209, 448.8209,
        448.0135, 448.0137, 448.0141, 448.8210, 448.8195, 448.8203, 448.0138,
        448.8199, 448.8210, 448.8192, 448.8212, 448.6914, 448.0142, 448.8204,
        448.8213, 448.2980, 448.8198, 448.8326, 448.0217, 448.0222, 448.8204,
        448.0139, 448.0135, 448.8211, 448.8194, 448.8204, 448.0135, 448.8196,
        448.8286, 448.8205, 448.8207, 448.6339, 448.8201, 448.8212, 448.8304,
        448.0135, 448.5087, 448.8222, 448.8218, 448.8211, 448.8200, 448.8231,
        448.8232, 448.8212, 448.8206, 448.0209, 448.8217, 448.0135, 448.8225,
        448.4675, 448.8221, 448.0140, 448.0239, 448.8193, 448.4343, 448.8201,
        448.0135, 448.8256, 448.8202, 448.8204, 448.8240, 448.0141, 448.0137,
        448.8196, 448.8232, 448.8203, 448.8231, 448.0135, 448.0186, 448.8224,
        448.8192, 448.0135, 448.8210, 448.0165, 448.4878, 448.8202, 448.0135,
        448.6898, 448.0392, 448.8203, 448.8204, 448.8214, 448.8270, 448.8208,
        448.8217, 448.0161, 448.0136, 448.6603, 448.8215, 448.8207, 448.8262,
        448.8280, 448.4243, 448.8214, 448.8205, 448.0211, 448.0139, 448.8206,
        448.8278, 448.8209, 448.4333, 448.4376, 448.8223, 448.8208, 448.8205,
        448.8212, 448.8204, 448.8203, 448.8190, 448.8196, 448.8198, 448.8230,
        448.4376, 448.0927, 448.0348, 448.8218, 448.8204, 448.0135, 448.8209,
        448.8513, 448.8200, 448.8214, 448.8301, 448.8204, 448.8209, 448.8208,
        448.8212, 448.8202, 448.0135, 448.8202, 448.8201, 448.8214, 448.8208,
        448.8209, 448.8224, 448.8188, 448.0140, 448.8192, 448.4353, 448.8202,
        448.8211, 448.0135, 448.8198, 448.8203, 448.8207, 448.8190, 448.4325,
        448.8198, 448.0351, 448.8204, 448.8212, 448.8190, 448.0386, 448.8236,
        448.0135, 448.0411, 448.0147, 448.0277, 448.0256, 448.8201, 448.8197,
        448.8199, 448.8212, 448.8192, 448.8210, 448.0139, 448.8215, 448.0165,
        448.0146, 448.8223, 448.8214, 448.8214, 448.8226, 448.8213, 448.8204,
        448.8292, 448.8201, 448.8203, 448.0135, 448.0135, 448.0509, 448.8234,
        448.8200, 448.8225, 448.8212, 448.0167, 448.0135, 448.4884, 448.0256,
        448.8214, 448.0148, 448.8192, 448.8195, 448.0137, 448.0257, 448.8229,
        448.8211, 448.8221, 448.8246, 448.8205, 448.8216, 448.8195, 448.8202,
        448.8212, 448.8232, 448.8207, 448.0135, 448.8209, 448.8209, 448.8200,
        448.4401, 448.8210, 448.8212, 448.0135, 448.8210, 448.8208, 448.8200,
        448.8230, 448.8203, 448.8209, 448.8196, 448.0148, 448.8189, 448.6066,
        448.0245, 448.8206, 448.8199, 448.8214, 448.4467, 448.8209, 448.8212,
        448.0140, 448.8211, 448.8225, 448.8328, 448.4370, 448.8193, 448.8235,
        448.8199, 448.8200, 448.8206, 448.8357, 448.8213, 448.8216, 448.8211,
        448.8203, 448.0160, 448.0212, 448.4316, 448.8193, 448.8206, 448.8199,
        448.0235, 448.4212, 448.8187, 448.0135, 448.0277, 448.8211, 448.0135,
        448.8206, 448.8201, 448.8210, 448.8209, 448.8201, 448.8226, 448.8210,
        448.8196, 448.8209, 448.8209, 448.0136, 448.8202, 448.8219, 448.8197,
        448.8369, 448.8211, 448.8199, 448.8215, 448.8204, 448.8199, 448.8209,
        448.8192, 448.0135, 448.8216, 448.8236, 448.0135, 448.0135, 448.8232,
        448.8202, 448.8210, 448.8208, 448.0141, 448.8207, 448.8198, 448.8209,
        448.8201, 448.8204, 448.7315, 448.8202, 448.8199, 448.0352, 448.8202,
        448.8196, 448.8206, 448.8211, 448.8270, 448.4319, 448.4347, 448.8210,
        448.8205, 448.8204, 448.8210, 448.8223, 448.8205, 448.8215, 448.0137,
        448.8196, 448.8230, 448.0192, 448.0135, 448.8201, 448.0261, 448.8206,
        448.8198, 448.8221, 448.8194, 448.8208, 448.8215, 448.1310, 448.8208,
        448.8196, 448.8202, 448.8212, 448.8236, 448.5941, 448.8221, 448.0135,
        448.0135, 448.0148, 448.8208, 448.8210, 448.4286, 448.8195, 448.8271,
        448.8206, 448.1026, 448.0140, 448.0225, 448.8197, 448.8198, 448.8250,
        448.8323, 448.8195, 448.8209, 448.0142, 448.8212, 448.8203, 448.8210,
        448.1627, 448.0135, 448.0135, 448.0542, 448.0135, 448.8197, 448.0167,
        448.8197, 448.2495, 448.8215, 448.8226, 448.8216, 448.6325, 448.0135,
        448.8208, 448.8226, 448.0170, 448.0185, 448.8196, 448.0135, 448.8209,
        448.8201, 448.0282, 448.8193, 448.8204, 448.8192, 448.8248, 448.8220,
        448.3248, 448.4304, 448.8204, 448.8358, 448.0147, 448.0152, 448.8195,
        448.0266, 448.0135, 448.8206, 448.8210, 448.8245, 448.8286, 448.8207,
        448.0135, 448.4439, 448.4310, 448.8202, 448.0300, 448.6392, 448.8212,
        448.0203, 448.8201, 448.0135, 448.8196, 448.8193, 448.4419, 448.8208,
        448.0150, 448.8203, 448.6430, 448.8198, 448.0314, 448.8197, 448.8202,
        448.8198, 448.7354, 448.8226, 448.0135, 448.8205, 448.7976, 448.0175,
        448.8218, 448.8204, 448.8201, 448.8201, 448.8203, 448.4626, 448.8204,
        448.8235, 448.0135, 448.8235, 448.0140, 448.8202, 448.0435, 448.8219,
        448.8209, 448.8214, 448.8193, 448.8211, 448.8200, 448.8197, 448.8206,
        448.8210, 448.0135, 448.0139, 448.8199, 448.8268, 448.8208, 448.5226,
        448.0135, 448.8215, 448.8226, 448.8199, 448.8201, 448.8189, 448.8212,
        448.8206, 448.8237, 448.8307, 448.8229, 448.8202, 448.0135, 448.4618,
        448.0137, 448.8194, 448.8194, 448.8275, 448.8217, 448.8196, 448.8222,
        448.8193, 448.8192, 448.8293, 448.0193, 448.8225, 448.8195, 448.0160,
        448.8238, 448.0142, 448.0295, 448.4425, 448.8202, 448.8201, 448.4296,
        448.8213, 448.8195, 448.8209, 448.6328, 448.8339, 448.0135, 448.8215,
        448.8209, 448.0186, 448.0162, 448.0137, 448.8189, 448.6302, 448.8201,
        448.8197, 448.8296, 448.8488, 448.0182, 448.0176, 448.8211, 448.4315,
        448.0173, 448.0141, 448.8203, 448.8236, 448.8194, 448.8195, 448.8204,
        448.8201, 448.0167, 448.8236, 448.0137, 448.8214, 448.8232, 448.8215,
        448.8196, 448.8203, 448.8205, 448.8158, 448.0155, 448.8197, 448.8204,
        448.8358, 448.0182, 448.4626, 448.0135, 448.0180, 448.8223, 448.8203,
        448.0135, 448.8332, 448.8199, 448.0135, 448.0165, 448.8210, 448.0507,
        448.0135, 448.8204, 448.8207, 448.8211, 448.6448, 448.8200, 448.8210,
        448.8187, 448.8201, 448.8198, 448.8260, 448.8239, 448.0135, 448.8210,
        448.8212, 448.7120, 448.8212, 448.8194, 448.8208, 448.8202, 448.8205,
        448.8232, 448.8195, 448.8190, 448.2937, 448.7475, 448.8212, 448.8246,
        448.8203, 448.0135, 448.8229, 448.8198, 448.8234, 448.8207, 448.8221,
        448.8219, 448.8206, 448.8207, 448.8203, 448.8207, 448.4302, 448.8196,
        448.8195, 448.8198, 448.8203, 448.8198, 448.8274, 448.4514, 448.8209,
        448.8197, 448.8195, 448.4946, 448.8208, 448.0135, 448.8194, 448.8333,
        448.0156, 448.8234, 448.0135, 448.8203, 448.8201, 448.8224, 448.8198,
        448.8235, 448.8202, 448.8204, 448.8201, 448.8205, 448.8210, 448.8201,
        448.0171, 448.4303, 448.6394, 448.0263, 448.0343, 448.8226, 448.8207,
        448.0190, 448.8235, 448.8211, 448.0147, 448.0137, 448.8194, 448.8188,
        448.8210, 448.8223, 448.8195, 448.4432, 448.8212, 448.0135, 448.0349,
        448.0284, 448.8196, 448.0136, 448.0180, 448.0135, 448.8226, 448.3099,
        448.8207, 448.0141, 448.8196, 448.8200, 448.8210, 448.8216, 448.8226,
        448.8207, 448.8205, 448.0135, 448.8311, 448.5883, 448.5465, 448.8297,
        448.6378, 448.8223], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([405.0943], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0034],
             [112.0034],
             [112.0035],
             [112.0035]],

            [[112.2049],
             [112.2049],
             [112.2070],
             [112.2070]],

            [[112.0034],
             [112.0034],
             [112.0034],
             [112.0034]],

            ...,

            [[112.2048],
             [112.2047],
             [112.2049],
             [112.2051]],

            [[112.2049],
             [112.2048],
             [112.2047],
             [112.2052]],

            [[112.2052],
             [112.2052],
             [112.2063],
             [112.2063]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0139, 448.8237, 448.0135,  ..., 448.8195, 448.8196, 448.8231],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0139, 448.8237, 448.0135,  ..., 448.8195, 448.8196, 448.8231],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0080],
             [112.0080],
             [112.0080],
             [112.0080]],

            [[112.0277],
             [112.0277],
             [112.2022],
             [112.2022]],

            [[112.2013],
             [112.2013],
             [112.2013],
             [112.2024]],

            ...,

            [[112.0117],
             [112.0117],
             [112.0122],
             [112.0122]],

            [[112.0213],
             [112.0192],
             [112.2018],
             [112.2018]],

            [[112.2013],
             [112.2037],
             [112.2012],
             [112.2012]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0320, 448.4598, 448.8064,  ..., 448.0477, 448.4441, 448.8074],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0320, 448.4598, 448.8064,  ..., 448.0477, 448.4441, 448.8074],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2014],
             [112.2007],
             [112.2008],
             [112.2008]],

            [[112.2054],
             [112.2054],
             [112.2010],
             [112.2010]],

            [[112.2007],
             [112.2013],
             [112.2011],
             [112.2012]],

            ...,

            [[112.2008],
             [112.2028],
             [112.2007],
             [112.2007]],

            [[112.2010],
             [112.2010],
             [112.2008],
             [112.2017]],

            [[112.2007],
             [112.2008],
             [112.2021],
             [112.2008]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8036, 448.8127, 448.8044,  ..., 448.8051, 448.8046, 448.8044],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8036, 448.8127, 448.8044,  ..., 448.8051, 448.8046, 448.8044],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2031],
             [112.2031],
             [112.2032],
             [112.2032]],

            [[112.2029],
             [112.2029],
             [112.2034],
             [112.2034]],

            [[112.2031],
             [112.2036],
             [112.2036],
             [112.2034]],

            ...,

            [[112.0046],
             [112.0060],
             [112.0060],
             [112.0045]],

            [[112.2028],
             [112.2029],
             [112.2029],
             [112.2052]],

            [[112.2029],
             [112.2030],
             [112.2031],
             [112.2037]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8127, 448.8126, 448.8137,  ..., 448.0211, 448.8138, 448.8126],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8127, 448.8126, 448.8137,  ..., 448.0211, 448.8138, 448.8126],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2031],
             [112.2031],
             [112.2047],
             [112.2047]],

            [[112.0036],
             [112.0036],
             [112.0036],
             [112.0036]],

            [[112.0124],
             [112.2054],
             [112.0150],
             [112.2039]],

            ...,

            [[112.2032],
             [112.2032],
             [112.2030],
             [112.2030]],

            [[112.2034],
             [112.2034],
             [112.2029],
             [112.2029]],

            [[112.2032],
             [112.2031],
             [112.2041],
             [112.2030]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8157, 448.0142, 448.4367,  ..., 448.8125, 448.8126, 448.8134],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8157, 448.0142, 448.4367,  ..., 448.8125, 448.8126, 448.8134],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2002],
             [112.2053],
             [112.2002],
             [112.2002]],

            [[112.2007],
             [112.2001],
             [112.2002],
             [112.2015]],

            [[112.0049],
             [112.0049],
             [112.0049],
             [112.0049]],

            ...,

            [[112.0243],
             [112.0243],
             [112.2011],
             [112.2011]],

            [[112.0049],
             [112.0049],
             [112.0048],
             [112.0049]],

            [[112.0050],
             [112.0059],
             [112.0050],
             [112.0050]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8060, 448.8025, 448.0195,  ..., 448.4507, 448.0194, 448.0209],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8060, 448.8025, 448.0195,  ..., 448.4507, 448.0194, 448.0209],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1992],
             [112.1951],
             [112.1989],
             [112.1951]],

            [[112.1949],
             [112.1951],
             [112.1960],
             [112.1950]],

            [[112.1956],
             [112.1956],
             [112.1964],
             [112.1964]],

            ...,

            [[112.1949],
             [112.1949],
             [112.1949],
             [112.1970]],

            [[112.1950],
             [112.1950],
             [112.1952],
             [112.1962]],

            [[112.1961],
             [112.1961],
             [112.1959],
             [112.1959]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7884, 448.7810, 448.7840,  ..., 448.7817, 448.7814, 448.7840],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7884, 448.7810, 448.7840,  ..., 448.7817, 448.7814, 448.7840],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1871],
             [112.1872],
             [112.1882],
             [112.1872]],

            [[112.1874],
             [112.1871],
             [112.1874],
             [112.1871]],

            [[112.1871],
             [112.1873],
             [112.1871],
             [112.1883]],

            ...,

            [[112.0222],
             [112.1906],
             [112.0226],
             [112.1878]],

            [[112.1871],
             [112.1871],
             [112.1871],
             [112.1871]],

            [[112.1872],
             [112.1872],
             [112.1879],
             [112.1879]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7498, 448.7491, 448.7498,  ..., 448.4232, 448.7483, 448.7501],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7498, 448.7491, 448.7498,  ..., 448.4232, 448.7483, 448.7501],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0168],
             [112.0156],
             [112.0172],
             [112.0155]],

            [[112.0165],
             [112.0187],
             [112.0155],
             [112.0155]],

            [[112.0154],
             [112.0156],
             [112.0155],
             [112.0155]],

            ...,

            [[112.1842],
             [112.1886],
             [112.1853],
             [112.1841]],

            [[112.0155],
             [112.0155],
             [112.0155],
             [112.0155]],

            [[112.1850],
             [112.1845],
             [112.1841],
             [112.1843]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0650, 448.0663, 448.0620,  ..., 448.7422, 448.0619, 448.7379],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0650, 448.0663, 448.0620,  ..., 448.7422, 448.0619, 448.7379],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0197],
             [112.0197],
             [112.0197],
             [112.0197]],

            [[112.1801],
             [112.1801],
             [112.1818],
             [112.1818]],

            [[112.1801],
             [112.1800],
             [112.1801],
             [112.1814]],

            ...,

            [[112.0198],
             [112.0197],
             [112.0199],
             [112.0197]],

            [[112.1805],
             [112.1805],
             [112.1800],
             [112.1800]],

            [[112.0314],
             [112.1811],
             [112.0414],
             [112.1805]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0787, 448.7238, 448.7215,  ..., 448.0790, 448.7210, 448.4343],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0787, 448.7238, 448.7215,  ..., 448.0790, 448.7210, 448.4343],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1749],
             [112.1749],
             [112.1755],
             [112.1755]],

            [[112.1759],
             [112.1757],
             [112.1746],
             [112.1745]],

            [[112.1719],
             [112.1746],
             [112.1747],
             [112.1747]],

            ...,

            [[112.1746],
             [112.1752],
             [112.1745],
             [112.1745]],

            [[112.0295],
             [112.1764],
             [112.0294],
             [112.1764]],

            [[112.1771],
             [112.0332],
             [112.0320],
             [112.1782]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7007, 448.7007, 448.6959,  ..., 448.6988, 448.4117, 448.4205],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7007, 448.7007, 448.6959,  ..., 448.6988, 448.4117, 448.4205],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1778],
             [112.1746],
             [112.0393],
             [112.1746]],

            [[112.0303],
             [112.0318],
             [112.0303],
             [112.0318]],

            [[112.1749],
             [112.1749],
             [112.1754],
             [112.1754]],

            ...,

            [[112.1748],
             [112.1748],
             [112.1767],
             [112.1767]],

            [[112.1749],
             [112.1746],
             [112.1746],
             [112.1762]],

            [[112.0305],
             [112.1262],
             [112.0325],
             [112.0325]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5663, 448.1241, 448.7006,  ..., 448.7030, 448.7002, 448.2217],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5663, 448.1241, 448.7006,  ..., 448.7030, 448.7002, 448.2217],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0320],
             [112.0348],
             [112.0339],
             [112.0339]],

            [[112.0319],
             [112.0318],
             [112.0318],
             [112.0319]],

            [[112.1804],
             [112.1756],
             [112.1772],
             [112.1772]],

            ...,

            [[112.0318],
             [112.0320],
             [112.0319],
             [112.0319]],

            [[112.0343],
             [112.1772],
             [112.0343],
             [112.1772]],

            [[112.1762],
             [112.1762],
             [112.1769],
             [112.1769]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1345, 448.1274, 448.7104,  ..., 448.1275, 448.4229, 448.7061],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1345, 448.1274, 448.7104,  ..., 448.1275, 448.4229, 448.7061],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1745],
             [112.1745],
             [112.1745],
             [112.1745]],

            [[112.1776],
             [112.1729],
             [112.1429],
             [112.1730]],

            [[112.0515],
             [112.1730],
             [112.1737],
             [112.1737]],

            ...,

            [[112.1772],
             [112.0415],
             [112.0417],
             [112.1773]],

            [[112.1731],
             [112.1753],
             [112.1730],
             [112.1732]],

            [[112.1770],
             [112.1770],
             [112.1730],
             [112.1730]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6980, 448.6663, 448.5718,  ..., 448.4377, 448.6945, 448.7001],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6980, 448.6663, 448.5718,  ..., 448.4377, 448.6945, 448.7001],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1674],
             [112.1672],
             [112.1672],
             [112.1695]],

            [[112.0534],
             [112.0534],
             [112.0536],
             [112.0536]],

            [[112.1674],
             [112.1674],
             [112.1680],
             [112.1680]],

            ...,

            [[112.1673],
             [112.1622],
             [112.1671],
             [112.1671]],

            [[112.0513],
             [112.0513],
             [112.0513],
             [112.0513]],

            [[112.1689],
             [112.1671],
             [112.1673],
             [112.1673]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6713, 448.2140, 448.6709,  ..., 448.6638, 448.2051, 448.6707],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6713, 448.2140, 448.6709,  ..., 448.6638, 448.2051, 448.6707],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1630],
             [112.1623],
             [112.1634],
             [112.1634]],

            [[112.1630],
             [112.1633],
             [112.1623],
             [112.1623]],

            [[112.1626],
             [112.1626],
             [112.1639],
             [112.1639]],

            ...,

            [[112.0605],
             [112.0605],
             [112.0605],
             [112.0605]],

            [[112.1623],
             [112.1640],
             [112.1623],
             [112.1625]],

            [[112.1628],
             [112.1649],
             [112.1629],
             [112.1629]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6522, 448.6510, 448.6530,  ..., 448.2418, 448.6511, 448.6534],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6522, 448.6510, 448.6530,  ..., 448.2418, 448.6511, 448.6534],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1567],
             [112.1550],
             [112.1564],
             [112.1550]],

            [[112.1549],
             [112.1556],
             [112.1550],
             [112.1564]],

            [[112.1548],
             [112.1563],
             [112.1550],
             [112.1557]],

            ...,

            [[112.0709],
             [112.0709],
             [112.0709],
             [112.0709]],

            [[112.1568],
             [112.1553],
             [112.1573],
             [112.1573]],

            [[112.1559],
             [112.1548],
             [112.1550],
             [112.1565]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6230, 448.6218, 448.6218,  ..., 448.2837, 448.6267, 448.6223],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6230, 448.6218, 448.6218,  ..., 448.2837, 448.6267, 448.6223],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1458],
             [112.1473],
             [112.1460],
             [112.1480]],

            [[112.1462],
             [112.1461],
             [112.1462],
             [112.1462]],

            [[112.1489],
             [112.1459],
             [112.1460],
             [112.1460]],

            ...,

            [[112.1461],
             [112.0864],
             [112.1460],
             [112.1120]],

            [[112.1478],
             [112.1475],
             [112.1470],
             [112.1470]],

            [[112.1473],
             [112.1473],
             [112.1485],
             [112.1485]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5870, 448.5846, 448.5867,  ..., 448.4905, 448.5893, 448.5916],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5870, 448.5846, 448.5867,  ..., 448.4905, 448.5893, 448.5916],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0127e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1344],
             [112.1344],
             [112.1342],
             [112.1342]],

            [[112.1342],
             [112.1358],
             [112.1340],
             [112.1360]],

            [[112.1360],
             [112.1360],
             [112.1340],
             [112.1352]],

            ...,

            [[112.1343],
             [112.1371],
             [112.1342],
             [112.1342]],

            [[112.1341],
             [112.1340],
             [112.1351],
             [112.1351]],

            [[112.1341],
             [112.1341],
             [112.1341],
             [112.1341]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5373, 448.5401, 448.5413,  ..., 448.5398, 448.5384, 448.5364],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5373, 448.5401, 448.5413,  ..., 448.5398, 448.5384, 448.5364],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1350],
             [112.1364],
             [112.1358],
             [112.1360]],

            [[112.1341],
             [112.1341],
             [112.1342],
             [112.1342]],

            [[112.1360],
             [112.1360],
             [112.1370],
             [112.1370]],

            ...,

            [[112.1348],
             [112.1350],
             [112.1368],
             [112.1346]],

            [[112.1359],
             [112.1341],
             [112.1358],
             [112.1340]],

            [[112.1355],
             [112.1355],
             [112.1369],
             [112.1369]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5433, 448.5366, 448.5459,  ..., 448.5411, 448.5398, 448.5449],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5433, 448.5366, 448.5459,  ..., 448.5411, 448.5398, 448.5449],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1355],
             [112.1341],
             [112.1355],
             [112.1341]],

            [[112.1344],
             [112.1365],
             [112.1350],
             [112.1350]],

            [[112.0954],
             [112.0955],
             [112.0954],
             [112.0954]],

            ...,

            [[112.1349],
             [112.1353],
             [112.1370],
             [112.1370]],

            [[112.1339],
             [112.1358],
             [112.1341],
             [112.1362]],

            [[112.0955],
             [112.0954],
             [112.0954],
             [112.0955]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5392, 448.5410, 448.3818, 448.5396, 448.5407, 448.5387, 448.5387,
            448.5397, 448.3817, 448.5452, 448.5386, 448.3817, 448.5430, 448.5230,
            448.3818, 448.5407, 448.3823, 448.5417, 448.3829, 448.5375, 448.4239,
            448.5406, 448.3833, 448.5390, 448.4874, 448.5380, 448.3847, 448.4663,
            448.5374, 448.5379, 448.5366, 448.3817, 448.5377, 448.5383, 448.4717,
            448.5395, 448.5403, 448.5382, 448.5417, 448.3817, 448.5391, 448.5397,
            448.5363, 448.4644, 448.5420, 448.5369, 448.3818, 448.5402, 448.5399,
            448.5443, 448.5406, 448.3859, 448.5381, 448.5011, 448.3818, 448.3817,
            448.5412, 448.5433, 448.5396, 448.5381, 448.5396, 448.5378, 448.3818,
            448.5381, 448.5361, 448.3817, 448.5397, 448.3857, 448.3817, 448.3821,
            448.5447, 448.3900, 448.5411, 448.5433, 448.3818, 448.5388, 448.5425,
            448.5447, 448.5385, 448.5409, 448.5417, 448.3829, 448.5427, 448.5394,
            448.3842, 448.5386, 448.3830, 448.5434, 448.5380, 448.5393, 448.5424,
            448.5386, 448.5378, 448.5412, 448.5411, 448.5417, 448.5399, 448.5363,
            448.3818, 448.5442, 448.3817, 448.4635, 448.5416, 448.5389, 448.3817,
            448.5029, 448.5024, 448.5434, 448.5405, 448.5420, 448.5412, 448.5397,
            448.5377, 448.5395, 448.5422, 448.3817, 448.5399, 448.5388, 448.5402,
            448.4266, 448.3817, 448.5408, 448.5389, 448.5377, 448.3817, 448.5397,
            448.5430, 448.5403, 448.5380, 448.5380, 448.5405, 448.5407, 448.4616,
            448.5382, 448.5402, 448.5380, 448.3820, 448.3818, 448.4635, 448.3864,
            448.3827, 448.3817, 448.5417, 448.3819, 448.3818, 448.5424, 448.5386,
            448.5416, 448.5377, 448.4631, 448.5391, 448.5384, 448.5404, 448.5431,
            448.5416, 448.5383, 448.5409, 448.5375, 448.5397, 448.5370, 448.5400,
            448.5398, 448.5379, 448.5431, 448.3842, 448.5391, 448.3870, 448.3828,
            448.5103, 448.5450, 448.3819, 448.5399, 448.5376, 448.5393, 448.3840,
            448.5396, 448.3818, 448.5392, 448.5393, 448.3818, 448.5278, 448.5396,
            448.5410, 448.5395, 448.5365, 448.5445, 448.3821, 448.5375, 448.3817,
            448.5401, 448.5388, 448.5373, 448.5408, 448.5460, 448.4627, 448.5385,
            448.4639, 448.5369, 448.5429, 448.3830, 448.5444, 448.5452, 448.3850,
            448.5445, 448.5435, 448.5392, 448.4646, 448.5369, 448.5388, 448.5398,
            448.5147, 448.4663, 448.3818, 448.5430, 448.5391, 448.5408, 448.5389,
            448.3847, 448.5432, 448.5372, 448.5389, 448.3837, 448.5007, 448.5408,
            448.3817, 448.5389, 448.5367, 448.5418, 448.4955, 448.3867, 448.3911,
            448.5424, 448.5372, 448.5434, 448.5387, 448.4635, 448.4700, 448.3818,
            448.3818, 448.5400, 448.5394, 448.5384, 448.5366, 448.4627, 448.5381,
            448.5391, 448.5403, 448.3817, 448.5368, 448.5414, 448.5429, 448.3834,
            448.5436, 448.5405, 448.4633, 448.5380, 448.5402, 448.5425, 448.5408,
            448.5407, 448.5375, 448.5438, 448.4719, 448.3848, 448.5381, 448.5379,
            448.5371, 448.5426, 448.5362, 448.3932, 448.5388, 448.5419, 448.5436,
            448.5119, 448.3822, 448.5434, 448.5374, 448.4643, 448.5450, 448.5384,
            448.5369, 448.5393, 448.5362, 448.5388, 448.3817, 448.4771, 448.5405,
            448.5371, 448.5374, 448.5400, 448.3818, 448.5108, 448.3838, 448.3818,
            448.5415, 448.5003, 448.5391, 448.3895, 448.5408, 448.5399, 448.5406,
            448.3830, 448.5404, 448.5406, 448.5016, 448.3828, 448.5376, 448.3818,
            448.5411, 448.4781, 448.3818, 448.5399, 448.4642, 448.5398, 448.5419,
            448.5438, 448.3860, 448.5387, 448.4631, 448.3818, 448.3831, 448.5399,
            448.5361, 448.5013, 448.3940, 448.5443, 448.5397, 448.5408, 448.3830,
            448.3817, 448.3818, 448.5403, 448.5395, 448.5403, 448.3820, 448.5437,
            448.5374, 448.5430, 448.5370, 448.5390, 448.5437, 448.5383, 448.5380,
            448.3828, 448.4694, 448.3878, 448.5421, 448.3817, 448.3818, 448.3818,
            448.3828, 448.5391, 448.5407, 448.5002, 448.3847, 448.5414, 448.5365,
            448.3973, 448.5443, 448.3817, 448.5370, 448.5399, 448.5372, 448.5384,
            448.4628, 448.5378, 448.5375, 448.5396, 448.3818, 448.5374, 448.3818,
            448.4649, 448.3817, 448.5420, 448.3828, 448.5417, 448.3833, 448.3900,
            448.5414, 448.5440, 448.4629, 448.5339, 448.5397, 448.5392, 448.5388,
            448.5400, 448.5409, 448.3818, 448.5384, 448.5396, 448.5446, 448.5392,
            448.3817, 448.5393, 448.3916, 448.5389, 448.5452, 448.5429, 448.3817,
            448.5411, 448.5380, 448.5411, 448.5383, 448.5444, 448.5360, 448.5394,
            448.5380, 448.5387, 448.5397, 448.5439, 448.5407, 448.5418, 448.5443,
            448.5414, 448.5397, 448.5403, 448.5371, 448.4631, 448.3830, 448.5393,
            448.5411, 448.5396, 448.5394, 448.5379, 448.5374, 448.3827, 448.5373,
            448.5381, 448.3817, 448.5390, 448.5395, 448.3825, 448.5389, 448.3824,
            448.3817, 448.5430, 448.3820, 448.5416, 448.5008, 448.5383, 448.5377,
            448.5419, 448.3817, 448.5411, 448.5394, 448.5444, 448.5180, 448.3818,
            448.4632, 448.5410, 448.5442, 448.5003, 448.5403, 448.5438, 448.5401,
            448.5390, 448.3817, 448.3857, 448.3817, 448.4627, 448.3822, 448.5387,
            448.5400, 448.3818, 448.5402, 448.5397, 448.5408, 448.5425, 448.3831,
            448.5393, 448.5450, 448.5400, 448.5400, 448.5371, 448.5389, 448.3817,
            448.5369, 448.5424, 448.5399, 448.5406, 448.5403, 448.5389, 448.5381,
            448.5403, 448.3823, 448.5388, 448.5399, 448.5395, 448.5409, 448.5378,
            448.5381, 448.5392, 448.5387, 448.5414, 448.5394, 448.5394, 448.5447,
            448.5396, 448.3939, 448.5007, 448.5364, 448.4648, 448.5406, 448.4629,
            448.5383, 448.5394, 448.5394, 448.3818, 448.3832, 448.5040, 448.3821,
            448.5383, 448.3818, 448.5387, 448.3817, 448.5405, 448.3829, 448.5438,
            448.3840, 448.5387, 448.5255, 448.5380, 448.5393, 448.4635, 448.5405,
            448.3875, 448.5437, 448.4633, 448.5392, 448.5019, 448.5401, 448.3818,
            448.3833, 448.5405, 448.5388, 448.5403, 448.3857, 448.5383, 448.5406,
            448.5390, 448.5399, 448.5438, 448.5400, 448.5426, 448.5396, 448.5417,
            448.5399, 448.4258, 448.5421, 448.4632, 448.5375, 448.3817, 448.5384,
            448.5365, 448.5386, 448.3817, 448.3817, 448.3818, 448.5403, 448.3890,
            448.5392, 448.4592, 448.5394, 448.5364, 448.5416, 448.5403, 448.5417,
            448.3817, 448.4684, 448.3840, 448.5388, 448.5454, 448.5442, 448.3818,
            448.5388, 448.5433, 448.5411, 448.5366, 448.5377, 448.5364, 448.5410,
            448.5389, 448.5363, 448.5376, 448.5407, 448.5399, 448.5432, 448.4053,
            448.3828, 448.5394, 448.5451, 448.3823, 448.3820, 448.5379, 448.3832,
            448.3817, 448.5392, 448.3854, 448.3819, 448.5378, 448.4647, 448.5397,
            448.5385, 448.5449, 448.5372, 448.5398, 448.5421, 448.3821, 448.4636,
            448.5364, 448.5384, 448.5401, 448.4601, 448.5386, 448.5384, 448.4252,
            448.5399, 448.5390, 448.3899, 448.5390, 448.5435, 448.3825, 448.5370,
            448.3819, 448.3839, 448.5432, 448.5369, 448.3838, 448.5411, 448.3911,
            448.4649, 448.5370, 448.5373, 448.5399, 448.4611, 448.5410, 448.3822,
            448.3817, 448.3821, 448.5388, 448.5392, 448.5423, 448.3818, 448.5398,
            448.5378, 448.3820, 448.4651, 448.3818, 448.5414, 448.3817, 448.5437,
            448.5423, 448.5408, 448.5410, 448.5431, 448.3824, 448.5373, 448.5368,
            448.5399, 448.5388, 448.5400, 448.3867, 448.4646, 448.5370, 448.5416,
            448.5414, 448.3824, 448.3834, 448.4643, 448.5424, 448.5398, 448.5381,
            448.5397, 448.5387, 448.4651, 448.5402, 448.5385, 448.5397, 448.5436,
            448.5383, 448.5391, 448.5402, 448.5374, 448.5406, 448.3832, 448.3830,
            448.5399, 448.5434, 448.5386, 448.5290, 448.5373, 448.3822, 448.5431,
            448.3845, 448.5388, 448.5439, 448.5405, 448.3817, 448.5406, 448.5422,
            448.3820, 448.5399, 448.5371, 448.4632, 448.3818, 448.3818, 448.5394,
            448.5436, 448.5403, 448.5427, 448.3818, 448.5406, 448.5427, 448.5372,
            448.5407, 448.3817, 448.5453, 448.5369, 448.5417, 448.4633, 448.3828,
            448.5362, 448.3818, 448.5399, 448.5367, 448.5389, 448.5393, 448.3844,
            448.3821, 448.5365, 448.3817, 448.5403, 448.5383, 448.5411, 448.5423,
            448.5433, 448.5399, 448.3828, 448.5404, 448.5424, 448.5410, 448.5386,
            448.3817, 448.3817, 448.5404, 448.5367, 448.5418, 448.5374, 448.3826,
            448.5422, 448.3817, 448.5434, 448.5435, 448.5438, 448.5408, 448.3875,
            448.5369, 448.5447, 448.3820, 448.5400, 448.5370, 448.5402, 448.3900,
            448.3839, 448.5389, 448.5107, 448.5399, 448.3820, 448.5388, 448.4643,
            448.5390, 448.3888, 448.3817, 448.5433, 448.5378, 448.3833, 448.5364,
            448.5390, 448.5378, 448.5405, 448.5397, 448.5376, 448.5418, 448.5373,
            448.5372, 448.5428, 448.5404, 448.3819, 448.5372, 448.3820, 448.4632,
            448.5392, 448.5383, 448.3818, 448.5399, 448.3819, 448.3833, 448.5384,
            448.5387, 448.3817, 448.5400, 448.5374, 448.3821, 448.5388, 448.4627,
            448.5414, 448.5413, 448.5399, 448.5397, 448.5385, 448.5393, 448.4632,
            448.5417, 448.5393, 448.5433, 448.5410, 448.5375, 448.5394, 448.3817,
            448.5002, 448.3817, 448.5404, 448.5394, 448.5417, 448.5391, 448.5390,
            448.5389, 448.3818, 448.3820, 448.5396, 448.5398, 448.5388, 448.3818,
            448.5374, 448.5447, 448.5403, 448.5399, 448.5433, 448.5374, 448.5418,
            448.5397, 448.3817, 448.5406, 448.5376, 448.5377, 448.5396, 448.5411,
            448.5428, 448.3819, 448.5391, 448.5388, 448.4627, 448.5405, 448.3942,
            448.3823, 448.5373, 448.5434, 448.5433, 448.5426, 448.5393, 448.3822,
            448.5415, 448.5375, 448.5401, 448.5412, 448.5382, 448.5381, 448.5441,
            448.5389, 448.5387, 448.5395, 448.3818, 448.3818, 448.5423, 448.5371,
            448.4836, 448.3828, 448.5425, 448.5363, 448.5383, 448.5433, 448.5375,
            448.5401, 448.5410, 448.5392, 448.5402, 448.5399, 448.5391, 448.4631,
            448.5402, 448.5426, 448.5449, 448.5400, 448.5374, 448.5377, 448.5432,
            448.5437, 448.5401, 448.5399, 448.3828, 448.3845, 448.5404, 448.3818,
            448.4717, 448.3817, 448.3870, 448.5390, 448.5444, 448.3820, 448.5372,
            448.3819, 448.3818, 448.5387, 448.3820, 448.4749, 448.5417, 448.5412,
            448.5437, 448.5394, 448.5395, 448.5428, 448.3818, 448.5398, 448.5443,
            448.5400, 448.3818], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5392, 448.5410, 448.3818, 448.5396, 448.5407, 448.5387, 448.5387,
        448.5397, 448.3817, 448.5452, 448.5386, 448.3817, 448.5430, 448.5230,
        448.3818, 448.5407, 448.3823, 448.5417, 448.3829, 448.5375, 448.4239,
        448.5406, 448.3833, 448.5390, 448.4874, 448.5380, 448.3847, 448.4663,
        448.5374, 448.5379, 448.5366, 448.3817, 448.5377, 448.5383, 448.4717,
        448.5395, 448.5403, 448.5382, 448.5417, 448.3817, 448.5391, 448.5397,
        448.5363, 448.4644, 448.5420, 448.5369, 448.3818, 448.5402, 448.5399,
        448.5443, 448.5406, 448.3859, 448.5381, 448.5011, 448.3818, 448.3817,
        448.5412, 448.5433, 448.5396, 448.5381, 448.5396, 448.5378, 448.3818,
        448.5381, 448.5361, 448.3817, 448.5397, 448.3857, 448.3817, 448.3821,
        448.5447, 448.3900, 448.5411, 448.5433, 448.3818, 448.5388, 448.5425,
        448.5447, 448.5385, 448.5409, 448.5417, 448.3829, 448.5427, 448.5394,
        448.3842, 448.5386, 448.3830, 448.5434, 448.5380, 448.5393, 448.5424,
        448.5386, 448.5378, 448.5412, 448.5411, 448.5417, 448.5399, 448.5363,
        448.3818, 448.5442, 448.3817, 448.4635, 448.5416, 448.5389, 448.3817,
        448.5029, 448.5024, 448.5434, 448.5405, 448.5420, 448.5412, 448.5397,
        448.5377, 448.5395, 448.5422, 448.3817, 448.5399, 448.5388, 448.5402,
        448.4266, 448.3817, 448.5408, 448.5389, 448.5377, 448.3817, 448.5397,
        448.5430, 448.5403, 448.5380, 448.5380, 448.5405, 448.5407, 448.4616,
        448.5382, 448.5402, 448.5380, 448.3820, 448.3818, 448.4635, 448.3864,
        448.3827, 448.3817, 448.5417, 448.3819, 448.3818, 448.5424, 448.5386,
        448.5416, 448.5377, 448.4631, 448.5391, 448.5384, 448.5404, 448.5431,
        448.5416, 448.5383, 448.5409, 448.5375, 448.5397, 448.5370, 448.5400,
        448.5398, 448.5379, 448.5431, 448.3842, 448.5391, 448.3870, 448.3828,
        448.5103, 448.5450, 448.3819, 448.5399, 448.5376, 448.5393, 448.3840,
        448.5396, 448.3818, 448.5392, 448.5393, 448.3818, 448.5278, 448.5396,
        448.5410, 448.5395, 448.5365, 448.5445, 448.3821, 448.5375, 448.3817,
        448.5401, 448.5388, 448.5373, 448.5408, 448.5460, 448.4627, 448.5385,
        448.4639, 448.5369, 448.5429, 448.3830, 448.5444, 448.5452, 448.3850,
        448.5445, 448.5435, 448.5392, 448.4646, 448.5369, 448.5388, 448.5398,
        448.5147, 448.4663, 448.3818, 448.5430, 448.5391, 448.5408, 448.5389,
        448.3847, 448.5432, 448.5372, 448.5389, 448.3837, 448.5007, 448.5408,
        448.3817, 448.5389, 448.5367, 448.5418, 448.4955, 448.3867, 448.3911,
        448.5424, 448.5372, 448.5434, 448.5387, 448.4635, 448.4700, 448.3818,
        448.3818, 448.5400, 448.5394, 448.5384, 448.5366, 448.4627, 448.5381,
        448.5391, 448.5403, 448.3817, 448.5368, 448.5414, 448.5429, 448.3834,
        448.5436, 448.5405, 448.4633, 448.5380, 448.5402, 448.5425, 448.5408,
        448.5407, 448.5375, 448.5438, 448.4719, 448.3848, 448.5381, 448.5379,
        448.5371, 448.5426, 448.5362, 448.3932, 448.5388, 448.5419, 448.5436,
        448.5119, 448.3822, 448.5434, 448.5374, 448.4643, 448.5450, 448.5384,
        448.5369, 448.5393, 448.5362, 448.5388, 448.3817, 448.4771, 448.5405,
        448.5371, 448.5374, 448.5400, 448.3818, 448.5108, 448.3838, 448.3818,
        448.5415, 448.5003, 448.5391, 448.3895, 448.5408, 448.5399, 448.5406,
        448.3830, 448.5404, 448.5406, 448.5016, 448.3828, 448.5376, 448.3818,
        448.5411, 448.4781, 448.3818, 448.5399, 448.4642, 448.5398, 448.5419,
        448.5438, 448.3860, 448.5387, 448.4631, 448.3818, 448.3831, 448.5399,
        448.5361, 448.5013, 448.3940, 448.5443, 448.5397, 448.5408, 448.3830,
        448.3817, 448.3818, 448.5403, 448.5395, 448.5403, 448.3820, 448.5437,
        448.5374, 448.5430, 448.5370, 448.5390, 448.5437, 448.5383, 448.5380,
        448.3828, 448.4694, 448.3878, 448.5421, 448.3817, 448.3818, 448.3818,
        448.3828, 448.5391, 448.5407, 448.5002, 448.3847, 448.5414, 448.5365,
        448.3973, 448.5443, 448.3817, 448.5370, 448.5399, 448.5372, 448.5384,
        448.4628, 448.5378, 448.5375, 448.5396, 448.3818, 448.5374, 448.3818,
        448.4649, 448.3817, 448.5420, 448.3828, 448.5417, 448.3833, 448.3900,
        448.5414, 448.5440, 448.4629, 448.5339, 448.5397, 448.5392, 448.5388,
        448.5400, 448.5409, 448.3818, 448.5384, 448.5396, 448.5446, 448.5392,
        448.3817, 448.5393, 448.3916, 448.5389, 448.5452, 448.5429, 448.3817,
        448.5411, 448.5380, 448.5411, 448.5383, 448.5444, 448.5360, 448.5394,
        448.5380, 448.5387, 448.5397, 448.5439, 448.5407, 448.5418, 448.5443,
        448.5414, 448.5397, 448.5403, 448.5371, 448.4631, 448.3830, 448.5393,
        448.5411, 448.5396, 448.5394, 448.5379, 448.5374, 448.3827, 448.5373,
        448.5381, 448.3817, 448.5390, 448.5395, 448.3825, 448.5389, 448.3824,
        448.3817, 448.5430, 448.3820, 448.5416, 448.5008, 448.5383, 448.5377,
        448.5419, 448.3817, 448.5411, 448.5394, 448.5444, 448.5180, 448.3818,
        448.4632, 448.5410, 448.5442, 448.5003, 448.5403, 448.5438, 448.5401,
        448.5390, 448.3817, 448.3857, 448.3817, 448.4627, 448.3822, 448.5387,
        448.5400, 448.3818, 448.5402, 448.5397, 448.5408, 448.5425, 448.3831,
        448.5393, 448.5450, 448.5400, 448.5400, 448.5371, 448.5389, 448.3817,
        448.5369, 448.5424, 448.5399, 448.5406, 448.5403, 448.5389, 448.5381,
        448.5403, 448.3823, 448.5388, 448.5399, 448.5395, 448.5409, 448.5378,
        448.5381, 448.5392, 448.5387, 448.5414, 448.5394, 448.5394, 448.5447,
        448.5396, 448.3939, 448.5007, 448.5364, 448.4648, 448.5406, 448.4629,
        448.5383, 448.5394, 448.5394, 448.3818, 448.3832, 448.5040, 448.3821,
        448.5383, 448.3818, 448.5387, 448.3817, 448.5405, 448.3829, 448.5438,
        448.3840, 448.5387, 448.5255, 448.5380, 448.5393, 448.4635, 448.5405,
        448.3875, 448.5437, 448.4633, 448.5392, 448.5019, 448.5401, 448.3818,
        448.3833, 448.5405, 448.5388, 448.5403, 448.3857, 448.5383, 448.5406,
        448.5390, 448.5399, 448.5438, 448.5400, 448.5426, 448.5396, 448.5417,
        448.5399, 448.4258, 448.5421, 448.4632, 448.5375, 448.3817, 448.5384,
        448.5365, 448.5386, 448.3817, 448.3817, 448.3818, 448.5403, 448.3890,
        448.5392, 448.4592, 448.5394, 448.5364, 448.5416, 448.5403, 448.5417,
        448.3817, 448.4684, 448.3840, 448.5388, 448.5454, 448.5442, 448.3818,
        448.5388, 448.5433, 448.5411, 448.5366, 448.5377, 448.5364, 448.5410,
        448.5389, 448.5363, 448.5376, 448.5407, 448.5399, 448.5432, 448.4053,
        448.3828, 448.5394, 448.5451, 448.3823, 448.3820, 448.5379, 448.3832,
        448.3817, 448.5392, 448.3854, 448.3819, 448.5378, 448.4647, 448.5397,
        448.5385, 448.5449, 448.5372, 448.5398, 448.5421, 448.3821, 448.4636,
        448.5364, 448.5384, 448.5401, 448.4601, 448.5386, 448.5384, 448.4252,
        448.5399, 448.5390, 448.3899, 448.5390, 448.5435, 448.3825, 448.5370,
        448.3819, 448.3839, 448.5432, 448.5369, 448.3838, 448.5411, 448.3911,
        448.4649, 448.5370, 448.5373, 448.5399, 448.4611, 448.5410, 448.3822,
        448.3817, 448.3821, 448.5388, 448.5392, 448.5423, 448.3818, 448.5398,
        448.5378, 448.3820, 448.4651, 448.3818, 448.5414, 448.3817, 448.5437,
        448.5423, 448.5408, 448.5410, 448.5431, 448.3824, 448.5373, 448.5368,
        448.5399, 448.5388, 448.5400, 448.3867, 448.4646, 448.5370, 448.5416,
        448.5414, 448.3824, 448.3834, 448.4643, 448.5424, 448.5398, 448.5381,
        448.5397, 448.5387, 448.4651, 448.5402, 448.5385, 448.5397, 448.5436,
        448.5383, 448.5391, 448.5402, 448.5374, 448.5406, 448.3832, 448.3830,
        448.5399, 448.5434, 448.5386, 448.5290, 448.5373, 448.3822, 448.5431,
        448.3845, 448.5388, 448.5439, 448.5405, 448.3817, 448.5406, 448.5422,
        448.3820, 448.5399, 448.5371, 448.4632, 448.3818, 448.3818, 448.5394,
        448.5436, 448.5403, 448.5427, 448.3818, 448.5406, 448.5427, 448.5372,
        448.5407, 448.3817, 448.5453, 448.5369, 448.5417, 448.4633, 448.3828,
        448.5362, 448.3818, 448.5399, 448.5367, 448.5389, 448.5393, 448.3844,
        448.3821, 448.5365, 448.3817, 448.5403, 448.5383, 448.5411, 448.5423,
        448.5433, 448.5399, 448.3828, 448.5404, 448.5424, 448.5410, 448.5386,
        448.3817, 448.3817, 448.5404, 448.5367, 448.5418, 448.5374, 448.3826,
        448.5422, 448.3817, 448.5434, 448.5435, 448.5438, 448.5408, 448.3875,
        448.5369, 448.5447, 448.3820, 448.5400, 448.5370, 448.5402, 448.3900,
        448.3839, 448.5389, 448.5107, 448.5399, 448.3820, 448.5388, 448.4643,
        448.5390, 448.3888, 448.3817, 448.5433, 448.5378, 448.3833, 448.5364,
        448.5390, 448.5378, 448.5405, 448.5397, 448.5376, 448.5418, 448.5373,
        448.5372, 448.5428, 448.5404, 448.3819, 448.5372, 448.3820, 448.4632,
        448.5392, 448.5383, 448.3818, 448.5399, 448.3819, 448.3833, 448.5384,
        448.5387, 448.3817, 448.5400, 448.5374, 448.3821, 448.5388, 448.4627,
        448.5414, 448.5413, 448.5399, 448.5397, 448.5385, 448.5393, 448.4632,
        448.5417, 448.5393, 448.5433, 448.5410, 448.5375, 448.5394, 448.3817,
        448.5002, 448.3817, 448.5404, 448.5394, 448.5417, 448.5391, 448.5390,
        448.5389, 448.3818, 448.3820, 448.5396, 448.5398, 448.5388, 448.3818,
        448.5374, 448.5447, 448.5403, 448.5399, 448.5433, 448.5374, 448.5418,
        448.5397, 448.3817, 448.5406, 448.5376, 448.5377, 448.5396, 448.5411,
        448.5428, 448.3819, 448.5391, 448.5388, 448.4627, 448.5405, 448.3942,
        448.3823, 448.5373, 448.5434, 448.5433, 448.5426, 448.5393, 448.3822,
        448.5415, 448.5375, 448.5401, 448.5412, 448.5382, 448.5381, 448.5441,
        448.5389, 448.5387, 448.5395, 448.3818, 448.3818, 448.5423, 448.5371,
        448.4836, 448.3828, 448.5425, 448.5363, 448.5383, 448.5433, 448.5375,
        448.5401, 448.5410, 448.5392, 448.5402, 448.5399, 448.5391, 448.4631,
        448.5402, 448.5426, 448.5449, 448.5400, 448.5374, 448.5377, 448.5432,
        448.5437, 448.5401, 448.5399, 448.3828, 448.3845, 448.5404, 448.3818,
        448.4717, 448.3817, 448.3870, 448.5390, 448.5444, 448.3820, 448.5372,
        448.3819, 448.3818, 448.5387, 448.3820, 448.4749, 448.5417, 448.5412,
        448.5437, 448.5394, 448.5395, 448.5428, 448.3818, 448.5398, 448.5443,
        448.5400, 448.3818], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([403.0078], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1341],
             [112.1341],
             [112.1355],
             [112.1355]],

            [[112.0954],
             [112.0954],
             [112.0955],
             [112.0955]],

            [[112.1169],
             [112.1340],
             [112.1342],
             [112.1342]],

            ...,

            [[112.1341],
             [112.1341],
             [112.1365],
             [112.1350]],

            [[112.1346],
             [112.1369],
             [112.1342],
             [112.1348]],

            [[112.0955],
             [112.0955],
             [112.0955],
             [112.0955]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5392, 448.3818, 448.5192,  ..., 448.5397, 448.5405, 448.3818],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5392, 448.3818, 448.5192,  ..., 448.5397, 448.5405, 448.3818],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1059],
             [112.1059],
             [112.1059],
             [112.1059]],

            [[112.1063],
             [112.1063],
             [112.1062],
             [112.1062]],

            [[112.1270],
             [112.1270],
             [112.1277],
             [112.1277]],

            ...,

            [[112.1250],
             [112.1276],
             [112.1265],
             [112.1265]],

            [[112.1251],
             [112.1259],
             [112.1275],
             [112.1275]],

            [[112.1270],
             [112.1270],
             [112.1281],
             [112.1281]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4238, 448.4249, 448.5095,  ..., 448.5056, 448.5059, 448.5103],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4238, 448.4249, 448.5095,  ..., 448.5056, 448.5059, 448.5103],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1175],
             [112.1192],
             [112.1178],
             [112.1178]],

            [[112.1182],
             [112.1189],
             [112.1181],
             [112.1201]],

            [[112.1146],
             [112.1151],
             [112.1146],
             [112.1151]],

            ...,

            [[112.1179],
             [112.1201],
             [112.1181],
             [112.1181]],

            [[112.1198],
             [112.1182],
             [112.1181],
             [112.1181]],

            [[112.1193],
             [112.1148],
             [112.1188],
             [112.1188]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4724, 448.4754, 448.4593,  ..., 448.4743, 448.4741, 448.4718],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4724, 448.4754, 448.4593,  ..., 448.4743, 448.4741, 448.4718],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1195],
             [112.1195],
             [112.1197],
             [112.1197]],

            [[112.1151],
             [112.1166],
             [112.1150],
             [112.1168]],

            [[112.1151],
             [112.1151],
             [112.1171],
             [112.1171]],

            ...,

            [[112.1188],
             [112.1190],
             [112.1188],
             [112.1188]],

            [[112.1154],
             [112.1154],
             [112.1171],
             [112.1171]],

            [[112.1173],
             [112.1182],
             [112.1164],
             [112.1170]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4782, 448.4635, 448.4644,  ..., 448.4755, 448.4651, 448.4688],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4782, 448.4635, 448.4644,  ..., 448.4755, 448.4651, 448.4688],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1133],
             [112.1152],
             [112.1163],
             [112.1163]],

            [[112.1146],
             [112.1146],
             [112.1164],
             [112.1164]],

            [[112.1133],
             [112.1150],
             [112.1135],
             [112.1153]],

            ...,

            [[112.1134],
             [112.1141],
             [112.1133],
             [112.1144]],

            [[112.1141],
             [112.1155],
             [112.1162],
             [112.1162]],

            [[112.1220],
             [112.1223],
             [112.1221],
             [112.1221]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4611, 448.4619, 448.4571,  ..., 448.4552, 448.4619, 448.4886],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4611, 448.4619, 448.4571,  ..., 448.4552, 448.4619, 448.4886],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1119],
             [112.1122],
             [112.1120],
             [112.1136]],

            [[112.1244],
             [112.1247],
             [112.1247],
             [112.1244]],

            [[112.1244],
             [112.1248],
             [112.1244],
             [112.1249]],

            ...,

            [[112.1123],
             [112.1123],
             [112.1124],
             [112.1124]],

            [[112.1124],
             [112.1137],
             [112.1137],
             [112.1149]],

            [[112.1145],
             [112.1125],
             [112.1128],
             [112.1128]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4498, 448.4981, 448.4985,  ..., 448.4493, 448.4546, 448.4526],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4498, 448.4981, 448.4985,  ..., 448.4493, 448.4546, 448.4526],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1106],
             [112.1106],
             [112.1108],
             [112.1279]],

            [[112.1238],
             [112.1099],
             [112.1099],
             [112.1275]],

            [[112.1107],
             [112.1107],
             [112.1118],
             [112.1118]],

            ...,

            [[112.1274],
             [112.1274],
             [112.1274],
             [112.1274]],

            [[112.1275],
             [112.1273],
             [112.1275],
             [112.1277]],

            [[112.1114],
             [112.1114],
             [112.1123],
             [112.1123]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4601, 448.4712, 448.4450,  ..., 448.5095, 448.5099, 448.4474],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4601, 448.4712, 448.4450,  ..., 448.5095, 448.5099, 448.4474],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1125],
             [112.1125],
             [112.1134],
             [112.1134]],

            [[112.1113],
             [112.1290],
             [112.1294],
             [112.1113]],

            [[112.1113],
             [112.1128],
             [112.1138],
             [112.1138]],

            ...,

            [[112.1112],
             [112.1130],
             [112.1121],
             [112.1121]],

            [[112.1136],
             [112.1138],
             [112.1138],
             [112.1138]],

            [[112.1126],
             [112.1113],
             [112.1113],
             [112.1140]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4518, 448.4810, 448.4517,  ..., 448.4483, 448.4549, 448.4492],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4518, 448.4810, 448.4517,  ..., 448.4483, 448.4549, 448.4492],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1347],
             [112.1071],
             [112.1071],
             [112.1347]],

            [[112.1339],
             [112.1339],
             [112.1339],
             [112.1339]],

            [[112.1076],
             [112.1095],
             [112.1087],
             [112.1087]],

            ...,

            [[112.1068],
             [112.1082],
             [112.1077],
             [112.1095]],

            [[112.1344],
             [112.1339],
             [112.1339],
             [112.1344]],

            [[112.1339],
             [112.1342],
             [112.1339],
             [112.1339]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4836, 448.5356, 448.4344,  ..., 448.4321, 448.5367, 448.5359],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4836, 448.5356, 448.4344,  ..., 448.4321, 448.5367, 448.5359],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1029],
             [112.1029],
             [112.1029],
             [112.1029]],

            [[112.1024],
             [112.1024],
             [112.1029],
             [112.1029]],

            [[112.1047],
             [112.1048],
             [112.1047],
             [112.1048]],

            ...,

            [[112.1040],
             [112.1024],
             [112.1024],
             [112.1024]],

            [[112.1040],
             [112.1040],
             [112.1047],
             [112.1047]],

            [[112.1380],
             [112.1383],
             [112.1383],
             [112.1380]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4116, 448.4106, 448.4191,  ..., 448.4113, 448.4174, 448.5526],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4116, 448.4106, 448.4191,  ..., 448.4113, 448.4174, 448.5526],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1039],
             [112.1031],
             [112.1039],
             [112.1031]],

            [[112.1054],
             [112.1054],
             [112.1054],
             [112.1054]],

            [[112.1033],
             [112.1058],
             [112.1032],
             [112.1042]],

            ...,

            [[112.1381],
             [112.1382],
             [112.1381],
             [112.1382]],

            [[112.1044],
             [112.1031],
             [112.1047],
             [112.1047]],

            [[112.1037],
             [112.1032],
             [112.1030],
             [112.1030]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4139, 448.4215, 448.4165,  ..., 448.5526, 448.4168, 448.4130],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4139, 448.4215, 448.4165,  ..., 448.5526, 448.4168, 448.4130],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1008],
             [112.1008],
             [112.1008],
             [112.1008]],

            [[112.1407],
             [112.1409],
             [112.1381],
             [112.1381]],

            [[112.1008],
             [112.1018],
             [112.1008],
             [112.1008]],

            ...,

            [[112.1405],
             [112.1405],
             [112.1405],
             [112.1405]],

            [[112.1020],
             [112.1020],
             [112.1036],
             [112.1036]],

            [[112.1008],
             [112.1008],
             [112.1009],
             [112.1009]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4033, 448.5577, 448.4041,  ..., 448.5620, 448.4113, 448.4033],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4033, 448.5577, 448.4041,  ..., 448.5620, 448.4113, 448.4033],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0990],
             [112.0990],
             [112.1003],
             [112.1003]],

            [[112.0982],
             [112.0982],
             [112.0984],
             [112.0984]],

            [[112.0998],
             [112.0993],
             [112.1007],
             [112.1007]],

            ...,

            [[112.1432],
             [112.1432],
             [112.1419],
             [112.1432]],

            [[112.0981],
             [112.0994],
             [112.0981],
             [112.0996]],

            [[112.0994],
             [112.1009],
             [112.1003],
             [112.0994]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3985, 448.3934, 448.4005,  ..., 448.5714, 448.3952, 448.4000],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3985, 448.3934, 448.4005,  ..., 448.5714, 448.3952, 448.4000],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0974],
             [112.0993],
             [112.0972],
             [112.0986]],

            [[112.0972],
             [112.0986],
             [112.0978],
             [112.0978]],

            [[112.0972],
             [112.0986],
             [112.0995],
             [112.0976]],

            ...,

            [[112.0973],
             [112.0976],
             [112.0987],
             [112.0995]],

            [[112.0972],
             [112.0973],
             [112.0981],
             [112.0981]],

            [[112.1442],
             [112.1442],
             [112.1442],
             [112.1442]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3925, 448.3914, 448.3929,  ..., 448.3931, 448.3908, 448.5770],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3925, 448.3914, 448.3929,  ..., 448.3931, 448.3908, 448.5770],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0973],
             [112.0982],
             [112.0992],
             [112.0970]],

            [[112.1453],
             [112.1001],
             [112.1453],
             [112.1001]],

            [[112.0968],
             [112.0968],
             [112.0970],
             [112.0970]],

            ...,

            [[112.0970],
             [112.0970],
             [112.0986],
             [112.0986]],

            [[112.1458],
             [112.0982],
             [112.1459],
             [112.0969]],

            [[112.1457],
             [112.0974],
             [112.1459],
             [112.0969]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3917, 448.4908, 448.3876,  ..., 448.3912, 448.4868, 448.4859],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3917, 448.4908, 448.3876,  ..., 448.3912, 448.4868, 448.4859],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0953],
             [112.0953],
             [112.0960],
             [112.0960]],

            [[112.0946],
             [112.0946],
             [112.0946],
             [112.0946]],

            [[112.0949],
             [112.0941],
             [112.0945],
             [112.0945]],

            ...,

            [[112.0940],
             [112.0956],
             [112.0939],
             [112.0949]],

            [[112.0947],
             [112.0947],
             [112.0960],
             [112.0960]],

            [[112.0941],
             [112.0941],
             [112.0954],
             [112.0954]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3825, 448.3785, 448.3779,  ..., 448.3784, 448.3813, 448.3788],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3825, 448.3785, 448.3779,  ..., 448.3784, 448.3813, 448.3788],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0894],
             [112.0917],
             [112.0896],
             [112.0899]],

            [[112.1515],
             [112.1515],
             [112.1515],
             [112.1515]],

            [[112.0893],
             [112.0913],
             [112.0898],
             [112.0904]],

            ...,

            [[112.0899],
             [112.0918],
             [112.0903],
             [112.0903]],

            [[112.1515],
             [112.1515],
             [112.1515],
             [112.1515]],

            [[112.0894],
             [112.0894],
             [112.0909],
             [112.0909]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3607, 448.6060, 448.3607,  ..., 448.3623, 448.6060, 448.3607],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3607, 448.6060, 448.3607,  ..., 448.3623, 448.6060, 448.3607],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1558],
             [112.1558],
             [112.1558],
             [112.1558]],

            [[112.0845],
             [112.0869],
             [112.0845],
             [112.0845]],

            [[112.0845],
             [112.0842],
             [112.0844],
             [112.0848]],

            ...,

            [[112.0844],
             [112.0853],
             [112.0859],
             [112.0859]],

            [[112.0850],
             [112.0868],
             [112.0844],
             [112.0852]],

            [[112.0851],
             [112.0843],
             [112.0860],
             [112.0843]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6234, 448.3404, 448.3379,  ..., 448.3414, 448.3414, 448.3398],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6234, 448.3404, 448.3379,  ..., 448.3414, 448.3414, 448.3398],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0103e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0762],
             [112.0912],
             [112.1469],
             [112.0762]],

            [[112.1659],
             [112.1659],
             [112.1659],
             [112.1659]],

            [[112.0763],
             [112.0776],
             [112.0763],
             [112.0775]],

            ...,

            [[112.0773],
             [112.0780],
             [112.0790],
             [112.0790]],

            [[112.1659],
             [112.1659],
             [112.1659],
             [112.1659]],

            [[112.1551],
             [112.0762],
             [112.0764],
             [112.0764]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3906, 448.6635, 448.3076,  ..., 448.3133, 448.6635, 448.3841],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3906, 448.6635, 448.3076,  ..., 448.3133, 448.6635, 448.3841],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0762],
             [112.0763],
             [112.0763],
             [112.0764]],

            [[112.0768],
             [112.0790],
             [112.0767],
             [112.0762]],

            [[112.0764],
             [112.0764],
             [112.0763],
             [112.0763]],

            ...,

            [[112.0776],
             [112.1660],
             [112.1410],
             [112.1658]],

            [[112.0774],
             [112.0774],
             [112.0786],
             [112.0786]],

            [[112.1659],
             [112.1659],
             [112.1660],
             [112.1660]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3053, 448.3087, 448.3054,  ..., 448.5505, 448.3121, 448.6638],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3053, 448.3087, 448.3054,  ..., 448.5505, 448.3121, 448.6638],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1659],
             [112.1659],
             [112.1659],
             [112.1659]],

            [[112.1660],
             [112.0798],
             [112.1660],
             [112.1660]],

            [[112.0781],
             [112.0781],
             [112.0783],
             [112.0783]],

            ...,

            [[112.0765],
             [112.1661],
             [112.1661],
             [112.0766]],

            [[112.0768],
             [112.0768],
             [112.0768],
             [112.0768]],

            [[112.0763],
             [112.0764],
             [112.0782],
             [112.0777]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6635, 448.5779, 448.3127, 448.3109, 448.3069, 448.3087, 448.3120,
            448.3082, 448.6639, 448.4821, 448.3112, 448.3142, 448.6635, 448.4744,
            448.3088, 448.3117, 448.3076, 448.3088, 448.6636, 448.6635, 448.3096,
            448.6636, 448.6635, 448.6635, 448.6636, 448.3093, 448.3060, 448.6640,
            448.6638, 448.3089, 448.3133, 448.3056, 448.3132, 448.3929, 448.4849,
            448.3087, 448.3067, 448.3104, 448.3103, 448.3117, 448.6635, 448.3088,
            448.3133, 448.6635, 448.3119, 448.3099, 448.6635, 448.3092, 448.3081,
            448.3129, 448.3086, 448.3117, 448.3066, 448.3058, 448.3088, 448.6631,
            448.3074, 448.3089, 448.3081, 448.6641, 448.6635, 448.3091, 448.4813,
            448.3055, 448.3094, 448.3083, 448.3133, 448.4241, 448.6635, 448.3090,
            448.3087, 448.6639, 448.6640, 448.6638, 448.6606, 448.3057, 448.6636,
            448.3122, 448.4832, 448.3069, 448.6635, 448.3114, 448.6635, 448.3090,
            448.3058, 448.3970, 448.3062, 448.4850, 448.4710, 448.3090, 448.3110,
            448.4866, 448.6635, 448.6638, 448.6636, 448.3071, 448.6639, 448.3093,
            448.3056, 448.3109, 448.6635, 448.3128, 448.3112, 448.3082, 448.3091,
            448.3069, 448.6635, 448.6635, 448.3135, 448.3091, 448.3112, 448.3093,
            448.3069, 448.3052, 448.4049, 448.6635, 448.4852, 448.6635, 448.4849,
            448.3096, 448.3086, 448.3135, 448.3083, 448.6638, 448.3079, 448.6636,
            448.5309, 448.3091, 448.4839, 448.3070, 448.6637, 448.5770, 448.6635,
            448.6635, 448.3079, 448.3102, 448.3055, 448.6635, 448.6636, 448.6635,
            448.3062, 448.4619, 448.3119, 448.3084, 448.3071, 448.3112, 448.3096,
            448.6635, 448.6640, 448.3095, 448.4842, 448.3053, 448.3090, 448.3052,
            448.6638, 448.3085, 448.6638, 448.4854, 448.3134, 448.3050, 448.3174,
            448.3108, 448.3049, 448.3068, 448.3064, 448.6635, 448.3120, 448.3076,
            448.3074, 448.3114, 448.3051, 448.6636, 448.3060, 448.3110, 448.3062,
            448.3067, 448.3109, 448.3057, 448.6635, 448.3092, 448.6635, 448.3098,
            448.3598, 448.6636, 448.3128, 448.3068, 448.3083, 448.6636, 448.3104,
            448.3093, 448.3084, 448.3106, 448.4829, 448.3064, 448.3067, 448.6635,
            448.3089, 448.3057, 448.3093, 448.3070, 448.6537, 448.4848, 448.3102,
            448.3120, 448.5346, 448.6635, 448.3122, 448.3095, 448.3116, 448.3090,
            448.3060, 448.6635, 448.3068, 448.3086, 448.3052, 448.6638, 448.3087,
            448.4852, 448.3091, 448.3118, 448.5968, 448.3073, 448.4002, 448.6626,
            448.3091, 448.3137, 448.3081, 448.3086, 448.3094, 448.6639, 448.6637,
            448.3106, 448.3084, 448.6635, 448.6635, 448.3090, 448.3055, 448.3111,
            448.3097, 448.3093, 448.3099, 448.4783, 448.4836, 448.6599, 448.4858,
            448.3068, 448.3114, 448.4853, 448.3099, 448.6635, 448.3104, 448.6635,
            448.3091, 448.6635, 448.3109, 448.3071, 448.6636, 448.6638, 448.6635,
            448.3089, 448.3066, 448.3107, 448.3049, 448.6635, 448.6635, 448.6635,
            448.3096, 448.3085, 448.3107, 448.3089, 448.6636, 448.6638, 448.6635,
            448.3107, 448.3091, 448.3121, 448.6635, 448.4851, 448.4876, 448.3094,
            448.3131, 448.6635, 448.4876, 448.6637, 448.4851, 448.3078, 448.6635,
            448.3084, 448.6635, 448.3110, 448.3066, 448.3092, 448.3103, 448.3089,
            448.6547, 448.3082, 448.6638, 448.3056, 448.3121, 448.6635, 448.3120,
            448.3073, 448.3131, 448.3112, 448.3133, 448.3057, 448.3097, 448.3134,
            448.6638, 448.3087, 448.3083, 448.4857, 448.3499, 448.3078, 448.6638,
            448.3070, 448.3113, 448.3049, 448.3083, 448.3084, 448.3069, 448.6638,
            448.3081, 448.6639, 448.3062, 448.6638, 448.3053, 448.6639, 448.3086,
            448.6635, 448.3078, 448.6637, 448.3059, 448.4178, 448.6635, 448.6639,
            448.4868, 448.3096, 448.6635, 448.6635, 448.3077, 448.3095, 448.6635,
            448.6636, 448.3072, 448.3057, 448.6638, 448.3087, 448.3066, 448.6635,
            448.3130, 448.3090, 448.3079, 448.6637, 448.6635, 448.4838, 448.6506,
            448.3954, 448.3090, 448.3081, 448.3074, 448.3073, 448.3089, 448.3118,
            448.3087, 448.3098, 448.3063, 448.3123, 448.6635, 448.3133, 448.3086,
            448.3045, 448.6635, 448.3100, 448.3093, 448.3079, 448.3085, 448.3133,
            448.3088, 448.3056, 448.4717, 448.6635, 448.3095, 448.6589, 448.3135,
            448.3057, 448.4815, 448.6638, 448.3093, 448.3083, 448.6636, 448.3099,
            448.3078, 448.4852, 448.6639, 448.3060, 448.3137, 448.6639, 448.3117,
            448.3118, 448.4929, 448.3058, 448.3089, 448.6640, 448.6639, 448.3108,
            448.6637, 448.3071, 448.3069, 448.3085, 448.3092, 448.3103, 448.3075,
            448.3945, 448.3099, 448.4853, 448.3073, 448.3092, 448.3101, 448.3504,
            448.3132, 448.6635, 448.6641, 448.3127, 448.3084, 448.6635, 448.3089,
            448.6635, 448.3078, 448.3111, 448.6636, 448.3794, 448.6640, 448.3110,
            448.4841, 448.4854, 448.3063, 448.3058, 448.3114, 448.3081, 448.3083,
            448.3086, 448.6638, 448.3087, 448.3114, 448.3070, 448.6635, 448.4886,
            448.3052, 448.3103, 448.6635, 448.6635, 448.6589, 448.3110, 448.3070,
            448.3129, 448.3098, 448.5747, 448.6635, 448.3102, 448.6639, 448.3137,
            448.6637, 448.4869, 448.3085, 448.5739, 448.6635, 448.3087, 448.3117,
            448.3106, 448.4855, 448.3127, 448.6636, 448.3078, 448.3125, 448.3081,
            448.3110, 448.3128, 448.4432, 448.3093, 448.3081, 448.3082, 448.6635,
            448.6634, 448.3075, 448.3100, 448.3098, 448.6636, 448.3057, 448.3123,
            448.3074, 448.6638, 448.3055, 448.3052, 448.3074, 448.6635, 448.3086,
            448.3087, 448.3101, 448.3078, 448.3112, 448.3078, 448.3090, 448.4558,
            448.6635, 448.3093, 448.3059, 448.3062, 448.3141, 448.3075, 448.3049,
            448.3130, 448.6635, 448.3078, 448.3114, 448.3091, 448.3109, 448.6635,
            448.3101, 448.3077, 448.6635, 448.6637, 448.6635, 448.4014, 448.3120,
            448.3063, 448.6635, 448.3126, 448.3104, 448.3094, 448.3091, 448.3106,
            448.6541, 448.3097, 448.3121, 448.3121, 448.3057, 448.6636, 448.3063,
            448.3058, 448.3085, 448.6637, 448.3158, 448.3105, 448.6638, 448.6635,
            448.6597, 448.3069, 448.3062, 448.3060, 448.6635, 448.3135, 448.3103,
            448.3100, 448.6635, 448.3133, 448.3061, 448.3054, 448.4860, 448.6635,
            448.3090, 448.6637, 448.3062, 448.3079, 448.3084, 448.3091, 448.3083,
            448.3087, 448.5746, 448.4854, 448.3093, 448.6635, 448.4846, 448.3085,
            448.3093, 448.4255, 448.3093, 448.3091, 448.6069, 448.6638, 448.5769,
            448.6635, 448.6635, 448.3103, 448.3096, 448.3951, 448.3122, 448.3133,
            448.3079, 448.3115, 448.3087, 448.3054, 448.3090, 448.6638, 448.3128,
            448.6638, 448.3116, 448.3096, 448.3105, 448.6599, 448.3085, 448.3083,
            448.3109, 448.6638, 448.3087, 448.6562, 448.3045, 448.6635, 448.3145,
            448.3120, 448.3121, 448.3117, 448.6635, 448.3123, 448.3076, 448.4894,
            448.3119, 448.3078, 448.6635, 448.6636, 448.3099, 448.6596, 448.3111,
            448.3098, 448.3058, 448.6637, 448.3081, 448.3100, 448.3118, 448.3090,
            448.3083, 448.3081, 448.3088, 448.4111, 448.6635, 448.3091, 448.3061,
            448.3085, 448.3069, 448.3081, 448.3141, 448.3105, 448.6638, 448.3063,
            448.3302, 448.3088, 448.3918, 448.6635, 448.3059, 448.3082, 448.6635,
            448.6635, 448.6635, 448.3083, 448.6635, 448.3088, 448.6636, 448.3058,
            448.3109, 448.6637, 448.3106, 448.3084, 448.3106, 448.4156, 448.3088,
            448.3113, 448.3139, 448.3081, 448.6635, 448.3119, 448.3130, 448.3080,
            448.3123, 448.6635, 448.6637, 448.4852, 448.3818, 448.4849, 448.3076,
            448.6635, 448.3083, 448.4877, 448.3088, 448.6637, 448.6635, 448.5748,
            448.4854, 448.6635, 448.3124, 448.6635, 448.3085, 448.3090, 448.3074,
            448.3113, 448.6638, 448.3130, 448.3058, 448.4901, 448.3054, 448.3086,
            448.3055, 448.3098, 448.3118, 448.3071, 448.3118, 448.6635, 448.3130,
            448.6638, 448.3054, 448.3120, 448.3109, 448.3091, 448.3089, 448.4858,
            448.3087, 448.3061, 448.3107, 448.3106, 448.3079, 448.3092, 448.6638,
            448.3101, 448.3088, 448.4854, 448.3107, 448.3101, 448.3096, 448.3111,
            448.3112, 448.6635, 448.6635, 448.6637, 448.3264, 448.3117, 448.3083,
            448.3064, 448.4848, 448.3081, 448.3094, 448.6637, 448.6635, 448.6641,
            448.3101, 448.3120, 448.3122, 448.3072, 448.3079, 448.3109, 448.3132,
            448.3089, 448.3113, 448.3065, 448.3053, 448.3134, 448.6636, 448.3087,
            448.3135, 448.3087, 448.6640, 448.3099, 448.4938, 448.3091, 448.3104,
            448.3096, 448.3128, 448.3198, 448.3090, 448.3105, 448.6635, 448.6638,
            448.3094, 448.3103, 448.6635, 448.3090, 448.3063, 448.6636, 448.3119,
            448.3113, 448.3073, 448.3065, 448.3123, 448.3080, 448.3089, 448.3057,
            448.4935, 448.3098, 448.3058, 448.3089, 448.3080, 448.3105, 448.3517,
            448.3091, 448.3088, 448.3053, 448.6632, 448.3939, 448.3064, 448.3089,
            448.6638, 448.3078, 448.4853, 448.3083, 448.3116, 448.3098, 448.6638,
            448.3056, 448.3083, 448.3075, 448.6635, 448.3056, 448.3092, 448.3088,
            448.3115, 448.3531, 448.4863, 448.3063, 448.3110, 448.6618, 448.3059,
            448.3094, 448.6638, 448.3110, 448.6641, 448.3099, 448.6635, 448.3091,
            448.4850, 448.6635, 448.3088, 448.3063, 448.3113, 448.3110, 448.6635,
            448.6635, 448.3095, 448.3087, 448.3092, 448.3098, 448.3075, 448.3065,
            448.3103, 448.3075, 448.6638, 448.6635, 448.3090, 448.3091, 448.3078,
            448.3072, 448.3098, 448.6637, 448.3125, 448.3101, 448.3076, 448.6635,
            448.3117, 448.3077, 448.3117, 448.3086, 448.3135, 448.6637, 448.3092,
            448.4853, 448.3078, 448.3062, 448.3112, 448.4851, 448.3060, 448.3083,
            448.6636, 448.3059, 448.3076, 448.3139, 448.6635, 448.3110, 448.4850,
            448.6637, 448.3093, 448.6635, 448.3095, 448.3074, 448.6638, 448.3089,
            448.3088, 448.3077, 448.6635, 448.3058, 448.4851, 448.3138, 448.3059,
            448.6532, 448.3060, 448.6049, 448.6638, 448.4810, 448.3088, 448.3060,
            448.3114, 448.3140, 448.6635, 448.6625, 448.4851, 448.3062, 448.3105,
            448.3118, 448.3083, 448.3060, 448.3068, 448.3093, 448.3065, 448.3100,
            448.3997, 448.6635, 448.3102, 448.3092, 448.6637, 448.6639, 448.3969,
            448.3078, 448.3069, 448.3056, 448.6635, 448.3105, 448.3106, 448.4853,
            448.3072, 448.3086], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6635, 448.5779, 448.3127, 448.3109, 448.3069, 448.3087, 448.3120,
        448.3082, 448.6639, 448.4821, 448.3112, 448.3142, 448.6635, 448.4744,
        448.3088, 448.3117, 448.3076, 448.3088, 448.6636, 448.6635, 448.3096,
        448.6636, 448.6635, 448.6635, 448.6636, 448.3093, 448.3060, 448.6640,
        448.6638, 448.3089, 448.3133, 448.3056, 448.3132, 448.3929, 448.4849,
        448.3087, 448.3067, 448.3104, 448.3103, 448.3117, 448.6635, 448.3088,
        448.3133, 448.6635, 448.3119, 448.3099, 448.6635, 448.3092, 448.3081,
        448.3129, 448.3086, 448.3117, 448.3066, 448.3058, 448.3088, 448.6631,
        448.3074, 448.3089, 448.3081, 448.6641, 448.6635, 448.3091, 448.4813,
        448.3055, 448.3094, 448.3083, 448.3133, 448.4241, 448.6635, 448.3090,
        448.3087, 448.6639, 448.6640, 448.6638, 448.6606, 448.3057, 448.6636,
        448.3122, 448.4832, 448.3069, 448.6635, 448.3114, 448.6635, 448.3090,
        448.3058, 448.3970, 448.3062, 448.4850, 448.4710, 448.3090, 448.3110,
        448.4866, 448.6635, 448.6638, 448.6636, 448.3071, 448.6639, 448.3093,
        448.3056, 448.3109, 448.6635, 448.3128, 448.3112, 448.3082, 448.3091,
        448.3069, 448.6635, 448.6635, 448.3135, 448.3091, 448.3112, 448.3093,
        448.3069, 448.3052, 448.4049, 448.6635, 448.4852, 448.6635, 448.4849,
        448.3096, 448.3086, 448.3135, 448.3083, 448.6638, 448.3079, 448.6636,
        448.5309, 448.3091, 448.4839, 448.3070, 448.6637, 448.5770, 448.6635,
        448.6635, 448.3079, 448.3102, 448.3055, 448.6635, 448.6636, 448.6635,
        448.3062, 448.4619, 448.3119, 448.3084, 448.3071, 448.3112, 448.3096,
        448.6635, 448.6640, 448.3095, 448.4842, 448.3053, 448.3090, 448.3052,
        448.6638, 448.3085, 448.6638, 448.4854, 448.3134, 448.3050, 448.3174,
        448.3108, 448.3049, 448.3068, 448.3064, 448.6635, 448.3120, 448.3076,
        448.3074, 448.3114, 448.3051, 448.6636, 448.3060, 448.3110, 448.3062,
        448.3067, 448.3109, 448.3057, 448.6635, 448.3092, 448.6635, 448.3098,
        448.3598, 448.6636, 448.3128, 448.3068, 448.3083, 448.6636, 448.3104,
        448.3093, 448.3084, 448.3106, 448.4829, 448.3064, 448.3067, 448.6635,
        448.3089, 448.3057, 448.3093, 448.3070, 448.6537, 448.4848, 448.3102,
        448.3120, 448.5346, 448.6635, 448.3122, 448.3095, 448.3116, 448.3090,
        448.3060, 448.6635, 448.3068, 448.3086, 448.3052, 448.6638, 448.3087,
        448.4852, 448.3091, 448.3118, 448.5968, 448.3073, 448.4002, 448.6626,
        448.3091, 448.3137, 448.3081, 448.3086, 448.3094, 448.6639, 448.6637,
        448.3106, 448.3084, 448.6635, 448.6635, 448.3090, 448.3055, 448.3111,
        448.3097, 448.3093, 448.3099, 448.4783, 448.4836, 448.6599, 448.4858,
        448.3068, 448.3114, 448.4853, 448.3099, 448.6635, 448.3104, 448.6635,
        448.3091, 448.6635, 448.3109, 448.3071, 448.6636, 448.6638, 448.6635,
        448.3089, 448.3066, 448.3107, 448.3049, 448.6635, 448.6635, 448.6635,
        448.3096, 448.3085, 448.3107, 448.3089, 448.6636, 448.6638, 448.6635,
        448.3107, 448.3091, 448.3121, 448.6635, 448.4851, 448.4876, 448.3094,
        448.3131, 448.6635, 448.4876, 448.6637, 448.4851, 448.3078, 448.6635,
        448.3084, 448.6635, 448.3110, 448.3066, 448.3092, 448.3103, 448.3089,
        448.6547, 448.3082, 448.6638, 448.3056, 448.3121, 448.6635, 448.3120,
        448.3073, 448.3131, 448.3112, 448.3133, 448.3057, 448.3097, 448.3134,
        448.6638, 448.3087, 448.3083, 448.4857, 448.3499, 448.3078, 448.6638,
        448.3070, 448.3113, 448.3049, 448.3083, 448.3084, 448.3069, 448.6638,
        448.3081, 448.6639, 448.3062, 448.6638, 448.3053, 448.6639, 448.3086,
        448.6635, 448.3078, 448.6637, 448.3059, 448.4178, 448.6635, 448.6639,
        448.4868, 448.3096, 448.6635, 448.6635, 448.3077, 448.3095, 448.6635,
        448.6636, 448.3072, 448.3057, 448.6638, 448.3087, 448.3066, 448.6635,
        448.3130, 448.3090, 448.3079, 448.6637, 448.6635, 448.4838, 448.6506,
        448.3954, 448.3090, 448.3081, 448.3074, 448.3073, 448.3089, 448.3118,
        448.3087, 448.3098, 448.3063, 448.3123, 448.6635, 448.3133, 448.3086,
        448.3045, 448.6635, 448.3100, 448.3093, 448.3079, 448.3085, 448.3133,
        448.3088, 448.3056, 448.4717, 448.6635, 448.3095, 448.6589, 448.3135,
        448.3057, 448.4815, 448.6638, 448.3093, 448.3083, 448.6636, 448.3099,
        448.3078, 448.4852, 448.6639, 448.3060, 448.3137, 448.6639, 448.3117,
        448.3118, 448.4929, 448.3058, 448.3089, 448.6640, 448.6639, 448.3108,
        448.6637, 448.3071, 448.3069, 448.3085, 448.3092, 448.3103, 448.3075,
        448.3945, 448.3099, 448.4853, 448.3073, 448.3092, 448.3101, 448.3504,
        448.3132, 448.6635, 448.6641, 448.3127, 448.3084, 448.6635, 448.3089,
        448.6635, 448.3078, 448.3111, 448.6636, 448.3794, 448.6640, 448.3110,
        448.4841, 448.4854, 448.3063, 448.3058, 448.3114, 448.3081, 448.3083,
        448.3086, 448.6638, 448.3087, 448.3114, 448.3070, 448.6635, 448.4886,
        448.3052, 448.3103, 448.6635, 448.6635, 448.6589, 448.3110, 448.3070,
        448.3129, 448.3098, 448.5747, 448.6635, 448.3102, 448.6639, 448.3137,
        448.6637, 448.4869, 448.3085, 448.5739, 448.6635, 448.3087, 448.3117,
        448.3106, 448.4855, 448.3127, 448.6636, 448.3078, 448.3125, 448.3081,
        448.3110, 448.3128, 448.4432, 448.3093, 448.3081, 448.3082, 448.6635,
        448.6634, 448.3075, 448.3100, 448.3098, 448.6636, 448.3057, 448.3123,
        448.3074, 448.6638, 448.3055, 448.3052, 448.3074, 448.6635, 448.3086,
        448.3087, 448.3101, 448.3078, 448.3112, 448.3078, 448.3090, 448.4558,
        448.6635, 448.3093, 448.3059, 448.3062, 448.3141, 448.3075, 448.3049,
        448.3130, 448.6635, 448.3078, 448.3114, 448.3091, 448.3109, 448.6635,
        448.3101, 448.3077, 448.6635, 448.6637, 448.6635, 448.4014, 448.3120,
        448.3063, 448.6635, 448.3126, 448.3104, 448.3094, 448.3091, 448.3106,
        448.6541, 448.3097, 448.3121, 448.3121, 448.3057, 448.6636, 448.3063,
        448.3058, 448.3085, 448.6637, 448.3158, 448.3105, 448.6638, 448.6635,
        448.6597, 448.3069, 448.3062, 448.3060, 448.6635, 448.3135, 448.3103,
        448.3100, 448.6635, 448.3133, 448.3061, 448.3054, 448.4860, 448.6635,
        448.3090, 448.6637, 448.3062, 448.3079, 448.3084, 448.3091, 448.3083,
        448.3087, 448.5746, 448.4854, 448.3093, 448.6635, 448.4846, 448.3085,
        448.3093, 448.4255, 448.3093, 448.3091, 448.6069, 448.6638, 448.5769,
        448.6635, 448.6635, 448.3103, 448.3096, 448.3951, 448.3122, 448.3133,
        448.3079, 448.3115, 448.3087, 448.3054, 448.3090, 448.6638, 448.3128,
        448.6638, 448.3116, 448.3096, 448.3105, 448.6599, 448.3085, 448.3083,
        448.3109, 448.6638, 448.3087, 448.6562, 448.3045, 448.6635, 448.3145,
        448.3120, 448.3121, 448.3117, 448.6635, 448.3123, 448.3076, 448.4894,
        448.3119, 448.3078, 448.6635, 448.6636, 448.3099, 448.6596, 448.3111,
        448.3098, 448.3058, 448.6637, 448.3081, 448.3100, 448.3118, 448.3090,
        448.3083, 448.3081, 448.3088, 448.4111, 448.6635, 448.3091, 448.3061,
        448.3085, 448.3069, 448.3081, 448.3141, 448.3105, 448.6638, 448.3063,
        448.3302, 448.3088, 448.3918, 448.6635, 448.3059, 448.3082, 448.6635,
        448.6635, 448.6635, 448.3083, 448.6635, 448.3088, 448.6636, 448.3058,
        448.3109, 448.6637, 448.3106, 448.3084, 448.3106, 448.4156, 448.3088,
        448.3113, 448.3139, 448.3081, 448.6635, 448.3119, 448.3130, 448.3080,
        448.3123, 448.6635, 448.6637, 448.4852, 448.3818, 448.4849, 448.3076,
        448.6635, 448.3083, 448.4877, 448.3088, 448.6637, 448.6635, 448.5748,
        448.4854, 448.6635, 448.3124, 448.6635, 448.3085, 448.3090, 448.3074,
        448.3113, 448.6638, 448.3130, 448.3058, 448.4901, 448.3054, 448.3086,
        448.3055, 448.3098, 448.3118, 448.3071, 448.3118, 448.6635, 448.3130,
        448.6638, 448.3054, 448.3120, 448.3109, 448.3091, 448.3089, 448.4858,
        448.3087, 448.3061, 448.3107, 448.3106, 448.3079, 448.3092, 448.6638,
        448.3101, 448.3088, 448.4854, 448.3107, 448.3101, 448.3096, 448.3111,
        448.3112, 448.6635, 448.6635, 448.6637, 448.3264, 448.3117, 448.3083,
        448.3064, 448.4848, 448.3081, 448.3094, 448.6637, 448.6635, 448.6641,
        448.3101, 448.3120, 448.3122, 448.3072, 448.3079, 448.3109, 448.3132,
        448.3089, 448.3113, 448.3065, 448.3053, 448.3134, 448.6636, 448.3087,
        448.3135, 448.3087, 448.6640, 448.3099, 448.4938, 448.3091, 448.3104,
        448.3096, 448.3128, 448.3198, 448.3090, 448.3105, 448.6635, 448.6638,
        448.3094, 448.3103, 448.6635, 448.3090, 448.3063, 448.6636, 448.3119,
        448.3113, 448.3073, 448.3065, 448.3123, 448.3080, 448.3089, 448.3057,
        448.4935, 448.3098, 448.3058, 448.3089, 448.3080, 448.3105, 448.3517,
        448.3091, 448.3088, 448.3053, 448.6632, 448.3939, 448.3064, 448.3089,
        448.6638, 448.3078, 448.4853, 448.3083, 448.3116, 448.3098, 448.6638,
        448.3056, 448.3083, 448.3075, 448.6635, 448.3056, 448.3092, 448.3088,
        448.3115, 448.3531, 448.4863, 448.3063, 448.3110, 448.6618, 448.3059,
        448.3094, 448.6638, 448.3110, 448.6641, 448.3099, 448.6635, 448.3091,
        448.4850, 448.6635, 448.3088, 448.3063, 448.3113, 448.3110, 448.6635,
        448.6635, 448.3095, 448.3087, 448.3092, 448.3098, 448.3075, 448.3065,
        448.3103, 448.3075, 448.6638, 448.6635, 448.3090, 448.3091, 448.3078,
        448.3072, 448.3098, 448.6637, 448.3125, 448.3101, 448.3076, 448.6635,
        448.3117, 448.3077, 448.3117, 448.3086, 448.3135, 448.6637, 448.3092,
        448.4853, 448.3078, 448.3062, 448.3112, 448.4851, 448.3060, 448.3083,
        448.6636, 448.3059, 448.3076, 448.3139, 448.6635, 448.3110, 448.4850,
        448.6637, 448.3093, 448.6635, 448.3095, 448.3074, 448.6638, 448.3089,
        448.3088, 448.3077, 448.6635, 448.3058, 448.4851, 448.3138, 448.3059,
        448.6532, 448.3060, 448.6049, 448.6638, 448.4810, 448.3088, 448.3060,
        448.3114, 448.3140, 448.6635, 448.6625, 448.4851, 448.3062, 448.3105,
        448.3118, 448.3083, 448.3060, 448.3068, 448.3093, 448.3065, 448.3100,
        448.3997, 448.6635, 448.3102, 448.3092, 448.6637, 448.6639, 448.3969,
        448.3078, 448.3069, 448.3056, 448.6635, 448.3105, 448.3106, 448.4853,
        448.3072, 448.3086], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([404.0104], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1658],
             [112.0764],
             [112.0763],
             [112.0763]],

            [[112.0763],
             [112.0778],
             [112.0765],
             [112.0776]],

            [[112.0762],
             [112.0777],
             [112.0785],
             [112.0766]],

            ...,

            [[112.0763],
             [112.0766],
             [112.0778],
             [112.0778]],

            [[112.0775],
             [112.0775],
             [112.0788],
             [112.0788]],

            [[112.0776],
             [112.0762],
             [112.0782],
             [112.0764]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3947, 448.3081, 448.3090,  ..., 448.3086, 448.3127, 448.3085],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3947, 448.3081, 448.3090,  ..., 448.3086, 448.3127, 448.3085],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0691],
             [112.0691],
             [112.0693],
             [112.0693]],

            [[112.1751],
             [112.1751],
             [112.1751],
             [112.1751]],

            [[112.0689],
             [112.0707],
             [112.0692],
             [112.0692]],

            ...,

            [[112.0687],
             [112.0693],
             [112.0688],
             [112.0697]],

            [[112.0704],
             [112.0704],
             [112.0716],
             [112.0716]],

            [[112.0707],
             [112.0706],
             [112.0706],
             [112.0707]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2769, 448.7005, 448.2780,  ..., 448.2765, 448.2840, 448.2826],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2769, 448.7005, 448.2780,  ..., 448.2765, 448.2840, 448.2826],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0650],
             [112.0652],
             [112.0651],
             [112.0653]],

            [[112.0637],
             [112.0637],
             [112.0639],
             [112.0639]],

            [[112.1827],
             [112.1827],
             [112.1827],
             [112.1827]],

            ...,

            [[112.0645],
             [112.0645],
             [112.0654],
             [112.0654]],

            [[112.0631],
             [112.0631],
             [112.0646],
             [112.0646]],

            [[112.0646],
             [112.0629],
             [112.0631],
             [112.0649]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2606, 448.2552, 448.7308,  ..., 448.2599, 448.2553, 448.2556],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2606, 448.2552, 448.7308,  ..., 448.2599, 448.2553, 448.2556],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0607],
             [112.0585],
             [112.0607],
             [112.0607]],

            [[112.1883],
             [112.0581],
             [112.0581],
             [112.1883]],

            [[112.0582],
             [112.0606],
             [112.0603],
             [112.0603]],

            ...,

            [[112.0582],
             [112.0599],
             [112.0582],
             [112.0585]],

            [[112.0583],
             [112.0603],
             [112.0581],
             [112.0596]],

            [[112.0585],
             [112.0581],
             [112.0585],
             [112.0581]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2406, 448.4928, 448.2394,  ..., 448.2348, 448.2363, 448.2332],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2406, 448.4928, 448.2394,  ..., 448.2348, 448.2363, 448.2332],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0515],
             [112.0503],
             [112.0517],
             [112.0507]],

            [[112.1871],
             [112.0492],
             [112.1972],
             [112.0493]],

            [[112.0493],
             [112.0500],
             [112.0494],
             [112.0507]],

            ...,

            [[112.0494],
             [112.0505],
             [112.0494],
             [112.0505]],

            [[112.0501],
             [112.0501],
             [112.0516],
             [112.0516]],

            [[112.0506],
             [112.0518],
             [112.0506],
             [112.0518]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2043, 448.4827, 448.1993,  ..., 448.1997, 448.2034, 448.2049],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2043, 448.4827, 448.1993,  ..., 448.1997, 448.2034, 448.2049],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0392],
             [112.0401],
             [112.0413],
             [112.0394]],

            [[112.2087],
             [112.2087],
             [112.2087],
             [112.2087]],

            [[112.2070],
             [112.2054],
             [112.2070],
             [112.2054]],

            ...,

            [[112.0390],
             [112.0390],
             [112.0407],
             [112.0407]],

            [[112.2087],
             [112.2073],
             [112.2085],
             [112.2085]],

            [[112.2079],
             [112.0387],
             [112.2080],
             [112.0387]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1600, 448.8348, 448.8250,  ..., 448.1594, 448.8329, 448.4933],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1600, 448.8348, 448.8250,  ..., 448.1594, 448.8329, 448.4933],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0287],
             [112.0306],
             [112.0291],
             [112.0291]],

            [[112.2154],
             [112.2180],
             [112.0283],
             [112.0282]],

            [[112.2182],
             [112.0309],
             [112.2182],
             [112.0277]],

            ...,

            [[112.2186],
             [112.2187],
             [112.2181],
             [112.2183]],

            [[112.2187],
             [112.2187],
             [112.2187],
             [112.2187]],

            [[112.2187],
             [112.2187],
             [112.2183],
             [112.2183]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1174, 448.4900, 448.4951,  ..., 448.8738, 448.8748, 448.8740],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1174, 448.4900, 448.4951,  ..., 448.8738, 448.8748, 448.8740],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0213],
             [112.0234],
             [112.0212],
             [112.0233]],

            [[112.0229],
             [112.0236],
             [112.0220],
             [112.0220]],

            [[112.0225],
             [112.0224],
             [112.0223],
             [112.0238]],

            ...,

            [[112.2260],
             [112.2260],
             [112.2260],
             [112.2260]],

            [[112.2258],
             [112.0326],
             [112.2258],
             [112.0326]],

            [[112.2260],
             [112.2258],
             [112.2260],
             [112.2258]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0893, 448.0906, 448.0910,  ..., 448.9040, 448.5168, 448.9037],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0893, 448.0906, 448.0910,  ..., 448.9040, 448.5168, 448.9037],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0183],
             [112.0157],
             [112.0184],
             [112.0161]],

            [[112.2314],
             [112.0164],
             [112.2293],
             [112.2293]],

            [[112.0173],
             [112.0168],
             [112.0175],
             [112.0186]],

            ...,

            [[112.0163],
             [112.0180],
             [112.0160],
             [112.0183]],

            [[112.0160],
             [112.0160],
             [112.0161],
             [112.0161]],

            [[112.0168],
             [112.0184],
             [112.0185],
             [112.0185]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0685, 448.7065, 448.0701,  ..., 448.0685, 448.0641, 448.0721],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0685, 448.7065, 448.0701,  ..., 448.0685, 448.0641, 448.0721],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0081],
             [112.0089],
             [112.0081],
             [112.0089]],

            [[112.2389],
             [112.2389],
             [112.2389],
             [112.2389]],

            [[112.2389],
             [112.2378],
             [112.2387],
             [112.2387]],

            ...,

            [[112.0105],
             [112.0109],
             [112.0107],
             [112.0086]],

            [[112.2373],
             [112.2383],
             [112.2385],
             [112.2361]],

            [[112.0097],
             [112.0111],
             [112.0100],
             [112.0100]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0340, 448.9558, 448.9542,  ..., 448.0407, 448.9502, 448.0408],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0340, 448.9558, 448.9542,  ..., 448.0407, 448.9502, 448.0408],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0061],
             [112.0053],
             [112.0062],
             [112.0045]],

            [[112.0047],
             [112.0061],
             [112.0057],
             [112.0037]],

            [[112.0039],
             [112.0055],
             [112.0039],
             [112.0055]],

            ...,

            [[112.0035],
             [112.0035],
             [112.0036],
             [112.0036]],

            [[112.0033],
             [112.0038],
             [112.0055],
             [112.0058]],

            [[112.0036],
             [112.0043],
             [112.0038],
             [112.0038]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0221, 448.0202, 448.0188,  ..., 448.0143, 448.0184, 448.0154],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0221, 448.0202, 448.0188,  ..., 448.0143, 448.0184, 448.0154],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0021],
             [112.0021],
             [112.0026],
             [112.0026]],

            [[112.2479],
             [112.2479],
             [112.2479],
             [112.2479]],

            [[112.0017],
             [112.0024],
             [112.0017],
             [112.0002]],

            ...,

            [[112.2394],
             [111.9991],
             [111.9999],
             [112.0003]],

            [[112.0001],
             [112.0024],
             [112.0016],
             [112.0022]],

            [[112.0003],
             [112.0004],
             [112.0023],
             [112.0015]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0093, 448.9916, 448.0059,  ..., 448.2387, 448.0064, 448.0045],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0093, 448.9916, 448.0059,  ..., 448.2387, 448.0064, 448.0045],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2530],
             [112.2521],
             [112.2529],
             [112.2529]],

            [[111.9945],
             [111.9947],
             [112.2002],
             [112.2002]],

            [[112.2522],
             [112.2522],
             [112.0679],
             [112.0679]],

            ...,

            [[111.9962],
             [111.9960],
             [111.9963],
             [111.9970]],

            [[111.9968],
             [111.9951],
             [111.9965],
             [111.9945]],

            [[111.9956],
             [111.9954],
             [111.9961],
             [111.9969]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([449.0108, 448.3895, 448.6403,  ..., 447.9855, 447.9830, 447.9840],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([449.0108, 448.3895, 448.6403,  ..., 447.9855, 447.9830, 447.9840],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9925],
             [111.9918],
             [111.9937],
             [111.9919]],

            [[111.9940],
             [111.9937],
             [111.9935],
             [111.9928]],

            [[112.2539],
             [112.2539],
             [112.2539],
             [112.2539]],

            ...,

            [[111.9917],
             [111.9938],
             [111.9929],
             [111.9929]],

            [[111.9935],
             [111.9921],
             [111.9939],
             [111.9925]],

            [[111.9932],
             [111.9932],
             [111.9938],
             [111.9938]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9698, 447.9741, 449.0157,  ..., 447.9713, 447.9719, 447.9739],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9698, 447.9741, 449.0157,  ..., 447.9713, 447.9719, 447.9739],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9958],
             [111.9943],
             [111.9959],
             [111.9943]],

            [[112.2509],
             [112.2507],
             [112.2509],
             [112.2509]],

            [[112.2491],
             [111.9936],
             [112.2492],
             [111.9936]],

            ...,

            [[111.9960],
             [111.9960],
             [111.9962],
             [111.9962]],

            [[112.2504],
             [112.2504],
             [112.1745],
             [112.1745]],

            [[112.2507],
             [112.2406],
             [112.2502],
             [112.2502]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9803, 449.0034, 448.4854,  ..., 447.9843, 448.8499, 448.9918],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9803, 449.0034, 448.4854,  ..., 447.9843, 448.8499, 448.9918],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9928],
             [111.9926],
             [111.9942],
             [111.9942]],

            [[111.9939],
             [111.9940],
             [111.9941],
             [111.9936]],

            [[111.9926],
             [111.9926],
             [111.9942],
             [111.9942]],

            ...,

            [[111.9915],
             [111.9930],
             [111.9923],
             [111.9933]],

            [[112.2507],
             [112.2507],
             [112.2508],
             [112.2505]],

            [[112.2496],
             [111.9916],
             [112.2494],
             [111.9917]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9738, 447.9756, 447.9736,  ..., 447.9702, 449.0027, 448.4822],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9738, 447.9756, 447.9736,  ..., 447.9702, 449.0027, 448.4822],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9937],
             [111.9954],
             [112.0008],
             [111.9954]],

            [[111.9969],
             [111.9969],
             [111.9970],
             [111.9970]],

            [[111.9954],
             [111.9964],
             [111.9967],
             [111.9967]],

            ...,

            [[112.2481],
             [112.2481],
             [112.2481],
             [112.2481]],

            [[111.9966],
             [111.9970],
             [111.9969],
             [111.9969]],

            [[111.9963],
             [111.9968],
             [111.9969],
             [111.9970]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9853, 447.9879, 447.9852,  ..., 448.9923, 447.9874, 447.9870],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9853, 447.9879, 447.9852,  ..., 448.9923, 447.9874, 447.9870],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[111.9983],
             [111.9973],
             [111.9981],
             [111.9981]],

            [[112.2456],
             [112.2456],
             [112.2456],
             [112.2456]],

            [[112.2383],
             [112.2376],
             [112.2455],
             [112.2453]],

            ...,

            [[112.2422],
             [112.2422],
             [112.2381],
             [112.2381]],

            [[111.9965],
             [111.9973],
             [111.9986],
             [111.9986]],

            [[111.9965],
             [111.9976],
             [111.9973],
             [111.9973]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([447.9918, 448.9825, 448.9668,  ..., 448.9605, 447.9909, 447.9886],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([447.9918, 448.9825, 448.9668,  ..., 448.9605, 447.9909, 447.9886],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0141e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0021],
             [112.2332],
             [112.2322],
             [112.0021]],

            [[112.2412],
             [112.2412],
             [112.2406],
             [112.2406]],

            [[112.0023],
             [112.0012],
             [112.0109],
             [112.0023]],

            ...,

            [[112.0037],
             [112.0029],
             [112.0032],
             [112.0037]],

            [[112.2411],
             [112.2412],
             [112.2412],
             [112.2413]],

            [[112.0021],
             [112.0031],
             [112.0022],
             [112.0031]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4696, 448.9637, 448.0167,  ..., 448.0135, 448.9647, 448.0106],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4696, 448.9637, 448.0167,  ..., 448.0135, 448.9647, 448.0106],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2407],
             [112.2407],
             [112.2401],
             [112.2401]],

            [[112.0022],
             [112.0022],
             [112.0031],
             [112.0031]],

            [[112.2397],
             [112.2397],
             [112.2388],
             [112.2388]],

            ...,

            [[112.0584],
             [112.0018],
             [112.0072],
             [112.0022]],

            [[112.2403],
             [112.2404],
             [112.0015],
             [112.0015]],

            [[112.0038],
             [112.0038],
             [112.0037],
             [112.0037]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9616, 448.0107, 448.9569,  ..., 448.0696, 448.4836, 448.0150],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9616, 448.0107, 448.9569,  ..., 448.0696, 448.4836, 448.0150],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2393],
             [112.2412],
             [112.2412],
             [112.2390]],

            [[112.2391],
             [112.0019],
             [112.0037],
             [112.0037]],

            [[112.0031],
             [112.0038],
             [112.0025],
             [112.0029]],

            ...,

            [[112.2413],
             [112.2413],
             [112.2413],
             [112.2413]],

            [[112.2408],
             [112.2402],
             [112.2411],
             [112.2245]],

            [[112.0015],
             [112.0015],
             [112.0024],
             [112.0024]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9606, 448.2483, 448.0123, 448.9639, 448.0121, 448.0146, 448.9651,
            448.0146, 448.9651, 448.0130, 448.9650, 448.2489, 448.0116, 448.9651,
            448.0129, 448.0087, 448.9642, 448.0121, 448.9623, 448.0121, 448.0115,
            448.0146, 448.0131, 448.9580, 448.0142, 448.0117, 448.0140, 448.0041,
            448.5025, 448.5487, 448.0127, 448.0147, 448.0131, 448.0080, 448.0120,
            448.0131, 448.0132, 448.0121, 448.9649, 448.0108, 448.0078, 448.4781,
            448.0118, 448.0122, 448.6608, 448.0085, 448.0124, 448.0148, 448.0120,
            448.0132, 448.0120, 448.0124, 448.0124, 448.0135, 448.0128, 448.0130,
            448.0126, 448.9615, 448.9644, 448.0097, 448.9651, 448.9647, 448.0120,
            448.0130, 448.0116, 448.2435, 448.0134, 448.0149, 448.0092, 448.9648,
            448.1872, 448.0122, 448.0114, 448.0126, 448.0146, 448.0143, 448.0105,
            448.0120, 448.9632, 448.3188, 448.0123, 448.0131, 448.9532, 448.9649,
            448.0134, 448.0137, 448.0132, 448.9648, 448.0107, 448.9623, 448.0120,
            448.0114, 448.0139, 448.0146, 448.9649, 448.0121, 448.0119, 448.0121,
            448.0126, 448.9597, 448.0113, 448.0142, 448.0136, 448.2631, 448.0175,
            448.0092, 448.9100, 448.0134, 448.4780, 448.0125, 448.0118, 448.0140,
            448.0139, 448.0137, 448.7247, 448.0096, 448.0124, 448.0126, 448.2451,
            448.0114, 448.0133, 448.2334, 448.0148, 448.4788, 448.9650, 448.0136,
            448.0114, 448.9651, 448.0098, 448.9644, 448.0091, 448.9650, 448.9650,
            448.9650, 448.4829, 448.0092, 448.0126, 448.0129, 448.9624, 448.0134,
            448.0096, 448.0110, 448.0109, 448.9650, 448.9644, 448.0123, 448.0089,
            448.0137, 448.0105, 448.9651, 448.9651, 448.0086, 448.0080, 448.0073,
            448.0128, 448.8993, 448.0123, 448.0120, 448.0123, 448.0095, 448.0119,
            448.4801, 448.0148, 448.4812, 448.4811, 448.0110, 448.0123, 448.0082,
            448.4827, 448.7264, 448.0139, 448.0150, 448.0105, 448.0117, 448.4830,
            448.9633, 448.0109, 448.9635, 448.0134, 448.0086, 448.9650, 448.9648,
            448.0113, 448.0125, 448.0116, 448.0094, 448.0148, 448.0118, 448.0125,
            448.9630, 448.0118, 448.0121, 448.0111, 448.0129, 448.0138, 448.0091,
            448.0147, 448.4846, 448.0117, 448.9631, 448.9245, 448.0119, 448.9651,
            448.0095, 448.0249, 448.0121, 448.0125, 448.0096, 448.0136, 448.0125,
            448.0117, 448.0132, 448.0102, 448.0141, 448.9650, 448.0120, 448.0114,
            448.4826, 448.9594, 448.9651, 448.9369, 448.9637, 448.9378, 448.0135,
            448.0068, 448.0115, 448.6222, 448.9639, 448.0100, 448.0059, 448.0123,
            448.0130, 448.4829, 448.0121, 448.4834, 448.9402, 448.0125, 448.0150,
            448.0095, 448.0537, 448.0095, 448.0134, 448.0115, 448.4820, 448.0101,
            448.8929, 448.0101, 448.0117, 448.0133, 448.0136, 448.0140, 448.0117,
            448.0117, 448.0110, 448.4897, 448.5764, 448.9648, 448.9639, 448.0147,
            448.0123, 448.0099, 448.9619, 448.9651, 448.0146, 448.4265, 448.9650,
            448.0132, 448.0110, 448.0106, 448.0147, 448.0123, 448.0110, 448.0125,
            448.0144, 448.0880, 448.9650, 448.4834, 448.0125, 448.0131, 448.0147,
            448.0131, 448.0131, 448.0126, 448.4817, 448.0117, 448.4766, 448.0138,
            448.0124, 448.0107, 448.9633, 448.9637, 448.0136, 448.9648, 448.0147,
            448.0114, 448.0128, 448.8155, 448.0122, 448.0147, 448.2030, 448.0085,
            448.0107, 448.0121, 448.0147, 448.9634, 448.9650, 448.0129, 448.9645,
            448.0118, 448.0132, 448.0135, 448.9619, 448.0127, 448.0124, 448.9650,
            448.4829, 448.9647, 448.9651, 448.9651, 448.0126, 448.0085, 448.0120,
            448.0150, 448.0118, 448.0081, 448.0142, 448.0126, 448.0063, 448.0119,
            448.9527, 448.0068, 448.0120, 448.0146, 448.0125, 448.9651, 448.0139,
            448.4844, 448.9648, 448.0146, 448.0126, 448.0103, 448.9651, 448.0123,
            448.0147, 448.0118, 448.0126, 448.0123, 448.9641, 448.0143, 448.0131,
            448.0115, 448.9650, 448.0142, 448.0069, 448.9651, 448.0117, 448.9650,
            448.0135, 448.0102, 448.9626, 448.1002, 448.0096, 448.0120, 448.9392,
            448.7108, 448.0128, 448.0123, 448.0122, 448.0138, 448.9651, 448.0137,
            448.0108, 448.0108, 448.0121, 448.9651, 448.2445, 448.0123, 448.0129,
            448.9587, 448.0138, 448.0068, 448.9568, 448.4825, 448.0126, 448.0115,
            448.0096, 448.0072, 448.9650, 448.0118, 448.0122, 448.4637, 448.0148,
            448.9558, 448.0124, 448.0134, 448.0134, 448.4751, 448.9600, 448.0112,
            448.9619, 448.0121, 448.0109, 448.6704, 448.0135, 448.9448, 448.0097,
            448.9539, 448.9636, 448.0139, 448.5518, 448.0129, 448.0112, 448.0121,
            448.0099, 448.0112, 448.4789, 448.0120, 448.0086, 448.9651, 448.0085,
            448.0229, 448.7492, 448.9643, 448.0117, 448.9522, 448.9651, 448.9633,
            448.0139, 448.0115, 448.0148, 448.0141, 448.9625, 448.0112, 448.9651,
            448.0138, 448.0042, 448.0087, 448.0117, 448.0148, 448.0120, 448.0109,
            448.0128, 448.9568, 448.0107, 448.0127, 448.9651, 448.0121, 448.9651,
            448.0100, 448.0123, 448.0115, 448.2434, 448.4829, 448.9262, 448.0119,
            448.9651, 448.0074, 448.9650, 448.9651, 448.0148, 448.0096, 448.2308,
            448.0094, 448.0114, 448.2437, 448.0124, 448.9651, 448.4752, 448.9651,
            448.0092, 448.0120, 448.0150, 448.0134, 448.0120, 448.0146, 448.0087,
            448.0147, 448.2014, 448.6804, 448.9651, 448.0124, 448.9364, 448.0123,
            448.9648, 448.0119, 448.0075, 448.0089, 448.9651, 448.0125, 448.9651,
            448.0147, 448.0148, 448.0117, 448.0126, 448.0145, 448.0087, 448.0102,
            448.0133, 448.0122, 448.9651, 448.9641, 448.0147, 448.9649, 448.0125,
            448.9650, 448.0129, 448.0137, 448.0123, 448.0116, 448.0105, 448.9651,
            448.0117, 448.0127, 448.0131, 448.0396, 448.0123, 448.9648, 448.0125,
            448.0104, 448.9647, 448.0063, 448.0147, 448.0126, 448.0121, 448.0131,
            448.0101, 448.0146, 448.9639, 448.0149, 448.0119, 448.0147, 448.0100,
            448.7165, 448.9651, 448.9651, 448.0142, 448.0241, 448.0134, 448.0139,
            448.0074, 448.0105, 448.0141, 448.2434, 448.0121, 448.0099, 448.0114,
            448.0140, 448.0132, 448.0115, 448.0146, 448.0120, 448.0122, 448.0120,
            448.9651, 448.0141, 448.4829, 448.0131, 448.0117, 448.9647, 448.0061,
            448.9651, 448.0136, 448.0116, 448.9651, 448.9650, 448.0147, 448.0126,
            448.0107, 448.9635, 448.9651, 448.0114, 448.0114, 448.0122, 448.4830,
            448.0118, 448.0120, 448.0121, 448.0091, 448.9651, 448.0117, 448.0119,
            448.0137, 448.0138, 448.0090, 448.0121, 448.0141, 448.9651, 448.0126,
            448.9641, 448.0109, 448.0117, 448.0092, 448.0120, 448.0123, 448.0058,
            448.9651, 448.4830, 448.0071, 448.4014, 448.0112, 448.0107, 448.0119,
            448.0123, 448.9615, 448.0129, 448.0118, 448.0120, 448.9651, 448.0129,
            448.0112, 448.0124, 448.0146, 448.0137, 448.0130, 448.6766, 448.0102,
            448.8687, 448.9651, 448.0096, 448.9649, 448.0111, 448.9606, 448.9649,
            448.0139, 448.0120, 448.0121, 448.0129, 448.4636, 448.0100, 448.7176,
            448.0148, 448.0123, 448.0105, 448.9651, 448.0141, 448.0113, 448.0137,
            448.0147, 448.9524, 448.0137, 448.0125, 448.8569, 448.0111, 448.2440,
            448.0135, 448.0228, 448.9650, 448.0123, 448.0107, 448.0141, 448.0082,
            448.0148, 448.0119, 448.0144, 448.0137, 448.0047, 448.4772, 448.9612,
            448.9651, 448.0113, 448.0244, 448.9634, 448.9635, 448.0103, 448.0127,
            448.7206, 448.0090, 448.9613, 448.0112, 448.4831, 448.0137, 448.9651,
            448.9437, 448.0098, 448.9651, 448.9564, 448.2472, 448.0129, 448.0077,
            448.0054, 448.0125, 448.0120, 448.9591, 448.0120, 448.0112, 448.9329,
            448.9016, 448.9613, 448.0138, 448.9648, 448.0148, 448.0106, 448.0092,
            448.0128, 448.0126, 448.0135, 448.2557, 448.0122, 448.0121, 448.0118,
            448.9650, 448.0123, 448.0124, 448.0097, 448.0121, 448.0797, 448.9651,
            448.0121, 448.0119, 448.0128, 448.0133, 448.6754, 448.0121, 448.0130,
            448.9651, 448.0073, 448.0122, 448.0083, 448.0117, 448.0140, 448.0106,
            448.4822, 448.0081, 448.4787, 448.0121, 448.9651, 448.0148, 448.9644,
            448.0120, 448.0147, 448.0102, 448.0121, 448.0136, 448.0102, 448.9608,
            448.0084, 448.0134, 448.2762, 448.0140, 448.0130, 448.0104, 448.0120,
            448.0089, 448.9651, 448.0096, 448.0122, 448.0126, 448.0069, 448.0128,
            448.0141, 448.0148, 448.0103, 448.0122, 448.0150, 448.0150, 448.0098,
            448.2435, 448.2247, 448.0126, 448.0095, 448.0149, 448.0142, 448.9609,
            448.0110, 448.0108, 448.0115, 448.0076, 448.0073, 448.0077, 448.0092,
            448.9626, 448.0140, 448.0129, 448.0144, 448.1583, 448.0066, 448.9648,
            448.0135, 448.0147, 448.0092, 448.0113, 448.0138, 448.9649, 448.3412,
            448.0120, 448.0064, 448.0121, 448.9574, 448.0101, 448.0103, 448.0118,
            448.0143, 448.9651, 448.0145, 448.0133, 448.0079, 448.9651, 448.0136,
            448.4825, 448.0123, 448.4685, 448.0139, 448.0109, 448.0133, 448.1702,
            448.0121, 448.0099, 448.0067, 448.9651, 448.4830, 448.0147, 448.0135,
            448.4830, 448.0128, 448.9651, 448.0071, 448.9648, 448.0064, 448.9651,
            448.9651, 448.0077, 448.0100, 448.0134, 448.0106, 448.0114, 448.0137,
            448.9634, 448.9651, 448.0133, 448.0130, 448.0109, 448.4587, 448.0064,
            448.9648, 448.0124, 448.0211, 448.0110, 448.0112, 448.0121, 448.9648,
            448.9651, 448.0547, 448.0096, 448.9650, 448.0105, 448.9479, 448.0117,
            448.0122, 448.4830, 448.0098, 448.0149, 448.0140, 448.9633, 448.0131,
            448.0147, 448.0139, 448.1573, 448.0121, 448.0147, 448.0123, 448.0106,
            448.9651, 448.0099, 448.9635, 448.0106, 448.0150, 448.0068, 448.4047,
            448.0121, 448.0118, 448.0147, 448.9634, 448.0131, 448.0148, 448.0147,
            448.0115, 448.4836, 448.0135, 448.0117, 448.0134, 448.0129, 448.0140,
            448.0124, 448.0147, 448.9598, 448.0146, 448.4824, 448.0119, 448.9508,
            448.0150, 448.0147, 448.9546, 448.2360, 448.9651, 448.0108, 448.0088,
            448.0124, 448.9634, 448.4979, 448.0148, 448.4802, 448.9510, 448.0092,
            448.0129, 448.9651, 448.9619, 448.6973, 448.0140, 448.9086, 448.0106,
            448.9643, 448.0067, 448.0112, 448.9648, 448.0131, 448.4830, 448.0101,
            448.9649, 448.0070, 448.9623, 448.0147, 448.0144, 448.9518, 448.9651,
            448.9466, 448.0079], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9606, 448.2483, 448.0123, 448.9639, 448.0121, 448.0146, 448.9651,
        448.0146, 448.9651, 448.0130, 448.9650, 448.2489, 448.0116, 448.9651,
        448.0129, 448.0087, 448.9642, 448.0121, 448.9623, 448.0121, 448.0115,
        448.0146, 448.0131, 448.9580, 448.0142, 448.0117, 448.0140, 448.0041,
        448.5025, 448.5487, 448.0127, 448.0147, 448.0131, 448.0080, 448.0120,
        448.0131, 448.0132, 448.0121, 448.9649, 448.0108, 448.0078, 448.4781,
        448.0118, 448.0122, 448.6608, 448.0085, 448.0124, 448.0148, 448.0120,
        448.0132, 448.0120, 448.0124, 448.0124, 448.0135, 448.0128, 448.0130,
        448.0126, 448.9615, 448.9644, 448.0097, 448.9651, 448.9647, 448.0120,
        448.0130, 448.0116, 448.2435, 448.0134, 448.0149, 448.0092, 448.9648,
        448.1872, 448.0122, 448.0114, 448.0126, 448.0146, 448.0143, 448.0105,
        448.0120, 448.9632, 448.3188, 448.0123, 448.0131, 448.9532, 448.9649,
        448.0134, 448.0137, 448.0132, 448.9648, 448.0107, 448.9623, 448.0120,
        448.0114, 448.0139, 448.0146, 448.9649, 448.0121, 448.0119, 448.0121,
        448.0126, 448.9597, 448.0113, 448.0142, 448.0136, 448.2631, 448.0175,
        448.0092, 448.9100, 448.0134, 448.4780, 448.0125, 448.0118, 448.0140,
        448.0139, 448.0137, 448.7247, 448.0096, 448.0124, 448.0126, 448.2451,
        448.0114, 448.0133, 448.2334, 448.0148, 448.4788, 448.9650, 448.0136,
        448.0114, 448.9651, 448.0098, 448.9644, 448.0091, 448.9650, 448.9650,
        448.9650, 448.4829, 448.0092, 448.0126, 448.0129, 448.9624, 448.0134,
        448.0096, 448.0110, 448.0109, 448.9650, 448.9644, 448.0123, 448.0089,
        448.0137, 448.0105, 448.9651, 448.9651, 448.0086, 448.0080, 448.0073,
        448.0128, 448.8993, 448.0123, 448.0120, 448.0123, 448.0095, 448.0119,
        448.4801, 448.0148, 448.4812, 448.4811, 448.0110, 448.0123, 448.0082,
        448.4827, 448.7264, 448.0139, 448.0150, 448.0105, 448.0117, 448.4830,
        448.9633, 448.0109, 448.9635, 448.0134, 448.0086, 448.9650, 448.9648,
        448.0113, 448.0125, 448.0116, 448.0094, 448.0148, 448.0118, 448.0125,
        448.9630, 448.0118, 448.0121, 448.0111, 448.0129, 448.0138, 448.0091,
        448.0147, 448.4846, 448.0117, 448.9631, 448.9245, 448.0119, 448.9651,
        448.0095, 448.0249, 448.0121, 448.0125, 448.0096, 448.0136, 448.0125,
        448.0117, 448.0132, 448.0102, 448.0141, 448.9650, 448.0120, 448.0114,
        448.4826, 448.9594, 448.9651, 448.9369, 448.9637, 448.9378, 448.0135,
        448.0068, 448.0115, 448.6222, 448.9639, 448.0100, 448.0059, 448.0123,
        448.0130, 448.4829, 448.0121, 448.4834, 448.9402, 448.0125, 448.0150,
        448.0095, 448.0537, 448.0095, 448.0134, 448.0115, 448.4820, 448.0101,
        448.8929, 448.0101, 448.0117, 448.0133, 448.0136, 448.0140, 448.0117,
        448.0117, 448.0110, 448.4897, 448.5764, 448.9648, 448.9639, 448.0147,
        448.0123, 448.0099, 448.9619, 448.9651, 448.0146, 448.4265, 448.9650,
        448.0132, 448.0110, 448.0106, 448.0147, 448.0123, 448.0110, 448.0125,
        448.0144, 448.0880, 448.9650, 448.4834, 448.0125, 448.0131, 448.0147,
        448.0131, 448.0131, 448.0126, 448.4817, 448.0117, 448.4766, 448.0138,
        448.0124, 448.0107, 448.9633, 448.9637, 448.0136, 448.9648, 448.0147,
        448.0114, 448.0128, 448.8155, 448.0122, 448.0147, 448.2030, 448.0085,
        448.0107, 448.0121, 448.0147, 448.9634, 448.9650, 448.0129, 448.9645,
        448.0118, 448.0132, 448.0135, 448.9619, 448.0127, 448.0124, 448.9650,
        448.4829, 448.9647, 448.9651, 448.9651, 448.0126, 448.0085, 448.0120,
        448.0150, 448.0118, 448.0081, 448.0142, 448.0126, 448.0063, 448.0119,
        448.9527, 448.0068, 448.0120, 448.0146, 448.0125, 448.9651, 448.0139,
        448.4844, 448.9648, 448.0146, 448.0126, 448.0103, 448.9651, 448.0123,
        448.0147, 448.0118, 448.0126, 448.0123, 448.9641, 448.0143, 448.0131,
        448.0115, 448.9650, 448.0142, 448.0069, 448.9651, 448.0117, 448.9650,
        448.0135, 448.0102, 448.9626, 448.1002, 448.0096, 448.0120, 448.9392,
        448.7108, 448.0128, 448.0123, 448.0122, 448.0138, 448.9651, 448.0137,
        448.0108, 448.0108, 448.0121, 448.9651, 448.2445, 448.0123, 448.0129,
        448.9587, 448.0138, 448.0068, 448.9568, 448.4825, 448.0126, 448.0115,
        448.0096, 448.0072, 448.9650, 448.0118, 448.0122, 448.4637, 448.0148,
        448.9558, 448.0124, 448.0134, 448.0134, 448.4751, 448.9600, 448.0112,
        448.9619, 448.0121, 448.0109, 448.6704, 448.0135, 448.9448, 448.0097,
        448.9539, 448.9636, 448.0139, 448.5518, 448.0129, 448.0112, 448.0121,
        448.0099, 448.0112, 448.4789, 448.0120, 448.0086, 448.9651, 448.0085,
        448.0229, 448.7492, 448.9643, 448.0117, 448.9522, 448.9651, 448.9633,
        448.0139, 448.0115, 448.0148, 448.0141, 448.9625, 448.0112, 448.9651,
        448.0138, 448.0042, 448.0087, 448.0117, 448.0148, 448.0120, 448.0109,
        448.0128, 448.9568, 448.0107, 448.0127, 448.9651, 448.0121, 448.9651,
        448.0100, 448.0123, 448.0115, 448.2434, 448.4829, 448.9262, 448.0119,
        448.9651, 448.0074, 448.9650, 448.9651, 448.0148, 448.0096, 448.2308,
        448.0094, 448.0114, 448.2437, 448.0124, 448.9651, 448.4752, 448.9651,
        448.0092, 448.0120, 448.0150, 448.0134, 448.0120, 448.0146, 448.0087,
        448.0147, 448.2014, 448.6804, 448.9651, 448.0124, 448.9364, 448.0123,
        448.9648, 448.0119, 448.0075, 448.0089, 448.9651, 448.0125, 448.9651,
        448.0147, 448.0148, 448.0117, 448.0126, 448.0145, 448.0087, 448.0102,
        448.0133, 448.0122, 448.9651, 448.9641, 448.0147, 448.9649, 448.0125,
        448.9650, 448.0129, 448.0137, 448.0123, 448.0116, 448.0105, 448.9651,
        448.0117, 448.0127, 448.0131, 448.0396, 448.0123, 448.9648, 448.0125,
        448.0104, 448.9647, 448.0063, 448.0147, 448.0126, 448.0121, 448.0131,
        448.0101, 448.0146, 448.9639, 448.0149, 448.0119, 448.0147, 448.0100,
        448.7165, 448.9651, 448.9651, 448.0142, 448.0241, 448.0134, 448.0139,
        448.0074, 448.0105, 448.0141, 448.2434, 448.0121, 448.0099, 448.0114,
        448.0140, 448.0132, 448.0115, 448.0146, 448.0120, 448.0122, 448.0120,
        448.9651, 448.0141, 448.4829, 448.0131, 448.0117, 448.9647, 448.0061,
        448.9651, 448.0136, 448.0116, 448.9651, 448.9650, 448.0147, 448.0126,
        448.0107, 448.9635, 448.9651, 448.0114, 448.0114, 448.0122, 448.4830,
        448.0118, 448.0120, 448.0121, 448.0091, 448.9651, 448.0117, 448.0119,
        448.0137, 448.0138, 448.0090, 448.0121, 448.0141, 448.9651, 448.0126,
        448.9641, 448.0109, 448.0117, 448.0092, 448.0120, 448.0123, 448.0058,
        448.9651, 448.4830, 448.0071, 448.4014, 448.0112, 448.0107, 448.0119,
        448.0123, 448.9615, 448.0129, 448.0118, 448.0120, 448.9651, 448.0129,
        448.0112, 448.0124, 448.0146, 448.0137, 448.0130, 448.6766, 448.0102,
        448.8687, 448.9651, 448.0096, 448.9649, 448.0111, 448.9606, 448.9649,
        448.0139, 448.0120, 448.0121, 448.0129, 448.4636, 448.0100, 448.7176,
        448.0148, 448.0123, 448.0105, 448.9651, 448.0141, 448.0113, 448.0137,
        448.0147, 448.9524, 448.0137, 448.0125, 448.8569, 448.0111, 448.2440,
        448.0135, 448.0228, 448.9650, 448.0123, 448.0107, 448.0141, 448.0082,
        448.0148, 448.0119, 448.0144, 448.0137, 448.0047, 448.4772, 448.9612,
        448.9651, 448.0113, 448.0244, 448.9634, 448.9635, 448.0103, 448.0127,
        448.7206, 448.0090, 448.9613, 448.0112, 448.4831, 448.0137, 448.9651,
        448.9437, 448.0098, 448.9651, 448.9564, 448.2472, 448.0129, 448.0077,
        448.0054, 448.0125, 448.0120, 448.9591, 448.0120, 448.0112, 448.9329,
        448.9016, 448.9613, 448.0138, 448.9648, 448.0148, 448.0106, 448.0092,
        448.0128, 448.0126, 448.0135, 448.2557, 448.0122, 448.0121, 448.0118,
        448.9650, 448.0123, 448.0124, 448.0097, 448.0121, 448.0797, 448.9651,
        448.0121, 448.0119, 448.0128, 448.0133, 448.6754, 448.0121, 448.0130,
        448.9651, 448.0073, 448.0122, 448.0083, 448.0117, 448.0140, 448.0106,
        448.4822, 448.0081, 448.4787, 448.0121, 448.9651, 448.0148, 448.9644,
        448.0120, 448.0147, 448.0102, 448.0121, 448.0136, 448.0102, 448.9608,
        448.0084, 448.0134, 448.2762, 448.0140, 448.0130, 448.0104, 448.0120,
        448.0089, 448.9651, 448.0096, 448.0122, 448.0126, 448.0069, 448.0128,
        448.0141, 448.0148, 448.0103, 448.0122, 448.0150, 448.0150, 448.0098,
        448.2435, 448.2247, 448.0126, 448.0095, 448.0149, 448.0142, 448.9609,
        448.0110, 448.0108, 448.0115, 448.0076, 448.0073, 448.0077, 448.0092,
        448.9626, 448.0140, 448.0129, 448.0144, 448.1583, 448.0066, 448.9648,
        448.0135, 448.0147, 448.0092, 448.0113, 448.0138, 448.9649, 448.3412,
        448.0120, 448.0064, 448.0121, 448.9574, 448.0101, 448.0103, 448.0118,
        448.0143, 448.9651, 448.0145, 448.0133, 448.0079, 448.9651, 448.0136,
        448.4825, 448.0123, 448.4685, 448.0139, 448.0109, 448.0133, 448.1702,
        448.0121, 448.0099, 448.0067, 448.9651, 448.4830, 448.0147, 448.0135,
        448.4830, 448.0128, 448.9651, 448.0071, 448.9648, 448.0064, 448.9651,
        448.9651, 448.0077, 448.0100, 448.0134, 448.0106, 448.0114, 448.0137,
        448.9634, 448.9651, 448.0133, 448.0130, 448.0109, 448.4587, 448.0064,
        448.9648, 448.0124, 448.0211, 448.0110, 448.0112, 448.0121, 448.9648,
        448.9651, 448.0547, 448.0096, 448.9650, 448.0105, 448.9479, 448.0117,
        448.0122, 448.4830, 448.0098, 448.0149, 448.0140, 448.9633, 448.0131,
        448.0147, 448.0139, 448.1573, 448.0121, 448.0147, 448.0123, 448.0106,
        448.9651, 448.0099, 448.9635, 448.0106, 448.0150, 448.0068, 448.4047,
        448.0121, 448.0118, 448.0147, 448.9634, 448.0131, 448.0148, 448.0147,
        448.0115, 448.4836, 448.0135, 448.0117, 448.0134, 448.0129, 448.0140,
        448.0124, 448.0147, 448.9598, 448.0146, 448.4824, 448.0119, 448.9508,
        448.0150, 448.0147, 448.9546, 448.2360, 448.9651, 448.0108, 448.0088,
        448.0124, 448.9634, 448.4979, 448.0148, 448.4802, 448.9510, 448.0092,
        448.0129, 448.9651, 448.9619, 448.6973, 448.0140, 448.9086, 448.0106,
        448.9643, 448.0067, 448.0112, 448.9648, 448.0131, 448.4830, 448.0101,
        448.9649, 448.0070, 448.9623, 448.0147, 448.0144, 448.9518, 448.9651,
        448.9466, 448.0079], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([402.4187], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0021],
             [112.0027],
             [112.0023],
             [112.0023]],

            [[112.2413],
             [112.2413],
             [112.2413],
             [112.2413]],

            [[112.0037],
             [112.0026],
             [112.0023],
             [112.0036]],

            ...,

            [[112.0025],
             [112.0037],
             [112.0023],
             [112.0025]],

            [[112.0035],
             [112.0024],
             [112.0021],
             [112.0037]],

            [[112.2408],
             [112.2408],
             [112.2407],
             [112.2407]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0094, 448.9651, 448.0123,  ..., 448.0109, 448.0117, 448.9630],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0094, 448.9651, 448.0123,  ..., 448.0109, 448.0117, 448.9630],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0060],
             [112.0060],
             [112.0063],
             [112.0063]],

            [[112.2384],
             [112.2228],
             [112.2384],
             [112.2246]],

            [[112.2374],
             [112.0042],
             [112.2307],
             [112.2307]],

            ...,

            [[112.0049],
             [112.0053],
             [112.0044],
             [112.0044]],

            [[112.0052],
             [112.0052],
             [112.0052],
             [112.0052]],

            [[112.0036],
             [112.0034],
             [112.0048],
             [112.0047]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0246, 448.9242, 448.7029,  ..., 448.0190, 448.0208, 448.0165],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0246, 448.9242, 448.7029,  ..., 448.0190, 448.0208, 448.0165],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2356],
             [112.2356],
             [112.2356],
             [112.2356]],

            [[112.0083],
             [112.0083],
             [112.0083],
             [112.0083]],

            [[112.2355],
             [112.2355],
             [112.2356],
             [112.2353]],

            ...,

            [[112.0080],
             [112.0086],
             [112.0080],
             [112.0086]],

            [[112.2355],
             [112.2319],
             [112.2328],
             [112.2328]],

            [[112.2356],
             [112.2354],
             [112.2355],
             [112.2355]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9423, 448.0331, 448.9419,  ..., 448.0332, 448.9329, 448.9420],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9423, 448.0331, 448.9419,  ..., 448.0332, 448.9329, 448.9420],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0119],
             [112.0127],
             [112.0119],
             [112.0119]],

            [[112.0128],
             [112.0128],
             [112.0128],
             [112.0128]],

            [[112.0125],
             [112.0125],
             [112.0132],
             [112.0139]],

            ...,

            [[112.0127],
             [112.0127],
             [112.0139],
             [112.0139]],

            [[112.0127],
             [112.0124],
             [112.0126],
             [112.0122]],

            [[112.0127],
             [112.0127],
             [112.0135],
             [112.0135]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0485, 448.0513, 448.0520,  ..., 448.0532, 448.0498, 448.0524],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0485, 448.0513, 448.0520,  ..., 448.0532, 448.0498, 448.0524],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0191],
             [112.0197],
             [112.0192],
             [112.0192]],

            [[112.0193],
             [112.0198],
             [112.0194],
             [112.0202]],

            [[112.0202],
             [112.0202],
             [112.0203],
             [112.0203]],

            ...,

            [[112.2225],
             [112.2229],
             [112.2229],
             [112.2226]],

            [[112.0192],
             [112.0200],
             [112.0202],
             [112.0202]],

            [[112.2229],
             [112.2229],
             [112.2229],
             [112.2229]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.0773, 448.0787, 448.0809,  ..., 448.8909, 448.0796, 448.8916],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.0773, 448.0787, 448.0809,  ..., 448.8909, 448.0796, 448.8916],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0260],
             [112.0260],
             [112.0270],
             [112.0264]],

            [[112.0266],
             [112.0270],
             [112.0259],
             [112.0260]],

            [[112.0269],
             [112.0269],
             [112.0269],
             [112.0269]],

            ...,

            [[112.2146],
             [112.0259],
             [112.0255],
             [112.0255]],

            [[112.0266],
             [112.0267],
             [112.0269],
             [112.0270]],

            [[112.0270],
             [112.0265],
             [112.0267],
             [112.0267]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1053, 448.1055, 448.1076,  ..., 448.2914, 448.1072, 448.1068],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1053, 448.1055, 448.1076,  ..., 448.2914, 448.1072, 448.1068],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0330],
             [112.0330],
             [112.0329],
             [112.0329]],

            [[112.0328],
             [112.0329],
             [112.0333],
             [112.0335]],

            [[112.0332],
             [112.0334],
             [112.0326],
             [112.0326]],

            ...,

            [[112.0324],
             [112.0334],
             [112.0335],
             [112.0326]],

            [[112.0324],
             [112.0326],
             [112.1759],
             [112.1759]],

            [[112.1645],
             [112.1645],
             [112.0326],
             [112.0326]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1317, 448.1325, 448.1318,  ..., 448.1318, 448.4167, 448.3941],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1317, 448.1325, 448.1318,  ..., 448.1318, 448.4167, 448.3941],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0445],
             [112.0446],
             [112.0445],
             [112.0446]],

            [[112.0444],
             [112.0444],
             [112.0450],
             [112.0442]],

            [[112.0440],
             [112.0442],
             [112.0440],
             [112.0442]],

            ...,

            [[112.0447],
             [112.0443],
             [112.0444],
             [112.0444]],

            [[112.0440],
             [112.1939],
             [112.0440],
             [112.0440]],

            [[112.1991],
             [112.1991],
             [112.1991],
             [112.1991]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1783, 448.1780, 448.1765,  ..., 448.1779, 448.3260, 448.7963],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1783, 448.1780, 448.1765,  ..., 448.1779, 448.3260, 448.7963],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1912],
             [112.0506],
             [112.1912],
             [112.0506]],

            [[112.1927],
             [112.1927],
             [112.1927],
             [112.1927]],

            [[112.1927],
             [112.1926],
             [112.1927],
             [112.1927]],

            ...,

            [[112.1927],
             [112.1915],
             [112.1925],
             [112.1925]],

            [[112.0510],
             [112.0510],
             [112.0506],
             [112.0511]],

            [[112.0510],
             [112.0510],
             [112.0512],
             [112.0512]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4836, 448.7707, 448.7706,  ..., 448.7691, 448.2037, 448.2045],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4836, 448.7707, 448.7706,  ..., 448.7691, 448.2037, 448.2045],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0563],
             [112.0564],
             [112.0563],
             [112.0565]],

            [[112.0564],
             [112.1861],
             [112.1803],
             [112.0573]],

            [[112.1864],
             [112.1864],
             [112.0566],
             [112.0566]],

            ...,

            [[112.1865],
             [112.1865],
             [112.1865],
             [112.1865]],

            [[112.1865],
             [112.1865],
             [112.1865],
             [112.1865]],

            [[112.1616],
             [112.1616],
             [112.0563],
             [112.0563]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2255, 448.4801, 448.4861,  ..., 448.7459, 448.7459, 448.4358],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2255, 448.4801, 448.4861,  ..., 448.7459, 448.7459, 448.4358],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0631],
             [112.0632],
             [112.0632],
             [112.0632]],

            [[112.1797],
             [112.1797],
             [112.1797],
             [112.1797]],

            [[112.0632],
             [112.0630],
             [112.0630],
             [112.0632]],

            ...,

            [[112.0632],
             [112.0630],
             [112.0631],
             [112.0632]],

            [[112.0629],
             [112.0630],
             [112.0630],
             [112.0633]],

            [[112.0631],
             [112.0630],
             [112.0634],
             [112.0631]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2527, 448.7189, 448.2525,  ..., 448.2525, 448.2521, 448.2526],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2527, 448.7189, 448.2525,  ..., 448.2525, 448.2521, 448.2526],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0696],
             [112.0696],
             [112.0697],
             [112.0697]],

            [[112.0707],
             [112.0695],
             [112.0695],
             [112.0695]],

            [[112.1732],
             [112.1732],
             [112.1732],
             [112.1732]],

            ...,

            [[112.0703],
             [112.0695],
             [112.0695],
             [112.0695]],

            [[112.0697],
             [112.0697],
             [112.0695],
             [112.0695]],

            [[112.0696],
             [112.0696],
             [112.0696],
             [112.0698]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2785, 448.2792, 448.6930,  ..., 448.2789, 448.2785, 448.2787],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2785, 448.2792, 448.6930,  ..., 448.2789, 448.2785, 448.2787],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1460],
             [112.0750],
             [112.1351],
             [112.0747]],

            [[112.0748],
             [112.0748],
             [112.0746],
             [112.0746]],

            [[112.0748],
             [112.0756],
             [112.0747],
             [112.0747]],

            ...,

            [[112.0748],
             [112.0748],
             [112.0747],
             [112.0747]],

            [[112.0747],
             [112.0747],
             [112.0747],
             [112.0747]],

            [[112.0747],
             [112.0747],
             [112.0746],
             [112.0746]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4308, 448.2988, 448.2999,  ..., 448.2990, 448.2988, 448.2986],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4308, 448.2988, 448.2999,  ..., 448.2990, 448.2988, 448.2986],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0780],
             [112.0780],
             [112.0778],
             [112.0778]],

            [[112.1636],
             [112.1636],
             [112.1636],
             [112.1636]],

            [[112.0780],
             [112.0780],
             [112.0780],
             [112.0780]],

            ...,

            [[112.0782],
             [112.0782],
             [112.0781],
             [112.0781]],

            [[112.0781],
             [112.0778],
             [112.0781],
             [112.0781]],

            [[112.0781],
             [112.0781],
             [112.0780],
             [112.0780]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3116, 448.6545, 448.3121,  ..., 448.3126, 448.3121, 448.3123],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3116, 448.6545, 448.3121,  ..., 448.3126, 448.3121, 448.3123],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1633],
             [112.1633],
             [112.1633],
             [112.1633]],

            [[112.0763],
             [112.0763],
             [112.0764],
             [112.0760]],

            [[112.0763],
             [112.0763],
             [112.0764],
             [112.0763]],

            ...,

            [[112.0763],
             [112.0763],
             [112.0764],
             [112.0761]],

            [[112.1633],
             [112.1633],
             [112.1633],
             [112.1633]],

            [[112.1619],
             [112.1633],
             [112.1633],
             [112.0776]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6530, 448.3051, 448.3054,  ..., 448.3051, 448.6530, 448.5660],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6530, 448.3051, 448.3054,  ..., 448.3051, 448.6530, 448.5660],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0727],
             [112.0724],
             [112.0727],
             [112.0724]],

            [[112.0727],
             [112.0727],
             [112.0728],
             [112.0723]],

            [[112.0727],
             [112.0726],
             [112.0727],
             [112.0725]],

            ...,

            [[112.0727],
             [112.0727],
             [112.0726],
             [112.0726]],

            [[112.1533],
             [112.1533],
             [112.1366],
             [112.1366]],

            [[112.0726],
             [112.0726],
             [112.0727],
             [112.0723]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2902, 448.2904, 448.2904,  ..., 448.2907, 448.5798, 448.2902],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2902, 448.2904, 448.2904,  ..., 448.2907, 448.5798, 448.2902],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0670],
             [112.0670],
             [112.0670],
             [112.0670]],

            [[112.1721],
             [112.1715],
             [112.1721],
             [112.1715]],

            [[112.1721],
             [112.1720],
             [112.1721],
             [112.1721]],

            ...,

            [[112.1707],
             [112.0670],
             [112.0665],
             [112.0665]],

            [[112.0669],
             [112.0666],
             [112.0668],
             [112.0667]],

            [[112.0664],
             [112.0664],
             [112.0664],
             [112.0664]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2680, 448.6870, 448.6882,  ..., 448.3707, 448.2670, 448.2657],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2680, 448.6870, 448.6882,  ..., 448.3707, 448.2670, 448.2657],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0668],
             [112.0668],
             [112.0666],
             [112.0666]],

            [[112.0659],
             [112.0659],
             [112.0663],
             [112.0663]],

            [[112.0667],
             [112.0664],
             [112.0668],
             [112.0661]],

            ...,

            [[112.0667],
             [112.0661],
             [112.0668],
             [112.0667]],

            [[112.1728],
             [112.1707],
             [112.0655],
             [112.0655]],

            [[112.1728],
             [112.1679],
             [112.1727],
             [112.1727]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2668, 448.2643, 448.2661,  ..., 448.2664, 448.4745, 448.6861],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2668, 448.2643, 448.2661,  ..., 448.2664, 448.4745, 448.6861],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0009e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0659],
             [112.0659],
             [112.0659],
             [112.0659]],

            [[112.0657],
             [112.0650],
             [112.0659],
             [112.0658]],

            [[112.0658],
             [112.0658],
             [112.0651],
             [112.0651]],

            ...,

            [[112.0658],
             [112.0655],
             [112.0658],
             [112.0655]],

            [[112.0656],
             [112.0656],
             [112.0651],
             [112.0651]],

            [[112.0657],
             [112.0657],
             [112.0658],
             [112.0658]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2635, 448.2625, 448.2619,  ..., 448.2624, 448.2614, 448.2630],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2635, 448.2625, 448.2619,  ..., 448.2624, 448.2614, 448.2630],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0656],
             [112.0656],
             [112.0655],
             [112.0655]],

            [[112.0657],
             [112.0656],
             [112.0658],
             [112.0650]],

            [[112.0655],
             [112.0659],
             [112.0653],
             [112.0653]],

            ...,

            [[112.0657],
             [112.0650],
             [112.0657],
             [112.0658]],

            [[112.0659],
             [112.0658],
             [112.0659],
             [112.0656]],

            [[112.0658],
             [112.0658],
             [112.0658],
             [112.0658]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2623, 448.2621, 448.2619,  ..., 448.2623, 448.2631, 448.2633],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2623, 448.2621, 448.2619,  ..., 448.2623, 448.2631, 448.2633],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1658],
             [112.0658],
             [112.0651],
             [112.0651]],

            [[112.1741],
             [112.1733],
             [112.1741],
             [112.1732]],

            [[112.0658],
             [112.0658],
             [112.0657],
             [112.0658]],

            ...,

            [[112.0658],
             [112.0658],
             [112.0655],
             [112.0655]],

            [[112.1741],
             [112.1686],
             [112.1737],
             [112.1737]],

            [[112.0651],
             [112.0658],
             [112.0650],
             [112.0650]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3618, 448.6947, 448.2631, 448.2623, 448.6967, 448.4672, 448.3919,
            448.2600, 448.2624, 448.2634, 448.2615, 448.2630, 448.5706, 448.2628,
            448.2636, 448.2615, 448.6966, 448.2643, 448.2608, 448.6962, 448.2634,
            448.2616, 448.6967, 448.2629, 448.2612, 448.2600, 448.2626, 448.2615,
            448.2625, 448.2632, 448.2617, 448.2632, 448.2628, 448.2733, 448.2612,
            448.2612, 448.6963, 448.4777, 448.2613, 448.2627, 448.6953, 448.2601,
            448.2625, 448.2622, 448.6962, 448.2625, 448.2574, 448.6966, 448.2624,
            448.2620, 448.6918, 448.2630, 448.3594, 448.6967, 448.4725, 448.2625,
            448.2624, 448.2623, 448.2600, 448.2623, 448.6967, 448.6967, 448.2633,
            448.2630, 448.2619, 448.2630, 448.2626, 448.2626, 448.3630, 448.2635,
            448.2617, 448.2622, 448.6967, 448.6812, 448.6966, 448.2624, 448.3522,
            448.6543, 448.2620, 448.6960, 448.2614, 448.2628, 448.2628, 448.2630,
            448.6967, 448.2617, 448.5689, 448.2624, 448.4699, 448.2625, 448.2628,
            448.5800, 448.2625, 448.6963, 448.4872, 448.6855, 448.2592, 448.2602,
            448.6967, 448.2633, 448.2627, 448.2630, 448.6967, 448.6961, 448.2623,
            448.2623, 448.6956, 448.2628, 448.2626, 448.2604, 448.2629, 448.4792,
            448.2614, 448.6967, 448.2635, 448.6934, 448.2623, 448.6967, 448.4766,
            448.6927, 448.2624, 448.2615, 448.2619, 448.2625, 448.2632, 448.2621,
            448.6792, 448.2626, 448.2880, 448.2621, 448.2614, 448.2613, 448.2614,
            448.6967, 448.2630, 448.6965, 448.2602, 448.2626, 448.6688, 448.5735,
            448.2615, 448.6960, 448.2624, 448.6966, 448.2631, 448.2624, 448.2608,
            448.2625, 448.2630, 448.6964, 448.2616, 448.6967, 448.2626, 448.6947,
            448.2614, 448.2625, 448.2625, 448.2621, 448.2609, 448.2634, 448.2623,
            448.2625, 448.6967, 448.2623, 448.2627, 448.6913, 448.2630, 448.5846,
            448.2635, 448.2814, 448.2610, 448.2630, 448.2622, 448.2603, 448.2620,
            448.2603, 448.2632, 448.2625, 448.6967, 448.2627, 448.6967, 448.2622,
            448.2620, 448.6947, 448.2599, 448.6964, 448.2636, 448.2631, 448.6966,
            448.2629, 448.2622, 448.2629, 448.2624, 448.2633, 448.6966, 448.2633,
            448.2581, 448.2620, 448.2629, 448.6967, 448.4777, 448.4721, 448.6967,
            448.2624, 448.3901, 448.2625, 448.2611, 448.5123, 448.2625, 448.2635,
            448.2624, 448.2604, 448.4709, 448.6915, 448.2611, 448.2623, 448.6960,
            448.6967, 448.6964, 448.2624, 448.6967, 448.6958, 448.2612, 448.6967,
            448.6962, 448.2628, 448.2631, 448.2624, 448.2623, 448.2676, 448.2634,
            448.6967, 448.2623, 448.2619, 448.6967, 448.2612, 448.2626, 448.6963,
            448.2614, 448.2624, 448.6967, 448.2624, 448.6964, 448.2629, 448.2615,
            448.5138, 448.3701, 448.2604, 448.2622, 448.4782, 448.2618, 448.2621,
            448.2630, 448.6967, 448.6942, 448.2633, 448.2624, 448.2600, 448.2616,
            448.2559, 448.2631, 448.2612, 448.2611, 448.2634, 448.2632, 448.2626,
            448.2614, 448.6962, 448.2615, 448.6967, 448.2610, 448.2621, 448.6967,
            448.3640, 448.2620, 448.2609, 448.2615, 448.2619, 448.2619, 448.2628,
            448.6965, 448.2623, 448.6967, 448.2631, 448.2621, 448.4769, 448.2628,
            448.6930, 448.2632, 448.6909, 448.6942, 448.2623, 448.2613, 448.2616,
            448.6853, 448.6967, 448.2622, 448.4397, 448.6918, 448.2614, 448.3124,
            448.2574, 448.2620, 448.2630, 448.5609, 448.2614, 448.6954, 448.2634,
            448.2620, 448.4726, 448.2625, 448.4779, 448.6959, 448.6967, 448.2633,
            448.2618, 448.2627, 448.4774, 448.2624, 448.2634, 448.2624, 448.2624,
            448.6967, 448.6088, 448.2625, 448.2603, 448.2623, 448.4458, 448.2632,
            448.2605, 448.3611, 448.2612, 448.4777, 448.6967, 448.2625, 448.2625,
            448.6967, 448.2633, 448.2634, 448.6967, 448.2623, 448.2620, 448.2599,
            448.6861, 448.2776, 448.6953, 448.2625, 448.2606, 448.2622, 448.2648,
            448.2623, 448.6967, 448.2624, 448.2628, 448.4780, 448.2620, 448.2622,
            448.6967, 448.2623, 448.2623, 448.2701, 448.6957, 448.2624, 448.6967,
            448.2617, 448.6519, 448.2634, 448.6967, 448.2634, 448.6967, 448.6966,
            448.2619, 448.3707, 448.6961, 448.2634, 448.2604, 448.2609, 448.2623,
            448.2613, 448.5831, 448.2626, 448.2628, 448.4774, 448.2632, 448.2633,
            448.2628, 448.6927, 448.2626, 448.2632, 448.2615, 448.2628, 448.2623,
            448.2620, 448.2623, 448.2624, 448.2621, 448.2626, 448.6967, 448.2625,
            448.2617, 448.2601, 448.6967, 448.6967, 448.2618, 448.6967, 448.2624,
            448.2620, 448.2715, 448.2617, 448.2623, 448.5847, 448.6945, 448.6906,
            448.2614, 448.6967, 448.5549, 448.5832, 448.4757, 448.2623, 448.2632,
            448.6960, 448.6949, 448.2623, 448.2624, 448.2606, 448.2627, 448.2618,
            448.4679, 448.2606, 448.5839, 448.6963, 448.2607, 448.6966, 448.2574,
            448.2625, 448.2622, 448.2628, 448.2635, 448.2621, 448.2631, 448.2625,
            448.2612, 448.2619, 448.6963, 448.2623, 448.2626, 448.2607, 448.2628,
            448.6967, 448.6958, 448.3679, 448.2625, 448.2628, 448.6967, 448.2625,
            448.2621, 448.2625, 448.2623, 448.6967, 448.6871, 448.2617, 448.2573,
            448.6966, 448.2628, 448.6960, 448.2617, 448.2622, 448.2612, 448.6959,
            448.2623, 448.6936, 448.2931, 448.6963, 448.2623, 448.2565, 448.6965,
            448.6967, 448.2613, 448.2616, 448.2606, 448.5193, 448.2633, 448.2573,
            448.2633, 448.6931, 448.6966, 448.2586, 448.6967, 448.2625, 448.6913,
            448.2615, 448.2623, 448.6015, 448.2598, 448.2632, 448.2612, 448.2613,
            448.2615, 448.2624, 448.2626, 448.2619, 448.2625, 448.6967, 448.2628,
            448.4059, 448.2632, 448.6957, 448.2616, 448.2604, 448.3715, 448.2623,
            448.6753, 448.2632, 448.2625, 448.2601, 448.2632, 448.2623, 448.6956,
            448.2633, 448.6967, 448.2628, 448.2629, 448.2627, 448.6965, 448.2608,
            448.2631, 448.2627, 448.6967, 448.2623, 448.2630, 448.2621, 448.2630,
            448.6967, 448.2629, 448.2634, 448.2634, 448.2618, 448.2635, 448.3676,
            448.6962, 448.5814, 448.2617, 448.2632, 448.2623, 448.2617, 448.6958,
            448.6966, 448.2628, 448.2632, 448.2625, 448.2622, 448.2624, 448.2626,
            448.6959, 448.6935, 448.6967, 448.2632, 448.6967, 448.2615, 448.2568,
            448.6967, 448.2631, 448.2623, 448.2623, 448.2621, 448.6967, 448.2634,
            448.6946, 448.2625, 448.4720, 448.6965, 448.2607, 448.5865, 448.6967,
            448.2622, 448.5820, 448.2623, 448.2613, 448.6880, 448.2631, 448.2633,
            448.2607, 448.2624, 448.6967, 448.2632, 448.2628, 448.2635, 448.6966,
            448.6967, 448.6967, 448.2631, 448.2629, 448.2623, 448.6967, 448.2631,
            448.2621, 448.2617, 448.2620, 448.2625, 448.2623, 448.2633, 448.2624,
            448.2626, 448.6965, 448.2629, 448.6966, 448.6955, 448.2625, 448.2625,
            448.2624, 448.2615, 448.2624, 448.2634, 448.2629, 448.2625, 448.6967,
            448.6952, 448.2641, 448.2609, 448.2623, 448.2625, 448.2609, 448.2602,
            448.2623, 448.2625, 448.2624, 448.4715, 448.2630, 448.2621, 448.6966,
            448.5832, 448.6754, 448.2623, 448.4782, 448.2633, 448.4783, 448.2606,
            448.2631, 448.2600, 448.2613, 448.2622, 448.2610, 448.6125, 448.2626,
            448.2623, 448.2634, 448.4775, 448.2625, 448.2617, 448.2633, 448.2625,
            448.6967, 448.6967, 448.2624, 448.2625, 448.2619, 448.6966, 448.2620,
            448.6967, 448.2610, 448.6959, 448.2631, 448.6967, 448.2617, 448.2621,
            448.4776, 448.2617, 448.2622, 448.2633, 448.2628, 448.2626, 448.2624,
            448.2627, 448.2615, 448.4767, 448.4784, 448.2633, 448.2633, 448.2624,
            448.2629, 448.2614, 448.2612, 448.2627, 448.2600, 448.2623, 448.2624,
            448.2622, 448.6960, 448.2619, 448.6952, 448.2624, 448.2629, 448.6953,
            448.2615, 448.2618, 448.6891, 448.6967, 448.2623, 448.6967, 448.6967,
            448.2609, 448.2629, 448.2606, 448.2621, 448.2630, 448.6947, 448.2617,
            448.6958, 448.2615, 448.6965, 448.6967, 448.2604, 448.2614, 448.2623,
            448.2573, 448.2629, 448.2617, 448.2630, 448.6922, 448.2625, 448.2623,
            448.6966, 448.6967, 448.2612, 448.2621, 448.6967, 448.2626, 448.2631,
            448.2621, 448.2634, 448.2628, 448.2625, 448.6967, 448.5854, 448.2603,
            448.5813, 448.3678, 448.2627, 448.2610, 448.2628, 448.2626, 448.6905,
            448.2603, 448.2625, 448.2629, 448.2622, 448.2626, 448.2627, 448.6966,
            448.2632, 448.2628, 448.2631, 448.2623, 448.2607, 448.5777, 448.2629,
            448.2623, 448.2622, 448.2621, 448.2625, 448.2619, 448.4280, 448.2612,
            448.4736, 448.2633, 448.2626, 448.2613, 448.5854, 448.2625, 448.2628,
            448.6967, 448.2615, 448.2628, 448.2602, 448.6962, 448.2603, 448.2632,
            448.2625, 448.2621, 448.2572, 448.2621, 448.2623, 448.2621, 448.2624,
            448.2619, 448.2633, 448.2618, 448.2625, 448.2624, 448.2622, 448.2631,
            448.2624, 448.6951, 448.2624, 448.6964, 448.6967, 448.5833, 448.2626,
            448.6958, 448.2632, 448.2610, 448.6893, 448.6966, 448.6967, 448.2622,
            448.2621, 448.6863, 448.2620, 448.2607, 448.2600, 448.4605, 448.2620,
            448.2625, 448.2603, 448.2610, 448.2632, 448.2626, 448.2634, 448.2612,
            448.2618, 448.2627, 448.6932, 448.6967, 448.2626, 448.2624, 448.2625,
            448.6967, 448.6967, 448.6966, 448.2623, 448.6966, 448.2633, 448.2633,
            448.2625, 448.6965, 448.6966, 448.2632, 448.6956, 448.2632, 448.6952,
            448.2612, 448.2627, 448.6937, 448.6963, 448.2619, 448.2632, 448.6959,
            448.6967, 448.2618, 448.2633, 448.2610, 448.4766, 448.2613, 448.2628,
            448.4485, 448.2625, 448.2623, 448.2623, 448.2623, 448.4776, 448.2614,
            448.4844, 448.6967, 448.5844, 448.3583, 448.2633, 448.2631, 448.2631,
            448.2633, 448.2625, 448.6967, 448.6967, 448.6949, 448.6964, 448.4781,
            448.2620, 448.2619, 448.6967, 448.2624, 448.2633, 448.6913, 448.6967,
            448.2623, 448.6967, 448.2624, 448.2619, 448.2634, 448.2625, 448.2628,
            448.6956, 448.2620, 448.2625, 448.2627, 448.2633, 448.5345, 448.6967,
            448.2623, 448.6967, 448.2611, 448.6927, 448.2625, 448.2626, 448.4765,
            448.2618, 448.2624, 448.4780, 448.4757, 448.2632, 448.2629, 448.2626,
            448.6967, 448.2632, 448.2629, 448.6967, 448.2633, 448.2632, 448.2623,
            448.2625, 448.6968, 448.2617, 448.2611, 448.2614, 448.6967, 448.2626,
            448.6902, 448.2610], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3618, 448.6947, 448.2631, 448.2623, 448.6967, 448.4672, 448.3919,
        448.2600, 448.2624, 448.2634, 448.2615, 448.2630, 448.5706, 448.2628,
        448.2636, 448.2615, 448.6966, 448.2643, 448.2608, 448.6962, 448.2634,
        448.2616, 448.6967, 448.2629, 448.2612, 448.2600, 448.2626, 448.2615,
        448.2625, 448.2632, 448.2617, 448.2632, 448.2628, 448.2733, 448.2612,
        448.2612, 448.6963, 448.4777, 448.2613, 448.2627, 448.6953, 448.2601,
        448.2625, 448.2622, 448.6962, 448.2625, 448.2574, 448.6966, 448.2624,
        448.2620, 448.6918, 448.2630, 448.3594, 448.6967, 448.4725, 448.2625,
        448.2624, 448.2623, 448.2600, 448.2623, 448.6967, 448.6967, 448.2633,
        448.2630, 448.2619, 448.2630, 448.2626, 448.2626, 448.3630, 448.2635,
        448.2617, 448.2622, 448.6967, 448.6812, 448.6966, 448.2624, 448.3522,
        448.6543, 448.2620, 448.6960, 448.2614, 448.2628, 448.2628, 448.2630,
        448.6967, 448.2617, 448.5689, 448.2624, 448.4699, 448.2625, 448.2628,
        448.5800, 448.2625, 448.6963, 448.4872, 448.6855, 448.2592, 448.2602,
        448.6967, 448.2633, 448.2627, 448.2630, 448.6967, 448.6961, 448.2623,
        448.2623, 448.6956, 448.2628, 448.2626, 448.2604, 448.2629, 448.4792,
        448.2614, 448.6967, 448.2635, 448.6934, 448.2623, 448.6967, 448.4766,
        448.6927, 448.2624, 448.2615, 448.2619, 448.2625, 448.2632, 448.2621,
        448.6792, 448.2626, 448.2880, 448.2621, 448.2614, 448.2613, 448.2614,
        448.6967, 448.2630, 448.6965, 448.2602, 448.2626, 448.6688, 448.5735,
        448.2615, 448.6960, 448.2624, 448.6966, 448.2631, 448.2624, 448.2608,
        448.2625, 448.2630, 448.6964, 448.2616, 448.6967, 448.2626, 448.6947,
        448.2614, 448.2625, 448.2625, 448.2621, 448.2609, 448.2634, 448.2623,
        448.2625, 448.6967, 448.2623, 448.2627, 448.6913, 448.2630, 448.5846,
        448.2635, 448.2814, 448.2610, 448.2630, 448.2622, 448.2603, 448.2620,
        448.2603, 448.2632, 448.2625, 448.6967, 448.2627, 448.6967, 448.2622,
        448.2620, 448.6947, 448.2599, 448.6964, 448.2636, 448.2631, 448.6966,
        448.2629, 448.2622, 448.2629, 448.2624, 448.2633, 448.6966, 448.2633,
        448.2581, 448.2620, 448.2629, 448.6967, 448.4777, 448.4721, 448.6967,
        448.2624, 448.3901, 448.2625, 448.2611, 448.5123, 448.2625, 448.2635,
        448.2624, 448.2604, 448.4709, 448.6915, 448.2611, 448.2623, 448.6960,
        448.6967, 448.6964, 448.2624, 448.6967, 448.6958, 448.2612, 448.6967,
        448.6962, 448.2628, 448.2631, 448.2624, 448.2623, 448.2676, 448.2634,
        448.6967, 448.2623, 448.2619, 448.6967, 448.2612, 448.2626, 448.6963,
        448.2614, 448.2624, 448.6967, 448.2624, 448.6964, 448.2629, 448.2615,
        448.5138, 448.3701, 448.2604, 448.2622, 448.4782, 448.2618, 448.2621,
        448.2630, 448.6967, 448.6942, 448.2633, 448.2624, 448.2600, 448.2616,
        448.2559, 448.2631, 448.2612, 448.2611, 448.2634, 448.2632, 448.2626,
        448.2614, 448.6962, 448.2615, 448.6967, 448.2610, 448.2621, 448.6967,
        448.3640, 448.2620, 448.2609, 448.2615, 448.2619, 448.2619, 448.2628,
        448.6965, 448.2623, 448.6967, 448.2631, 448.2621, 448.4769, 448.2628,
        448.6930, 448.2632, 448.6909, 448.6942, 448.2623, 448.2613, 448.2616,
        448.6853, 448.6967, 448.2622, 448.4397, 448.6918, 448.2614, 448.3124,
        448.2574, 448.2620, 448.2630, 448.5609, 448.2614, 448.6954, 448.2634,
        448.2620, 448.4726, 448.2625, 448.4779, 448.6959, 448.6967, 448.2633,
        448.2618, 448.2627, 448.4774, 448.2624, 448.2634, 448.2624, 448.2624,
        448.6967, 448.6088, 448.2625, 448.2603, 448.2623, 448.4458, 448.2632,
        448.2605, 448.3611, 448.2612, 448.4777, 448.6967, 448.2625, 448.2625,
        448.6967, 448.2633, 448.2634, 448.6967, 448.2623, 448.2620, 448.2599,
        448.6861, 448.2776, 448.6953, 448.2625, 448.2606, 448.2622, 448.2648,
        448.2623, 448.6967, 448.2624, 448.2628, 448.4780, 448.2620, 448.2622,
        448.6967, 448.2623, 448.2623, 448.2701, 448.6957, 448.2624, 448.6967,
        448.2617, 448.6519, 448.2634, 448.6967, 448.2634, 448.6967, 448.6966,
        448.2619, 448.3707, 448.6961, 448.2634, 448.2604, 448.2609, 448.2623,
        448.2613, 448.5831, 448.2626, 448.2628, 448.4774, 448.2632, 448.2633,
        448.2628, 448.6927, 448.2626, 448.2632, 448.2615, 448.2628, 448.2623,
        448.2620, 448.2623, 448.2624, 448.2621, 448.2626, 448.6967, 448.2625,
        448.2617, 448.2601, 448.6967, 448.6967, 448.2618, 448.6967, 448.2624,
        448.2620, 448.2715, 448.2617, 448.2623, 448.5847, 448.6945, 448.6906,
        448.2614, 448.6967, 448.5549, 448.5832, 448.4757, 448.2623, 448.2632,
        448.6960, 448.6949, 448.2623, 448.2624, 448.2606, 448.2627, 448.2618,
        448.4679, 448.2606, 448.5839, 448.6963, 448.2607, 448.6966, 448.2574,
        448.2625, 448.2622, 448.2628, 448.2635, 448.2621, 448.2631, 448.2625,
        448.2612, 448.2619, 448.6963, 448.2623, 448.2626, 448.2607, 448.2628,
        448.6967, 448.6958, 448.3679, 448.2625, 448.2628, 448.6967, 448.2625,
        448.2621, 448.2625, 448.2623, 448.6967, 448.6871, 448.2617, 448.2573,
        448.6966, 448.2628, 448.6960, 448.2617, 448.2622, 448.2612, 448.6959,
        448.2623, 448.6936, 448.2931, 448.6963, 448.2623, 448.2565, 448.6965,
        448.6967, 448.2613, 448.2616, 448.2606, 448.5193, 448.2633, 448.2573,
        448.2633, 448.6931, 448.6966, 448.2586, 448.6967, 448.2625, 448.6913,
        448.2615, 448.2623, 448.6015, 448.2598, 448.2632, 448.2612, 448.2613,
        448.2615, 448.2624, 448.2626, 448.2619, 448.2625, 448.6967, 448.2628,
        448.4059, 448.2632, 448.6957, 448.2616, 448.2604, 448.3715, 448.2623,
        448.6753, 448.2632, 448.2625, 448.2601, 448.2632, 448.2623, 448.6956,
        448.2633, 448.6967, 448.2628, 448.2629, 448.2627, 448.6965, 448.2608,
        448.2631, 448.2627, 448.6967, 448.2623, 448.2630, 448.2621, 448.2630,
        448.6967, 448.2629, 448.2634, 448.2634, 448.2618, 448.2635, 448.3676,
        448.6962, 448.5814, 448.2617, 448.2632, 448.2623, 448.2617, 448.6958,
        448.6966, 448.2628, 448.2632, 448.2625, 448.2622, 448.2624, 448.2626,
        448.6959, 448.6935, 448.6967, 448.2632, 448.6967, 448.2615, 448.2568,
        448.6967, 448.2631, 448.2623, 448.2623, 448.2621, 448.6967, 448.2634,
        448.6946, 448.2625, 448.4720, 448.6965, 448.2607, 448.5865, 448.6967,
        448.2622, 448.5820, 448.2623, 448.2613, 448.6880, 448.2631, 448.2633,
        448.2607, 448.2624, 448.6967, 448.2632, 448.2628, 448.2635, 448.6966,
        448.6967, 448.6967, 448.2631, 448.2629, 448.2623, 448.6967, 448.2631,
        448.2621, 448.2617, 448.2620, 448.2625, 448.2623, 448.2633, 448.2624,
        448.2626, 448.6965, 448.2629, 448.6966, 448.6955, 448.2625, 448.2625,
        448.2624, 448.2615, 448.2624, 448.2634, 448.2629, 448.2625, 448.6967,
        448.6952, 448.2641, 448.2609, 448.2623, 448.2625, 448.2609, 448.2602,
        448.2623, 448.2625, 448.2624, 448.4715, 448.2630, 448.2621, 448.6966,
        448.5832, 448.6754, 448.2623, 448.4782, 448.2633, 448.4783, 448.2606,
        448.2631, 448.2600, 448.2613, 448.2622, 448.2610, 448.6125, 448.2626,
        448.2623, 448.2634, 448.4775, 448.2625, 448.2617, 448.2633, 448.2625,
        448.6967, 448.6967, 448.2624, 448.2625, 448.2619, 448.6966, 448.2620,
        448.6967, 448.2610, 448.6959, 448.2631, 448.6967, 448.2617, 448.2621,
        448.4776, 448.2617, 448.2622, 448.2633, 448.2628, 448.2626, 448.2624,
        448.2627, 448.2615, 448.4767, 448.4784, 448.2633, 448.2633, 448.2624,
        448.2629, 448.2614, 448.2612, 448.2627, 448.2600, 448.2623, 448.2624,
        448.2622, 448.6960, 448.2619, 448.6952, 448.2624, 448.2629, 448.6953,
        448.2615, 448.2618, 448.6891, 448.6967, 448.2623, 448.6967, 448.6967,
        448.2609, 448.2629, 448.2606, 448.2621, 448.2630, 448.6947, 448.2617,
        448.6958, 448.2615, 448.6965, 448.6967, 448.2604, 448.2614, 448.2623,
        448.2573, 448.2629, 448.2617, 448.2630, 448.6922, 448.2625, 448.2623,
        448.6966, 448.6967, 448.2612, 448.2621, 448.6967, 448.2626, 448.2631,
        448.2621, 448.2634, 448.2628, 448.2625, 448.6967, 448.5854, 448.2603,
        448.5813, 448.3678, 448.2627, 448.2610, 448.2628, 448.2626, 448.6905,
        448.2603, 448.2625, 448.2629, 448.2622, 448.2626, 448.2627, 448.6966,
        448.2632, 448.2628, 448.2631, 448.2623, 448.2607, 448.5777, 448.2629,
        448.2623, 448.2622, 448.2621, 448.2625, 448.2619, 448.4280, 448.2612,
        448.4736, 448.2633, 448.2626, 448.2613, 448.5854, 448.2625, 448.2628,
        448.6967, 448.2615, 448.2628, 448.2602, 448.6962, 448.2603, 448.2632,
        448.2625, 448.2621, 448.2572, 448.2621, 448.2623, 448.2621, 448.2624,
        448.2619, 448.2633, 448.2618, 448.2625, 448.2624, 448.2622, 448.2631,
        448.2624, 448.6951, 448.2624, 448.6964, 448.6967, 448.5833, 448.2626,
        448.6958, 448.2632, 448.2610, 448.6893, 448.6966, 448.6967, 448.2622,
        448.2621, 448.6863, 448.2620, 448.2607, 448.2600, 448.4605, 448.2620,
        448.2625, 448.2603, 448.2610, 448.2632, 448.2626, 448.2634, 448.2612,
        448.2618, 448.2627, 448.6932, 448.6967, 448.2626, 448.2624, 448.2625,
        448.6967, 448.6967, 448.6966, 448.2623, 448.6966, 448.2633, 448.2633,
        448.2625, 448.6965, 448.6966, 448.2632, 448.6956, 448.2632, 448.6952,
        448.2612, 448.2627, 448.6937, 448.6963, 448.2619, 448.2632, 448.6959,
        448.6967, 448.2618, 448.2633, 448.2610, 448.4766, 448.2613, 448.2628,
        448.4485, 448.2625, 448.2623, 448.2623, 448.2623, 448.4776, 448.2614,
        448.4844, 448.6967, 448.5844, 448.3583, 448.2633, 448.2631, 448.2631,
        448.2633, 448.2625, 448.6967, 448.6967, 448.6949, 448.6964, 448.4781,
        448.2620, 448.2619, 448.6967, 448.2624, 448.2633, 448.6913, 448.6967,
        448.2623, 448.6967, 448.2624, 448.2619, 448.2634, 448.2625, 448.2628,
        448.6956, 448.2620, 448.2625, 448.2627, 448.2633, 448.5345, 448.6967,
        448.2623, 448.6967, 448.2611, 448.6927, 448.2625, 448.2626, 448.4765,
        448.2618, 448.2624, 448.4780, 448.4757, 448.2632, 448.2629, 448.2626,
        448.6967, 448.2632, 448.2629, 448.6967, 448.2633, 448.2632, 448.2623,
        448.2625, 448.6968, 448.2617, 448.2611, 448.2614, 448.6967, 448.2626,
        448.6902, 448.2610], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([407.9233], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0658],
             [112.0658],
             [112.0658],
             [112.0658]],

            [[112.0658],
             [112.0655],
             [112.0659],
             [112.0658]],

            [[112.1705],
             [112.0658],
             [112.1705],
             [112.0658]],

            ...,

            [[112.0658],
             [112.0650],
             [112.0658],
             [112.0658]],

            [[112.0658],
             [112.0658],
             [112.0657],
             [112.0651]],

            [[112.0653],
             [112.0658],
             [112.0653],
             [112.0658]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2632, 448.2631, 448.4725,  ..., 448.2625, 448.2625, 448.2622],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2632, 448.2631, 448.4725,  ..., 448.2625, 448.2625, 448.2622],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1657],
             [112.1739],
             [112.0660],
             [112.0656]],

            [[112.1729],
             [112.1729],
             [112.1695],
             [112.1695]],

            [[112.0659],
             [112.0659],
             [112.0659],
             [112.0659]],

            ...,

            [[112.0656],
             [112.0651],
             [112.0659],
             [112.0659]],

            [[112.0657],
             [112.0660],
             [112.0652],
             [112.0660]],

            [[112.1736],
             [112.0658],
             [112.0638],
             [112.0638]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4712, 448.6849, 448.2636,  ..., 448.2626, 448.2628, 448.3669],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4712, 448.6849, 448.2636,  ..., 448.2626, 448.2628, 448.3669],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1747],
             [112.1747],
             [112.1747],
             [112.1747]],

            [[112.0659],
             [112.0660],
             [112.0654],
             [112.0654]],

            [[112.0660],
             [112.0651],
             [112.0660],
             [112.0658]],

            ...,

            [[112.1747],
             [112.1747],
             [112.1747],
             [112.1747]],

            [[112.1747],
             [112.1747],
             [112.1747],
             [112.1747]],

            [[112.0661],
             [112.0650],
             [112.0661],
             [112.0661]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6987, 448.2625, 448.2629,  ..., 448.6987, 448.6987, 448.2633],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6987, 448.2625, 448.2629,  ..., 448.6987, 448.6987, 448.2633],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0639],
             [112.0633],
             [112.0670],
             [112.0670]],

            [[112.0670],
             [112.0668],
             [112.0667],
             [112.0667]],

            [[112.0658],
             [112.0670],
             [112.0668],
             [112.0666]],

            ...,

            [[112.0664],
             [112.0664],
             [112.0658],
             [112.0658]],

            [[112.0658],
             [112.0658],
             [112.0658],
             [112.0658]],

            [[112.1731],
             [112.1568],
             [112.1718],
             [112.1718]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2612, 448.2672, 448.2662,  ..., 448.2646, 448.2631, 448.6735],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2612, 448.2672, 448.2662,  ..., 448.2646, 448.2631, 448.6735],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0686],
             [112.0688],
             [112.0685],
             [112.0688]],

            [[112.1708],
             [112.1708],
             [112.1707],
             [112.1707]],

            [[112.1710],
             [112.1710],
             [112.1710],
             [112.1710]],

            ...,

            [[112.0686],
             [112.0688],
             [112.0686],
             [112.0688]],

            [[112.0680],
             [112.0683],
             [112.0676],
             [112.0676]],

            [[112.0677],
             [112.0677],
             [112.0676],
             [112.0676]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2748, 448.6829, 448.6840,  ..., 448.2749, 448.2714, 448.2704],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2748, 448.6829, 448.6840,  ..., 448.2749, 448.2714, 448.2704],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1637],
             [112.1637],
             [112.1637],
             [112.1637]],

            [[112.0771],
             [112.0762],
             [112.0775],
             [112.0775]],

            [[112.1637],
             [112.1637],
             [112.1637],
             [112.1637]],

            ...,

            [[112.1633],
             [112.0763],
             [112.1600],
             [112.1600]],

            [[112.0767],
             [112.0775],
             [112.0774],
             [112.0760]],

            [[112.1624],
             [112.0773],
             [112.1624],
             [112.0773]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6547, 448.3082, 448.6547,  ..., 448.5596, 448.3076, 448.4794],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6547, 448.3082, 448.6547,  ..., 448.5596, 448.3076, 448.4794],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0908],
             [112.0913],
             [112.0904],
             [112.0912]],

            [[112.1456],
             [112.1454],
             [112.1456],
             [112.1456]],

            [[112.0910],
             [112.0894],
             [112.0907],
             [112.0903]],

            ...,

            [[112.0910],
             [112.0910],
             [112.0906],
             [112.0906]],

            [[112.1441],
             [112.1441],
             [112.1437],
             [112.1437]],

            [[112.0907],
             [112.0907],
             [112.0893],
             [112.0893]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3636, 448.5823, 448.3614,  ..., 448.3631, 448.5756, 448.3599],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3636, 448.5823, 448.3614,  ..., 448.3631, 448.5756, 448.3599],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0978],
             [112.0995],
             [112.0995],
             [112.0976]],

            [[112.0994],
             [112.0994],
             [112.0980],
             [112.0980]],

            [[112.0956],
             [112.1323],
             [112.1292],
             [112.1324]],

            ...,

            [[112.1324],
             [112.1324],
             [112.1324],
             [112.1324]],

            [[112.0997],
             [112.1312],
             [112.0952],
             [112.0996]],

            [[112.0969],
             [112.1324],
             [112.1323],
             [112.0996]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3943, 448.3948, 448.4895,  ..., 448.5297, 448.4257, 448.4611],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3943, 448.3948, 448.4895,  ..., 448.5297, 448.4257, 448.4611],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1076],
             [112.1071],
             [112.1075],
             [112.1072]],

            [[112.1077],
             [112.1074],
             [112.1076],
             [112.1077]],

            [[112.1075],
             [112.1077],
             [112.1075],
             [112.1071]],

            ...,

            [[112.1058],
             [112.1058],
             [112.1049],
             [112.1072]],

            [[112.1204],
             [112.1203],
             [112.1204],
             [112.1204]],

            [[112.1062],
             [112.1069],
             [112.1071],
             [112.1049]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4294, 448.4304, 448.4297,  ..., 448.4238, 448.4814, 448.4250],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4294, 448.4304, 448.4297,  ..., 448.4238, 448.4814, 448.4250],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1105],
             [112.1083],
             [112.1101],
             [112.1104]],

            [[112.1118],
             [112.1118],
             [112.1122],
             [112.1122]],

            [[112.1110],
             [112.1099],
             [112.1111],
             [112.1099]],

            ...,

            [[112.1109],
             [112.1091],
             [112.1081],
             [112.1109]],

            [[112.1104],
             [112.1109],
             [112.1103],
             [112.1103]],

            [[112.1124],
             [112.1112],
             [112.1006],
             [112.1006]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4392, 448.4480, 448.4419,  ..., 448.4390, 448.4418, 448.4249],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4392, 448.4480, 448.4419,  ..., 448.4390, 448.4418, 448.4249],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1042],
             [112.1044],
             [112.1044],
             [112.1042]],

            [[112.1043],
             [112.1043],
             [112.1131],
             [112.1131]],

            [[112.1156],
             [112.1148],
             [112.1156],
             [112.1148]],

            ...,

            [[112.1145],
             [112.1119],
             [112.1149],
             [112.1134]],

            [[112.1131],
             [112.1131],
             [112.1121],
             [112.1121]],

            [[112.1132],
             [112.1150],
             [112.1155],
             [112.1155]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4172, 448.4349, 448.4607,  ..., 448.4548, 448.4503, 448.4592],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4172, 448.4349, 448.4607,  ..., 448.4548, 448.4503, 448.4592],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1153],
             [112.1153],
             [112.1150],
             [112.1150]],

            [[112.1003],
             [112.1005],
             [112.1005],
             [112.1002]],

            [[112.1158],
             [112.1139],
             [112.1162],
             [112.1169]],

            ...,

            [[112.1005],
             [112.1176],
             [112.1176],
             [112.1171]],

            [[112.1005],
             [112.1005],
             [112.1005],
             [112.1005]],

            [[112.1153],
             [112.1153],
             [112.1138],
             [112.1138]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4605, 448.4015, 448.4629,  ..., 448.4529, 448.4020, 448.4583],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4605, 448.4015, 448.4629,  ..., 448.4529, 448.4020, 448.4583],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1206],
             [112.1206],
             [112.1201],
             [112.1201]],

            [[112.0947],
             [112.1197],
             [112.0950],
             [112.0950]],

            [[112.1186],
             [112.1186],
             [112.1182],
             [112.1182]],

            ...,

            [[112.1192],
             [112.1210],
             [112.1183],
             [112.1197]],

            [[112.1189],
             [112.1189],
             [112.1183],
             [112.1183]],

            [[112.1211],
             [112.1211],
             [112.1206],
             [112.1206]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4814, 448.4045, 448.4737,  ..., 448.4782, 448.4743, 448.4835],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4814, 448.4045, 448.4737,  ..., 448.4782, 448.4743, 448.4835],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1275],
             [112.1275],
             [112.1271],
             [112.1271]],

            [[112.1249],
             [112.1273],
             [112.1245],
             [112.1271]],

            [[112.1266],
             [112.1239],
             [112.1250],
             [112.1250]],

            ...,

            [[112.0882],
             [112.0882],
             [112.0883],
             [112.0883]],

            [[112.1247],
             [112.1239],
             [112.1261],
             [112.1268]],

            [[112.1243],
             [112.1239],
             [112.1242],
             [112.1238]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5092, 448.5038, 448.5005,  ..., 448.3531, 448.5015, 448.4962],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5092, 448.5038, 448.5005,  ..., 448.3531, 448.5015, 448.4962],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1279],
             [112.1279],
             [112.1266],
             [112.1266]],

            [[112.1298],
             [112.1297],
             [112.1273],
             [112.1298]],

            [[112.1270],
             [112.1274],
             [112.1267],
             [112.1267]],

            ...,

            [[112.0851],
             [112.1282],
             [112.0852],
             [112.1302]],

            [[112.1286],
             [112.1268],
             [112.1292],
             [112.1299]],

            [[112.1271],
             [112.1275],
             [112.1267],
             [112.1267]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5089, 448.5167, 448.5079,  ..., 448.4287, 448.5145, 448.5079],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5089, 448.5167, 448.5079,  ..., 448.4287, 448.5145, 448.5079],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1319],
             [112.1294],
             [112.1317],
             [112.1288]],

            [[112.1296],
             [112.1287],
             [112.1289],
             [112.1288]],

            [[112.0815],
             [112.1332],
             [112.0814],
             [112.1327]],

            ...,

            [[112.1320],
             [112.1327],
             [112.1316],
             [112.1326]],

            [[112.1317],
             [112.1288],
             [112.1299],
             [112.1291]],

            [[112.0811],
             [112.0811],
             [112.0811],
             [112.0811]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5219, 448.5161, 448.4288,  ..., 448.5288, 448.5194, 448.3243],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5219, 448.5161, 448.4288,  ..., 448.5288, 448.5194, 448.3243],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1341],
             [112.1358],
             [112.1358],
             [112.1330]],

            [[112.0768],
             [112.0768],
             [112.0769],
             [112.0769]],

            [[112.1369],
             [112.1370],
             [112.1367],
             [112.0779]],

            ...,

            [[112.1363],
             [112.1336],
             [112.1364],
             [112.1347]],

            [[112.0764],
             [112.0764],
             [112.0764],
             [112.0764]],

            [[112.1363],
             [112.1367],
             [112.1355],
             [112.1365]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5388, 448.3074, 448.4886,  ..., 448.5410, 448.3055, 448.5449],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5388, 448.3074, 448.4886,  ..., 448.5410, 448.3055, 448.5449],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1453],
             [112.1436],
             [112.1425],
             [112.1447]],

            [[112.1459],
             [112.1459],
             [112.1459],
             [112.1459]],

            [[112.1458],
             [112.1462],
             [112.1450],
             [112.1457]],

            ...,

            [[112.0681],
             [112.0691],
             [112.0686],
             [112.0692]],

            [[112.0689],
             [112.1468],
             [112.0684],
             [112.1472]],

            [[112.1428],
             [112.1423],
             [112.1426],
             [112.1425]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5762, 448.5837, 448.5826,  ..., 448.2750, 448.4312, 448.5702],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5762, 448.5837, 448.5826,  ..., 448.2750, 448.4312, 448.5702],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0371e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1543],
             [112.1564],
             [112.1533],
             [112.1561]],

            [[112.0587],
             [112.0587],
             [112.1556],
             [112.0589]],

            [[112.1559],
             [112.1545],
             [112.1533],
             [112.1533]],

            ...,

            [[112.1567],
             [112.1567],
             [112.1548],
             [112.1548]],

            [[112.0586],
             [112.0586],
             [112.0586],
             [112.0586]],

            [[112.1543],
             [112.1543],
             [112.1533],
             [112.1533]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6201, 448.3320, 448.6170,  ..., 448.6232, 448.2343, 448.6151],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6201, 448.3320, 448.6170,  ..., 448.6232, 448.2343, 448.6151],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0605],
             [112.1571],
             [112.0607],
             [112.1571]],

            [[112.1558],
             [112.1546],
             [112.1562],
             [112.1533]],

            [[112.0586],
             [112.0586],
             [112.0586],
             [112.0586]],

            ...,

            [[112.0586],
             [112.0587],
             [112.0586],
             [112.0586]],

            [[112.1556],
             [112.1556],
             [112.1547],
             [112.1547]],

            [[112.1567],
             [112.1568],
             [112.1553],
             [112.1533]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4354, 448.6199, 448.2343,  ..., 448.2345, 448.6207, 448.6220],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4354, 448.6199, 448.2343,  ..., 448.2345, 448.6207, 448.6220],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1568],
             [112.1568],
             [112.1567],
             [112.1567]],

            [[112.0598],
             [112.0598],
             [112.0596],
             [112.0596]],

            [[112.1562],
             [112.1565],
             [112.1538],
             [112.1559]],

            ...,

            [[112.1552],
             [112.1540],
             [112.1556],
             [112.1533]],

            [[112.1544],
             [112.1562],
             [112.1538],
             [112.1538]],

            [[112.1539],
             [112.1565],
             [112.1563],
             [112.1534]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6270, 448.2388, 448.6223, 448.6168, 448.4383, 448.6148, 448.6243,
            448.6201, 448.2347, 448.2542, 448.6274, 448.6235, 448.6306, 448.6189,
            448.6151, 448.2343, 448.4382, 448.6201, 448.6200, 448.6193, 448.6209,
            448.6190, 448.6223, 448.2348, 448.6195, 448.2358, 448.6178, 448.6173,
            448.4363, 448.6277, 448.2343, 448.6142, 448.4487, 448.2399, 448.6211,
            448.2344, 448.6212, 448.6185, 448.6164, 448.6219, 448.6176, 448.2343,
            448.6172, 448.6244, 448.6145, 448.6194, 448.2344, 448.6224, 448.2360,
            448.6194, 448.6141, 448.6143, 448.6156, 448.6183, 448.6199, 448.6277,
            448.2344, 448.2368, 448.6209, 448.6151, 448.6147, 448.6194, 448.2423,
            448.6132, 448.6196, 448.6201, 448.6136, 448.6252, 448.6153, 448.6229,
            448.6237, 448.6207, 448.2344, 448.2372, 448.6136, 448.6241, 448.6198,
            448.2344, 448.6221, 448.6299, 448.2377, 448.2354, 448.6193, 448.6268,
            448.4329, 448.6152, 448.2353, 448.6218, 448.2343, 448.6198, 448.6183,
            448.2382, 448.6223, 448.2344, 448.2476, 448.6206, 448.6201, 448.6252,
            448.2343, 448.6152, 448.2386, 448.6151, 448.5850, 448.6220, 448.6212,
            448.6165, 448.5973, 448.2366, 448.2343, 448.6264, 448.6202, 448.2742,
            448.4351, 448.6223, 448.2368, 448.2343, 448.6254, 448.6240, 448.6205,
            448.6267, 448.2343, 448.6215, 448.2357, 448.6266, 448.6254, 448.6186,
            448.2343, 448.2343, 448.6140, 448.2370, 448.6154, 448.2367, 448.6267,
            448.6310, 448.2386, 448.6197, 448.6176, 448.2370, 448.6215, 448.6202,
            448.2343, 448.6210, 448.6180, 448.6183, 448.6136, 448.6145, 448.6192,
            448.6248, 448.2343, 448.6218, 448.5506, 448.6209, 448.6200, 448.4350,
            448.6284, 448.2677, 448.6169, 448.6277, 448.2343, 448.2404, 448.6207,
            448.6237, 448.6149, 448.4349, 448.6203, 448.4277, 448.6261, 448.6156,
            448.6215, 448.6204, 448.2344, 448.6199, 448.6178, 448.6242, 448.6297,
            448.6148, 448.6204, 448.2368, 448.6190, 448.5326, 448.6206, 448.6169,
            448.4355, 448.6187, 448.6195, 448.6147, 448.6028, 448.2345, 448.6246,
            448.2344, 448.6158, 448.6196, 448.2399, 448.6242, 448.6183, 448.6132,
            448.5322, 448.6200, 448.2394, 448.6195, 448.6240, 448.2375, 448.6135,
            448.6142, 448.6216, 448.4358, 448.4350, 448.4371, 448.6256, 448.6290,
            448.2365, 448.2350, 448.6148, 448.4352, 448.2343, 448.6269, 448.6172,
            448.4322, 448.6181, 448.6146, 448.6188, 448.6178, 448.2364, 448.6295,
            448.6196, 448.6203, 448.6197, 448.2343, 448.6198, 448.2343, 448.6199,
            448.6158, 448.6133, 448.6203, 448.6287, 448.6202, 448.2343, 448.2345,
            448.6199, 448.6160, 448.6206, 448.6267, 448.6205, 448.6201, 448.2657,
            448.6162, 448.6101, 448.6201, 448.3388, 448.6174, 448.6257, 448.6227,
            448.6231, 448.2871, 448.6256, 448.6239, 448.6171, 448.4288, 448.6166,
            448.6212, 448.4347, 448.2344, 448.2343, 448.6183, 448.2373, 448.3379,
            448.4346, 448.6151, 448.2347, 448.6254, 448.6244, 448.6214, 448.6204,
            448.6204, 448.6279, 448.4379, 448.6220, 448.2344, 448.6152, 448.6175,
            448.6282, 448.6113, 448.6175, 448.6075, 448.6198, 448.2373, 448.6153,
            448.6252, 448.6197, 448.6222, 448.2346, 448.6155, 448.6197, 448.6216,
            448.6213, 448.2346, 448.5323, 448.6194, 448.2357, 448.4360, 448.6169,
            448.6180, 448.4373, 448.6195, 448.5244, 448.6190, 448.6216, 448.6284,
            448.2383, 448.6258, 448.6208, 448.6279, 448.6283, 448.6170, 448.6218,
            448.2347, 448.6210, 448.6188, 448.3298, 448.6271, 448.6243, 448.6195,
            448.2343, 448.6205, 448.6152, 448.2345, 448.6204, 448.4367, 448.4355,
            448.6174, 448.6267, 448.6266, 448.2357, 448.2400, 448.6196, 448.3398,
            448.6249, 448.6200, 448.6169, 448.5976, 448.6192, 448.6163, 448.2343,
            448.6196, 448.6231, 448.6201, 448.6188, 448.2367, 448.6293, 448.3364,
            448.2344, 448.6177, 448.6210, 448.6170, 448.6206, 448.5339, 448.6264,
            448.6250, 448.2358, 448.6149, 448.6191, 448.6155, 448.6225, 448.6200,
            448.6166, 448.6232, 448.6212, 448.6281, 448.4337, 448.6190, 448.5343,
            448.3344, 448.6255, 448.6253, 448.6205, 448.6201, 448.4365, 448.6149,
            448.6201, 448.6192, 448.6291, 448.2343, 448.2395, 448.6201, 448.6270,
            448.2364, 448.6221, 448.4320, 448.6151, 448.6178, 448.6224, 448.6144,
            448.6174, 448.6205, 448.2377, 448.2344, 448.4925, 448.6237, 448.5343,
            448.5284, 448.6157, 448.6243, 448.2343, 448.4347, 448.2361, 448.6263,
            448.6165, 448.6158, 448.6256, 448.6194, 448.6188, 448.6208, 448.2343,
            448.2343, 448.2440, 448.6238, 448.6227, 448.6132, 448.6174, 448.2380,
            448.6194, 448.6161, 448.6133, 448.2368, 448.2367, 448.6151, 448.6210,
            448.6251, 448.5325, 448.6168, 448.6218, 448.2354, 448.6174, 448.6181,
            448.6219, 448.3287, 448.6195, 448.6219, 448.6217, 448.6154, 448.6223,
            448.2585, 448.2343, 448.6231, 448.2368, 448.6192, 448.2368, 448.6217,
            448.6176, 448.6191, 448.6195, 448.6206, 448.2385, 448.2344, 448.4355,
            448.6151, 448.6176, 448.6189, 448.6234, 448.6200, 448.6295, 448.6200,
            448.6149, 448.6200, 448.6270, 448.4486, 448.6237, 448.2343, 448.2350,
            448.2344, 448.3358, 448.4412, 448.2391, 448.6213, 448.6186, 448.6268,
            448.3350, 448.6231, 448.6177, 448.6199, 448.6274, 448.2410, 448.6273,
            448.6284, 448.6249, 448.6187, 448.6131, 448.6211, 448.6195, 448.6186,
            448.6185, 448.6267, 448.2350, 448.6259, 448.6208, 448.6150, 448.2364,
            448.3386, 448.6287, 448.6130, 448.6210, 448.6154, 448.2344, 448.6264,
            448.6192, 448.6164, 448.2372, 448.5342, 448.2344, 448.6235, 448.6138,
            448.6243, 448.6267, 448.6138, 448.6163, 448.6146, 448.6273, 448.6269,
            448.6214, 448.6204, 448.6186, 448.6204, 448.2368, 448.6228, 448.2343,
            448.3381, 448.6148, 448.2347, 448.2813, 448.6198, 448.5323, 448.6243,
            448.6201, 448.6280, 448.6271, 448.6218, 448.2353, 448.4396, 448.6168,
            448.6243, 448.6249, 448.2346, 448.6233, 448.6198, 448.6196, 448.6216,
            448.6192, 448.5345, 448.6194, 448.4363, 448.6175, 448.6187, 448.6267,
            448.6199, 448.6203, 448.4841, 448.6190, 448.6146, 448.6185, 448.6195,
            448.2357, 448.6206, 448.6137, 448.6248, 448.6187, 448.6187, 448.6196,
            448.6163, 448.6270, 448.6191, 448.6152, 448.6105, 448.2369, 448.6178,
            448.6175, 448.2372, 448.6200, 448.3154, 448.6183, 448.6178, 448.6285,
            448.6203, 448.4278, 448.2350, 448.6226, 448.6196, 448.6131, 448.6222,
            448.2346, 448.6198, 448.2346, 448.6162, 448.6196, 448.4352, 448.6150,
            448.6216, 448.3357, 448.2354, 448.6226, 448.6207, 448.3268, 448.6271,
            448.5038, 448.2362, 448.6236, 448.2343, 448.2347, 448.6205, 448.6216,
            448.6196, 448.6183, 448.6200, 448.6101, 448.6267, 448.2360, 448.6134,
            448.4345, 448.6188, 448.6271, 448.6202, 448.4695, 448.6212, 448.6133,
            448.2371, 448.6213, 448.6299, 448.5314, 448.6129, 448.6150, 448.2344,
            448.2343, 448.6187, 448.6194, 448.6175, 448.6199, 448.6282, 448.6207,
            448.6238, 448.6178, 448.6255, 448.2343, 448.6140, 448.6171, 448.6199,
            448.2343, 448.6198, 448.6160, 448.6229, 448.6212, 448.6156, 448.6200,
            448.6191, 448.4196, 448.6208, 448.2372, 448.2403, 448.6168, 448.6217,
            448.6202, 448.6209, 448.5344, 448.6210, 448.2344, 448.6150, 448.6257,
            448.2344, 448.6246, 448.6198, 448.6184, 448.2343, 448.6132, 448.2346,
            448.2350, 448.2367, 448.2366, 448.6227, 448.3398, 448.6246, 448.6219,
            448.6232, 448.4466, 448.6134, 448.6183, 448.2401, 448.6207, 448.3373,
            448.6184, 448.2343, 448.6135, 448.2343, 448.6145, 448.4537, 448.6286,
            448.6295, 448.2365, 448.6218, 448.6247, 448.2344, 448.6211, 448.6136,
            448.2354, 448.6202, 448.2343, 448.2343, 448.6160, 448.6204, 448.6190,
            448.6211, 448.6178, 448.2344, 448.4425, 448.6170, 448.6169, 448.6242,
            448.6278, 448.6130, 448.5336, 448.6102, 448.2343, 448.6217, 448.6211,
            448.6242, 448.6200, 448.6204, 448.6187, 448.6215, 448.5334, 448.6157,
            448.6230, 448.6204, 448.6136, 448.6286, 448.6254, 448.2343, 448.6201,
            448.6202, 448.2378, 448.6291, 448.6270, 448.6194, 448.6190, 448.4106,
            448.2344, 448.6195, 448.2352, 448.6303, 448.4364, 448.6140, 448.6155,
            448.6240, 448.6183, 448.6172, 448.2350, 448.6147, 448.2343, 448.6187,
            448.2382, 448.6194, 448.2346, 448.2359, 448.6205, 448.6287, 448.2344,
            448.2362, 448.6191, 448.6197, 448.6209, 448.4385, 448.2346, 448.6279,
            448.6197, 448.2352, 448.6176, 448.6248, 448.6231, 448.6176, 448.4471,
            448.2365, 448.6218, 448.2343, 448.2393, 448.2343, 448.6220, 448.6298,
            448.5375, 448.6165, 448.6172, 448.6129, 448.6177, 448.6257, 448.6181,
            448.6187, 448.6213, 448.6218, 448.6174, 448.6202, 448.6217, 448.5379,
            448.6190, 448.6148, 448.6226, 448.6215, 448.2383, 448.6151, 448.4342,
            448.4846, 448.4406, 448.6186, 448.6144, 448.6190, 448.6199, 448.2343,
            448.2344, 448.6213, 448.6183, 448.6196, 448.6326, 448.6252, 448.6267,
            448.6138, 448.6151, 448.2368, 448.6186, 448.6201, 448.6244, 448.6248,
            448.2344, 448.6191, 448.6142, 448.6201, 448.6205, 448.6232, 448.2343,
            448.6156, 448.6219, 448.4352, 448.6188, 448.2343, 448.6246, 448.2350,
            448.6223, 448.6223, 448.6300, 448.6209, 448.6187, 448.2344, 448.2343,
            448.2346, 448.6194, 448.6154, 448.6199, 448.2346, 448.6103, 448.2344,
            448.6227, 448.6129, 448.6166, 448.5386, 448.6251, 448.4347, 448.6195,
            448.6194, 448.6129, 448.6189, 448.4120, 448.6194, 448.6201, 448.6183,
            448.2345, 448.6129, 448.6202, 448.6181, 448.6216, 448.2361, 448.6222,
            448.6174, 448.6136, 448.2363, 448.5372, 448.6199, 448.4363, 448.6204,
            448.6144, 448.6190, 448.2453, 448.6169, 448.6241, 448.5327, 448.6155,
            448.4348, 448.6163, 448.6288, 448.6305, 448.4346, 448.2368, 448.6175,
            448.6143, 448.6186, 448.6226, 448.6129, 448.6303, 448.2398, 448.6141,
            448.2347, 448.6186, 448.6238, 448.6216, 448.2343, 448.6147, 448.2343,
            448.4351, 448.6272, 448.6175, 448.6182, 448.2343, 448.6172, 448.6296,
            448.6201, 448.6208, 448.5292, 448.6267, 448.2344, 448.4447, 448.6180,
            448.6182, 448.6201], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6270, 448.2388, 448.6223, 448.6168, 448.4383, 448.6148, 448.6243,
        448.6201, 448.2347, 448.2542, 448.6274, 448.6235, 448.6306, 448.6189,
        448.6151, 448.2343, 448.4382, 448.6201, 448.6200, 448.6193, 448.6209,
        448.6190, 448.6223, 448.2348, 448.6195, 448.2358, 448.6178, 448.6173,
        448.4363, 448.6277, 448.2343, 448.6142, 448.4487, 448.2399, 448.6211,
        448.2344, 448.6212, 448.6185, 448.6164, 448.6219, 448.6176, 448.2343,
        448.6172, 448.6244, 448.6145, 448.6194, 448.2344, 448.6224, 448.2360,
        448.6194, 448.6141, 448.6143, 448.6156, 448.6183, 448.6199, 448.6277,
        448.2344, 448.2368, 448.6209, 448.6151, 448.6147, 448.6194, 448.2423,
        448.6132, 448.6196, 448.6201, 448.6136, 448.6252, 448.6153, 448.6229,
        448.6237, 448.6207, 448.2344, 448.2372, 448.6136, 448.6241, 448.6198,
        448.2344, 448.6221, 448.6299, 448.2377, 448.2354, 448.6193, 448.6268,
        448.4329, 448.6152, 448.2353, 448.6218, 448.2343, 448.6198, 448.6183,
        448.2382, 448.6223, 448.2344, 448.2476, 448.6206, 448.6201, 448.6252,
        448.2343, 448.6152, 448.2386, 448.6151, 448.5850, 448.6220, 448.6212,
        448.6165, 448.5973, 448.2366, 448.2343, 448.6264, 448.6202, 448.2742,
        448.4351, 448.6223, 448.2368, 448.2343, 448.6254, 448.6240, 448.6205,
        448.6267, 448.2343, 448.6215, 448.2357, 448.6266, 448.6254, 448.6186,
        448.2343, 448.2343, 448.6140, 448.2370, 448.6154, 448.2367, 448.6267,
        448.6310, 448.2386, 448.6197, 448.6176, 448.2370, 448.6215, 448.6202,
        448.2343, 448.6210, 448.6180, 448.6183, 448.6136, 448.6145, 448.6192,
        448.6248, 448.2343, 448.6218, 448.5506, 448.6209, 448.6200, 448.4350,
        448.6284, 448.2677, 448.6169, 448.6277, 448.2343, 448.2404, 448.6207,
        448.6237, 448.6149, 448.4349, 448.6203, 448.4277, 448.6261, 448.6156,
        448.6215, 448.6204, 448.2344, 448.6199, 448.6178, 448.6242, 448.6297,
        448.6148, 448.6204, 448.2368, 448.6190, 448.5326, 448.6206, 448.6169,
        448.4355, 448.6187, 448.6195, 448.6147, 448.6028, 448.2345, 448.6246,
        448.2344, 448.6158, 448.6196, 448.2399, 448.6242, 448.6183, 448.6132,
        448.5322, 448.6200, 448.2394, 448.6195, 448.6240, 448.2375, 448.6135,
        448.6142, 448.6216, 448.4358, 448.4350, 448.4371, 448.6256, 448.6290,
        448.2365, 448.2350, 448.6148, 448.4352, 448.2343, 448.6269, 448.6172,
        448.4322, 448.6181, 448.6146, 448.6188, 448.6178, 448.2364, 448.6295,
        448.6196, 448.6203, 448.6197, 448.2343, 448.6198, 448.2343, 448.6199,
        448.6158, 448.6133, 448.6203, 448.6287, 448.6202, 448.2343, 448.2345,
        448.6199, 448.6160, 448.6206, 448.6267, 448.6205, 448.6201, 448.2657,
        448.6162, 448.6101, 448.6201, 448.3388, 448.6174, 448.6257, 448.6227,
        448.6231, 448.2871, 448.6256, 448.6239, 448.6171, 448.4288, 448.6166,
        448.6212, 448.4347, 448.2344, 448.2343, 448.6183, 448.2373, 448.3379,
        448.4346, 448.6151, 448.2347, 448.6254, 448.6244, 448.6214, 448.6204,
        448.6204, 448.6279, 448.4379, 448.6220, 448.2344, 448.6152, 448.6175,
        448.6282, 448.6113, 448.6175, 448.6075, 448.6198, 448.2373, 448.6153,
        448.6252, 448.6197, 448.6222, 448.2346, 448.6155, 448.6197, 448.6216,
        448.6213, 448.2346, 448.5323, 448.6194, 448.2357, 448.4360, 448.6169,
        448.6180, 448.4373, 448.6195, 448.5244, 448.6190, 448.6216, 448.6284,
        448.2383, 448.6258, 448.6208, 448.6279, 448.6283, 448.6170, 448.6218,
        448.2347, 448.6210, 448.6188, 448.3298, 448.6271, 448.6243, 448.6195,
        448.2343, 448.6205, 448.6152, 448.2345, 448.6204, 448.4367, 448.4355,
        448.6174, 448.6267, 448.6266, 448.2357, 448.2400, 448.6196, 448.3398,
        448.6249, 448.6200, 448.6169, 448.5976, 448.6192, 448.6163, 448.2343,
        448.6196, 448.6231, 448.6201, 448.6188, 448.2367, 448.6293, 448.3364,
        448.2344, 448.6177, 448.6210, 448.6170, 448.6206, 448.5339, 448.6264,
        448.6250, 448.2358, 448.6149, 448.6191, 448.6155, 448.6225, 448.6200,
        448.6166, 448.6232, 448.6212, 448.6281, 448.4337, 448.6190, 448.5343,
        448.3344, 448.6255, 448.6253, 448.6205, 448.6201, 448.4365, 448.6149,
        448.6201, 448.6192, 448.6291, 448.2343, 448.2395, 448.6201, 448.6270,
        448.2364, 448.6221, 448.4320, 448.6151, 448.6178, 448.6224, 448.6144,
        448.6174, 448.6205, 448.2377, 448.2344, 448.4925, 448.6237, 448.5343,
        448.5284, 448.6157, 448.6243, 448.2343, 448.4347, 448.2361, 448.6263,
        448.6165, 448.6158, 448.6256, 448.6194, 448.6188, 448.6208, 448.2343,
        448.2343, 448.2440, 448.6238, 448.6227, 448.6132, 448.6174, 448.2380,
        448.6194, 448.6161, 448.6133, 448.2368, 448.2367, 448.6151, 448.6210,
        448.6251, 448.5325, 448.6168, 448.6218, 448.2354, 448.6174, 448.6181,
        448.6219, 448.3287, 448.6195, 448.6219, 448.6217, 448.6154, 448.6223,
        448.2585, 448.2343, 448.6231, 448.2368, 448.6192, 448.2368, 448.6217,
        448.6176, 448.6191, 448.6195, 448.6206, 448.2385, 448.2344, 448.4355,
        448.6151, 448.6176, 448.6189, 448.6234, 448.6200, 448.6295, 448.6200,
        448.6149, 448.6200, 448.6270, 448.4486, 448.6237, 448.2343, 448.2350,
        448.2344, 448.3358, 448.4412, 448.2391, 448.6213, 448.6186, 448.6268,
        448.3350, 448.6231, 448.6177, 448.6199, 448.6274, 448.2410, 448.6273,
        448.6284, 448.6249, 448.6187, 448.6131, 448.6211, 448.6195, 448.6186,
        448.6185, 448.6267, 448.2350, 448.6259, 448.6208, 448.6150, 448.2364,
        448.3386, 448.6287, 448.6130, 448.6210, 448.6154, 448.2344, 448.6264,
        448.6192, 448.6164, 448.2372, 448.5342, 448.2344, 448.6235, 448.6138,
        448.6243, 448.6267, 448.6138, 448.6163, 448.6146, 448.6273, 448.6269,
        448.6214, 448.6204, 448.6186, 448.6204, 448.2368, 448.6228, 448.2343,
        448.3381, 448.6148, 448.2347, 448.2813, 448.6198, 448.5323, 448.6243,
        448.6201, 448.6280, 448.6271, 448.6218, 448.2353, 448.4396, 448.6168,
        448.6243, 448.6249, 448.2346, 448.6233, 448.6198, 448.6196, 448.6216,
        448.6192, 448.5345, 448.6194, 448.4363, 448.6175, 448.6187, 448.6267,
        448.6199, 448.6203, 448.4841, 448.6190, 448.6146, 448.6185, 448.6195,
        448.2357, 448.6206, 448.6137, 448.6248, 448.6187, 448.6187, 448.6196,
        448.6163, 448.6270, 448.6191, 448.6152, 448.6105, 448.2369, 448.6178,
        448.6175, 448.2372, 448.6200, 448.3154, 448.6183, 448.6178, 448.6285,
        448.6203, 448.4278, 448.2350, 448.6226, 448.6196, 448.6131, 448.6222,
        448.2346, 448.6198, 448.2346, 448.6162, 448.6196, 448.4352, 448.6150,
        448.6216, 448.3357, 448.2354, 448.6226, 448.6207, 448.3268, 448.6271,
        448.5038, 448.2362, 448.6236, 448.2343, 448.2347, 448.6205, 448.6216,
        448.6196, 448.6183, 448.6200, 448.6101, 448.6267, 448.2360, 448.6134,
        448.4345, 448.6188, 448.6271, 448.6202, 448.4695, 448.6212, 448.6133,
        448.2371, 448.6213, 448.6299, 448.5314, 448.6129, 448.6150, 448.2344,
        448.2343, 448.6187, 448.6194, 448.6175, 448.6199, 448.6282, 448.6207,
        448.6238, 448.6178, 448.6255, 448.2343, 448.6140, 448.6171, 448.6199,
        448.2343, 448.6198, 448.6160, 448.6229, 448.6212, 448.6156, 448.6200,
        448.6191, 448.4196, 448.6208, 448.2372, 448.2403, 448.6168, 448.6217,
        448.6202, 448.6209, 448.5344, 448.6210, 448.2344, 448.6150, 448.6257,
        448.2344, 448.6246, 448.6198, 448.6184, 448.2343, 448.6132, 448.2346,
        448.2350, 448.2367, 448.2366, 448.6227, 448.3398, 448.6246, 448.6219,
        448.6232, 448.4466, 448.6134, 448.6183, 448.2401, 448.6207, 448.3373,
        448.6184, 448.2343, 448.6135, 448.2343, 448.6145, 448.4537, 448.6286,
        448.6295, 448.2365, 448.6218, 448.6247, 448.2344, 448.6211, 448.6136,
        448.2354, 448.6202, 448.2343, 448.2343, 448.6160, 448.6204, 448.6190,
        448.6211, 448.6178, 448.2344, 448.4425, 448.6170, 448.6169, 448.6242,
        448.6278, 448.6130, 448.5336, 448.6102, 448.2343, 448.6217, 448.6211,
        448.6242, 448.6200, 448.6204, 448.6187, 448.6215, 448.5334, 448.6157,
        448.6230, 448.6204, 448.6136, 448.6286, 448.6254, 448.2343, 448.6201,
        448.6202, 448.2378, 448.6291, 448.6270, 448.6194, 448.6190, 448.4106,
        448.2344, 448.6195, 448.2352, 448.6303, 448.4364, 448.6140, 448.6155,
        448.6240, 448.6183, 448.6172, 448.2350, 448.6147, 448.2343, 448.6187,
        448.2382, 448.6194, 448.2346, 448.2359, 448.6205, 448.6287, 448.2344,
        448.2362, 448.6191, 448.6197, 448.6209, 448.4385, 448.2346, 448.6279,
        448.6197, 448.2352, 448.6176, 448.6248, 448.6231, 448.6176, 448.4471,
        448.2365, 448.6218, 448.2343, 448.2393, 448.2343, 448.6220, 448.6298,
        448.5375, 448.6165, 448.6172, 448.6129, 448.6177, 448.6257, 448.6181,
        448.6187, 448.6213, 448.6218, 448.6174, 448.6202, 448.6217, 448.5379,
        448.6190, 448.6148, 448.6226, 448.6215, 448.2383, 448.6151, 448.4342,
        448.4846, 448.4406, 448.6186, 448.6144, 448.6190, 448.6199, 448.2343,
        448.2344, 448.6213, 448.6183, 448.6196, 448.6326, 448.6252, 448.6267,
        448.6138, 448.6151, 448.2368, 448.6186, 448.6201, 448.6244, 448.6248,
        448.2344, 448.6191, 448.6142, 448.6201, 448.6205, 448.6232, 448.2343,
        448.6156, 448.6219, 448.4352, 448.6188, 448.2343, 448.6246, 448.2350,
        448.6223, 448.6223, 448.6300, 448.6209, 448.6187, 448.2344, 448.2343,
        448.2346, 448.6194, 448.6154, 448.6199, 448.2346, 448.6103, 448.2344,
        448.6227, 448.6129, 448.6166, 448.5386, 448.6251, 448.4347, 448.6195,
        448.6194, 448.6129, 448.6189, 448.4120, 448.6194, 448.6201, 448.6183,
        448.2345, 448.6129, 448.6202, 448.6181, 448.6216, 448.2361, 448.6222,
        448.6174, 448.6136, 448.2363, 448.5372, 448.6199, 448.4363, 448.6204,
        448.6144, 448.6190, 448.2453, 448.6169, 448.6241, 448.5327, 448.6155,
        448.4348, 448.6163, 448.6288, 448.6305, 448.4346, 448.2368, 448.6175,
        448.6143, 448.6186, 448.6226, 448.6129, 448.6303, 448.2398, 448.6141,
        448.2347, 448.6186, 448.6238, 448.6216, 448.2343, 448.6147, 448.2343,
        448.4351, 448.6272, 448.6175, 448.6182, 448.2343, 448.6172, 448.6296,
        448.6201, 448.6208, 448.5292, 448.6267, 448.2344, 448.4447, 448.6180,
        448.6182, 448.6201], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([392.7209], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0588],
             [112.0643],
             [112.0588],
             [112.0600]],

            [[112.1544],
             [112.1556],
             [112.1549],
             [112.1534]],

            [[112.1551],
             [112.1551],
             [112.1547],
             [112.1547]],

            ...,

            [[112.0590],
             [112.0586],
             [112.0586],
             [112.0591]],

            [[112.1567],
             [112.1542],
             [112.1565],
             [112.1539]],

            [[112.1566],
             [112.1532],
             [112.1559],
             [112.1555]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2420, 448.6183, 448.6196,  ..., 448.2354, 448.6212, 448.6213],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2420, 448.6183, 448.6196,  ..., 448.2354, 448.6212, 448.6213],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1614],
             [112.1614],
             [112.1602],
             [112.1602]],

            [[112.1599],
             [112.1599],
             [112.1584],
             [112.1608]],

            [[112.0604],
             [112.0605],
             [112.0604],
             [112.0604]],

            ...,

            [[112.1627],
             [112.1610],
             [112.1615],
             [112.1615]],

            [[112.0735],
             [112.1612],
             [112.1620],
             [112.1620]],

            [[112.1581],
             [112.1585],
             [112.1585],
             [112.1581]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6432, 448.6389, 448.2417,  ..., 448.6465, 448.5587, 448.6331],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6432, 448.6389, 448.2417,  ..., 448.6465, 448.5587, 448.6331],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0672],
             [112.0672],
             [112.1627],
             [112.1627]],

            [[112.1585],
             [112.1601],
             [112.1578],
             [112.1600]],

            [[112.1591],
             [112.1604],
             [112.1579],
             [112.1596]],

            ...,

            [[112.1628],
             [112.1628],
             [112.1629],
             [112.1629]],

            [[112.1599],
             [112.1577],
             [112.1603],
             [112.1594]],

            [[112.0658],
             [112.0658],
             [112.0699],
             [112.0702]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4597, 448.6364, 448.6370,  ..., 448.6513, 448.6374, 448.2718],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4597, 448.6364, 448.6370,  ..., 448.6513, 448.6374, 448.2718],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1588],
             [112.1567],
             [112.1568],
             [112.1568]],

            [[112.0687],
             [112.0687],
             [112.0687],
             [112.0687]],

            [[112.0693],
             [112.1614],
             [112.0717],
             [112.0717]],

            ...,

            [[112.1568],
             [112.1567],
             [112.1568],
             [112.1567]],

            [[112.0689],
             [112.0720],
             [112.0720],
             [112.0687]],

            [[112.1575],
             [112.1566],
             [112.1568],
             [112.1568]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6290, 448.2747, 448.3740,  ..., 448.6270, 448.2816, 448.6277],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6290, 448.2747, 448.3740,  ..., 448.6270, 448.2816, 448.6277],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1533],
             [112.1533],
             [112.1533],
             [112.1533]],

            [[112.0739],
             [112.1574],
             [112.0760],
             [112.0760]],

            [[112.1547],
             [112.1547],
             [112.1547],
             [112.1547]],

            ...,

            [[112.0760],
             [112.0760],
             [112.1557],
             [112.1557]],

            [[112.1529],
             [112.1529],
             [112.1529],
             [112.1529]],

            [[112.1556],
             [112.1544],
             [112.1550],
             [112.1550]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6130, 448.3832, 448.6187,  ..., 448.4634, 448.6116, 448.6199],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6130, 448.3832, 448.6187,  ..., 448.4634, 448.6116, 448.6199],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1512],
             [112.1512],
             [112.1492],
             [112.1492]],

            [[112.1509],
             [112.1494],
             [112.1503],
             [112.1503]],

            [[112.0782],
             [112.0785],
             [112.0782],
             [112.0784]],

            ...,

            [[112.1499],
             [112.1510],
             [112.1492],
             [112.1514]],

            [[112.0783],
             [112.0783],
             [112.0784],
             [112.0784]],

            [[112.1515],
             [112.1518],
             [112.1506],
             [112.1511]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6008, 448.6008, 448.3134,  ..., 448.6015, 448.3134, 448.6050],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6008, 448.6008, 448.3134,  ..., 448.6015, 448.3134, 448.6050],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1460],
             [112.1462],
             [112.1460],
             [112.1462]],

            [[112.1486],
             [112.1483],
             [112.1467],
             [112.1479]],

            [[112.1471],
             [112.1471],
             [112.1468],
             [112.1468]],

            ...,

            [[112.1478],
             [112.1489],
             [112.1489],
             [112.1472]],

            [[112.1473],
             [112.1486],
             [112.1468],
             [112.1487]],

            [[112.0839],
             [112.1491],
             [112.1503],
             [112.1507]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5844, 448.5915, 448.5879,  ..., 448.5928, 448.5915, 448.5339],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5844, 448.5915, 448.5879,  ..., 448.5928, 448.5915, 448.5339],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0805],
             [112.0794],
             [112.0793],
             [112.0811]],

            [[112.0793],
             [112.0795],
             [112.0793],
             [112.0793]],

            [[112.1525],
             [112.1518],
             [112.1520],
             [112.1518]],

            ...,

            [[112.0796],
             [112.0793],
             [112.0793],
             [112.0796]],

            [[112.1553],
             [112.1537],
             [112.1559],
             [112.1537]],

            [[112.1414],
             [112.1249],
             [112.1537],
             [112.1537]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3204, 448.3174, 448.6080,  ..., 448.3178, 448.6187, 448.5738],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3204, 448.3174, 448.6080,  ..., 448.3178, 448.6187, 448.5738],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0801],
             [112.1580],
             [112.0800],
             [112.1581]],

            [[112.1574],
             [112.1569],
             [112.1576],
             [112.1566]],

            [[112.1566],
             [112.1559],
             [112.1562],
             [112.1560]],

            ...,

            [[112.1567],
             [112.1564],
             [112.1560],
             [112.1571]],

            [[112.1572],
             [112.1566],
             [112.1564],
             [112.1561]],

            [[112.1575],
             [112.1561],
             [112.1574],
             [112.1573]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4761, 448.6285, 448.6248,  ..., 448.6262, 448.6263, 448.6283],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4761, 448.6285, 448.6248,  ..., 448.6262, 448.6263, 448.6283],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1596],
             [112.1595],
             [112.1597],
             [112.1596]],

            [[112.0826],
             [112.1613],
             [112.1621],
             [112.1621]],

            [[112.1606],
             [112.1613],
             [112.1607],
             [112.1607]],

            ...,

            [[112.0780],
             [112.0780],
             [112.0780],
             [112.0780]],

            [[112.1616],
             [112.1609],
             [112.1620],
             [112.1609]],

            [[112.1611],
             [112.1611],
             [112.1601],
             [112.1601]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6384, 448.5681, 448.6432,  ..., 448.3120, 448.6454, 448.6424],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6384, 448.5681, 448.6432,  ..., 448.3120, 448.6454, 448.6424],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1576],
             [112.1576],
             [112.1574],
             [112.1574]],

            [[112.0826],
             [112.0826],
             [112.1609],
             [112.1609]],

            [[112.1583],
             [112.1583],
             [112.1582],
             [112.1582]],

            ...,

            [[112.1585],
             [112.1585],
             [112.1575],
             [112.1575]],

            [[112.1577],
             [112.1575],
             [112.1576],
             [112.1575]],

            [[112.0822],
             [112.0831],
             [112.0825],
             [112.0825]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6300, 448.4869, 448.6329,  ..., 448.6320, 448.6303, 448.3303],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6300, 448.4869, 448.6329,  ..., 448.6320, 448.6303, 448.3303],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0893],
             [112.1547],
             [112.0892],
             [112.1547]],

            [[112.1544],
             [112.1534],
             [112.1535],
             [112.1542]],

            [[112.1565],
             [112.1565],
             [112.1559],
             [112.1559]],

            ...,

            [[112.1534],
             [112.1544],
             [112.1535],
             [112.1544]],

            [[112.1543],
             [112.1543],
             [112.1543],
             [112.1543]],

            [[112.1544],
             [112.1544],
             [112.1537],
             [112.1537]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4879, 448.6154, 448.6250,  ..., 448.6157, 448.6174, 448.6163],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4879, 448.6154, 448.6250,  ..., 448.6157, 448.6174, 448.6163],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0913],
             [112.0913],
             [112.1524],
             [112.0909]],

            [[112.1503],
             [112.1501],
             [112.1497],
             [112.1497]],

            [[112.1498],
             [112.1498],
             [112.1496],
             [112.1496]],

            ...,

            [[112.1502],
             [112.1492],
             [112.1502],
             [112.1493]],

            [[112.1496],
             [112.1502],
             [112.1492],
             [112.1502]],

            [[112.1494],
             [112.1494],
             [112.1493],
             [112.1493]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4258, 448.5999, 448.5988,  ..., 448.5990, 448.5993, 448.5974],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4258, 448.5999, 448.5988,  ..., 448.5990, 448.5993, 448.5974],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1441],
             [112.1441],
             [112.1441],
             [112.1441]],

            [[112.1449],
             [112.1443],
             [112.1443],
             [112.1443]],

            [[112.1441],
             [112.1441],
             [112.1441],
             [112.1442]],

            ...,

            [[112.0990],
             [112.1467],
             [112.0989],
             [112.1457]],

            [[112.1450],
             [112.1442],
             [112.1444],
             [112.1444]],

            [[112.1442],
             [112.1442],
             [112.1445],
             [112.1445]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5765, 448.5779, 448.5766,  ..., 448.4903, 448.5780, 448.5775],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5765, 448.5779, 448.5766,  ..., 448.4903, 448.5780, 448.5775],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1030],
             [112.1030],
             [112.1030],
             [112.1030]],

            [[112.1030],
             [112.1030],
             [112.1030],
             [112.1030]],

            [[112.1425],
             [112.1422],
             [112.1416],
             [112.1415]],

            ...,

            [[112.1418],
             [112.1415],
             [112.1416],
             [112.1416]],

            [[112.1424],
             [112.1420],
             [112.1424],
             [112.1420]],

            [[112.1043],
             [112.1043],
             [112.1436],
             [112.1034]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4119, 448.4119, 448.5679,  ..., 448.5666, 448.5688, 448.4556],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4119, 448.4119, 448.5679,  ..., 448.5666, 448.5688, 448.4556],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1044],
             [112.1046],
             [112.1044],
             [112.1044]],

            [[112.1054],
             [112.1418],
             [112.1065],
             [112.1065]],

            [[112.1414],
             [112.1435],
             [112.1413],
             [112.1413]],

            ...,

            [[112.1408],
             [112.1407],
             [112.1407],
             [112.1407]],

            [[112.1414],
             [112.1414],
             [112.1408],
             [112.1408]],

            [[112.1410],
             [112.1410],
             [112.1413],
             [112.1410]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4179, 448.4603, 448.5676,  ..., 448.5630, 448.5642, 448.5642],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4179, 448.4603, 448.5676,  ..., 448.5630, 448.5642, 448.5642],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1399],
             [112.1394],
             [112.1398],
             [112.1393]],

            [[112.1091],
             [112.1112],
             [112.1080],
             [112.1403]],

            [[112.1394],
             [112.1394],
             [112.1393],
             [112.1393]],

            ...,

            [[112.1413],
             [112.1400],
             [112.1397],
             [112.1397]],

            [[112.1074],
             [112.1071],
             [112.1074],
             [112.1071]],

            [[112.1395],
             [112.1394],
             [112.1396],
             [112.1396]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5583, 448.4686, 448.5573,  ..., 448.5608, 448.4290, 448.5580],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5583, 448.4686, 448.5573,  ..., 448.5608, 448.4290, 448.5580],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1390],
             [112.1390],
             [112.1391],
             [112.1391]],

            [[112.1392],
             [112.1393],
             [112.1390],
             [112.1390]],

            [[112.1088],
             [112.1088],
             [112.1088],
             [112.1090]],

            ...,

            [[112.1391],
             [112.1393],
             [112.1391],
             [112.1389]],

            [[112.1392],
             [112.1392],
             [112.1392],
             [112.1392]],

            [[112.1132],
             [112.1394],
             [112.1407],
             [112.1407]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5561, 448.5565, 448.4354,  ..., 448.5564, 448.5568, 448.5340],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5561, 448.5565, 448.4354,  ..., 448.5564, 448.5568, 448.5340],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0010e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1372],
             [112.1373],
             [112.1372],
             [112.1373]],

            [[112.1375],
             [112.1375],
             [112.1373],
             [112.1373]],

            [[112.1373],
             [112.1376],
             [112.1373],
             [112.1376]],

            ...,

            [[112.1372],
             [112.1376],
             [112.1373],
             [112.1373]],

            [[112.1373],
             [112.1373],
             [112.1375],
             [112.1375]],

            [[112.1375],
             [112.1375],
             [112.1372],
             [112.1372]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5490, 448.5497, 448.5497,  ..., 448.5494, 448.5496, 448.5494],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5490, 448.5497, 448.5497,  ..., 448.5494, 448.5496, 448.5494],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1375],
             [112.1376],
             [112.1374],
             [112.1374]],

            [[112.1375],
             [112.1375],
             [112.1373],
             [112.1375]],

            [[112.1372],
             [112.1375],
             [112.1375],
             [112.1375]],

            ...,

            [[112.1376],
             [112.1373],
             [112.1375],
             [112.1374]],

            [[112.1373],
             [112.1373],
             [112.1374],
             [112.1375]],

            [[112.1114],
             [112.1119],
             [112.1119],
             [112.1113]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5498, 448.5497, 448.5497,  ..., 448.5497, 448.5496, 448.4465],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5498, 448.5497, 448.5497,  ..., 448.5497, 448.5496, 448.4465],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1115],
             [112.1183],
             [112.1115],
             [112.1125]],

            [[112.1392],
             [112.1376],
             [112.1377],
             [112.1377]],

            [[112.1373],
             [112.1376],
             [112.1373],
             [112.1372]],

            ...,

            [[112.1377],
             [112.1377],
             [112.1377],
             [112.1377]],

            [[112.1114],
             [112.1114],
             [112.1114],
             [112.1114]],

            [[112.1113],
             [112.1115],
             [112.1114],
             [112.1114]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4537, 448.5522, 448.5494, 448.5508, 448.5503, 448.4472, 448.5495,
            448.5505, 448.5499, 448.5497, 448.4453, 448.5494, 448.5497, 448.5004,
            448.5496, 448.5488, 448.5497, 448.4453, 448.4484, 448.5495, 448.5499,
            448.4759, 448.5502, 448.5306, 448.5496, 448.5497, 448.5502, 448.5494,
            448.5497, 448.5506, 448.5496, 448.5515, 448.5497, 448.5493, 448.5497,
            448.5497, 448.5526, 448.4754, 448.5498, 448.5508, 448.5007, 448.5488,
            448.4453, 448.5491, 448.5494, 448.5498, 448.4512, 448.5497, 448.5500,
            448.5494, 448.5496, 448.4513, 448.5010, 448.5262, 448.4483, 448.4453,
            448.4761, 448.5496, 448.4478, 448.5295, 448.4463, 448.5533, 448.5494,
            448.5506, 448.5497, 448.5500, 448.4470, 448.5496, 448.5503, 448.5491,
            448.5531, 448.4480, 448.4453, 448.5491, 448.4453, 448.4456, 448.5497,
            448.5497, 448.5010, 448.5497, 448.5497, 448.5495, 448.4462, 448.5299,
            448.5496, 448.5491, 448.5488, 448.5495, 448.4456, 448.5496, 448.5506,
            448.4457, 448.5534, 448.5504, 448.4453, 448.4462, 448.5491, 448.5298,
            448.5497, 448.4483, 448.5497, 448.5504, 448.5505, 448.4457, 448.4922,
            448.5502, 448.4470, 448.5495, 448.5492, 448.5490, 448.5491, 448.5493,
            448.5498, 448.5491, 448.5493, 448.4454, 448.5490, 448.4453, 448.5506,
            448.5519, 448.4453, 448.5493, 448.5492, 448.5499, 448.5035, 448.4453,
            448.4453, 448.4453, 448.5511, 448.5496, 448.5490, 448.5056, 448.5515,
            448.5273, 448.4805, 448.5516, 448.4486, 448.5501, 448.5488, 448.5497,
            448.5294, 448.4453, 448.5493, 448.5494, 448.5498, 448.5500, 448.5496,
            448.5531, 448.5493, 448.5494, 448.5497, 448.5501, 448.4459, 448.4470,
            448.5498, 448.5495, 448.4463, 448.5492, 448.5496, 448.4456, 448.5501,
            448.5551, 448.4584, 448.5051, 448.5493, 448.5497, 448.5532, 448.5491,
            448.5286, 448.5492, 448.5416, 448.5499, 448.5492, 448.5496, 448.4544,
            448.5494, 448.4453, 448.5496, 448.5499, 448.5031, 448.5497, 448.5503,
            448.4512, 448.5551, 448.5496, 448.5502, 448.5005, 448.5271, 448.5500,
            448.4453, 448.5496, 448.5494, 448.5496, 448.5502, 448.5494, 448.5496,
            448.4756, 448.5533, 448.4456, 448.5494, 448.5010, 448.5497, 448.5498,
            448.5490, 448.5015, 448.4454, 448.5495, 448.5488, 448.5488, 448.5497,
            448.5496, 448.5495, 448.5496, 448.5498, 448.4453, 448.5496, 448.5496,
            448.4467, 448.5011, 448.5506, 448.5009, 448.5503, 448.5491, 448.4453,
            448.5498, 448.5499, 448.5496, 448.5496, 448.5010, 448.5497, 448.5487,
            448.4453, 448.5493, 448.4753, 448.5494, 448.5430, 448.5498, 448.5494,
            448.5497, 448.4462, 448.5496, 448.5501, 448.5500, 448.5512, 448.5491,
            448.5499, 448.5498, 448.5508, 448.5491, 448.4462, 448.5497, 448.5493,
            448.5498, 448.5491, 448.5497, 448.5032, 448.5499, 448.4456, 448.5495,
            448.5494, 448.5497, 448.4453, 448.5496, 448.5496, 448.5494, 448.5497,
            448.5497, 448.4453, 448.5498, 448.5498, 448.4507, 448.5497, 448.5495,
            448.4453, 448.5498, 448.5497, 448.5500, 448.5496, 448.4491, 448.5504,
            448.5494, 448.5496, 448.5491, 448.5514, 448.4462, 448.5496, 448.5487,
            448.5497, 448.5497, 448.5499, 448.5508, 448.5496, 448.5496, 448.5498,
            448.5549, 448.4453, 448.5498, 448.5498, 448.4453, 448.5505, 448.5499,
            448.5502, 448.5494, 448.4465, 448.5495, 448.5494, 448.5500, 448.5497,
            448.5498, 448.5490, 448.5490, 448.5497, 448.5499, 448.4456, 448.4453,
            448.5495, 448.5500, 448.5497, 448.5505, 448.5490, 448.5490, 448.5012,
            448.5491, 448.5496, 448.5493, 448.4455, 448.5487, 448.5572, 448.4471,
            448.5495, 448.5494, 448.5502, 448.5496, 448.5496, 448.5506, 448.5499,
            448.4453, 448.5003, 448.5511, 448.5500, 448.4478, 448.5494, 448.5496,
            448.5499, 448.5503, 448.5496, 448.5496, 448.5502, 448.5010, 448.4863,
            448.5500, 448.5493, 448.5496, 448.5498, 448.5498, 448.5519, 448.5495,
            448.5493, 448.4471, 448.5517, 448.5488, 448.5494, 448.5497, 448.5494,
            448.4458, 448.5503, 448.4460, 448.4460, 448.5490, 448.4453, 448.5499,
            448.5493, 448.5496, 448.5011, 448.5492, 448.5516, 448.5505, 448.5500,
            448.5498, 448.4453, 448.5497, 448.5507, 448.5498, 448.5495, 448.5500,
            448.5507, 448.5496, 448.5500, 448.5505, 448.5278, 448.4453, 448.4597,
            448.5500, 448.5543, 448.5496, 448.4468, 448.5496, 448.4487, 448.5007,
            448.5497, 448.4758, 448.4453, 448.5497, 448.4453, 448.5510, 448.5495,
            448.5525, 448.5494, 448.4453, 448.5494, 448.4521, 448.5494, 448.5507,
            448.4457, 448.4811, 448.5500, 448.5493, 448.5491, 448.5504, 448.5494,
            448.5495, 448.5498, 448.5496, 448.5496, 448.5493, 448.5488, 448.5492,
            448.4468, 448.5495, 448.5494, 448.5491, 448.5491, 448.5504, 448.5291,
            448.4453, 448.5504, 448.5495, 448.5227, 448.5517, 448.5494, 448.4791,
            448.5513, 448.5498, 448.5488, 448.5495, 448.5512, 448.4453, 448.5497,
            448.5518, 448.5534, 448.5497, 448.5499, 448.5498, 448.5035, 448.5494,
            448.5497, 448.4453, 448.5501, 448.5508, 448.5497, 448.5498, 448.5496,
            448.5493, 448.4478, 448.4543, 448.5500, 448.5494, 448.5493, 448.4454,
            448.5011, 448.5491, 448.5490, 448.5489, 448.5494, 448.4456, 448.5275,
            448.4453, 448.5497, 448.5521, 448.5534, 448.5491, 448.5072, 448.5497,
            448.4467, 448.5497, 448.4502, 448.5496, 448.4453, 448.5522, 448.5498,
            448.5494, 448.5496, 448.5025, 448.5505, 448.5550, 448.5503, 448.5010,
            448.5497, 448.4453, 448.5008, 448.5503, 448.5499, 448.5547, 448.5518,
            448.5504, 448.5491, 448.5494, 448.4464, 448.5496, 448.5024, 448.4471,
            448.4457, 448.4453, 448.5524, 448.5501, 448.5496, 448.5496, 448.4475,
            448.5504, 448.5493, 448.5541, 448.5512, 448.5503, 448.5507, 448.5015,
            448.5491, 448.5498, 448.5499, 448.5007, 448.5497, 448.5030, 448.5491,
            448.4453, 448.5497, 448.5497, 448.5500, 448.5495, 448.5516, 448.5529,
            448.4784, 448.5489, 448.5499, 448.5490, 448.4453, 448.5025, 448.4456,
            448.5269, 448.4506, 448.5496, 448.4757, 448.5490, 448.5521, 448.5493,
            448.5495, 448.5529, 448.5498, 448.5519, 448.5496, 448.5342, 448.4464,
            448.5498, 448.5012, 448.5490, 448.5497, 448.5508, 448.4555, 448.5500,
            448.5496, 448.5495, 448.5496, 448.5495, 448.4465, 448.5413, 448.5503,
            448.5495, 448.5494, 448.5497, 448.5504, 448.5491, 448.4476, 448.5492,
            448.5497, 448.4453, 448.5495, 448.4453, 448.4474, 448.5498, 448.5497,
            448.4485, 448.5507, 448.5497, 448.4484, 448.5498, 448.4760, 448.4453,
            448.5497, 448.4498, 448.5497, 448.5500, 448.5494, 448.5494, 448.5497,
            448.4454, 448.5502, 448.5020, 448.5008, 448.4455, 448.5496, 448.5499,
            448.5006, 448.5498, 448.5496, 448.5507, 448.4471, 448.5510, 448.5510,
            448.5493, 448.5505, 448.4453, 448.5499, 448.5496, 448.5521, 448.5496,
            448.5519, 448.5016, 448.4470, 448.5494, 448.5533, 448.5505, 448.4453,
            448.5013, 448.5495, 448.5497, 448.5497, 448.5510, 448.5503, 448.5499,
            448.4453, 448.5550, 448.5496, 448.5497, 448.5543, 448.4465, 448.5503,
            448.5496, 448.5497, 448.4758, 448.5498, 448.5024, 448.5501, 448.5492,
            448.4460, 448.4454, 448.5494, 448.5497, 448.5494, 448.5493, 448.4454,
            448.5496, 448.5490, 448.5491, 448.5498, 448.4461, 448.4454, 448.5489,
            448.4590, 448.5497, 448.5498, 448.5495, 448.5494, 448.5498, 448.4454,
            448.4453, 448.5500, 448.5543, 448.4453, 448.4783, 448.5496, 448.5505,
            448.5494, 448.5509, 448.5507, 448.5537, 448.5498, 448.4461, 448.5497,
            448.5499, 448.5507, 448.5497, 448.5491, 448.5496, 448.5502, 448.5497,
            448.5500, 448.5505, 448.5504, 448.5511, 448.5498, 448.5495, 448.5500,
            448.5496, 448.5489, 448.5538, 448.5512, 448.4453, 448.5510, 448.5494,
            448.5496, 448.5496, 448.5508, 448.5517, 448.4531, 448.5496, 448.5505,
            448.5499, 448.5517, 448.5497, 448.5494, 448.5490, 448.4462, 448.5301,
            448.5496, 448.5495, 448.5498, 448.4459, 448.5499, 448.5002, 448.5512,
            448.5042, 448.5491, 448.4453, 448.4453, 448.5500, 448.5496, 448.5496,
            448.5495, 448.5016, 448.5495, 448.5501, 448.5496, 448.4455, 448.5497,
            448.5497, 448.5526, 448.5497, 448.5504, 448.5276, 448.5507, 448.5496,
            448.5488, 448.5491, 448.5489, 448.5491, 448.5493, 448.5513, 448.5522,
            448.5026, 448.5495, 448.5497, 448.5492, 448.5495, 448.4453, 448.4453,
            448.5514, 448.5495, 448.5497, 448.5508, 448.5548, 448.4454, 448.4453,
            448.5009, 448.4759, 448.5513, 448.5497, 448.4470, 448.5492, 448.4454,
            448.5494, 448.4461, 448.5496, 448.5497, 448.5497, 448.5498, 448.4471,
            448.5498, 448.5497, 448.5513, 448.5548, 448.5497, 448.5490, 448.5500,
            448.4463, 448.5550, 448.5510, 448.5266, 448.5499, 448.4455, 448.5493,
            448.5488, 448.5502, 448.5500, 448.5498, 448.5542, 448.5491, 448.5503,
            448.5508, 448.5496, 448.5497, 448.5497, 448.5497, 448.4453, 448.4453,
            448.5500, 448.5009, 448.5496, 448.4501, 448.5488, 448.5496, 448.5518,
            448.5522, 448.4453, 448.4455, 448.5498, 448.5498, 448.5514, 448.5493,
            448.4765, 448.5499, 448.5493, 448.4453, 448.4560, 448.5494, 448.5496,
            448.5495, 448.5503, 448.5500, 448.4499, 448.5526, 448.4481, 448.5488,
            448.4456, 448.5506, 448.5494, 448.5494, 448.4467, 448.5520, 448.5493,
            448.5495, 448.4453, 448.5497, 448.5492, 448.4453, 448.5500, 448.5534,
            448.5494, 448.5540, 448.4457, 448.5496, 448.4971, 448.5493, 448.5507,
            448.5491, 448.5500, 448.5497, 448.5516, 448.5498, 448.5494, 448.5496,
            448.5498, 448.5493, 448.5524, 448.5518, 448.5552, 448.5281, 448.5551,
            448.4455, 448.5560, 448.5498, 448.5496, 448.5499, 448.4454, 448.5494,
            448.5490, 448.5494, 448.5006, 448.5551, 448.5032, 448.5491, 448.5009,
            448.5498, 448.5491, 448.5519, 448.5504, 448.5010, 448.5294, 448.5487,
            448.5500, 448.4807, 448.5496, 448.4460, 448.5497, 448.5491, 448.5500,
            448.5113, 448.5492, 448.4454, 448.5497, 448.5269, 448.5023, 448.5497,
            448.5509, 448.5493, 448.4588, 448.5291, 448.4467, 448.4773, 448.5505,
            448.5501, 448.5488, 448.5497, 448.5503, 448.5496, 448.5498, 448.5508,
            448.4455, 448.4456], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4537, 448.5522, 448.5494, 448.5508, 448.5503, 448.4472, 448.5495,
        448.5505, 448.5499, 448.5497, 448.4453, 448.5494, 448.5497, 448.5004,
        448.5496, 448.5488, 448.5497, 448.4453, 448.4484, 448.5495, 448.5499,
        448.4759, 448.5502, 448.5306, 448.5496, 448.5497, 448.5502, 448.5494,
        448.5497, 448.5506, 448.5496, 448.5515, 448.5497, 448.5493, 448.5497,
        448.5497, 448.5526, 448.4754, 448.5498, 448.5508, 448.5007, 448.5488,
        448.4453, 448.5491, 448.5494, 448.5498, 448.4512, 448.5497, 448.5500,
        448.5494, 448.5496, 448.4513, 448.5010, 448.5262, 448.4483, 448.4453,
        448.4761, 448.5496, 448.4478, 448.5295, 448.4463, 448.5533, 448.5494,
        448.5506, 448.5497, 448.5500, 448.4470, 448.5496, 448.5503, 448.5491,
        448.5531, 448.4480, 448.4453, 448.5491, 448.4453, 448.4456, 448.5497,
        448.5497, 448.5010, 448.5497, 448.5497, 448.5495, 448.4462, 448.5299,
        448.5496, 448.5491, 448.5488, 448.5495, 448.4456, 448.5496, 448.5506,
        448.4457, 448.5534, 448.5504, 448.4453, 448.4462, 448.5491, 448.5298,
        448.5497, 448.4483, 448.5497, 448.5504, 448.5505, 448.4457, 448.4922,
        448.5502, 448.4470, 448.5495, 448.5492, 448.5490, 448.5491, 448.5493,
        448.5498, 448.5491, 448.5493, 448.4454, 448.5490, 448.4453, 448.5506,
        448.5519, 448.4453, 448.5493, 448.5492, 448.5499, 448.5035, 448.4453,
        448.4453, 448.4453, 448.5511, 448.5496, 448.5490, 448.5056, 448.5515,
        448.5273, 448.4805, 448.5516, 448.4486, 448.5501, 448.5488, 448.5497,
        448.5294, 448.4453, 448.5493, 448.5494, 448.5498, 448.5500, 448.5496,
        448.5531, 448.5493, 448.5494, 448.5497, 448.5501, 448.4459, 448.4470,
        448.5498, 448.5495, 448.4463, 448.5492, 448.5496, 448.4456, 448.5501,
        448.5551, 448.4584, 448.5051, 448.5493, 448.5497, 448.5532, 448.5491,
        448.5286, 448.5492, 448.5416, 448.5499, 448.5492, 448.5496, 448.4544,
        448.5494, 448.4453, 448.5496, 448.5499, 448.5031, 448.5497, 448.5503,
        448.4512, 448.5551, 448.5496, 448.5502, 448.5005, 448.5271, 448.5500,
        448.4453, 448.5496, 448.5494, 448.5496, 448.5502, 448.5494, 448.5496,
        448.4756, 448.5533, 448.4456, 448.5494, 448.5010, 448.5497, 448.5498,
        448.5490, 448.5015, 448.4454, 448.5495, 448.5488, 448.5488, 448.5497,
        448.5496, 448.5495, 448.5496, 448.5498, 448.4453, 448.5496, 448.5496,
        448.4467, 448.5011, 448.5506, 448.5009, 448.5503, 448.5491, 448.4453,
        448.5498, 448.5499, 448.5496, 448.5496, 448.5010, 448.5497, 448.5487,
        448.4453, 448.5493, 448.4753, 448.5494, 448.5430, 448.5498, 448.5494,
        448.5497, 448.4462, 448.5496, 448.5501, 448.5500, 448.5512, 448.5491,
        448.5499, 448.5498, 448.5508, 448.5491, 448.4462, 448.5497, 448.5493,
        448.5498, 448.5491, 448.5497, 448.5032, 448.5499, 448.4456, 448.5495,
        448.5494, 448.5497, 448.4453, 448.5496, 448.5496, 448.5494, 448.5497,
        448.5497, 448.4453, 448.5498, 448.5498, 448.4507, 448.5497, 448.5495,
        448.4453, 448.5498, 448.5497, 448.5500, 448.5496, 448.4491, 448.5504,
        448.5494, 448.5496, 448.5491, 448.5514, 448.4462, 448.5496, 448.5487,
        448.5497, 448.5497, 448.5499, 448.5508, 448.5496, 448.5496, 448.5498,
        448.5549, 448.4453, 448.5498, 448.5498, 448.4453, 448.5505, 448.5499,
        448.5502, 448.5494, 448.4465, 448.5495, 448.5494, 448.5500, 448.5497,
        448.5498, 448.5490, 448.5490, 448.5497, 448.5499, 448.4456, 448.4453,
        448.5495, 448.5500, 448.5497, 448.5505, 448.5490, 448.5490, 448.5012,
        448.5491, 448.5496, 448.5493, 448.4455, 448.5487, 448.5572, 448.4471,
        448.5495, 448.5494, 448.5502, 448.5496, 448.5496, 448.5506, 448.5499,
        448.4453, 448.5003, 448.5511, 448.5500, 448.4478, 448.5494, 448.5496,
        448.5499, 448.5503, 448.5496, 448.5496, 448.5502, 448.5010, 448.4863,
        448.5500, 448.5493, 448.5496, 448.5498, 448.5498, 448.5519, 448.5495,
        448.5493, 448.4471, 448.5517, 448.5488, 448.5494, 448.5497, 448.5494,
        448.4458, 448.5503, 448.4460, 448.4460, 448.5490, 448.4453, 448.5499,
        448.5493, 448.5496, 448.5011, 448.5492, 448.5516, 448.5505, 448.5500,
        448.5498, 448.4453, 448.5497, 448.5507, 448.5498, 448.5495, 448.5500,
        448.5507, 448.5496, 448.5500, 448.5505, 448.5278, 448.4453, 448.4597,
        448.5500, 448.5543, 448.5496, 448.4468, 448.5496, 448.4487, 448.5007,
        448.5497, 448.4758, 448.4453, 448.5497, 448.4453, 448.5510, 448.5495,
        448.5525, 448.5494, 448.4453, 448.5494, 448.4521, 448.5494, 448.5507,
        448.4457, 448.4811, 448.5500, 448.5493, 448.5491, 448.5504, 448.5494,
        448.5495, 448.5498, 448.5496, 448.5496, 448.5493, 448.5488, 448.5492,
        448.4468, 448.5495, 448.5494, 448.5491, 448.5491, 448.5504, 448.5291,
        448.4453, 448.5504, 448.5495, 448.5227, 448.5517, 448.5494, 448.4791,
        448.5513, 448.5498, 448.5488, 448.5495, 448.5512, 448.4453, 448.5497,
        448.5518, 448.5534, 448.5497, 448.5499, 448.5498, 448.5035, 448.5494,
        448.5497, 448.4453, 448.5501, 448.5508, 448.5497, 448.5498, 448.5496,
        448.5493, 448.4478, 448.4543, 448.5500, 448.5494, 448.5493, 448.4454,
        448.5011, 448.5491, 448.5490, 448.5489, 448.5494, 448.4456, 448.5275,
        448.4453, 448.5497, 448.5521, 448.5534, 448.5491, 448.5072, 448.5497,
        448.4467, 448.5497, 448.4502, 448.5496, 448.4453, 448.5522, 448.5498,
        448.5494, 448.5496, 448.5025, 448.5505, 448.5550, 448.5503, 448.5010,
        448.5497, 448.4453, 448.5008, 448.5503, 448.5499, 448.5547, 448.5518,
        448.5504, 448.5491, 448.5494, 448.4464, 448.5496, 448.5024, 448.4471,
        448.4457, 448.4453, 448.5524, 448.5501, 448.5496, 448.5496, 448.4475,
        448.5504, 448.5493, 448.5541, 448.5512, 448.5503, 448.5507, 448.5015,
        448.5491, 448.5498, 448.5499, 448.5007, 448.5497, 448.5030, 448.5491,
        448.4453, 448.5497, 448.5497, 448.5500, 448.5495, 448.5516, 448.5529,
        448.4784, 448.5489, 448.5499, 448.5490, 448.4453, 448.5025, 448.4456,
        448.5269, 448.4506, 448.5496, 448.4757, 448.5490, 448.5521, 448.5493,
        448.5495, 448.5529, 448.5498, 448.5519, 448.5496, 448.5342, 448.4464,
        448.5498, 448.5012, 448.5490, 448.5497, 448.5508, 448.4555, 448.5500,
        448.5496, 448.5495, 448.5496, 448.5495, 448.4465, 448.5413, 448.5503,
        448.5495, 448.5494, 448.5497, 448.5504, 448.5491, 448.4476, 448.5492,
        448.5497, 448.4453, 448.5495, 448.4453, 448.4474, 448.5498, 448.5497,
        448.4485, 448.5507, 448.5497, 448.4484, 448.5498, 448.4760, 448.4453,
        448.5497, 448.4498, 448.5497, 448.5500, 448.5494, 448.5494, 448.5497,
        448.4454, 448.5502, 448.5020, 448.5008, 448.4455, 448.5496, 448.5499,
        448.5006, 448.5498, 448.5496, 448.5507, 448.4471, 448.5510, 448.5510,
        448.5493, 448.5505, 448.4453, 448.5499, 448.5496, 448.5521, 448.5496,
        448.5519, 448.5016, 448.4470, 448.5494, 448.5533, 448.5505, 448.4453,
        448.5013, 448.5495, 448.5497, 448.5497, 448.5510, 448.5503, 448.5499,
        448.4453, 448.5550, 448.5496, 448.5497, 448.5543, 448.4465, 448.5503,
        448.5496, 448.5497, 448.4758, 448.5498, 448.5024, 448.5501, 448.5492,
        448.4460, 448.4454, 448.5494, 448.5497, 448.5494, 448.5493, 448.4454,
        448.5496, 448.5490, 448.5491, 448.5498, 448.4461, 448.4454, 448.5489,
        448.4590, 448.5497, 448.5498, 448.5495, 448.5494, 448.5498, 448.4454,
        448.4453, 448.5500, 448.5543, 448.4453, 448.4783, 448.5496, 448.5505,
        448.5494, 448.5509, 448.5507, 448.5537, 448.5498, 448.4461, 448.5497,
        448.5499, 448.5507, 448.5497, 448.5491, 448.5496, 448.5502, 448.5497,
        448.5500, 448.5505, 448.5504, 448.5511, 448.5498, 448.5495, 448.5500,
        448.5496, 448.5489, 448.5538, 448.5512, 448.4453, 448.5510, 448.5494,
        448.5496, 448.5496, 448.5508, 448.5517, 448.4531, 448.5496, 448.5505,
        448.5499, 448.5517, 448.5497, 448.5494, 448.5490, 448.4462, 448.5301,
        448.5496, 448.5495, 448.5498, 448.4459, 448.5499, 448.5002, 448.5512,
        448.5042, 448.5491, 448.4453, 448.4453, 448.5500, 448.5496, 448.5496,
        448.5495, 448.5016, 448.5495, 448.5501, 448.5496, 448.4455, 448.5497,
        448.5497, 448.5526, 448.5497, 448.5504, 448.5276, 448.5507, 448.5496,
        448.5488, 448.5491, 448.5489, 448.5491, 448.5493, 448.5513, 448.5522,
        448.5026, 448.5495, 448.5497, 448.5492, 448.5495, 448.4453, 448.4453,
        448.5514, 448.5495, 448.5497, 448.5508, 448.5548, 448.4454, 448.4453,
        448.5009, 448.4759, 448.5513, 448.5497, 448.4470, 448.5492, 448.4454,
        448.5494, 448.4461, 448.5496, 448.5497, 448.5497, 448.5498, 448.4471,
        448.5498, 448.5497, 448.5513, 448.5548, 448.5497, 448.5490, 448.5500,
        448.4463, 448.5550, 448.5510, 448.5266, 448.5499, 448.4455, 448.5493,
        448.5488, 448.5502, 448.5500, 448.5498, 448.5542, 448.5491, 448.5503,
        448.5508, 448.5496, 448.5497, 448.5497, 448.5497, 448.4453, 448.4453,
        448.5500, 448.5009, 448.5496, 448.4501, 448.5488, 448.5496, 448.5518,
        448.5522, 448.4453, 448.4455, 448.5498, 448.5498, 448.5514, 448.5493,
        448.4765, 448.5499, 448.5493, 448.4453, 448.4560, 448.5494, 448.5496,
        448.5495, 448.5503, 448.5500, 448.4499, 448.5526, 448.4481, 448.5488,
        448.4456, 448.5506, 448.5494, 448.5494, 448.4467, 448.5520, 448.5493,
        448.5495, 448.4453, 448.5497, 448.5492, 448.4453, 448.5500, 448.5534,
        448.5494, 448.5540, 448.4457, 448.5496, 448.4971, 448.5493, 448.5507,
        448.5491, 448.5500, 448.5497, 448.5516, 448.5498, 448.5494, 448.5496,
        448.5498, 448.5493, 448.5524, 448.5518, 448.5552, 448.5281, 448.5551,
        448.4455, 448.5560, 448.5498, 448.5496, 448.5499, 448.4454, 448.5494,
        448.5490, 448.5494, 448.5006, 448.5551, 448.5032, 448.5491, 448.5009,
        448.5498, 448.5491, 448.5519, 448.5504, 448.5010, 448.5294, 448.5487,
        448.5500, 448.4807, 448.5496, 448.4460, 448.5497, 448.5491, 448.5500,
        448.5113, 448.5492, 448.4454, 448.5497, 448.5269, 448.5023, 448.5497,
        448.5509, 448.5493, 448.4588, 448.5291, 448.4467, 448.4773, 448.5505,
        448.5501, 448.5488, 448.5497, 448.5503, 448.5496, 448.5498, 448.5508,
        448.4455, 448.4456], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([407.8646], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1113],
             [112.1113],
             [112.1113],
             [112.1113]],

            [[112.1376],
             [112.1373],
             [112.1374],
             [112.1373]],

            [[112.1135],
             [112.1114],
             [112.1114],
             [112.1133]],

            ...,

            [[112.1376],
             [112.1372],
             [112.1374],
             [112.1374]],

            [[112.1374],
             [112.1372],
             [112.1374],
             [112.1373]],

            [[112.1113],
             [112.1113],
             [112.1113],
             [112.1113]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4453, 448.5496, 448.4496,  ..., 448.5496, 448.5493, 448.4453],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4453, 448.5496, 448.4496,  ..., 448.5496, 448.5493, 448.4453],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1315],
             [112.1315],
             [112.1315],
             [112.1315]],

            [[112.1219],
             [112.1219],
             [112.1219],
             [112.1219]],

            [[112.1315],
             [112.1316],
             [112.1316],
             [112.1317]],

            ...,

            [[112.1315],
             [112.1315],
             [112.1315],
             [112.1315]],

            [[112.1316],
             [112.1317],
             [112.1315],
             [112.1315]],

            [[112.1315],
             [112.1317],
             [112.1316],
             [112.1315]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5261, 448.4877, 448.5264,  ..., 448.5261, 448.5264, 448.5264],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5261, 448.4877, 448.5264,  ..., 448.5261, 448.5264, 448.5264],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1311],
             [112.1311],
             [112.1311],
             [112.1311]],

            [[112.1266],
             [112.1267],
             [112.1267],
             [112.1268]],

            [[112.1268],
             [112.1267],
             [112.1267],
             [112.1267]],

            ...,

            [[112.1267],
             [112.1271],
             [112.1267],
             [112.1267]],

            [[112.1268],
             [112.1268],
             [112.1267],
             [112.1267]],

            [[112.1268],
             [112.1267],
             [112.1267],
             [112.1268]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5245, 448.5068, 448.5070,  ..., 448.5073, 448.5070, 448.5070],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5245, 448.5068, 448.5070,  ..., 448.5073, 448.5070, 448.5070],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1215],
             [112.1183],
             [112.1200],
             [112.1183]],

            [[112.1184],
             [112.1184],
             [112.1184],
             [112.1184]],

            [[112.1186],
             [112.1183],
             [112.1184],
             [112.1187]],

            ...,

            [[112.1186],
             [112.1186],
             [112.1184],
             [112.1184]],

            [[112.1184],
             [112.1184],
             [112.1183],
             [112.1183]],

            [[112.1185],
             [112.1189],
             [112.1186],
             [112.1186]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4781, 448.4735, 448.4740,  ..., 448.4739, 448.4735, 448.4746],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4781, 448.4735, 448.4740,  ..., 448.4739, 448.4735, 448.4746],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1630],
             [112.1630],
             [112.1630],
             [112.1630]],

            [[112.1091],
             [112.1091],
             [112.1091],
             [112.1091]],

            [[112.1071],
             [112.1082],
             [112.1073],
             [112.1082]],

            ...,

            [[112.1630],
             [112.1630],
             [112.1624],
             [112.1624]],

            [[112.1080],
             [112.1084],
             [112.1083],
             [112.1085]],

            [[112.1090],
             [112.1090],
             [112.1092],
             [112.1092]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6519, 448.4363, 448.4308,  ..., 448.6506, 448.4333, 448.4366],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6519, 448.4363, 448.4308,  ..., 448.6506, 448.4333, 448.4366],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0993],
             [112.1004],
             [112.0996],
             [112.1000]],

            [[112.1781],
             [112.1781],
             [112.1781],
             [112.1781]],

            [[112.1689],
             [112.0992],
             [112.1731],
             [112.0992]],

            ...,

            [[112.1001],
             [112.1001],
             [112.1001],
             [112.1001]],

            [[112.1681],
             [112.1681],
             [112.1651],
             [112.1651]],

            [[112.1001],
             [112.1001],
             [112.1001],
             [112.1001]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3993, 448.7124, 448.5404,  ..., 448.4005, 448.6664, 448.4004],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3993, 448.7124, 448.5404,  ..., 448.4005, 448.6664, 448.4004],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1864],
             [112.0950],
             [112.1864],
             [112.0958]],

            [[112.0975],
             [112.0985],
             [112.0974],
             [112.0985]],

            [[112.0979],
             [112.0973],
             [112.0974],
             [112.1830]],

            ...,

            [[112.0986],
             [112.0979],
             [112.0981],
             [112.0981]],

            [[112.1802],
             [112.0973],
             [112.0971],
             [112.0971]],

            [[112.0980],
             [112.0980],
             [112.0988],
             [112.0982]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5636, 448.3919, 448.4756,  ..., 448.3927, 448.4717, 448.3931],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5636, 448.3919, 448.4756,  ..., 448.3927, 448.4717, 448.3931],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0961],
             [112.0966],
             [112.0959],
             [112.0969]],

            [[112.0958],
             [112.0963],
             [112.0967],
             [112.0970]],

            [[112.0954],
             [112.0986],
             [112.0921],
             [112.0954]],

            ...,

            [[112.1932],
             [112.0935],
             [112.1934],
             [112.0932]],

            [[112.0961],
             [112.0961],
             [112.0965],
             [112.0965]],

            [[112.0961],
             [112.0966],
             [112.0970],
             [112.0959]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3855, 448.3858, 448.3815,  ..., 448.5733, 448.3851, 448.3857],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3855, 448.3858, 448.3815,  ..., 448.5733, 448.3851, 448.3857],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0893],
             [112.0909],
             [112.0909],
             [112.0909]],

            [[112.0909],
             [112.0909],
             [112.0909],
             [112.0909]],

            [[112.2036],
             [112.2036],
             [112.2036],
             [112.2036]],

            ...,

            [[112.0895],
             [112.0909],
             [112.0909],
             [112.0909]],

            [[112.0904],
             [112.0904],
             [112.0909],
             [112.0909]],

            [[112.0921],
             [112.0927],
             [112.0917],
             [112.0927]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3619, 448.3636, 448.8143,  ..., 448.3622, 448.3625, 448.3692],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3619, 448.3636, 448.8143,  ..., 448.3622, 448.3625, 448.3692],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0830],
             [112.0830],
             [112.0829],
             [112.0829]],

            [[112.0835],
             [112.0828],
             [112.0836],
             [112.0843]],

            [[112.0815],
             [112.0829],
             [112.0826],
             [112.0826]],

            ...,

            [[112.0842],
             [112.0837],
             [112.0837],
             [112.0837]],

            [[112.0826],
             [112.0826],
             [112.0841],
             [112.0841]],

            [[112.2132],
             [112.2132],
             [112.2127],
             [112.2127]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3317, 448.3342, 448.3296,  ..., 448.3353, 448.3334, 448.8518],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3317, 448.3342, 448.3296,  ..., 448.3353, 448.3334, 448.8518],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0814],
             [112.0814],
             [112.0821],
             [112.0821]],

            [[112.2125],
             [112.0798],
             [112.2177],
             [112.0792]],

            [[112.0804],
             [112.0773],
             [112.0805],
             [112.0771]],

            ...,

            [[112.0802],
             [112.0802],
             [112.0803],
             [112.0803]],

            [[112.0803],
             [112.0803],
             [112.0818],
             [112.0818]],

            [[112.0819],
             [112.0810],
             [112.0814],
             [112.0821]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3271, 448.5893, 448.3153,  ..., 448.3210, 448.3242, 448.3264],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3271, 448.5893, 448.3153,  ..., 448.3210, 448.3242, 448.3264],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2259],
             [112.2259],
             [112.2259],
             [112.2259]],

            [[112.0765],
             [112.0778],
             [112.0761],
             [112.0770]],

            [[112.0765],
             [112.0765],
             [112.0754],
             [112.0754]],

            ...,

            [[112.0778],
             [112.0775],
             [112.0778],
             [112.0767]],

            [[112.2193],
             [112.2256],
             [112.2200],
             [112.2256]],

            [[112.0776],
             [112.0776],
             [112.0779],
             [112.0779]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9037, 448.3075, 448.3039,  ..., 448.3098, 448.8905, 448.3111],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9037, 448.3075, 448.3039,  ..., 448.3098, 448.8905, 448.3111],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2261],
             [112.2261],
             [112.2259],
             [112.2259]],

            [[112.2262],
             [112.2228],
             [112.2261],
             [112.2226]],

            [[112.2263],
             [112.2263],
             [112.2263],
             [112.2263]],

            ...,

            [[112.0768],
             [112.0749],
             [112.0749],
             [112.0768]],

            [[112.2263],
             [112.2263],
             [112.2263],
             [112.2263]],

            [[112.2262],
             [112.2263],
             [112.2263],
             [112.2262]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9040, 448.8976, 448.9053,  ..., 448.3034, 448.9052, 448.9051],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9040, 448.8976, 448.9053,  ..., 448.3034, 448.9052, 448.9051],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0704],
             [112.0720],
             [112.0707],
             [112.0707]],

            [[112.0700],
             [112.0702],
             [112.0720],
             [112.0700]],

            [[112.0702],
             [112.0720],
             [112.0720],
             [112.0720]],

            ...,

            [[112.0720],
             [112.0720],
             [112.0720],
             [112.0720]],

            [[112.0709],
             [112.0720],
             [112.0720],
             [112.0720]],

            [[112.0711],
             [112.0711],
             [112.0720],
             [112.0720]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2838, 448.2823, 448.2862,  ..., 448.2880, 448.2869, 448.2862],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2838, 448.2823, 448.2862,  ..., 448.2880, 448.2869, 448.2862],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2414],
             [112.2411],
             [112.2413],
             [112.2413]],

            [[112.2413],
             [112.2405],
             [112.2411],
             [112.2411]],

            [[112.0683],
             [112.0665],
             [112.0668],
             [112.0685]],

            ...,

            [[112.2364],
             [112.0651],
             [112.2354],
             [112.0657]],

            [[112.0683],
             [112.0676],
             [112.0670],
             [112.0685]],

            [[112.2412],
             [112.2397],
             [112.2412],
             [112.2391]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9651, 448.9642, 448.2702,  ..., 448.6026, 448.2714, 448.9612],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9651, 448.9642, 448.2702,  ..., 448.6026, 448.2714, 448.9612],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0680],
             [112.0697],
             [112.0697],
             [112.0694]],

            [[112.0695],
             [112.0676],
             [112.0678],
             [112.0697]],

            [[112.2386],
             [112.2363],
             [112.2380],
             [112.2380]],

            ...,

            [[112.2382],
             [112.2382],
             [112.2326],
             [112.2326]],

            [[112.0688],
             [112.0697],
             [112.0676],
             [112.0674]],

            [[112.0697],
             [112.0696],
             [112.0697],
             [112.0697]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2769, 448.2746, 448.9508,  ..., 448.9415, 448.2735, 448.2787],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2769, 448.2746, 448.9508,  ..., 448.9415, 448.2735, 448.2787],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0697],
             [112.0712],
             [112.0715],
             [112.0715]],

            [[112.0715],
             [112.0715],
             [112.0715],
             [112.0715]],

            [[112.0696],
             [112.0691],
             [112.0704],
             [112.0694]],

            ...,

            [[112.0693],
             [112.1331],
             [112.1442],
             [112.0694]],

            [[112.2358],
             [112.2358],
             [112.2358],
             [112.2358]],

            [[112.0712],
             [112.0707],
             [112.0699],
             [112.0714]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2839, 448.2859, 448.2784,  ..., 448.4161, 448.9430, 448.2832],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2839, 448.2859, 448.2784,  ..., 448.4161, 448.9430, 448.2832],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0684],
             [112.0675],
             [112.0679],
             [112.0692]],

            [[112.0692],
             [112.0676],
             [112.0687],
             [112.0683]],

            [[112.0674],
             [112.0691],
             [112.0687],
             [112.0687]],

            ...,

            [[112.0677],
             [112.0693],
             [112.0681],
             [112.0692]],

            [[112.0692],
             [112.0693],
             [112.0691],
             [112.0682]],

            [[112.0693],
             [112.0685],
             [112.0691],
             [112.0691]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2731, 448.2738, 448.2739,  ..., 448.2744, 448.2758, 448.2761],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2731, 448.2738, 448.2739,  ..., 448.2744, 448.2758, 448.2761],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([3.0119e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2379],
             [112.2365],
             [112.2379],
             [112.2367]],

            [[112.0642],
             [112.0627],
             [112.0637],
             [112.0620]],

            [[112.0629],
             [112.0636],
             [112.0645],
             [112.0645]],

            ...,

            [[112.0593],
             [112.0626],
             [112.0642],
             [112.0642]],

            [[112.0645],
             [112.0645],
             [112.0645],
             [112.0645]],

            [[112.0642],
             [112.0635],
             [112.0645],
             [112.0644]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9490, 448.2527, 448.2555,  ..., 448.2502, 448.2579, 448.2565],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9490, 448.2527, 448.2555,  ..., 448.2502, 448.2579, 448.2565],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2378],
             [112.2346],
             [112.2347],
             [112.2380]],

            [[112.2148],
             [112.0624],
             [112.0565],
             [112.0565]],

            [[112.0637],
             [112.0641],
             [112.0645],
             [112.0645]],

            ...,

            [[112.0611],
             [112.0635],
             [112.0628],
             [112.0628]],

            [[112.0627],
             [112.0633],
             [112.0627],
             [112.0643]],

            [[112.0623],
             [112.0637],
             [112.0625],
             [112.0639]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9451, 448.3902, 448.2568,  ..., 448.2502, 448.2529, 448.2525],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9451, 448.3902, 448.2568,  ..., 448.2502, 448.2529, 448.2525],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0644],
             [112.0644],
             [112.0645],
             [112.0645]],

            [[112.0645],
             [112.0633],
             [112.0637],
             [112.0645]],

            [[112.0637],
             [112.0642],
             [112.0645],
             [112.0645]],

            ...,

            [[112.2378],
             [112.2378],
             [112.2343],
             [112.2343]],

            [[112.0633],
             [112.0645],
             [112.0628],
             [112.0645]],

            [[112.0629],
             [112.0591],
             [112.0629],
             [112.0589]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2577, 448.2560, 448.2570, 448.2556, 448.2560, 448.9520, 448.2450,
            448.2575, 448.2581, 448.2531, 448.2547, 448.5930, 448.2577, 448.9504,
            448.2568, 448.2510, 448.2581, 448.2560, 448.2576, 448.2562, 448.2558,
            448.2409, 448.4080, 448.2579, 448.9422, 448.2550, 448.2416, 448.2533,
            448.2516, 448.2542, 448.9520, 448.2531, 448.2546, 448.2510, 448.4042,
            448.2341, 448.9457, 448.2578, 448.9520, 448.5738, 448.2571, 448.2571,
            448.2581, 448.2532, 448.2541, 448.2556, 448.2578, 448.2377, 448.2570,
            448.2534, 448.2548, 448.9510, 448.2549, 448.2534, 448.2580, 448.9520,
            448.2556, 448.2546, 448.2414, 448.4867, 448.2530, 448.2552, 448.2542,
            448.7646, 448.2554, 448.6221, 448.2547, 448.2517, 448.2410, 448.9497,
            448.2548, 448.2549, 448.7512, 448.2542, 448.2579, 448.2547, 448.2553,
            448.5851, 448.2552, 448.2524, 448.9515, 448.4188, 448.2545, 448.2554,
            448.2536, 448.2543, 448.2560, 448.2543, 448.9513, 448.2551, 448.2536,
            448.9516, 448.2251, 448.2558, 448.2542, 448.2482, 448.2568, 448.9519,
            448.9493, 448.2561, 448.2453, 448.2568, 448.5853, 448.9426, 448.9520,
            448.6740, 448.2544, 448.2549, 448.2545, 448.2538, 448.2560, 448.7473,
            448.5884, 448.2545, 448.2547, 448.2450, 448.2555, 448.2578, 448.2546,
            448.2592, 448.2578, 448.9519, 448.2554, 448.2490, 448.2527, 448.2580,
            448.9500, 448.2570, 448.2580, 448.5914, 448.2565, 448.2527, 448.9431,
            448.2539, 448.2535, 448.2562, 448.9509, 448.3885, 448.2572, 448.2562,
            448.2413, 448.2450, 448.2557, 448.2508, 448.2570, 448.9510, 448.2549,
            448.7575, 448.2512, 448.2565, 448.9519, 448.9520, 448.2520, 448.5772,
            448.4999, 448.2578, 448.2579, 448.2549, 448.2574, 448.2579, 448.2559,
            448.9463, 448.2578, 448.2556, 448.2541, 448.2446, 448.7653, 448.2556,
            448.2540, 448.5905, 448.2525, 448.2561, 448.2548, 448.2579, 448.9516,
            448.3720, 448.9514, 448.7136, 448.2543, 448.2548, 448.2500, 448.2562,
            448.2546, 448.2542, 448.2580, 448.2561, 448.2563, 448.7494, 448.2537,
            448.5889, 448.2496, 448.2548, 448.2523, 448.5922, 448.2380, 448.2403,
            448.2554, 448.2554, 448.2548, 448.2571, 448.2548, 448.2356, 448.9514,
            448.9461, 448.2496, 448.2571, 448.2572, 448.2562, 448.2546, 448.2579,
            448.9516, 448.2551, 448.2555, 448.2495, 448.8995, 448.5483, 448.2578,
            448.9509, 448.3667, 448.5828, 448.2575, 448.2349, 448.2494, 448.2561,
            448.5412, 448.2493, 448.2532, 448.2568, 448.2511, 448.2579, 448.2535,
            448.2567, 448.2565, 448.2546, 448.2521, 448.2541, 448.2581, 448.2544,
            448.2545, 448.2510, 448.2524, 448.2575, 448.2539, 448.2404, 448.2498,
            448.2534, 448.2465, 448.2574, 448.2544, 448.2548, 448.5586, 448.9468,
            448.2549, 448.2579, 448.9518, 448.2500, 448.9462, 448.2542, 448.2574,
            448.2479, 448.2559, 448.2546, 448.2580, 448.2552, 448.2562, 448.2504,
            448.9505, 448.2519, 448.2335, 448.9131, 448.2579, 448.2564, 448.2521,
            448.2531, 448.2569, 448.9434, 448.9503, 448.2557, 448.9519, 448.2535,
            448.2540, 448.2538, 448.4222, 448.2448, 448.2547, 448.2484, 448.2532,
            448.2580, 448.5849, 448.9461, 448.9520, 448.9462, 448.9509, 448.9520,
            448.2532, 448.2357, 448.9515, 448.2581, 448.2537, 448.4078, 448.2484,
            448.2540, 448.2511, 448.2578, 448.2555, 448.2539, 448.2437, 448.9268,
            448.5156, 448.9348, 448.2570, 448.9518, 448.2581, 448.9479, 448.9520,
            448.9380, 448.2580, 448.2517, 448.4046, 448.2563, 448.2532, 448.9515,
            448.9414, 448.2546, 448.2580, 448.2479, 448.2506, 448.2564, 448.2540,
            448.2510, 448.5800, 448.5914, 448.2562, 448.2533, 448.2545, 448.2322,
            448.2552, 448.4796, 448.2545, 448.2568, 448.2480, 448.2534, 448.2549,
            448.2558, 448.2489, 448.7025, 448.2570, 448.2575, 448.2573, 448.2581,
            448.9520, 448.2563, 448.2521, 448.2557, 448.7769, 448.4108, 448.2554,
            448.2567, 448.2572, 448.2575, 448.4184, 448.4164, 448.2581, 448.5864,
            448.2543, 448.2550, 448.9230, 448.2557, 448.2576, 448.2552, 448.2578,
            448.2580, 448.9379, 448.5768, 448.9493, 448.9374, 448.2579, 448.5587,
            448.2546, 448.2547, 448.2573, 448.2506, 448.2497, 448.9519, 448.2548,
            448.2569, 448.2573, 448.2549, 448.2525, 448.2571, 448.9518, 448.2556,
            448.9308, 448.2544, 448.9518, 448.4016, 448.2571, 448.9515, 448.2550,
            448.4223, 448.2580, 448.2579, 448.2496, 448.2575, 448.9520, 448.2562,
            448.2329, 448.5879, 448.2565, 448.2570, 448.9520, 448.2559, 448.2555,
            448.2571, 448.2562, 448.2559, 448.3213, 448.2565, 448.2575, 448.2551,
            448.5858, 448.2563, 448.5068, 448.5899, 448.9516, 448.9518, 448.2563,
            448.2374, 448.2579, 448.2568, 448.9409, 448.2576, 448.2307, 448.2552,
            448.9457, 448.5855, 448.3724, 448.2578, 448.2553, 448.2488, 448.5926,
            448.2335, 448.9505, 448.2563, 448.2466, 448.9516, 448.2457, 448.9514,
            448.2576, 448.2485, 448.2565, 448.9520, 448.2568, 448.2505, 448.2580,
            448.2563, 448.2565, 448.2548, 448.7643, 448.2551, 448.2581, 448.9520,
            448.2529, 448.2535, 448.5052, 448.5879, 448.2505, 448.2565, 448.2563,
            448.2483, 448.2567, 448.2503, 448.7576, 448.2551, 448.2547, 448.2567,
            448.9485, 448.2535, 448.2552, 448.2495, 448.2579, 448.2551, 448.9520,
            448.2563, 448.2545, 448.2512, 448.2577, 448.9108, 448.2523, 448.2551,
            448.9510, 448.2532, 448.2503, 448.2564, 448.9519, 448.9450, 448.2343,
            448.2459, 448.9503, 448.9520, 448.2549, 448.2580, 448.2572, 448.2568,
            448.2559, 448.2548, 448.2579, 448.2488, 448.5835, 448.9502, 448.2481,
            448.2548, 448.2535, 448.2545, 448.4661, 448.2572, 448.2560, 448.2548,
            448.2572, 448.2579, 448.2561, 448.2498, 448.2545, 448.2551, 448.2540,
            448.2531, 448.2550, 448.9501, 448.2476, 448.2548, 448.9512, 448.5668,
            448.5832, 448.2549, 448.2567, 448.2452, 448.2556, 448.2546, 448.4128,
            448.2549, 448.2520, 448.2570, 448.2562, 448.4170, 448.2542, 448.2524,
            448.4089, 448.9465, 448.2563, 448.8861, 448.2557, 448.2546, 448.2474,
            448.2559, 448.2561, 448.2557, 448.9516, 448.4050, 448.9508, 448.2542,
            448.2515, 448.2507, 448.9460, 448.2581, 448.2499, 448.2558, 448.2525,
            448.2565, 448.2532, 448.2411, 448.2549, 448.2529, 448.2530, 448.2579,
            448.2577, 448.2526, 448.9520, 448.9520, 448.2549, 448.2556, 448.2579,
            448.2558, 448.9517, 448.2576, 448.2535, 448.2564, 448.9355, 448.2464,
            448.2507, 448.2570, 448.2568, 448.2580, 448.2534, 448.2466, 448.2563,
            448.9520, 448.2580, 448.9430, 448.2542, 448.9509, 448.2418, 448.2527,
            448.9518, 448.2563, 448.2560, 448.2562, 448.2521, 448.2571, 448.2562,
            448.2577, 448.2528, 448.2519, 448.2538, 448.2576, 448.2557, 448.2547,
            448.9456, 448.2573, 448.2557, 448.9451, 448.2581, 448.2560, 448.9520,
            448.9490, 448.2551, 448.9485, 448.2579, 448.2544, 448.2513, 448.2545,
            448.2548, 448.2550, 448.2495, 448.9519, 448.2556, 448.2538, 448.2570,
            448.2581, 448.9520, 448.9518, 448.2474, 448.2563, 448.2512, 448.2574,
            448.9460, 448.2340, 448.2558, 448.2579, 448.2503, 448.2512, 448.2555,
            448.9175, 448.2580, 448.2550, 448.2579, 448.2565, 448.2520, 448.2558,
            448.9520, 448.2551, 448.2574, 448.2548, 448.2530, 448.2579, 448.2564,
            448.2361, 448.2547, 448.2517, 448.9444, 448.2579, 448.2581, 448.2575,
            448.2571, 448.9518, 448.9515, 448.2510, 448.2546, 448.2547, 448.9520,
            448.2556, 448.2567, 448.2471, 448.2569, 448.9519, 448.2580, 448.4022,
            448.4205, 448.2515, 448.2542, 448.2579, 448.2517, 448.5902, 448.2543,
            448.2537, 448.9410, 448.2552, 448.2544, 448.9390, 448.2543, 448.2556,
            448.2549, 448.2535, 448.2575, 448.2513, 448.2546, 448.2574, 448.2579,
            448.4716, 448.9406, 448.9520, 448.2580, 448.2477, 448.2571, 448.2574,
            448.2577, 448.2569, 448.2575, 448.2437, 448.2539, 448.2560, 448.9520,
            448.2534, 448.5402, 448.2374, 448.2580, 448.2567, 448.2556, 448.2565,
            448.2568, 448.9458, 448.2395, 448.9453, 448.9518, 448.2530, 448.2548,
            448.2579, 448.2579, 448.2482, 448.2543, 448.9518, 448.2551, 448.5681,
            448.9520, 448.2568, 448.2580, 448.7833, 448.2474, 448.2520, 448.2545,
            448.2531, 448.2548, 448.5818, 448.2561, 448.2628, 448.9495, 448.2556,
            448.2568, 448.9520, 448.2548, 448.5885, 448.2579, 448.2574, 448.2549,
            448.2551, 448.2553, 448.2580, 448.2555, 448.2487, 448.5877, 448.2503,
            448.2574, 448.7339, 448.2548, 448.2565, 448.9459, 448.2543, 448.2579,
            448.2533, 448.5917, 448.2562, 448.2563, 448.2529, 448.2579, 448.2531,
            448.2570, 448.9400, 448.2552, 448.2347, 448.2566, 448.2536, 448.3702,
            448.2548, 448.9520, 448.2555, 448.2546, 448.2542, 448.2475, 448.2370,
            448.2548, 448.2508, 448.2517, 448.2484, 448.2565, 448.5875, 448.9519,
            448.6785, 448.2515, 448.9509, 448.2546, 448.7343, 448.9509, 448.2574,
            448.4012, 448.9520, 448.2579, 448.2579, 448.2559, 448.2550, 448.7659,
            448.2578, 448.2573, 448.2548, 448.7543, 448.9460, 448.5856, 448.9399,
            448.2541, 448.2520, 448.2571, 448.2555, 448.5899, 448.2466, 448.2580,
            448.2576, 448.9509, 448.2547, 448.5806, 448.5866, 448.5822, 448.2535,
            448.2514, 448.2518, 448.2548, 448.9518, 448.4045, 448.2579, 448.2556,
            448.9520, 448.2549, 448.2533, 448.2567, 448.2559, 448.5912, 448.9500,
            448.2548, 448.2527, 448.2580, 448.9341, 448.2568, 448.9520, 448.2543,
            448.2542, 448.9477, 448.2580, 448.5889, 448.9519, 448.2580, 448.2578,
            448.7560, 448.5814, 448.2569, 448.9520, 448.9481, 448.2537, 448.9509,
            448.6765, 448.4073, 448.2562, 448.2578, 448.2580, 448.2579, 448.2568,
            448.2568, 448.9515, 448.2533, 448.2550, 448.9483, 448.3782, 448.2546,
            448.2550, 448.2545, 448.2559, 448.2528, 448.2563, 448.2580, 448.2579,
            448.2534, 448.5799, 448.2473, 448.5935, 448.2564, 448.5840, 448.9516,
            448.2461, 448.2545, 448.2560, 448.2552, 448.4850, 448.2580, 448.9519,
            448.2563, 448.2556, 448.9520, 448.2564, 448.2551, 448.2580, 448.5860,
            448.2549, 448.2548, 448.2559, 448.9520, 448.2548, 448.5884, 448.9442,
            448.2552, 448.2438], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2577, 448.2560, 448.2570, 448.2556, 448.2560, 448.9520, 448.2450,
        448.2575, 448.2581, 448.2531, 448.2547, 448.5930, 448.2577, 448.9504,
        448.2568, 448.2510, 448.2581, 448.2560, 448.2576, 448.2562, 448.2558,
        448.2409, 448.4080, 448.2579, 448.9422, 448.2550, 448.2416, 448.2533,
        448.2516, 448.2542, 448.9520, 448.2531, 448.2546, 448.2510, 448.4042,
        448.2341, 448.9457, 448.2578, 448.9520, 448.5738, 448.2571, 448.2571,
        448.2581, 448.2532, 448.2541, 448.2556, 448.2578, 448.2377, 448.2570,
        448.2534, 448.2548, 448.9510, 448.2549, 448.2534, 448.2580, 448.9520,
        448.2556, 448.2546, 448.2414, 448.4867, 448.2530, 448.2552, 448.2542,
        448.7646, 448.2554, 448.6221, 448.2547, 448.2517, 448.2410, 448.9497,
        448.2548, 448.2549, 448.7512, 448.2542, 448.2579, 448.2547, 448.2553,
        448.5851, 448.2552, 448.2524, 448.9515, 448.4188, 448.2545, 448.2554,
        448.2536, 448.2543, 448.2560, 448.2543, 448.9513, 448.2551, 448.2536,
        448.9516, 448.2251, 448.2558, 448.2542, 448.2482, 448.2568, 448.9519,
        448.9493, 448.2561, 448.2453, 448.2568, 448.5853, 448.9426, 448.9520,
        448.6740, 448.2544, 448.2549, 448.2545, 448.2538, 448.2560, 448.7473,
        448.5884, 448.2545, 448.2547, 448.2450, 448.2555, 448.2578, 448.2546,
        448.2592, 448.2578, 448.9519, 448.2554, 448.2490, 448.2527, 448.2580,
        448.9500, 448.2570, 448.2580, 448.5914, 448.2565, 448.2527, 448.9431,
        448.2539, 448.2535, 448.2562, 448.9509, 448.3885, 448.2572, 448.2562,
        448.2413, 448.2450, 448.2557, 448.2508, 448.2570, 448.9510, 448.2549,
        448.7575, 448.2512, 448.2565, 448.9519, 448.9520, 448.2520, 448.5772,
        448.4999, 448.2578, 448.2579, 448.2549, 448.2574, 448.2579, 448.2559,
        448.9463, 448.2578, 448.2556, 448.2541, 448.2446, 448.7653, 448.2556,
        448.2540, 448.5905, 448.2525, 448.2561, 448.2548, 448.2579, 448.9516,
        448.3720, 448.9514, 448.7136, 448.2543, 448.2548, 448.2500, 448.2562,
        448.2546, 448.2542, 448.2580, 448.2561, 448.2563, 448.7494, 448.2537,
        448.5889, 448.2496, 448.2548, 448.2523, 448.5922, 448.2380, 448.2403,
        448.2554, 448.2554, 448.2548, 448.2571, 448.2548, 448.2356, 448.9514,
        448.9461, 448.2496, 448.2571, 448.2572, 448.2562, 448.2546, 448.2579,
        448.9516, 448.2551, 448.2555, 448.2495, 448.8995, 448.5483, 448.2578,
        448.9509, 448.3667, 448.5828, 448.2575, 448.2349, 448.2494, 448.2561,
        448.5412, 448.2493, 448.2532, 448.2568, 448.2511, 448.2579, 448.2535,
        448.2567, 448.2565, 448.2546, 448.2521, 448.2541, 448.2581, 448.2544,
        448.2545, 448.2510, 448.2524, 448.2575, 448.2539, 448.2404, 448.2498,
        448.2534, 448.2465, 448.2574, 448.2544, 448.2548, 448.5586, 448.9468,
        448.2549, 448.2579, 448.9518, 448.2500, 448.9462, 448.2542, 448.2574,
        448.2479, 448.2559, 448.2546, 448.2580, 448.2552, 448.2562, 448.2504,
        448.9505, 448.2519, 448.2335, 448.9131, 448.2579, 448.2564, 448.2521,
        448.2531, 448.2569, 448.9434, 448.9503, 448.2557, 448.9519, 448.2535,
        448.2540, 448.2538, 448.4222, 448.2448, 448.2547, 448.2484, 448.2532,
        448.2580, 448.5849, 448.9461, 448.9520, 448.9462, 448.9509, 448.9520,
        448.2532, 448.2357, 448.9515, 448.2581, 448.2537, 448.4078, 448.2484,
        448.2540, 448.2511, 448.2578, 448.2555, 448.2539, 448.2437, 448.9268,
        448.5156, 448.9348, 448.2570, 448.9518, 448.2581, 448.9479, 448.9520,
        448.9380, 448.2580, 448.2517, 448.4046, 448.2563, 448.2532, 448.9515,
        448.9414, 448.2546, 448.2580, 448.2479, 448.2506, 448.2564, 448.2540,
        448.2510, 448.5800, 448.5914, 448.2562, 448.2533, 448.2545, 448.2322,
        448.2552, 448.4796, 448.2545, 448.2568, 448.2480, 448.2534, 448.2549,
        448.2558, 448.2489, 448.7025, 448.2570, 448.2575, 448.2573, 448.2581,
        448.9520, 448.2563, 448.2521, 448.2557, 448.7769, 448.4108, 448.2554,
        448.2567, 448.2572, 448.2575, 448.4184, 448.4164, 448.2581, 448.5864,
        448.2543, 448.2550, 448.9230, 448.2557, 448.2576, 448.2552, 448.2578,
        448.2580, 448.9379, 448.5768, 448.9493, 448.9374, 448.2579, 448.5587,
        448.2546, 448.2547, 448.2573, 448.2506, 448.2497, 448.9519, 448.2548,
        448.2569, 448.2573, 448.2549, 448.2525, 448.2571, 448.9518, 448.2556,
        448.9308, 448.2544, 448.9518, 448.4016, 448.2571, 448.9515, 448.2550,
        448.4223, 448.2580, 448.2579, 448.2496, 448.2575, 448.9520, 448.2562,
        448.2329, 448.5879, 448.2565, 448.2570, 448.9520, 448.2559, 448.2555,
        448.2571, 448.2562, 448.2559, 448.3213, 448.2565, 448.2575, 448.2551,
        448.5858, 448.2563, 448.5068, 448.5899, 448.9516, 448.9518, 448.2563,
        448.2374, 448.2579, 448.2568, 448.9409, 448.2576, 448.2307, 448.2552,
        448.9457, 448.5855, 448.3724, 448.2578, 448.2553, 448.2488, 448.5926,
        448.2335, 448.9505, 448.2563, 448.2466, 448.9516, 448.2457, 448.9514,
        448.2576, 448.2485, 448.2565, 448.9520, 448.2568, 448.2505, 448.2580,
        448.2563, 448.2565, 448.2548, 448.7643, 448.2551, 448.2581, 448.9520,
        448.2529, 448.2535, 448.5052, 448.5879, 448.2505, 448.2565, 448.2563,
        448.2483, 448.2567, 448.2503, 448.7576, 448.2551, 448.2547, 448.2567,
        448.9485, 448.2535, 448.2552, 448.2495, 448.2579, 448.2551, 448.9520,
        448.2563, 448.2545, 448.2512, 448.2577, 448.9108, 448.2523, 448.2551,
        448.9510, 448.2532, 448.2503, 448.2564, 448.9519, 448.9450, 448.2343,
        448.2459, 448.9503, 448.9520, 448.2549, 448.2580, 448.2572, 448.2568,
        448.2559, 448.2548, 448.2579, 448.2488, 448.5835, 448.9502, 448.2481,
        448.2548, 448.2535, 448.2545, 448.4661, 448.2572, 448.2560, 448.2548,
        448.2572, 448.2579, 448.2561, 448.2498, 448.2545, 448.2551, 448.2540,
        448.2531, 448.2550, 448.9501, 448.2476, 448.2548, 448.9512, 448.5668,
        448.5832, 448.2549, 448.2567, 448.2452, 448.2556, 448.2546, 448.4128,
        448.2549, 448.2520, 448.2570, 448.2562, 448.4170, 448.2542, 448.2524,
        448.4089, 448.9465, 448.2563, 448.8861, 448.2557, 448.2546, 448.2474,
        448.2559, 448.2561, 448.2557, 448.9516, 448.4050, 448.9508, 448.2542,
        448.2515, 448.2507, 448.9460, 448.2581, 448.2499, 448.2558, 448.2525,
        448.2565, 448.2532, 448.2411, 448.2549, 448.2529, 448.2530, 448.2579,
        448.2577, 448.2526, 448.9520, 448.9520, 448.2549, 448.2556, 448.2579,
        448.2558, 448.9517, 448.2576, 448.2535, 448.2564, 448.9355, 448.2464,
        448.2507, 448.2570, 448.2568, 448.2580, 448.2534, 448.2466, 448.2563,
        448.9520, 448.2580, 448.9430, 448.2542, 448.9509, 448.2418, 448.2527,
        448.9518, 448.2563, 448.2560, 448.2562, 448.2521, 448.2571, 448.2562,
        448.2577, 448.2528, 448.2519, 448.2538, 448.2576, 448.2557, 448.2547,
        448.9456, 448.2573, 448.2557, 448.9451, 448.2581, 448.2560, 448.9520,
        448.9490, 448.2551, 448.9485, 448.2579, 448.2544, 448.2513, 448.2545,
        448.2548, 448.2550, 448.2495, 448.9519, 448.2556, 448.2538, 448.2570,
        448.2581, 448.9520, 448.9518, 448.2474, 448.2563, 448.2512, 448.2574,
        448.9460, 448.2340, 448.2558, 448.2579, 448.2503, 448.2512, 448.2555,
        448.9175, 448.2580, 448.2550, 448.2579, 448.2565, 448.2520, 448.2558,
        448.9520, 448.2551, 448.2574, 448.2548, 448.2530, 448.2579, 448.2564,
        448.2361, 448.2547, 448.2517, 448.9444, 448.2579, 448.2581, 448.2575,
        448.2571, 448.9518, 448.9515, 448.2510, 448.2546, 448.2547, 448.9520,
        448.2556, 448.2567, 448.2471, 448.2569, 448.9519, 448.2580, 448.4022,
        448.4205, 448.2515, 448.2542, 448.2579, 448.2517, 448.5902, 448.2543,
        448.2537, 448.9410, 448.2552, 448.2544, 448.9390, 448.2543, 448.2556,
        448.2549, 448.2535, 448.2575, 448.2513, 448.2546, 448.2574, 448.2579,
        448.4716, 448.9406, 448.9520, 448.2580, 448.2477, 448.2571, 448.2574,
        448.2577, 448.2569, 448.2575, 448.2437, 448.2539, 448.2560, 448.9520,
        448.2534, 448.5402, 448.2374, 448.2580, 448.2567, 448.2556, 448.2565,
        448.2568, 448.9458, 448.2395, 448.9453, 448.9518, 448.2530, 448.2548,
        448.2579, 448.2579, 448.2482, 448.2543, 448.9518, 448.2551, 448.5681,
        448.9520, 448.2568, 448.2580, 448.7833, 448.2474, 448.2520, 448.2545,
        448.2531, 448.2548, 448.5818, 448.2561, 448.2628, 448.9495, 448.2556,
        448.2568, 448.9520, 448.2548, 448.5885, 448.2579, 448.2574, 448.2549,
        448.2551, 448.2553, 448.2580, 448.2555, 448.2487, 448.5877, 448.2503,
        448.2574, 448.7339, 448.2548, 448.2565, 448.9459, 448.2543, 448.2579,
        448.2533, 448.5917, 448.2562, 448.2563, 448.2529, 448.2579, 448.2531,
        448.2570, 448.9400, 448.2552, 448.2347, 448.2566, 448.2536, 448.3702,
        448.2548, 448.9520, 448.2555, 448.2546, 448.2542, 448.2475, 448.2370,
        448.2548, 448.2508, 448.2517, 448.2484, 448.2565, 448.5875, 448.9519,
        448.6785, 448.2515, 448.9509, 448.2546, 448.7343, 448.9509, 448.2574,
        448.4012, 448.9520, 448.2579, 448.2579, 448.2559, 448.2550, 448.7659,
        448.2578, 448.2573, 448.2548, 448.7543, 448.9460, 448.5856, 448.9399,
        448.2541, 448.2520, 448.2571, 448.2555, 448.5899, 448.2466, 448.2580,
        448.2576, 448.9509, 448.2547, 448.5806, 448.5866, 448.5822, 448.2535,
        448.2514, 448.2518, 448.2548, 448.9518, 448.4045, 448.2579, 448.2556,
        448.9520, 448.2549, 448.2533, 448.2567, 448.2559, 448.5912, 448.9500,
        448.2548, 448.2527, 448.2580, 448.9341, 448.2568, 448.9520, 448.2543,
        448.2542, 448.9477, 448.2580, 448.5889, 448.9519, 448.2580, 448.2578,
        448.7560, 448.5814, 448.2569, 448.9520, 448.9481, 448.2537, 448.9509,
        448.6765, 448.4073, 448.2562, 448.2578, 448.2580, 448.2579, 448.2568,
        448.2568, 448.9515, 448.2533, 448.2550, 448.9483, 448.3782, 448.2546,
        448.2550, 448.2545, 448.2559, 448.2528, 448.2563, 448.2580, 448.2579,
        448.2534, 448.5799, 448.2473, 448.5935, 448.2564, 448.5840, 448.9516,
        448.2461, 448.2545, 448.2560, 448.2552, 448.4850, 448.2580, 448.9519,
        448.2563, 448.2556, 448.9520, 448.2564, 448.2551, 448.2580, 448.5860,
        448.2549, 448.2548, 448.2559, 448.9520, 448.2548, 448.5884, 448.9442,
        448.2552, 448.2438], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([403.3528], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0645],
             [112.0645],
             [112.0645],
             [112.0645]],

            [[112.2375],
             [112.2378],
             [112.2335],
             [112.2345]],

            [[112.0645],
             [112.0644],
             [112.0643],
             [112.0643]],

            ...,

            [[112.0627],
             [112.0632],
             [112.0628],
             [112.0644]],

            [[112.0631],
             [112.0644],
             [112.0635],
             [112.0645]],

            [[112.0640],
             [112.0640],
             [112.0643],
             [112.0643]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2581, 448.9434, 448.2576,  ..., 448.2530, 448.2555, 448.2567],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2581, 448.9434, 448.2576,  ..., 448.2530, 448.2555, 448.2567],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0496],
             [112.0496],
             [112.0519],
             [112.0519]],

            [[112.2441],
             [112.0432],
             [112.2434],
             [112.2335]],

            [[112.0519],
             [112.0518],
             [112.0534],
             [112.0534]],

            ...,

            [[112.0530],
             [112.0533],
             [112.0526],
             [112.0517]],

            [[112.2419],
             [112.0500],
             [112.2162],
             [112.2162]],

            [[112.0532],
             [112.0532],
             [112.0533],
             [112.0533]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2028, 448.7642, 448.2106,  ..., 448.2106, 448.7243, 448.2131],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2028, 448.7642, 448.2106,  ..., 448.2106, 448.7243, 448.2131],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0404],
             [112.0401],
             [112.0416],
             [112.0414]],

            [[112.0412],
             [112.0414],
             [112.0413],
             [112.0414]],

            [[112.0414],
             [112.0414],
             [112.0414],
             [112.0414]],

            ...,

            [[112.0415],
             [112.0414],
             [112.0414],
             [112.0414]],

            [[112.2474],
             [112.0396],
             [112.2457],
             [112.0395]],

            [[112.0402],
             [112.0396],
             [112.0416],
             [112.0415]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1635, 448.1652, 448.1655,  ..., 448.1656, 448.5722, 448.1628],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1635, 448.1652, 448.1655,  ..., 448.1656, 448.5722, 448.1628],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0374],
             [112.0360],
             [112.0372],
             [112.0364]],

            [[112.0358],
             [112.0373],
             [112.0364],
             [112.0372]],

            [[112.0370],
             [112.0372],
             [112.0362],
             [112.0364]],

            ...,

            [[112.0345],
             [112.0345],
             [112.0349],
             [112.0349]],

            [[112.2543],
             [112.2536],
             [112.2542],
             [112.2542]],

            [[112.0347],
             [112.0347],
             [112.0360],
             [112.0360]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1469, 448.1466, 448.1467,  ..., 448.1389, 449.0163, 448.1413],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1469, 448.1466, 448.1467,  ..., 448.1389, 449.0163, 448.1413],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0336],
             [112.0339],
             [112.0352],
             [112.0351]],

            [[112.0353],
             [112.0341],
             [112.0343],
             [112.0350]],

            [[112.2543],
             [112.1700],
             [112.2508],
             [112.2508]],

            ...,

            [[112.0344],
             [112.0345],
             [112.0342],
             [112.0352]],

            [[112.0352],
             [112.0352],
             [112.0350],
             [112.0350]],

            [[112.2519],
             [112.2263],
             [112.0318],
             [112.0318]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.1378, 448.1387, 448.9261,  ..., 448.1383, 448.1404, 448.5418],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.1378, 448.1387, 448.9261,  ..., 448.1383, 448.1404, 448.5418],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2495],
             [112.2490],
             [112.2494],
             [112.2494]],

            [[112.0402],
             [112.0413],
             [112.0415],
             [112.0415]],

            [[112.0414],
             [112.0414],
             [112.0412],
             [112.0412]],

            ...,

            [[112.0414],
             [112.0415],
             [112.0414],
             [112.0414]],

            [[112.0411],
             [112.0411],
             [112.0413],
             [112.0413]],

            [[112.0399],
             [112.0396],
             [112.0412],
             [112.0412]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.9974, 448.1644, 448.1653,  ..., 448.1656, 448.1647, 448.1619],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.9974, 448.1644, 448.1653,  ..., 448.1656, 448.1647, 448.1619],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0530],
             [112.0530],
             [112.0530],
             [112.0530]],

            [[112.0529],
             [112.0536],
             [112.0530],
             [112.0537]],

            [[112.0537],
             [112.0537],
             [112.0537],
             [112.0537]],

            ...,

            [[112.0528],
             [112.0537],
             [112.0531],
             [112.0531]],

            [[112.0538],
             [112.0538],
             [112.0531],
             [112.0529]],

            [[112.0472],
             [112.0524],
             [112.0525],
             [112.0434]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.2119, 448.2131, 448.2147,  ..., 448.2128, 448.2135, 448.1955],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.2119, 448.2131, 448.2147,  ..., 448.2128, 448.2135, 448.1955],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2137],
             [112.2137],
             [112.2137],
             [112.2137]],

            [[112.0668],
             [112.0667],
             [112.0662],
             [112.0662]],

            [[112.0643],
             [112.0643],
             [112.0663],
             [112.0663]],

            ...,

            [[112.0669],
             [112.0669],
             [112.0667],
             [112.0667]],

            [[112.2137],
             [112.2137],
             [112.2137],
             [112.2137]],

            [[112.0668],
             [112.0666],
             [112.0667],
             [112.0667]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8546, 448.2659, 448.2612,  ..., 448.2672, 448.8546, 448.2668],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8546, 448.2659, 448.2612,  ..., 448.2672, 448.8546, 448.2668],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2023],
             [112.2023],
             [112.2023],
             [112.2023]],

            [[112.0756],
             [112.0763],
             [112.0752],
             [112.0761]],

            [[112.0759],
             [112.0760],
             [112.0758],
             [112.0761]],

            ...,

            [[112.0762],
             [112.0762],
             [112.0762],
             [112.0762]],

            [[112.0760],
             [112.0761],
             [112.0761],
             [112.0763]],

            [[112.2022],
             [112.1977],
             [112.2012],
             [112.2012]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8093, 448.3031, 448.3039,  ..., 448.3049, 448.3044, 448.8023],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8093, 448.3031, 448.3039,  ..., 448.3049, 448.3044, 448.8023],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0866],
             [112.0878],
             [112.0874],
             [112.0878]],

            [[112.0860],
             [112.0860],
             [112.0862],
             [112.0865]],

            [[112.0858],
             [112.0864],
             [112.0863],
             [112.0863]],

            ...,

            [[112.1887],
             [112.1884],
             [112.1887],
             [112.1887]],

            [[112.0865],
             [112.0862],
             [112.0864],
             [112.0864]],

            [[112.0865],
             [112.0865],
             [112.0865],
             [112.0862]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3496, 448.3447, 448.3447,  ..., 448.7545, 448.3456, 448.3458],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3496, 448.3447, 448.3447,  ..., 448.7545, 448.3456, 448.3458],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0945],
             [112.0945],
             [112.0948],
             [112.0948]],

            [[112.0890],
             [112.0926],
             [112.0945],
             [112.0945]],

            [[112.0945],
             [112.0946],
             [112.0944],
             [112.0944]],

            ...,

            [[112.0942],
             [112.0942],
             [112.0946],
             [112.0946]],

            [[112.0947],
             [112.0944],
             [112.0944],
             [112.0948]],

            [[112.0944],
             [112.0948],
             [112.0947],
             [112.0945]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3787, 448.3706, 448.3779,  ..., 448.3776, 448.3784, 448.3784],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3787, 448.3706, 448.3779,  ..., 448.3776, 448.3784, 448.3784],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1088],
             [112.1087],
             [112.1088],
             [112.1087]],

            [[112.1618],
             [112.1618],
             [112.1618],
             [112.1618]],

            [[112.1085],
             [112.1085],
             [112.1085],
             [112.1085]],

            ...,

            [[112.1086],
             [112.1087],
             [112.1089],
             [112.1086]],

            [[112.1618],
             [112.1618],
             [112.1618],
             [112.1618]],

            [[112.1071],
             [112.1071],
             [112.1073],
             [112.1073]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4350, 448.6473, 448.4340,  ..., 448.4349, 448.6472, 448.4289],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4350, 448.6473, 448.4340,  ..., 448.4349, 448.6472, 448.4289],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1205],
             [112.1205],
             [112.1206],
             [112.1203]],

            [[112.1203],
             [112.1479],
             [112.1201],
             [112.1457]],

            [[112.1205],
             [112.1194],
             [112.1197],
             [112.1402]],

            ...,

            [[112.1462],
             [112.1487],
             [112.1487],
             [112.1467]],

            [[112.1204],
             [112.1201],
             [112.1205],
             [112.1201]],

            [[112.1205],
             [112.1204],
             [112.1205],
             [112.1201]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4819, 448.5341, 448.4998,  ..., 448.5904, 448.4810, 448.4815],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4819, 448.5341, 448.4998,  ..., 448.5904, 448.4810, 448.4815],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1362],
             [112.1240],
             [112.1354],
             [112.1354]],

            [[112.1320],
             [112.1320],
             [112.1314],
             [112.1314]],

            [[112.1313],
             [112.1321],
             [112.1320],
             [112.1320]],

            ...,

            [[112.1364],
             [112.1364],
             [112.1364],
             [112.1364]],

            [[112.1315],
             [112.1315],
             [112.1314],
             [112.1314]],

            [[112.1320],
             [112.1314],
             [112.1319],
             [112.1315]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5310, 448.5268, 448.5273,  ..., 448.5455, 448.5258, 448.5268],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5310, 448.5268, 448.5273,  ..., 448.5455, 448.5258, 448.5268],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1430],
             [112.1425],
             [112.1430],
             [112.1421]],

            [[112.1429],
             [112.1427],
             [112.1423],
             [112.1428]],

            [[112.1174],
             [112.1424],
             [112.1193],
             [112.1430]],

            ...,

            [[112.1430],
             [112.1430],
             [112.1426],
             [112.1426]],

            [[112.1426],
             [112.1427],
             [112.1430],
             [112.1429]],

            [[112.1235],
             [112.1175],
             [112.1235],
             [112.1226]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.5706, 448.5707, 448.5220,  ..., 448.5713, 448.5712, 448.4871],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.5706, 448.5707, 448.5220,  ..., 448.5713, 448.5712, 448.4871],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1097],
             [112.1097],
             [112.1097],
             [112.1097]],

            [[112.1556],
             [112.1551],
             [112.1551],
             [112.1551]],

            [[112.1556],
             [112.1556],
             [112.1550],
             [112.1550]],

            ...,

            [[112.1559],
             [112.1553],
             [112.1560],
             [112.1551]],

            [[112.1561],
             [112.1553],
             [112.1559],
             [112.1559]],

            [[112.1561],
             [112.1558],
             [112.1561],
             [112.1558]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.4387, 448.6209, 448.6213,  ..., 448.6223, 448.6232, 448.6238],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.4387, 448.6209, 448.6213,  ..., 448.6223, 448.6232, 448.6238],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1697],
             [112.1690],
             [112.1702],
             [112.1702]],

            [[112.1702],
             [112.1701],
             [112.1702],
             [112.1702]],

            [[112.0927],
             [112.0926],
             [112.0926],
             [112.0927]],

            ...,

            [[112.1702],
             [112.1702],
             [112.1694],
             [112.1694]],

            [[112.1690],
             [112.1701],
             [112.1697],
             [112.1697]],

            [[112.1689],
             [112.1689],
             [112.1691],
             [112.1691]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.6791, 448.6808, 448.3707,  ..., 448.6793, 448.6785, 448.6760],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.6791, 448.6808, 448.3707,  ..., 448.6793, 448.6785, 448.6760],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.0774],
             [112.0774],
             [112.0774],
             [112.0774]],

            [[112.0774],
             [112.0776],
             [112.0776],
             [112.0774]],

            [[112.0774],
             [112.0774],
             [112.0774],
             [112.0774]],

            ...,

            [[112.1830],
             [112.1815],
             [112.1817],
             [112.1817]],

            [[112.1831],
             [112.1184],
             [112.1121],
             [112.1831]],

            [[112.1830],
             [112.1830],
             [112.1830],
             [112.1830]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.3094, 448.3100, 448.3094,  ..., 448.7280, 448.5966, 448.7320],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.3094, 448.3100, 448.3094,  ..., 448.7280, 448.5966, 448.7320],
       device='cuda:0', grad_fn=<ViewBackward0>)
tensor([2.9967e+09], device='cuda:0') train
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1954],
             [112.1938],
             [112.1945],
             [112.1945]],

            [[112.0619],
             [112.0619],
             [112.0619],
             [112.0619]],

            [[112.1956],
             [112.1953],
             [112.1957],
             [112.1953]],

            ...,

            [[112.1943],
             [112.1943],
             [112.1939],
             [112.1939]],

            [[112.0619],
             [112.0619],
             [112.0619],
             [112.0619]],

            [[112.1953],
             [112.1938],
             [112.1939],
             [112.1939]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7783, 448.2478, 448.7819,  ..., 448.7764, 448.2477, 448.7769],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7783, 448.2478, 448.7819,  ..., 448.7764, 448.2477, 448.7769],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1940],
             [112.1950],
             [112.1938],
             [112.1945]],

            [[112.1953],
             [112.1938],
             [112.1949],
             [112.1949]],

            [[112.1946],
             [112.1946],
             [112.1947],
             [112.1947]],

            ...,

            [[112.1946],
             [112.1939],
             [112.1953],
             [112.1945]],

            [[112.0619],
             [112.0620],
             [112.0619],
             [112.0619]],

            [[112.1845],
             [112.1955],
             [112.1333],
             [112.1333]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7772, 448.7790, 448.7786,  ..., 448.7784, 448.2478, 448.6466],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7772, 448.7790, 448.7786,  ..., 448.7784, 448.2478, 448.6466],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1957],
             [112.1953],
             [112.1955],
             [112.1955]],

            [[112.1955],
             [112.1948],
             [112.1949],
             [112.1949]],

            [[112.1952],
             [112.1949],
             [112.1954],
             [112.1955]],

            ...,

            [[112.1944],
             [112.1938],
             [112.1938],
             [112.1938]],

            [[112.1938],
             [112.1938],
             [112.1937],
             [112.1937]],

            [[112.1942],
             [112.1938],
             [112.1944],
             [112.1939]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7820, 448.7801, 448.7811, 448.6518, 448.7774, 448.7760, 448.6258,
            448.7773, 448.2478, 448.7780, 448.5533, 448.7281, 448.7819, 448.7822,
            448.7789, 448.2490, 448.7821, 448.7799, 448.7822, 448.7816, 448.5221,
            448.2477, 448.5162, 448.7750, 448.7790, 448.7794, 448.7801, 448.7788,
            448.2477, 448.7769, 448.7781, 448.7783, 448.5121, 448.7803, 448.7770,
            448.7775, 448.2516, 448.7795, 448.7822, 448.7794, 448.7759, 448.7779,
            448.5157, 448.7819, 448.2481, 448.7774, 448.7791, 448.7819, 448.7769,
            448.2477, 448.7784, 448.7817, 448.7779, 448.7749, 448.7759, 448.2478,
            448.2485, 448.7760, 448.7784, 448.7787, 448.7754, 448.7784, 448.7798,
            448.7784, 448.7789, 448.5149, 448.7821, 448.5167, 448.7814, 448.4761,
            448.7771, 448.2496, 448.7797, 448.2479, 448.7781, 448.7776, 448.7774,
            448.7798, 448.6486, 448.2477, 448.7821, 448.7799, 448.7752, 448.7798,
            448.2477, 448.7792, 448.7783, 448.2478, 448.7760, 448.7787, 448.5165,
            448.2494, 448.7767, 448.7775, 448.7786, 448.7782, 448.7786, 448.2491,
            448.7789, 448.7792, 448.2477, 448.7810, 448.2482, 448.7761, 448.7769,
            448.3840, 448.7762, 448.7809, 448.2477, 448.7771, 448.7786, 448.7787,
            448.2500, 448.7790, 448.7776, 448.7776, 448.7800, 448.7785, 448.2479,
            448.5198, 448.7765, 448.7819, 448.6553, 448.7759, 448.2505, 448.7790,
            448.2479, 448.7760, 448.7760, 448.7806, 448.7810, 448.7787, 448.7773,
            448.7820, 448.7800, 448.7783, 448.7793, 448.2607, 448.2491, 448.7805,
            448.7770, 448.2478, 448.7757, 448.7779, 448.2502, 448.7786, 448.7761,
            448.7805, 448.2480, 448.2477, 448.7763, 448.2479, 448.7788, 448.5134,
            448.7329, 448.7785, 448.7760, 448.3901, 448.7762, 448.7779, 448.7792,
            448.7805, 448.7808, 448.7778, 448.7817, 448.7778, 448.7756, 448.2477,
            448.7784, 448.4117, 448.7805, 448.7792, 448.7820, 448.7775, 448.7789,
            448.2477, 448.7819, 448.7757, 448.7760, 448.7801, 448.2477, 448.7799,
            448.7682, 448.7817, 448.7813, 448.2480, 448.2490, 448.7762, 448.7783,
            448.5132, 448.7817, 448.2477, 448.7775, 448.7775, 448.7790, 448.7753,
            448.2478, 448.7820, 448.7797, 448.2477, 448.2479, 448.7788, 448.7819,
            448.7791, 448.2489, 448.5170, 448.7814, 448.7811, 448.7764, 448.7798,
            448.7818, 448.7757, 448.7766, 448.3839, 448.7772, 448.4690, 448.3829,
            448.7792, 448.2477, 448.2487, 448.7820, 448.2480, 448.7778, 448.7768,
            448.5211, 448.7785, 448.7802, 448.4804, 448.2479, 448.2491, 448.7792,
            448.7757, 448.7808, 448.7817, 448.7784, 448.5173, 448.6491, 448.7792,
            448.7781, 448.7808, 448.7766, 448.7784, 448.7751, 448.7774, 448.7785,
            448.7785, 448.7780, 448.2491, 448.6621, 448.7819, 448.7815, 448.2494,
            448.7796, 448.7763, 448.7820, 448.6489, 448.2477, 448.7799, 448.7786,
            448.2477, 448.7764, 448.7823, 448.7793, 448.2477, 448.7791, 448.2481,
            448.2480, 448.7788, 448.7786, 448.2536, 448.2477, 448.7762, 448.7774,
            448.7808, 448.2480, 448.7820, 448.5170, 448.3834, 448.2487, 448.2479,
            448.2480, 448.7780, 448.7776, 448.7816, 448.7784, 448.2479, 448.7798,
            448.2575, 448.7804, 448.7777, 448.7791, 448.7761, 448.3881, 448.7763,
            448.2569, 448.7802, 448.5177, 448.2610, 448.7807, 448.7811, 448.7782,
            448.7789, 448.2489, 448.2477, 448.2505, 448.7783, 448.5121, 448.7797,
            448.7796, 448.7791, 448.7763, 448.7784, 448.7821, 448.7777, 448.7761,
            448.7819, 448.7753, 448.7773, 448.7773, 448.7793, 448.7767, 448.7820,
            448.5221, 448.2477, 448.2478, 448.7750, 448.5158, 448.7787, 448.7786,
            448.7782, 448.2477, 448.7757, 448.7748, 448.7820, 448.7769, 448.6525,
            448.7663, 448.2481, 448.7774, 448.7786, 448.7782, 448.2482, 448.2492,
            448.7805, 448.7780, 448.7749, 448.7819, 448.7799, 448.7792, 448.7773,
            448.7776, 448.3804, 448.7818, 448.7816, 448.7752, 448.7786, 448.7784,
            448.7759, 448.7783, 448.7803, 448.2477, 448.7789, 448.7789, 448.2480,
            448.2477, 448.7794, 448.7781, 448.7785, 448.2477, 448.5122, 448.5175,
            448.7775, 448.7753, 448.4073, 448.4604, 448.2477, 448.7751, 448.5161,
            448.3965, 448.7786, 448.7787, 448.7783, 448.7795, 448.7784, 448.7816,
            448.7802, 448.2477, 448.7775, 448.7822, 448.7787, 448.2477, 448.2483,
            448.7771, 448.7798, 448.7751, 448.7773, 448.7783, 448.2479, 448.7796,
            448.7762, 448.2478, 448.7794, 448.2477, 448.7794, 448.7752, 448.7786,
            448.7815, 448.7753, 448.5198, 448.7766, 448.7753, 448.2477, 448.7784,
            448.7779, 448.7796, 448.5176, 448.7792, 448.7787, 448.2477, 448.7802,
            448.7751, 448.5157, 448.7769, 448.7769, 448.6487, 448.7761, 448.2477,
            448.7809, 448.7792, 448.7790, 448.7787, 448.7753, 448.7784, 448.7785,
            448.7801, 448.7760, 448.7771, 448.5212, 448.5150, 448.2477, 448.7816,
            448.7795, 448.7822, 448.7822, 448.7774, 448.7763, 448.7788, 448.7751,
            448.2477, 448.7816, 448.7816, 448.2477, 448.2479, 448.7773, 448.7767,
            448.6510, 448.7757, 448.7814, 448.7784, 448.6481, 448.7759, 448.7782,
            448.7781, 448.7769, 448.2477, 448.2500, 448.7801, 448.5156, 448.2481,
            448.7781, 448.2477, 448.5224, 448.7779, 448.7784, 448.2477, 448.7755,
            448.7822, 448.7800, 448.7750, 448.7762, 448.7776, 448.7771, 448.7809,
            448.2478, 448.7781, 448.7809, 448.7752, 448.2477, 448.7750, 448.7775,
            448.2479, 448.5170, 448.7776, 448.2479, 448.2477, 448.7786, 448.7784,
            448.7769, 448.7822, 448.7779, 448.7816, 448.7775, 448.7778, 448.7818,
            448.2491, 448.7780, 448.5373, 448.7779, 448.7110, 448.7767, 448.7803,
            448.7820, 448.7762, 448.7791, 448.7750, 448.7820, 448.2477, 448.7784,
            448.2478, 448.7791, 448.2502, 448.7810, 448.7784, 448.6686, 448.7815,
            448.7757, 448.7816, 448.7809, 448.7805, 448.7814, 448.7770, 448.7823,
            448.2487, 448.7810, 448.7815, 448.7777, 448.7771, 448.7788, 448.7786,
            448.7809, 448.7796, 448.5167, 448.7787, 448.2477, 448.7789, 448.7794,
            448.7790, 448.7786, 448.2480, 448.7749, 448.7785, 448.7819, 448.6199,
            448.7757, 448.7765, 448.2498, 448.2477, 448.2487, 448.2501, 448.7791,
            448.7757, 448.7781, 448.5176, 448.7787, 448.7783, 448.7802, 448.7814,
            448.7756, 448.7786, 448.7789, 448.7747, 448.7762, 448.2477, 448.7758,
            448.7778, 448.7799, 448.2496, 448.2505, 448.7792, 448.7784, 448.7805,
            448.7750, 448.2483, 448.7787, 448.2489, 448.7821, 448.7787, 448.7769,
            448.5324, 448.7764, 448.7814, 448.2481, 448.7817, 448.7803, 448.7773,
            448.2483, 448.7817, 448.5358, 448.7789, 448.7791, 448.7775, 448.7778,
            448.2477, 448.6502, 448.2477, 448.7769, 448.7808, 448.7796, 448.7783,
            448.7803, 448.7758, 448.7762, 448.7789, 448.7781, 448.7762, 448.2489,
            448.7750, 448.2479, 448.2478, 448.5173, 448.7339, 448.7645, 448.7784,
            448.7754, 448.7809, 448.7750, 448.7770, 448.7756, 448.7787, 448.6525,
            448.2477, 448.7789, 448.2494, 448.2477, 448.6462, 448.7764, 448.7764,
            448.2476, 448.2477, 448.7820, 448.7783, 448.7780, 448.7499, 448.7785,
            448.7755, 448.2478, 448.7770, 448.7805, 448.3423, 448.7766, 448.7752,
            448.7772, 448.2477, 448.7805, 448.7816, 448.7818, 448.7755, 448.7816,
            448.7763, 448.7782, 448.7808, 448.7760, 448.7785, 448.7783, 448.7756,
            448.7759, 448.7799, 448.7646, 448.7787, 448.2493, 448.7755, 448.7761,
            448.4943, 448.7821, 448.7811, 448.7748, 448.7820, 448.7777, 448.7755,
            448.7797, 448.7784, 448.7776, 448.7820, 448.7776, 448.7761, 448.2477,
            448.2477, 448.7335, 448.7804, 448.5160, 448.7789, 448.7772, 448.5336,
            448.2477, 448.6359, 448.7796, 448.2480, 448.7812, 448.7798, 448.7806,
            448.7781, 448.7787, 448.7791, 448.7813, 448.7819, 448.7785, 448.7791,
            448.7802, 448.5157, 448.7822, 448.7781, 448.7784, 448.2480, 448.7787,
            448.7780, 448.7821, 448.7776, 448.7767, 448.5167, 448.7825, 448.7791,
            448.7810, 448.2479, 448.7820, 448.2493, 448.7805, 448.7802, 448.7764,
            448.7789, 448.7778, 448.7789, 448.7779, 448.7785, 448.7808, 448.2477,
            448.2487, 448.2515, 448.7791, 448.2667, 448.7805, 448.7751, 448.7778,
            448.7808, 448.7776, 448.7801, 448.7813, 448.7792, 448.7782, 448.2477,
            448.7780, 448.4936, 448.7812, 448.2477, 448.7813, 448.7801, 448.7786,
            448.7787, 448.5179, 448.2477, 448.7762, 448.2482, 448.7791, 448.7790,
            448.7796, 448.7805, 448.7794, 448.7751, 448.7794, 448.7787, 448.7756,
            448.7777, 448.7817, 448.7779, 448.7783, 448.7790, 448.7791, 448.7771,
            448.7789, 448.7789, 448.7816, 448.2477, 448.2478, 448.7795, 448.7798,
            448.7794, 448.7783, 448.7783, 448.7762, 448.7791, 448.7758, 448.7785,
            448.7816, 448.6441, 448.7775, 448.7784, 448.7778, 448.2491, 448.7822,
            448.2480, 448.7804, 448.3804, 448.7797, 448.2477, 448.2480, 448.7763,
            448.7814, 448.7773, 448.7785, 448.7754, 448.7789, 448.7809, 448.2488,
            448.5208, 448.7786, 448.7773, 448.5164, 448.7787, 448.7806, 448.2479,
            448.2499, 448.7750, 448.7792, 448.4520, 448.7765, 448.7758, 448.7783,
            448.2477, 448.7784, 448.6459, 448.7806, 448.7794, 448.2477, 448.6469,
            448.2477, 448.7759, 448.7784, 448.7790, 448.7781, 448.7761, 448.4857,
            448.7791, 448.6415, 448.7815, 448.7805, 448.5173, 448.7760, 448.7839,
            448.7821, 448.7810, 448.7782, 448.7760, 448.5170, 448.7778, 448.7800,
            448.7781, 448.7805, 448.7808, 448.7762, 448.5215, 448.7784, 448.6507,
            448.7788, 448.7794, 448.7821, 448.5173, 448.7793, 448.7816, 448.7788,
            448.2495, 448.7786, 448.7787, 448.2477, 448.7786, 448.7755, 448.7788,
            448.5294, 448.7798, 448.7817, 448.7800, 448.7783, 448.7776, 448.7780,
            448.7772, 448.7786, 448.2514, 448.2477, 448.2477, 448.7789, 448.7809,
            448.5103, 448.7789, 448.7785, 448.7811, 448.5159, 448.2477, 448.7764,
            448.6489, 448.7798, 448.7791, 448.7769, 448.7797, 448.7820, 448.2477,
            448.2477, 448.7809, 448.7780, 448.7771, 448.7789, 448.7819, 448.7789,
            448.7808, 448.7802, 448.2479, 448.7813, 448.7797, 448.7785, 448.7780,
            448.7789, 448.2478, 448.5173, 448.7766, 448.7798, 448.7818, 448.7758,
            448.7751, 448.7763], device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7820, 448.7801, 448.7811, 448.6518, 448.7774, 448.7760, 448.6258,
        448.7773, 448.2478, 448.7780, 448.5533, 448.7281, 448.7819, 448.7822,
        448.7789, 448.2490, 448.7821, 448.7799, 448.7822, 448.7816, 448.5221,
        448.2477, 448.5162, 448.7750, 448.7790, 448.7794, 448.7801, 448.7788,
        448.2477, 448.7769, 448.7781, 448.7783, 448.5121, 448.7803, 448.7770,
        448.7775, 448.2516, 448.7795, 448.7822, 448.7794, 448.7759, 448.7779,
        448.5157, 448.7819, 448.2481, 448.7774, 448.7791, 448.7819, 448.7769,
        448.2477, 448.7784, 448.7817, 448.7779, 448.7749, 448.7759, 448.2478,
        448.2485, 448.7760, 448.7784, 448.7787, 448.7754, 448.7784, 448.7798,
        448.7784, 448.7789, 448.5149, 448.7821, 448.5167, 448.7814, 448.4761,
        448.7771, 448.2496, 448.7797, 448.2479, 448.7781, 448.7776, 448.7774,
        448.7798, 448.6486, 448.2477, 448.7821, 448.7799, 448.7752, 448.7798,
        448.2477, 448.7792, 448.7783, 448.2478, 448.7760, 448.7787, 448.5165,
        448.2494, 448.7767, 448.7775, 448.7786, 448.7782, 448.7786, 448.2491,
        448.7789, 448.7792, 448.2477, 448.7810, 448.2482, 448.7761, 448.7769,
        448.3840, 448.7762, 448.7809, 448.2477, 448.7771, 448.7786, 448.7787,
        448.2500, 448.7790, 448.7776, 448.7776, 448.7800, 448.7785, 448.2479,
        448.5198, 448.7765, 448.7819, 448.6553, 448.7759, 448.2505, 448.7790,
        448.2479, 448.7760, 448.7760, 448.7806, 448.7810, 448.7787, 448.7773,
        448.7820, 448.7800, 448.7783, 448.7793, 448.2607, 448.2491, 448.7805,
        448.7770, 448.2478, 448.7757, 448.7779, 448.2502, 448.7786, 448.7761,
        448.7805, 448.2480, 448.2477, 448.7763, 448.2479, 448.7788, 448.5134,
        448.7329, 448.7785, 448.7760, 448.3901, 448.7762, 448.7779, 448.7792,
        448.7805, 448.7808, 448.7778, 448.7817, 448.7778, 448.7756, 448.2477,
        448.7784, 448.4117, 448.7805, 448.7792, 448.7820, 448.7775, 448.7789,
        448.2477, 448.7819, 448.7757, 448.7760, 448.7801, 448.2477, 448.7799,
        448.7682, 448.7817, 448.7813, 448.2480, 448.2490, 448.7762, 448.7783,
        448.5132, 448.7817, 448.2477, 448.7775, 448.7775, 448.7790, 448.7753,
        448.2478, 448.7820, 448.7797, 448.2477, 448.2479, 448.7788, 448.7819,
        448.7791, 448.2489, 448.5170, 448.7814, 448.7811, 448.7764, 448.7798,
        448.7818, 448.7757, 448.7766, 448.3839, 448.7772, 448.4690, 448.3829,
        448.7792, 448.2477, 448.2487, 448.7820, 448.2480, 448.7778, 448.7768,
        448.5211, 448.7785, 448.7802, 448.4804, 448.2479, 448.2491, 448.7792,
        448.7757, 448.7808, 448.7817, 448.7784, 448.5173, 448.6491, 448.7792,
        448.7781, 448.7808, 448.7766, 448.7784, 448.7751, 448.7774, 448.7785,
        448.7785, 448.7780, 448.2491, 448.6621, 448.7819, 448.7815, 448.2494,
        448.7796, 448.7763, 448.7820, 448.6489, 448.2477, 448.7799, 448.7786,
        448.2477, 448.7764, 448.7823, 448.7793, 448.2477, 448.7791, 448.2481,
        448.2480, 448.7788, 448.7786, 448.2536, 448.2477, 448.7762, 448.7774,
        448.7808, 448.2480, 448.7820, 448.5170, 448.3834, 448.2487, 448.2479,
        448.2480, 448.7780, 448.7776, 448.7816, 448.7784, 448.2479, 448.7798,
        448.2575, 448.7804, 448.7777, 448.7791, 448.7761, 448.3881, 448.7763,
        448.2569, 448.7802, 448.5177, 448.2610, 448.7807, 448.7811, 448.7782,
        448.7789, 448.2489, 448.2477, 448.2505, 448.7783, 448.5121, 448.7797,
        448.7796, 448.7791, 448.7763, 448.7784, 448.7821, 448.7777, 448.7761,
        448.7819, 448.7753, 448.7773, 448.7773, 448.7793, 448.7767, 448.7820,
        448.5221, 448.2477, 448.2478, 448.7750, 448.5158, 448.7787, 448.7786,
        448.7782, 448.2477, 448.7757, 448.7748, 448.7820, 448.7769, 448.6525,
        448.7663, 448.2481, 448.7774, 448.7786, 448.7782, 448.2482, 448.2492,
        448.7805, 448.7780, 448.7749, 448.7819, 448.7799, 448.7792, 448.7773,
        448.7776, 448.3804, 448.7818, 448.7816, 448.7752, 448.7786, 448.7784,
        448.7759, 448.7783, 448.7803, 448.2477, 448.7789, 448.7789, 448.2480,
        448.2477, 448.7794, 448.7781, 448.7785, 448.2477, 448.5122, 448.5175,
        448.7775, 448.7753, 448.4073, 448.4604, 448.2477, 448.7751, 448.5161,
        448.3965, 448.7786, 448.7787, 448.7783, 448.7795, 448.7784, 448.7816,
        448.7802, 448.2477, 448.7775, 448.7822, 448.7787, 448.2477, 448.2483,
        448.7771, 448.7798, 448.7751, 448.7773, 448.7783, 448.2479, 448.7796,
        448.7762, 448.2478, 448.7794, 448.2477, 448.7794, 448.7752, 448.7786,
        448.7815, 448.7753, 448.5198, 448.7766, 448.7753, 448.2477, 448.7784,
        448.7779, 448.7796, 448.5176, 448.7792, 448.7787, 448.2477, 448.7802,
        448.7751, 448.5157, 448.7769, 448.7769, 448.6487, 448.7761, 448.2477,
        448.7809, 448.7792, 448.7790, 448.7787, 448.7753, 448.7784, 448.7785,
        448.7801, 448.7760, 448.7771, 448.5212, 448.5150, 448.2477, 448.7816,
        448.7795, 448.7822, 448.7822, 448.7774, 448.7763, 448.7788, 448.7751,
        448.2477, 448.7816, 448.7816, 448.2477, 448.2479, 448.7773, 448.7767,
        448.6510, 448.7757, 448.7814, 448.7784, 448.6481, 448.7759, 448.7782,
        448.7781, 448.7769, 448.2477, 448.2500, 448.7801, 448.5156, 448.2481,
        448.7781, 448.2477, 448.5224, 448.7779, 448.7784, 448.2477, 448.7755,
        448.7822, 448.7800, 448.7750, 448.7762, 448.7776, 448.7771, 448.7809,
        448.2478, 448.7781, 448.7809, 448.7752, 448.2477, 448.7750, 448.7775,
        448.2479, 448.5170, 448.7776, 448.2479, 448.2477, 448.7786, 448.7784,
        448.7769, 448.7822, 448.7779, 448.7816, 448.7775, 448.7778, 448.7818,
        448.2491, 448.7780, 448.5373, 448.7779, 448.7110, 448.7767, 448.7803,
        448.7820, 448.7762, 448.7791, 448.7750, 448.7820, 448.2477, 448.7784,
        448.2478, 448.7791, 448.2502, 448.7810, 448.7784, 448.6686, 448.7815,
        448.7757, 448.7816, 448.7809, 448.7805, 448.7814, 448.7770, 448.7823,
        448.2487, 448.7810, 448.7815, 448.7777, 448.7771, 448.7788, 448.7786,
        448.7809, 448.7796, 448.5167, 448.7787, 448.2477, 448.7789, 448.7794,
        448.7790, 448.7786, 448.2480, 448.7749, 448.7785, 448.7819, 448.6199,
        448.7757, 448.7765, 448.2498, 448.2477, 448.2487, 448.2501, 448.7791,
        448.7757, 448.7781, 448.5176, 448.7787, 448.7783, 448.7802, 448.7814,
        448.7756, 448.7786, 448.7789, 448.7747, 448.7762, 448.2477, 448.7758,
        448.7778, 448.7799, 448.2496, 448.2505, 448.7792, 448.7784, 448.7805,
        448.7750, 448.2483, 448.7787, 448.2489, 448.7821, 448.7787, 448.7769,
        448.5324, 448.7764, 448.7814, 448.2481, 448.7817, 448.7803, 448.7773,
        448.2483, 448.7817, 448.5358, 448.7789, 448.7791, 448.7775, 448.7778,
        448.2477, 448.6502, 448.2477, 448.7769, 448.7808, 448.7796, 448.7783,
        448.7803, 448.7758, 448.7762, 448.7789, 448.7781, 448.7762, 448.2489,
        448.7750, 448.2479, 448.2478, 448.5173, 448.7339, 448.7645, 448.7784,
        448.7754, 448.7809, 448.7750, 448.7770, 448.7756, 448.7787, 448.6525,
        448.2477, 448.7789, 448.2494, 448.2477, 448.6462, 448.7764, 448.7764,
        448.2476, 448.2477, 448.7820, 448.7783, 448.7780, 448.7499, 448.7785,
        448.7755, 448.2478, 448.7770, 448.7805, 448.3423, 448.7766, 448.7752,
        448.7772, 448.2477, 448.7805, 448.7816, 448.7818, 448.7755, 448.7816,
        448.7763, 448.7782, 448.7808, 448.7760, 448.7785, 448.7783, 448.7756,
        448.7759, 448.7799, 448.7646, 448.7787, 448.2493, 448.7755, 448.7761,
        448.4943, 448.7821, 448.7811, 448.7748, 448.7820, 448.7777, 448.7755,
        448.7797, 448.7784, 448.7776, 448.7820, 448.7776, 448.7761, 448.2477,
        448.2477, 448.7335, 448.7804, 448.5160, 448.7789, 448.7772, 448.5336,
        448.2477, 448.6359, 448.7796, 448.2480, 448.7812, 448.7798, 448.7806,
        448.7781, 448.7787, 448.7791, 448.7813, 448.7819, 448.7785, 448.7791,
        448.7802, 448.5157, 448.7822, 448.7781, 448.7784, 448.2480, 448.7787,
        448.7780, 448.7821, 448.7776, 448.7767, 448.5167, 448.7825, 448.7791,
        448.7810, 448.2479, 448.7820, 448.2493, 448.7805, 448.7802, 448.7764,
        448.7789, 448.7778, 448.7789, 448.7779, 448.7785, 448.7808, 448.2477,
        448.2487, 448.2515, 448.7791, 448.2667, 448.7805, 448.7751, 448.7778,
        448.7808, 448.7776, 448.7801, 448.7813, 448.7792, 448.7782, 448.2477,
        448.7780, 448.4936, 448.7812, 448.2477, 448.7813, 448.7801, 448.7786,
        448.7787, 448.5179, 448.2477, 448.7762, 448.2482, 448.7791, 448.7790,
        448.7796, 448.7805, 448.7794, 448.7751, 448.7794, 448.7787, 448.7756,
        448.7777, 448.7817, 448.7779, 448.7783, 448.7790, 448.7791, 448.7771,
        448.7789, 448.7789, 448.7816, 448.2477, 448.2478, 448.7795, 448.7798,
        448.7794, 448.7783, 448.7783, 448.7762, 448.7791, 448.7758, 448.7785,
        448.7816, 448.6441, 448.7775, 448.7784, 448.7778, 448.2491, 448.7822,
        448.2480, 448.7804, 448.3804, 448.7797, 448.2477, 448.2480, 448.7763,
        448.7814, 448.7773, 448.7785, 448.7754, 448.7789, 448.7809, 448.2488,
        448.5208, 448.7786, 448.7773, 448.5164, 448.7787, 448.7806, 448.2479,
        448.2499, 448.7750, 448.7792, 448.4520, 448.7765, 448.7758, 448.7783,
        448.2477, 448.7784, 448.6459, 448.7806, 448.7794, 448.2477, 448.6469,
        448.2477, 448.7759, 448.7784, 448.7790, 448.7781, 448.7761, 448.4857,
        448.7791, 448.6415, 448.7815, 448.7805, 448.5173, 448.7760, 448.7839,
        448.7821, 448.7810, 448.7782, 448.7760, 448.5170, 448.7778, 448.7800,
        448.7781, 448.7805, 448.7808, 448.7762, 448.5215, 448.7784, 448.6507,
        448.7788, 448.7794, 448.7821, 448.5173, 448.7793, 448.7816, 448.7788,
        448.2495, 448.7786, 448.7787, 448.2477, 448.7786, 448.7755, 448.7788,
        448.5294, 448.7798, 448.7817, 448.7800, 448.7783, 448.7776, 448.7780,
        448.7772, 448.7786, 448.2514, 448.2477, 448.2477, 448.7789, 448.7809,
        448.5103, 448.7789, 448.7785, 448.7811, 448.5159, 448.2477, 448.7764,
        448.6489, 448.7798, 448.7791, 448.7769, 448.7797, 448.7820, 448.2477,
        448.2477, 448.7809, 448.7780, 448.7771, 448.7789, 448.7819, 448.7789,
        448.7808, 448.7802, 448.2479, 448.7813, 448.7797, 448.7785, 448.7780,
        448.7789, 448.2478, 448.5173, 448.7766, 448.7798, 448.7818, 448.7758,
        448.7751, 448.7763], device='cuda:0', grad_fn=<ViewBackward0>)
tensor([409.6598], device='cuda:0') test
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.1954],
             [112.1940],
             [112.1949],
             [112.1949]],

            [[112.0622],
             [112.1956],
             [112.0657],
             [112.0657]],

            [[112.1955],
             [112.1943],
             [112.1954],
             [112.1942]],

            ...,

            [[112.1954],
             [112.1954],
             [112.1950],
             [112.1950]],

            [[112.1938],
             [112.1940],
             [112.1942],
             [112.1942]],

            [[112.1943],
             [112.1942],
             [112.1944],
             [112.1938]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.7792, 448.3892, 448.7794,  ..., 448.7809, 448.7762, 448.7766],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.7792, 448.3892, 448.7794,  ..., 448.7809, 448.7762, 448.7766],
       device='cuda:0', grad_fn=<ViewBackward0>)
hello BatchedTensor(lvl=1, bdim=0, value=
    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            ...,
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], device='cuda:0')
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([[[112.2044],
             [112.2055],
             [112.2054],
             [112.2039]],

            [[112.0505],
             [112.2056],
             [112.0506],
             [112.2056]],

            [[112.0489],
             [112.0489],
             [112.0490],
             [112.0490]],

            ...,

            [[112.2042],
             [112.2036],
             [112.2040],
             [112.2037]],

            [[112.0496],
             [112.0496],
             [112.2059],
             [112.2059]],

            [[112.2055],
             [112.2045],
             [112.2055],
             [112.2048]]], device='cuda:0', grad_fn=<AddBackward0>)
) BatchedTensor(lvl=1, bdim=0, value=
    tensor([448.8193, 448.5123, 448.1957,  ..., 448.8155, 448.5110, 448.8203],
           device='cuda:0', grad_fn=<ViewBackward0>)
)
tensor([448.8193, 448.5123, 448.1957,  ..., 448.8155, 448.5110, 448.8203],
       device='cuda:0', grad_fn=<ViewBackward0>)
